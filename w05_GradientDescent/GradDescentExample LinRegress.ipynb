{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was written to demonstrate Gradient Descent. It is not the most efficient way of doing things and in practice, make sure to use the built in methods to do it\n",
    "\n",
    "Hopefully this will demonstrate things what is actually going on in .fit() and how it figures out the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for our old friend Linear Regression but others could be written similarly. As much as possible I am avoiding loops unless I think it will better demonstrate what's going on.\n",
    "\n",
    "Firstly we need a function that calculates the error. I am using MSE\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{1}{2m}\\sum (\\widehat{y_i} - y_i)^2\n",
    "\\end{equation}\n",
    "\n",
    "where $\\widehat{y_i} = w_0+w_1x_1+w_2x_2+....$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(X,y,w):\n",
    "    div = 2*len(y)\n",
    "    return ((np.dot(X,w) - y)**2).sum()/div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the best way of doing things, but let's make a function for calculating the change for one particular $w_c$\n",
    "\n",
    "c is the column number we're checking, the gradient for one particular one is\n",
    "\\begin{equation}\n",
    "\\frac{\\partial L}{\\partial w_c} = \\frac{1}{m}\\sum (\\widehat{y_i}-y_i)*x_c\n",
    "\\end{equation}\n",
    "\n",
    "which you should see reflected below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(X,y,w,c):\n",
    "    div = len(y)\n",
    "    return (X[:, c]*(np.dot(X,w) - y)).sum()/div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's me writing a loop (usually you don't do this, it increases the computational time and when doing this training - every optimisation counts, but I think it will demonstrate things better)\n",
    "\n",
    "full grad loops over all the weights, finds out the change for each individual w and puts it into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loopfullgrad(X,y,w):\n",
    "    allgrad = np.array([])\n",
    "    for i in range(len(w)):\n",
    "        allgrad = np.append(allgrad, grad(X,y,w,i))\n",
    "    return allgrad   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's a better one that doesn't use a loop so faster\n",
    "def fullgrad(X,y,w):\n",
    "    div = len(y)\n",
    "    prediction = np.dot(X,w)\n",
    "    allgrad = X.T.dot((prediction - y))/div\n",
    "    return allgrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for performing one step of gradient descent is done. Now let's set up the thing we want to find the best weights for.\n",
    "\n",
    "Like sklearn, this requires each row in X correspond to one from the sample. If we want an intercept ($w_0$), we need to add that in with feature 0 being all 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2],[1,5],[1,8],[1,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2],\n",
       "       [ 1,  5],\n",
       "       [ 1,  8],\n",
       "       [ 1, 12]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y is a 1-d as normal y[0] is the true value for X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([4,11,19,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 11, 19, 25])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to now pick initial weights to start with, there are two weights required\n",
    "\n",
    "I've just picked 20 and 50. You could set this with random numbers or maybe try 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([20, 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How bad is the current model of \n",
    "\\begin{equation}\n",
    "\\hat{y} = 20 + 50x\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74420.375"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(X,y,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the gradient now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 342.75, 2968.75])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onestep = loopfullgrad(X,y,w)\n",
    "onestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 342.75, 2968.75])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onestep = fullgrad(X,y,w)\n",
    "onestep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that\n",
    "\\begin{equation}\n",
    "\\nabla L = (342.75, 2968.75)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now update the weights using the learning rate of $\\alpha=1$\n",
    "\n",
    "\\begin{equation}\n",
    "\\textbf{w}^1 = \\textbf{w}^0 - \\alpha*\\nabla L\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -322.75, -2918.75])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newweight = w - alpha*onestep\n",
    "newweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259169836.8671875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(X,y,newweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that was a terrible attempt! Our $\\alpha$ is far too big. Let's try 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.5725, 20.3125])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_1 = w - alpha*onestep\n",
    "weight_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11913.470811718747"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(X,y,weight_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An improvement! \n",
    "\n",
    "Let's do another step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.18318125,  8.4462    ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_2 = weight_1 - alpha*fullgrad(X,y,weight_1)\n",
    "weight_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1923.257547730489"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(X,y,weight_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no way of avoiding loops now, so let's do 50 steps and see where we are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [14.60873094  3.70446177] , error: 326.492271589584\n",
      "Weights: [14.36009246  1.81097883] , error: 71.20501095436816\n",
      "Weights: [14.24175046  1.05616763] , error: 30.31903149997327\n",
      "Weights: [14.17554164  0.75657015] , error: 23.699990551816963\n",
      "Weights: [14.13021774  0.63895328] , error: 22.55802661361252\n",
      "Weights: [14.09328622  0.59408376] , error: 22.291816152387437\n",
      "Weights: [14.0597527   0.57829231] , error: 22.165953739761235\n",
      "Weights: [14.02762044  0.57412081] , error: 22.06290192165977\n",
      "Weights: [13.99609108  0.57458985] , error: 21.963873618182713\n",
      "Weights: [13.96484536  0.57690922] , error: 21.865864474689154\n",
      "Weights: [13.93375553  0.57996344] , error: 21.76839260866761\n",
      "Weights: [13.90277045  0.5833066 ] , error: 21.671379297957742\n",
      "Weights: [13.87186955  0.58676044] , error: 21.574810263022624\n",
      "Weights: [13.84104452  0.59025368] , error: 21.478681531562327\n",
      "Weights: [13.81029195  0.59375787] , error: 21.382990786324065\n",
      "Weights: [13.77961038  0.59726163] , error: 21.28773598223626\n",
      "Weights: [13.74899911  0.60076041] , error: 21.192915125357914\n",
      "Weights: [13.71845779  0.60425243] , error: 21.09852623751458\n",
      "Weights: [13.68798618  0.60773696] , error: 21.004567350611765\n",
      "Weights: [13.65758407  0.61121375] , error: 20.91103650569156\n",
      "Weights: [13.6272513   0.61468268] , error: 20.81793175274763\n",
      "Weights: [13.59698771  0.61814373] , error: 20.72525115066152\n",
      "Weights: [13.56679313  0.6215969 ] , error: 20.632992767158505\n",
      "Weights: [13.53666741  0.6250422 ] , error: 20.54115467876666\n",
      "Weights: [13.50661038  0.62847965] , error: 20.449734970776753\n",
      "Weights: [13.4766219   0.63190926] , error: 20.358731737202227\n",
      "Weights: [13.44670181  0.63533104] , error: 20.268143080739513\n",
      "Weights: [13.41684995  0.63874503] , error: 20.17796711272844\n",
      "Weights: [13.38706616  0.64215123] , error: 20.088201953112897\n",
      "Weights: [13.35735029  0.64554966] , error: 19.998845730401598\n",
      "Weights: [13.32770218  0.64894034] , error: 19.909896581629088\n",
      "Weights: [13.29812169  0.65232329] , error: 19.8213526523169\n",
      "Weights: [13.26860865  0.65569853] , error: 19.733212096434865\n",
      "Weights: [13.23916291  0.65906607] , error: 19.645473076362663\n",
      "Weights: [13.20978432  0.66242593] , error: 19.55813376285149\n",
      "Weights: [13.18047273  0.66577812] , error: 19.471192334985915\n",
      "Weights: [13.15122798  0.66912268] , error: 19.384646980145945\n",
      "Weights: [13.12204992  0.6724596 ] , error: 19.298495893969186\n",
      "Weights: [13.0929384   0.67578892] , error: 19.212737280313284\n",
      "Weights: [13.06389326  0.67911064] , error: 19.127369351218416\n",
      "Weights: [13.03491436  0.68242479] , error: 19.042390326870056\n",
      "Weights: [13.00600154  0.68573138] , error: 18.95779843556187\n",
      "Weights: [12.97715466  0.68903043] , error: 18.87359191365873\n",
      "Weights: [12.94837356  0.69232196] , error: 18.789769005560025\n",
      "Weights: [12.91965809  0.69560598] , error: 18.70632796366296\n",
      "Weights: [12.89100811  0.69888252] , error: 18.62326704832621\n",
      "Weights: [12.86242345  0.70215158] , error: 18.540584527833598\n",
      "Weights: [12.83390399  0.70541319] , error: 18.45827867835801\n",
      "Weights: [12.80544956  0.70866735] , error: 18.37634778392544\n",
      "Weights: [12.77706002  0.7119141 ] , error: 18.294790136379255\n"
     ]
    }
   ],
   "source": [
    "weights = weight_2\n",
    "for i in range(50):\n",
    "    weights = weights - alpha*fullgrad(X,y,weights)\n",
    "    print(\"Weights:\", weights, \", error:\", error(X,y,weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "still getting smaller, let's do some more but I'm going to break if the error flattens or increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [12.74873521  0.71515345] , error: 18.213604035344517\n",
      "Weights: [12.72047501  0.7183854 ] , error: 18.1327877881926\n",
      "Weights: [12.69227924  0.72160999] , error: 18.05233971000584\n",
      "Weights: [12.66414777  0.72482722] , error: 17.97225812354245\n",
      "Weights: [12.63608046  0.72803712] , error: 17.892541359201534\n",
      "Weights: [12.60807715  0.73123969] , error: 17.813187754988295\n",
      "Weights: [12.5801377   0.73443497] , error: 17.734195656479347\n",
      "Weights: [12.55226196  0.73762295] , error: 17.655563416788258\n",
      "Weights: [12.52444979  0.74080367] , error: 17.577289396531192\n",
      "Weights: [12.49670105  0.74397714] , error: 17.49937196379277\n",
      "Weights: [12.46901558  0.74714336] , error: 17.42180949409197\n",
      "Weights: [12.44139325  0.75030237] , error: 17.344600370348356\n",
      "Weights: [12.4138339   0.75345417] , error: 17.267742982848272\n",
      "Weights: [12.38633741  0.75659879] , error: 17.191235729211346\n",
      "Weights: [12.35890362  0.75973623] , error: 17.115077014357038\n",
      "Weights: [12.33153238  0.76286652] , error: 17.03926525047143\n",
      "Weights: [12.30422357  0.76598967] , error: 16.963798856974087\n",
      "Weights: [12.27697703  0.7691057 ] , error: 16.88867626048512\n",
      "Weights: [12.24979263  0.77221462] , error: 16.81389589479235\n",
      "Weights: [12.22267021  0.77531646] , error: 16.739456200818726\n",
      "Weights: [12.19560965  0.77841122] , error: 16.66535562658974\n",
      "Weights: [12.1686108   0.78149892] , error: 16.59159262720113\n",
      "Weights: [12.14167351  0.78457958] , error: 16.51816566478663\n",
      "Weights: [12.11479765  0.78765322] , error: 16.445073208485933\n",
      "Weights: [12.08798309  0.79071984] , error: 16.37231373441277\n",
      "Weights: [12.06122967  0.79377948] , error: 16.29988572562312\n",
      "Weights: [12.03453725  0.79683213] , error: 16.227787672083622\n",
      "Weights: [12.00790571  0.79987783] , error: 16.156018070640044\n",
      "Weights: [11.9813349   0.80291658] , error: 16.084575424985985\n",
      "Weights: [11.95482468  0.8059484 ] , error: 16.013458245631664\n",
      "Weights: [11.92837492  0.80897331] , error: 15.942665049872843\n",
      "Weights: [11.90198547  0.81199132] , error: 15.872194361759973\n",
      "Weights: [11.8756562   0.81500244] , error: 15.802044712067357\n",
      "Weights: [11.84938698  0.8180067 ] , error: 15.732214638262562\n",
      "Weights: [11.82317765  0.82100411] , error: 15.662702684475905\n",
      "Weights: [11.7970281   0.82399468] , error: 15.593507401470108\n",
      "Weights: [11.77093818  0.82697844] , error: 15.524627346610089\n",
      "Weights: [11.74490775  0.82995539] , error: 15.45606108383287\n",
      "Weights: [11.71893669  0.83292555] , error: 15.387807183617651\n",
      "Weights: [11.69302485  0.83588893] , error: 15.319864222956003\n",
      "Weights: [11.66717209  0.83884556] , error: 15.252230785322189\n",
      "Weights: [11.6413783   0.84179545] , error: 15.184905460643645\n",
      "Weights: [11.61564332  0.84473861] , error: 15.11788684527158\n",
      "Weights: [11.58996703  0.84767506] , error: 15.051173541951703\n",
      "Weights: [11.5643493   0.85060481] , error: 14.9847641597951\n",
      "Weights: [11.53878998  0.85352788] , error: 14.918657314249227\n",
      "Weights: [11.51328895  0.85644429] , error: 14.852851627069057\n",
      "Weights: [11.48784607  0.85935404] , error: 14.787345726288342\n",
      "Weights: [11.46246121  0.86225716] , error: 14.722138246190994\n",
      "Weights: [11.43713424  0.86515366] , error: 14.657227827282634\n"
     ]
    }
   ],
   "source": [
    "currenterror = error(X,y,weights)\n",
    "for i in range(50):\n",
    "    weights = weights - alpha*fullgrad(X,y,weights)\n",
    "    newerror = error(X,y,weights)\n",
    "    print(\"Weights:\", weights, \", error:\", newerror)\n",
    "    if newerror >= currenterror:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [11.41186502  0.86804356] , error: 14.592613116262225\n",
      "Weights: [11.38665343  0.87092686] , error: 14.528292765993875\n",
      "Weights: [11.36149933  0.87380359] , error: 14.464265435478765\n",
      "Weights: [11.3364026   0.87667376] , error: 14.400529789827129\n",
      "Weights: [11.31136309  0.87953738] , error: 14.337084500230496\n",
      "Weights: [11.28638069  0.88239447] , error: 14.273928243933957\n",
      "Weights: [11.26145526  0.88524505] , error: 14.21105970420857\n",
      "Weights: [11.23658666  0.88808913] , error: 14.148477570323932\n",
      "Weights: [11.21177478  0.89092672] , error: 14.086180537520852\n",
      "Weights: [11.18701948  0.89375784] , error: 14.024167306984111\n",
      "Weights: [11.16232063  0.89658251] , error: 13.962436585815455\n",
      "Weights: [11.1376781   0.89940073] , error: 13.900987087006559\n",
      "Weights: [11.11309177  0.90221252] , error: 13.839817529412253\n",
      "Weights: [11.08856151  0.90501791] , error: 13.778926637723778\n",
      "Weights: [11.06408719  0.9078169 ] , error: 13.718313142442222\n",
      "Weights: [11.03966867  0.9106095 ] , error: 13.657975779852043\n",
      "Weights: [11.01530585  0.91339574] , error: 13.597913291994708\n",
      "Weights: [10.99099858  0.91617562] , error: 13.53812442664248\n",
      "Weights: [10.96674674  0.91894916] , error: 13.478607937272319\n",
      "Weights: [10.9425502   0.92171638] , error: 13.419362583039879\n",
      "Weights: [10.91840884  0.92447729] , error: 13.360387128753636\n",
      "Weights: [10.89432254  0.9272319 ] , error: 13.301680344849151\n",
      "Weights: [10.87029116  0.92998023] , error: 13.243241007363425\n",
      "Weights: [10.84631458  0.93272229] , error: 13.185067897909375\n",
      "Weights: [10.82239268  0.9354581 ] , error: 13.127159803650441\n",
      "Weights: [10.79852533  0.93818767] , error: 13.069515517275313\n",
      "Weights: [10.77471241  0.94091102] , error: 13.01213383697272\n",
      "Weights: [10.7509538   0.94362815] , error: 12.955013566406425\n",
      "Weights: [10.72724936  0.94633909] , error: 12.898153514690241\n",
      "Weights: [10.70359897  0.94904385] , error: 12.841552496363224\n",
      "Weights: [10.68000253  0.95174244] , error: 12.785209331364943\n",
      "Weights: [10.65645989  0.95443487] , error: 12.7291228450109\n",
      "Weights: [10.63297093  0.95712117] , error: 12.673291867968025\n",
      "Weights: [10.60953554  0.95980134] , error: 12.617715236230282\n",
      "Weights: [10.5861536  0.9624754] , error: 12.56239179109443\n",
      "Weights: [10.56282497  0.96514336] , error: 12.50732037913585\n",
      "Weights: [10.53954955  0.96780523] , error: 12.452499852184493\n",
      "Weights: [10.5163272   0.97046104] , error: 12.397929067300963\n",
      "Weights: [10.49315781  0.97311079] , error: 12.343606886752655\n",
      "Weights: [10.47004125  0.97575449] , error: 12.289532177990061\n",
      "Weights: [10.44697741  0.97839217] , error: 12.235703813623159\n",
      "Weights: [10.42396616  0.98102383] , error: 12.182120671397897\n",
      "Weights: [10.40100739  0.9836495 ] , error: 12.128781634172773\n",
      "Weights: [10.37810098  0.98626917] , error: 12.07568558989561\n",
      "Weights: [10.3552468   0.98888287] , error: 12.022831431580297\n",
      "Weights: [10.33244474  0.99149061] , error: 11.970218057283752\n",
      "Weights: [10.30969467  0.9940924 ] , error: 11.917844370082953\n",
      "Weights: [10.28699649  0.99668826] , error: 11.865709278052035\n",
      "Weights: [10.26435007  0.9992782 ] , error: 11.813811694239543\n",
      "Weights: [10.24175529  1.00186224] , error: 11.762150536645802\n",
      "Weights: [10.21921203  1.00444038] , error: 11.71072472820028\n",
      "Weights: [10.19672019  1.00701264] , error: 11.659533196739215\n",
      "Weights: [10.17427963  1.00957904] , error: 11.60857487498322\n",
      "Weights: [10.15189025  1.01213958] , error: 11.557848700515036\n",
      "Weights: [10.12955193  1.01469429] , error: 11.507353615757387\n",
      "Weights: [10.10726454  1.01724317] , error: 11.457088567950912\n",
      "Weights: [10.08502798  1.01978623] , error: 11.40705250913226\n",
      "Weights: [10.06284213  1.0223235 ] , error: 11.357244396112199\n",
      "Weights: [10.04070688  1.02485498] , error: 11.307663190453878\n",
      "Weights: [10.0186221   1.02738069] , error: 11.258307858451191\n",
      "Weights: [9.99658768 1.02990064] , error: 11.20917737110721\n",
      "Weights: [9.97460351 1.03241484] , error: 11.160270704112733\n",
      "Weights: [9.95266947 1.03492331] , error: 11.111586837824937\n",
      "Weights: [9.93078545 1.03742606] , error: 11.063124757246111\n",
      "Weights: [9.90895134 1.0399231 ] , error: 11.014883452002513\n",
      "Weights: [9.88716702 1.04241445] , error: 10.966861916323271\n",
      "Weights: [9.86543237 1.04490011] , error: 10.91905914901944\n",
      "Weights: [9.84374729 1.04738011] , error: 10.871474153463128\n",
      "Weights: [9.82211166 1.04985445] , error: 10.82410593756671\n",
      "Weights: [9.80052537 1.05232315] , error: 10.776953513762132\n",
      "Weights: [9.7789883  1.05478622] , error: 10.730015898980358\n",
      "Weights: [9.75750035 1.05724368] , error: 10.68329211463083\n",
      "Weights: [9.7360614  1.05969552] , error: 10.636781186581103\n",
      "Weights: [9.71467133 1.06214178] , error: 10.59048214513651\n",
      "Weights: [9.69333005 1.06458246] , error: 10.544394025019958\n",
      "Weights: [9.67203743 1.06701757] , error: 10.4985158653518\n",
      "Weights: [9.65079337 1.06944713] , error: 10.4528467096298\n",
      "Weights: [9.62959776 1.07187115] , error: 10.407385605709202\n",
      "Weights: [9.60845048 1.07428965] , error: 10.362131605782842\n",
      "Weights: [9.58735142 1.07670262] , error: 10.317083766361458\n",
      "Weights: [9.56630048 1.0791101 ] , error: 10.272241148253944\n",
      "Weights: [9.54529754 1.08151208] , error: 10.227602816547806\n",
      "Weights: [9.5243425  1.08390859] , error: 10.183167840589674\n",
      "Weights: [9.50343525 1.08629963] , error: 10.13893529396589\n",
      "Weights: [9.48257567 1.08868522] , error: 10.094904254483197\n",
      "Weights: [9.46176366 1.09106537] , error: 10.051073804149496\n",
      "Weights: [9.44099911 1.09344009] , error: 10.00744302915474\n",
      "Weights: [9.42028191 1.0958094 ] , error: 9.964011019851846\n",
      "Weights: [9.39961196 1.0981733 ] , error: 9.920776870737757\n",
      "Weights: [9.37898914 1.10053181] , error: 9.877739680434551\n",
      "Weights: [9.35841336 1.10288495] , error: 9.83489855167064\n",
      "Weights: [9.33788449 1.10523271] , error: 9.7922525912621\n",
      "Weights: [9.31740243 1.10757513] , error: 9.749800910093999\n",
      "Weights: [9.29696709 1.1099122 ] , error: 9.707542623101894\n",
      "Weights: [9.27657834 1.11224394] , error: 9.665476849253368\n",
      "Weights: [9.2562361  1.11457037] , error: 9.623602711529657\n",
      "Weights: [9.23594023 1.11689149] , error: 9.58191933690738\n",
      "Weights: [9.21569066 1.11920732] , error: 9.540425856340317\n",
      "Weights: [9.19548726 1.12151786] , error: 9.49912140474131\n",
      "Weights: [9.17532993 1.12382314] , error: 9.458005120964218\n",
      "Weights: [9.15521857 1.12612316] , error: 9.417076147785956\n",
      "Weights: [9.13515307 1.12841793] , error: 9.376333631888642\n",
      "Weights: [9.11513333 1.13070748] , error: 9.335776723841784\n",
      "Weights: [9.09515924 1.1329918 ] , error: 9.295404578084584\n",
      "Weights: [9.0752307  1.13527091] , error: 9.255216352908324\n",
      "Weights: [9.05534761 1.13754482] , error: 9.215211210438774\n",
      "Weights: [9.03550986 1.13981355] , error: 9.175388316618756\n",
      "Weights: [9.01571734 1.14207711] , error: 9.135746841190759\n",
      "Weights: [8.99596996 1.1443355 ] , error: 9.096285957679617\n",
      "Weights: [8.97626762 1.14658874] , error: 9.057004843375266\n",
      "Weights: [8.9566102  1.14883685] , error: 9.017902679315624\n",
      "Weights: [8.93699761 1.15107983] , error: 8.978978650269475\n",
      "Weights: [8.91742975 1.15331769] , error: 8.940231944719516\n",
      "Weights: [8.89790651 1.15555045] , error: 8.901661754845406\n",
      "Weights: [8.87842779 1.15777812] , error: 8.863267276506942\n",
      "Weights: [8.85899348 1.16000071] , error: 8.82504770922728\n",
      "Weights: [8.8396035  1.16221823] , error: 8.787002256176256\n",
      "Weights: [8.82025774 1.16443069] , error: 8.749130124153771\n",
      "Weights: [8.80095609 1.16663811] , error: 8.71143052357324\n",
      "Weights: [8.78169845 1.16884049] , error: 8.673902668445173\n",
      "Weights: [8.76248474 1.17103786] , error: 8.636545776360725\n",
      "Weights: [8.74331483 1.17323021] , error: 8.59935906847543\n",
      "Weights: [8.72418865 1.17541756] , error: 8.562341769492955\n",
      "Weights: [8.70510607 1.17759992] , error: 8.525493107648922\n",
      "Weights: [8.68606702 1.17977731] , error: 8.488812314694831\n",
      "Weights: [8.66707138 1.18194973] , error: 8.45229862588204\n",
      "Weights: [8.64811906 1.1841172 ] , error: 8.415951279945816\n",
      "Weights: [8.62920996 1.18627972] , error: 8.37976951908946\n",
      "Weights: [8.61034398 1.18843731] , error: 8.343752588968528\n",
      "Weights: [8.59152102 1.19058999] , error: 8.307899738675086\n",
      "Weights: [8.57274099 1.19273775] , error: 8.27221022072205\n",
      "Weights: [8.55400378 1.19488062] , error: 8.236683291027632\n",
      "Weights: [8.5353093 1.1970186] , error: 8.20131820889978\n",
      "Weights: [8.51665745 1.1991517 ] , error: 8.166114237020784\n",
      "Weights: [8.49804814 1.20127994] , error: 8.131070641431863\n",
      "Weights: [8.47948126 1.20340333] , error: 8.09618669151789\n",
      "Weights: [8.46095672 1.20552187] , error: 8.061461659992151\n",
      "Weights: [8.44247443 1.20763558] , error: 8.026894822881184\n",
      "Weights: [8.42403428 1.20974448] , error: 7.992485459509675\n",
      "Weights: [8.40563619 1.21184856] , error: 7.958232852485441\n",
      "Weights: [8.38728005 1.21394785] , error: 7.924136287684486\n",
      "Weights: [8.36896577 1.21604234] , error: 7.890195054236082\n",
      "Weights: [8.35069325 1.21813207] , error: 7.856408444507968\n",
      "Weights: [8.3324624  1.22021702] , error: 7.822775754091614\n",
      "Weights: [8.31427313 1.22229722] , error: 7.789296281787484\n",
      "Weights: [8.29612534 1.22437268] , error: 7.755969329590473\n",
      "Weights: [8.27801893 1.22644341] , error: 7.7227942026753125\n",
      "Weights: [8.25995381 1.22850941] , error: 7.689770209382123\n",
      "Weights: [8.24192988 1.2305707 ] , error: 7.6568966612019445\n",
      "Weights: [8.22394706 1.23262729] , error: 7.624172872762426\n",
      "Weights: [8.20600525 1.2346792 ] , error: 7.591598161813524\n",
      "Weights: [8.18810435 1.23672642] , error: 7.5591718492132545\n",
      "Weights: [8.17024428 1.23876897] , error: 7.52689325891357\n",
      "Weights: [8.15242493 1.24080687] , error: 7.494761717946245\n",
      "Weights: [8.13464621 1.24284012] , error: 7.4627765564088495\n",
      "Weights: [8.11690804 1.24486873] , error: 7.430937107450775\n",
      "Weights: [8.09921032 1.24689271] , error: 7.399242707259348\n",
      "Weights: [8.08155296 1.24891208] , error: 7.367692695045973\n",
      "Weights: [8.06393587 1.25092685] , error: 7.336286413032355\n",
      "Weights: [8.04635895 1.25293702] , error: 7.305023206436817\n",
      "Weights: [8.02882211 1.25494261] , error: 7.273902423460608\n",
      "Weights: [8.01132526 1.25694362] , error: 7.242923415274332\n",
      "Weights: [7.99386831 1.25894007] , error: 7.2120855360044285\n",
      "Weights: [7.97645118 1.26093197] , error: 7.1813881427196895\n",
      "Weights: [7.95907376 1.26291932] , error: 7.150830595417866\n",
      "Weights: [7.94173597 1.26490215] , error: 7.120412257012332\n",
      "Weights: [7.92443771 1.26688045] , error: 7.090132493318784\n",
      "Weights: [7.9071789  1.26885424] , error: 7.0599906730420265\n",
      "Weights: [7.88995945 1.27082353] , error: 7.029986167762812\n",
      "Weights: [7.87277927 1.27278832] , error: 7.000118351924743\n",
      "Weights: [7.85563827 1.27474864] , error: 6.970386602821229\n",
      "Weights: [7.83853635 1.27670449] , error: 6.940790300582494\n",
      "Weights: [7.82147343 1.27865588] , error: 6.91132882816266\n",
      "Weights: [7.80444943 1.28060281] , error: 6.882001571326887\n",
      "Weights: [7.78746424 1.28254531] , error: 6.852807918638554\n",
      "Weights: [7.77051779 1.28448338] , error: 6.823747261446525\n",
      "Weights: [7.75360999 1.28641703] , error: 6.794818993872457\n",
      "Weights: [7.73674074 1.28834626] , error: 6.766022512798159\n",
      "Weights: [7.71990996 1.2902711 ] , error: 6.737357217853022\n",
      "Weights: [7.70311756 1.29219155] , error: 6.708822511401511\n",
      "Weights: [7.68636345 1.29410762] , error: 6.6804177985306925\n",
      "Weights: [7.66964755 1.29601932] , error: 6.652142487037841\n",
      "Weights: [7.65296978 1.29792666] , error: 6.623995987418079\n",
      "Weights: [7.63633003 1.29982966] , error: 6.595977712852107\n",
      "Weights: [7.61972823 1.30172831] , error: 6.568087079193941\n",
      "Weights: [7.60316428 1.30362263] , error: 6.540323504958777\n",
      "Weights: [7.58663811 1.30551263] , error: 6.512686411310813\n",
      "Weights: [7.57014963 1.30739833] , error: 6.485175222051222\n",
      "Weights: [7.55369874 1.30927972] , error: 6.4577893636061265\n",
      "Weights: [7.53728538 1.31115682] , error: 6.430528265014641\n",
      "Weights: [7.52090944 1.31302964] , error: 6.403391357916963\n",
      "Weights: [7.50457084 1.31489819] , error: 6.376378076542524\n",
      "Weights: [7.48826951 1.31676248] , error: 6.349487857698203\n",
      "Weights: [7.47200534 1.31862252] , error: 6.3227201407565765\n",
      "Weights: [7.45577827 1.32047832] , error: 6.2960743676442394\n",
      "Weights: [7.4395882  1.32232988] , error: 6.269549982830149\n",
      "Weights: [7.42343505 1.32417722] , error: 6.243146433314069\n",
      "Weights: [7.40731874 1.32602035] , error: 6.216863168615023\n",
      "Weights: [7.39123918 1.32785928] , error: 6.1906996407598145\n",
      "Weights: [7.37519628 1.32969401] , error: 6.16465530427163\n",
      "Weights: [7.35918998 1.33152456] , error: 6.138729616158632\n",
      "Weights: [7.34322017 1.33335094] , error: 6.112922035902656\n",
      "Weights: [7.32728678 1.33517314] , error: 6.087232025447933\n",
      "Weights: [7.31138972 1.3369912 ] , error: 6.061659049189893\n",
      "Weights: [7.29552892 1.33880511] , error: 6.0362025739639735\n",
      "Weights: [7.27970429 1.34061488] , error: 6.0108620690345065\n",
      "Weights: [7.26391574 1.34242052] , error: 5.985637006083667\n",
      "Weights: [7.2481632  1.34422205] , error: 5.960526859200449\n",
      "Weights: [7.23244658 1.34601947] , error: 5.935531104869708\n",
      "Weights: [7.2167658  1.34781279] , error: 5.910649221961231\n",
      "Weights: [7.20112077 1.34960202] , error: 5.885880691718886\n",
      "Weights: [7.18551143 1.35138717] , error: 5.86122499774981\n",
      "Weights: [7.16993768 1.35316825] , error: 5.836681626013626\n",
      "Weights: [7.15439945 1.35494527] , error: 5.81225006481173\n",
      "Weights: [7.13889665 1.35671823] , error: 5.787929804776643\n",
      "Weights: [7.1234292  1.35848716] , error: 5.763720338861366\n",
      "Weights: [7.10799703 1.36025205] , error: 5.739621162328825\n",
      "Weights: [7.09260004 1.36201291] , error: 5.715631772741329\n",
      "Weights: [7.07723817 1.36376976] , error: 5.691751669950125\n",
      "Weights: [7.06191133 1.3655226 ] , error: 5.667980356084933\n",
      "Weights: [7.04661944 1.36727144] , error: 5.64431733554361\n",
      "Weights: [7.03136242 1.3690163 ] , error: 5.620762114981776\n",
      "Weights: [7.0161402  1.37075718] , error: 5.59731420330255\n",
      "Weights: [7.00095269 1.37249409] , error: 5.573973111646304\n",
      "Weights: [6.98579981 1.37422703] , error: 5.5507383533804795\n",
      "Weights: [6.97068149 1.37595603] , error: 5.527609444089436\n",
      "Weights: [6.95559764 1.37768108] , error: 5.504585901564347\n",
      "Weights: [6.94054819 1.3794022 ] , error: 5.481667245793151\n",
      "Weights: [6.92553306 1.38111939] , error: 5.458852998950555\n",
      "Weights: [6.91055217 1.38283267] , error: 5.4361426853880435\n",
      "Weights: [6.89560544 1.38454204] , error: 5.413535831623994\n",
      "Weights: [6.8806928  1.38624751] , error: 5.3910319663337845\n",
      "Weights: [6.86581417 1.3879491 ] , error: 5.368630620339982\n",
      "Weights: [6.85096946 1.3896468 ] , error: 5.346331326602543\n",
      "Weights: [6.83615861 1.39134063] , error: 5.324133620209093\n",
      "Weights: [6.82138153 1.3930306 ] , error: 5.302037038365221\n",
      "Weights: [6.80663815 1.39471672] , error: 5.280041120384834\n",
      "Weights: [6.79192839 1.39639899] , error: 5.258145407680569\n",
      "Weights: [6.77725217 1.39807742] , error: 5.2363494437542\n",
      "Weights: [6.76260942 1.39975203] , error: 5.214652774187153\n",
      "Weights: [6.74800007 1.40142282] , error: 5.193054946631006\n",
      "Weights: [6.73342403 1.40308979] , error: 5.171555510798068\n",
      "Weights: [6.71888123 1.40475297] , error: 5.150154018452011\n",
      "Weights: [6.70437159 1.40641235] , error: 5.128850023398484\n",
      "Weights: [6.68989504 1.40806795] , error: 5.107643081475843\n",
      "Weights: [6.6754515  1.40971977] , error: 5.086532750545883\n",
      "Weights: [6.6610409  1.41136783] , error: 5.065518590484608\n",
      "Weights: [6.64666316 1.41301213] , error: 5.044600163173074\n",
      "Weights: [6.63231821 1.41465268] , error: 5.02377703248824\n",
      "Weights: [6.61800598 1.41628949] , error: 5.003048764293881\n",
      "Weights: [6.60372638 1.41792256] , error: 4.9824149264315345\n",
      "Weights: [6.58947934 1.41955191] , error: 4.9618750887114995\n",
      "Weights: [6.57526479 1.42117755] , error: 4.941428822903846\n",
      "Weights: [6.56108266 1.42279948] , error: 4.921075702729521\n",
      "Weights: [6.54693287 1.42441771] , error: 4.900815303851422\n",
      "Weights: [6.53281534 1.42603225] , error: 4.880647203865585\n",
      "Weights: [6.51873001 1.42764311] , error: 4.860570982292354\n",
      "Weights: [6.5046768  1.42925029] , error: 4.840586220567624\n",
      "Weights: [6.49065564 1.43085381] , error: 4.820692502034118\n",
      "Weights: [6.47666645 1.43245367] , error: 4.800889411932683\n",
      "Weights: [6.46270917 1.43404989] , error: 4.781176537393671\n",
      "Weights: [6.44878371 1.43564246] , error: 4.761553467428309\n",
      "Weights: [6.43489   1.4372314] , error: 4.742019792920137\n",
      "Weights: [6.42102798 1.43881672] , error: 4.722575106616473\n",
      "Weights: [6.40719758 1.44039842] , error: 4.703219003119943\n",
      "Weights: [6.39339871 1.44197652] , error: 4.683951078879993\n",
      "Weights: [6.3796313  1.44355102] , error: 4.664770932184515\n",
      "Weights: [6.3658953  1.44512193] , error: 4.645678163151441\n",
      "Weights: [6.35219061 1.44668925] , error: 4.626672373720426\n",
      "Weights: [6.33851718 1.448253  ] , error: 4.60775316764453\n",
      "Weights: [6.32487493 1.44981319] , error: 4.588920150481981\n",
      "Weights: [6.31126379 1.45136982] , error: 4.57017292958793\n",
      "Weights: [6.29768369 1.45292289] , error: 4.551511114106273\n",
      "Weights: [6.28413456 1.45447243] , error: 4.532934314961506\n",
      "Weights: [6.27061633 1.45601843] , error: 4.514442144850604\n",
      "Weights: [6.25712892 1.45756091] , error: 4.496034218234956\n",
      "Weights: [6.24367227 1.45909987] , error: 4.477710151332316\n",
      "Weights: [6.2302463  1.46063532] , error: 4.459469562108818\n",
      "Weights: [6.21685096 1.46216727] , error: 4.441312070270996\n",
      "Weights: [6.20348616 1.46369572] , error: 4.423237297257859\n",
      "Weights: [6.19015183 1.46522069] , error: 4.405244866233002\n",
      "Weights: [6.17684792 1.46674218] , error: 4.387334402076743\n",
      "Weights: [6.16357434 1.4682602 ] , error: 4.369505531378313\n",
      "Weights: [6.15033104 1.46977477] , error: 4.351757882428066\n",
      "Weights: [6.13711793 1.47128587] , error: 4.334091085209721\n",
      "Weights: [6.12393495 1.47279353] , error: 4.316504771392659\n",
      "Weights: [6.11078204 1.47429776] , error: 4.298998574324234\n",
      "Weights: [6.09765912 1.47579855] , error: 4.2815721290221385\n",
      "Weights: [6.08456613 1.47729592] , error: 4.264225072166792\n",
      "Weights: [6.07150299 1.47878987] , error: 4.246957042093757\n",
      "Weights: [6.05846965 1.48028042] , error: 4.229767678786214\n",
      "Weights: [6.04546602 1.48176757] , error: 4.212656623867431\n",
      "Weights: [6.03249205 1.48325133] , error: 4.195623520593332\n",
      "Weights: [6.01954767 1.4847317 ] , error: 4.1786680138450185\n",
      "Weights: [6.0066328 1.4862087] , error: 4.161789750121384\n",
      "Weights: [5.99374738 1.48768233] , error: 4.144988377531746\n",
      "Weights: [5.98089135 1.4891526 ] , error: 4.128263545788503\n",
      "Weights: [5.96806464 1.49061952] , error: 4.111614906199839\n",
      "Weights: [5.95526717 1.49208309] , error: 4.095042111662444\n",
      "Weights: [5.94249889 1.49354333] , error: 4.078544816654287\n",
      "Weights: [5.92975973 1.49500023] , error: 4.062122677227403\n",
      "Weights: [5.91704962 1.49645381] , error: 4.045775351000733\n",
      "Weights: [5.90436849 1.49790408] , error: 4.029502497152972\n",
      "Weights: [5.89171628 1.49935104] , error: 4.0133037764154755\n",
      "Weights: [5.87909292 1.5007947 ] , error: 3.9971788510651853\n",
      "Weights: [5.86649835 1.50223507] , error: 3.9811273849175737\n",
      "Weights: [5.8539325  1.50367215] , error: 3.9651490433196575\n",
      "Weights: [5.8413953  1.50510596] , error: 3.9492434931429963\n",
      "Weights: [5.8288867  1.50653649] , error: 3.9334104027767776\n",
      "Weights: [5.81640662 1.50796377] , error: 3.9176494421208674\n",
      "Weights: [5.803955   1.50938779] , error: 3.901960282578956\n",
      "Weights: [5.79153177 1.51080856] , error: 3.8863425970516903\n",
      "Weights: [5.77913688 1.51222609] , error: 3.8707960599298716\n",
      "Weights: [5.76677025 1.51364039] , error: 3.8553203470876456\n",
      "Weights: [5.75443182 1.51505147] , error: 3.8399151358757577\n",
      "Weights: [5.74212152 1.51645933] , error: 3.8245801051148316\n",
      "Weights: [5.7298393  1.51786397] , error: 3.8093149350886555\n",
      "Weights: [5.71758509 1.51926542] , error: 3.7941193075375383\n",
      "Weights: [5.70535883 1.52066366] , error: 3.7789929056516476\n",
      "Weights: [5.69316044 1.52205872] , error: 3.763935414064431\n",
      "Weights: [5.68098987 1.5234506 ] , error: 3.748946518846026\n",
      "Weights: [5.66884706 1.5248393 ] , error: 3.734025907496718\n",
      "Weights: [5.65673194 1.52622484] , error: 3.7191732689404278\n",
      "Weights: [5.64464444 1.52760722] , error: 3.704388293518221\n",
      "Weights: [5.63258451 1.52898644] , error: 3.6896706729818556\n",
      "Weights: [5.62055208 1.53036252] , error: 3.675020100487358\n",
      "Weights: [5.60854709 1.53173546] , error: 3.6604362705886175\n",
      "Weights: [5.59656947 1.53310527] , error: 3.645918879231024\n",
      "Weights: [5.58461917 1.53447196] , error: 3.631467623745133\n",
      "Weights: [5.57269612 1.53583553] , error: 3.617082202840344\n",
      "Weights: [5.56080026 1.53719599] , error: 3.6027623165986284\n",
      "Weights: [5.54893153 1.53855335] , error: 3.5885076664682707\n",
      "Weights: [5.53708987 1.53990761] , error: 3.5743179552576505\n",
      "Weights: [5.5252752  1.54125879] , error: 3.5601928871290403\n",
      "Weights: [5.51348748 1.54260688] , error: 3.5461321675924387\n",
      "Weights: [5.50172664 1.5439519 ] , error: 3.5321355034994375\n",
      "Weights: [5.48999262 1.54529385] , error: 3.518202603037096\n",
      "Weights: [5.47828536 1.54663274] , error: 3.504333175721868\n",
      "Weights: [5.4666048  1.54796858] , error: 3.490526932393552\n",
      "Weights: [5.45495087 1.54930137] , error: 3.476783585209243\n",
      "Weights: [5.44332352 1.55063113] , error: 3.463102847637345\n",
      "Weights: [5.43172268 1.55195785] , error: 3.4494844344515916\n",
      "Weights: [5.4201483  1.55328154] , error: 3.435928061725111\n",
      "Weights: [5.40860032 1.55460222] , error: 3.422433446824487\n",
      "Weights: [5.39707866 1.55591988] , error: 3.4090003084038774\n",
      "Weights: [5.38558328 1.55723454] , error: 3.3956283663991598\n",
      "Weights: [5.37411412 1.5585462 ] , error: 3.3823173420220654\n",
      "Weights: [5.36267111 1.55985488] , error: 3.369066957754391\n",
      "Weights: [5.35125419 1.56116056] , error: 3.3558769373421997\n",
      "Weights: [5.33986332 1.56246327] , error: 3.342747005790068\n",
      "Weights: [5.32849841 1.56376301] , error: 3.3296768893553486\n",
      "Weights: [5.31715942 1.56505978] , error: 3.316666315542464\n",
      "Weights: [5.30584629 1.5663536 ] , error: 3.3037150130972264\n",
      "Weights: [5.29455896 1.56764447] , error: 3.2908227120011833\n",
      "Weights: [5.28329737 1.56893239] , error: 3.2779891434659856\n",
      "Weights: [5.27206146 1.57021738] , error: 3.265214039927783\n",
      "Weights: [5.26085117 1.57149943] , error: 3.252497135041648\n",
      "Weights: [5.24966645 1.57277856] , error: 3.2398381636760227\n",
      "Weights: [5.23850723 1.57405478] , error: 3.227236861907195\n",
      "Weights: [5.22737346 1.57532808] , error: 3.2146929670137836\n",
      "Weights: [5.21626508 1.57659849] , error: 3.2022062174712715\n",
      "Weights: [5.20518203 1.57786599] , error: 3.189776352946552\n",
      "Weights: [5.19412426 1.5791306 ] , error: 3.1774031142925057\n",
      "Weights: [5.1830917  1.58039233] , error: 3.1650862435425786\n",
      "Weights: [5.1720843  1.58165119] , error: 3.152825483905425\n",
      "Weights: [5.161102   1.58290717] , error: 3.14062057975955\n",
      "Weights: [5.15014475 1.58416029] , error: 3.128471276647966\n",
      "Weights: [5.13921248 1.58541055] , error: 3.116377321272904\n",
      "Weights: [5.12830515 1.58665795] , error: 3.1043384614905243\n",
      "Weights: [5.11742268 1.58790252] , error: 3.0923544463056585\n",
      "Weights: [5.10656504 1.58914425] , error: 3.080425025866585\n",
      "Weights: [5.09573215 1.59038314] , error: 3.0685499514598114\n",
      "Weights: [5.08492397 1.59161921] , error: 3.0567289755048916\n",
      "Weights: [5.07414043 1.59285246] , error: 3.044961851549266\n",
      "Weights: [5.06338148 1.5940829 ] , error: 3.033248334263119\n",
      "Weights: [5.05264707 1.59531053] , error: 3.0215881794342687\n",
      "Weights: [5.04193714 1.59653536] , error: 3.0099811439630777\n",
      "Weights: [5.03125163 1.5977574 ] , error: 2.998426985857373\n",
      "Weights: [5.02059049 1.59897666] , error: 2.9869254642274146\n",
      "Weights: [5.00995366 1.60019313] , error: 2.9754763392808647\n",
      "Weights: [4.99934109 1.60140683] , error: 2.964079372317791\n",
      "Weights: [4.98875272 1.60261776] , error: 2.9527343257256904\n",
      "Weights: [4.97818849 1.60382593] , error: 2.941440962974534\n",
      "Weights: [4.96764836 1.60503134] , error: 2.93019904861184\n",
      "Weights: [4.95713226 1.60623401] , error: 2.919008348257751\n",
      "Weights: [4.94664014 1.60743393] , error: 2.907868628600168\n",
      "Weights: [4.93617195 1.60863112] , error: 2.8967796573898723\n",
      "Weights: [4.92572763 1.60982557] , error: 2.8857412034356833\n",
      "Weights: [4.91530713 1.61101731] , error: 2.8747530365996536\n",
      "Weights: [4.90491039 1.61220632] , error: 2.863814927792243\n",
      "Weights: [4.89453736 1.61339262] , error: 2.852926648967569\n",
      "Weights: [4.88418798 1.61457622] , error: 2.842087973118641\n",
      "Weights: [4.87386221 1.61575712] , error: 2.8312986742726247\n",
      "Weights: [4.86355998 1.61693533] , error: 2.8205585274861384\n",
      "Weights: [4.85328124 1.61811085] , error: 2.8098673088405564\n",
      "Weights: [4.84302595 1.61928369] , error: 2.799224795437346\n",
      "Weights: [4.83279404 1.62045385] , error: 2.7886307653934157\n",
      "Weights: [4.82258547 1.62162135] , error: 2.7780849978364937\n",
      "Weights: [4.81240017 1.62278618] , error: 2.767587272900518\n",
      "Weights: [4.8022381  1.62394836] , error: 2.7571373717210568\n",
      "Weights: [4.79209921 1.62510788] , error: 2.7467350764307445\n",
      "Weights: [4.78198343 1.62626477] , error: 2.7363801701547366\n",
      "Weights: [4.77189073 1.62741901] , error: 2.726072437006188\n",
      "Weights: [4.76182104 1.62857062] , error: 2.7158116620817663\n",
      "Weights: [4.75177431 1.62971961] , error: 2.705597631457145\n",
      "Weights: [4.74175049 1.63086597] , error: 2.6954301321825618\n",
      "Weights: [4.73174953 1.63200973] , error: 2.68530895227838\n",
      "Weights: [4.72177138 1.63315087] , error: 2.67523388073066\n",
      "Weights: [4.71181598 1.63428941] , error: 2.665204707486763\n",
      "Weights: [4.70188329 1.63542536] , error: 2.6552212234509738\n",
      "Weights: [4.69197324 1.63655871] , error: 2.6452832204801404\n",
      "Weights: [4.6820858  1.63768948] , error: 2.635390491379332\n",
      "Weights: [4.6722209  1.63881767] , error: 2.625542829897524\n",
      "Weights: [4.6623785  1.63994329] , error: 2.6157400307232934\n",
      "Weights: [4.65255854 1.64106634] , error: 2.6059818894805433\n",
      "Weights: [4.64276098 1.64218683] , error: 2.5962682027242336\n",
      "Weights: [4.63298576 1.64330477] , error: 2.5865987679361475\n",
      "Weights: [4.62323283 1.64442015] , error: 2.5769733835206674\n",
      "Weights: [4.61350214 1.645533  ] , error: 2.5673918488005687\n",
      "Weights: [4.60379364 1.6466433 ] , error: 2.5578539640128395\n",
      "Weights: [4.59410728 1.64775107] , error: 2.548359530304514\n",
      "Weights: [4.58444301 1.64885632] , error: 2.538908349728529\n",
      "Weights: [4.57480078 1.64995905] , error: 2.52950022523959\n",
      "Weights: [4.56518054 1.65105926] , error: 2.520134960690071\n",
      "Weights: [4.55558223 1.65215696] , error: 2.510812360825928\n",
      "Weights: [4.54600581 1.65325216] , error: 2.5015322312826087\n",
      "Weights: [4.53645123 1.65434486] , error: 2.492294378581026\n",
      "Weights: [4.52691844 1.65543507] , error: 2.4830986101235055\n",
      "Weights: [4.51740739 1.6565228 ] , error: 2.473944734189781\n",
      "Weights: [4.50791803 1.65760804] , error: 2.464832559932993\n",
      "Weights: [4.49845031 1.65869081] , error: 2.455761897375702\n",
      "Weights: [4.48900417 1.65977111] , error: 2.4467325574059458\n",
      "Weights: [4.47957958 1.66084895] , error: 2.4377443517732797\n",
      "Weights: [4.47017648 1.66192432] , error: 2.4287970930848624\n",
      "Weights: [4.46079482 1.66299725] , error: 2.41989059480154\n",
      "Weights: [4.45143456 1.66406773] , error: 2.4110246712339682\n",
      "Weights: [4.44209564 1.66513577] , error: 2.4021991375387324\n",
      "Weights: [4.43277802 1.66620137] , error: 2.3934138097144952\n",
      "Weights: [4.42348165 1.66726454] , error: 2.3846685045981615\n",
      "Weights: [4.41420648 1.66832529] , error: 2.3759630398610594\n",
      "Weights: [4.40495246 1.66938362] , error: 2.367297234005142\n",
      "Weights: [4.39571954 1.67043953] , error: 2.3586709063591953\n",
      "Weights: [4.38650767 1.67149304] , error: 2.3500838770750843\n",
      "Weights: [4.37731682 1.67254415] , error: 2.341535967123988\n",
      "Weights: [4.36814692 1.67359285] , error: 2.333026998292676\n",
      "Weights: [4.35899793 1.67463917] , error: 2.3245567931797955\n",
      "Weights: [4.34986981 1.6756831 ] , error: 2.3161251751921648\n",
      "Weights: [4.3407625  1.67672465] , error: 2.3077319685410957\n",
      "Weights: [4.33167596 1.67776383] , error: 2.299376998238734\n",
      "Weights: [4.32261014 1.67880063] , error: 2.291060090094398\n",
      "Weights: [4.313565   1.67983507] , error: 2.2827810707109584\n",
      "Weights: [4.30454048 1.68086715] , error: 2.274539767481216\n",
      "Weights: [4.29553654 1.68189688] , error: 2.2663360085843105\n",
      "Weights: [4.28655314 1.68292426] , error: 2.258169622982132\n",
      "Weights: [4.27759022 1.6839493 ] , error: 2.250040440415756\n",
      "Weights: [4.26864774 1.684972  ] , error: 2.2419482914018967\n",
      "Weights: [4.25972565 1.68599237] , error: 2.2338930072293706\n",
      "Weights: [4.25082391 1.68701041] , error: 2.225874419955579\n",
      "Weights: [4.24194247 1.68802613] , error: 2.2178923624030102\n",
      "Weights: [4.23308128 1.68903953] , error: 2.2099466681557476\n",
      "Weights: [4.2242403  1.69005062] , error: 2.2020371715560065\n",
      "Weights: [4.21541948 1.69105941] , error: 2.1941637077006795\n",
      "Weights: [4.20661878 1.69206589] , error: 2.186326112437895\n",
      "Weights: [4.19783814 1.69307008] , error: 2.178524222363595\n",
      "Weights: [4.18907753 1.69407198] , error: 2.1707578748181344\n",
      "Weights: [4.18033689 1.6950716 ] , error: 2.1630269078828808\n",
      "Weights: [4.17161619 1.69606894] , error: 2.155331160376844\n",
      "Weights: [4.16291538 1.697064  ] , error: 2.1476704718533184\n",
      "Weights: [4.1542344  1.69805679] , error: 2.14004468259653\n",
      "Weights: [4.14557323 1.69904732] , error: 2.1324536336183155\n",
      "Weights: [4.1369318  1.70003559] , error: 2.1248971666547978\n",
      "Weights: [4.12831008 1.70102161] , error: 2.1173751241630927\n",
      "Weights: [4.11970802 1.70200537] , error: 2.109887349318028\n",
      "Weights: [4.11112558 1.7029869 ] , error: 2.1024336860088626\n",
      "Weights: [4.10256271 1.70396618] , error: 2.095013978836043\n",
      "Weights: [4.09401936 1.70494324] , error: 2.0876280731079557\n",
      "Weights: [4.0854955  1.70591806] , error: 2.080275814837707\n",
      "Weights: [4.07699107 1.70689066] , error: 2.072957050739912\n",
      "Weights: [4.06850604 1.70786105] , error: 2.0656716282274896\n",
      "Weights: [4.06004036 1.70882922] , error: 2.0584193954084973\n",
      "Weights: [4.05159399 1.70979518] , error: 2.0512002010829535\n",
      "Weights: [4.04316687 1.71075894] , error: 2.04401389473969\n",
      "Weights: [4.03475897 1.71172051] , error: 2.0368603265532057\n",
      "Weights: [4.02637025 1.71267988] , error: 2.0297393473805556\n",
      "Weights: [4.01800066 1.71363706] , error: 2.022650808758232\n",
      "Weights: [4.00965015 1.71459206] , error: 2.0155945628990724\n",
      "Weights: [4.00131868 1.71554488] , error: 2.0085704626891783\n",
      "Weights: [3.99300622 1.71649553] , error: 2.001578361684848\n",
      "Weights: [3.98471271 1.71744401] , error: 1.9946181141095212\n",
      "Weights: [3.97643811 1.71839033] , error: 1.9876895748507448\n",
      "Weights: [3.96818238 1.71933449] , error: 1.9807925994571427\n",
      "Weights: [3.95994548 1.72027649] , error: 1.973927044135406\n",
      "Weights: [3.95172736 1.72121635] , error: 1.9670927657472945\n",
      "Weights: [3.94352798 1.72215407] , error: 1.9602896218066568\n",
      "Weights: [3.93534731 1.72308964] , error: 1.953517470476446\n",
      "Weights: [3.92718528 1.72402309] , error: 1.9467761705657856\n",
      "Weights: [3.91904187 1.7249544 ] , error: 1.9400655815270034\n",
      "Weights: [3.91091703 1.72588359] , error: 1.9333855634527108\n",
      "Weights: [3.90281072 1.72681066] , error: 1.9267359770728911\n",
      "Weights: [3.89472289 1.72773562] , error: 1.920116683751985\n",
      "Weights: [3.88665351 1.72865847] , error: 1.9135275454860088\n",
      "Weights: [3.87860252 1.72957922] , error: 1.9069684248996726\n",
      "Weights: [3.8705699  1.73049786] , error: 1.9004391852435167\n",
      "Weights: [3.8625556  1.73141441] , error: 1.8939396903910646\n",
      "Weights: [3.85455957 1.73232887] , error: 1.8874698048359762\n",
      "Weights: [3.84658177 1.73324124] , error: 1.8810293936892348\n",
      "Weights: [3.83862217 1.73415154] , error: 1.874618322676323\n",
      "Weights: [3.83068072 1.73505975] , error: 1.8682364581344317\n",
      "Weights: [3.82275738 1.7359659 ] , error: 1.86188366700967\n",
      "Weights: [3.81485211 1.73686998] , error: 1.8555598168542864\n",
      "Weights: [3.80696487 1.737772  ] , error: 1.849264775823921\n",
      "Weights: [3.79909561 1.73867196] , error: 1.8429984126748418\n",
      "Weights: [3.79124429 1.73956987] , error: 1.8367605967612144\n",
      "Weights: [3.78341088 1.74046573] , error: 1.830551198032383\n",
      "Weights: [3.77559534 1.74135955] , error: 1.824370087030152\n",
      "Weights: [3.76779761 1.74225133] , error: 1.8182171348860885\n",
      "Weights: [3.76001767 1.74314108] , error: 1.812092213318839\n",
      "Weights: [3.75225547 1.7440288 ] , error: 1.805995194631451\n",
      "Weights: [3.74451098 1.74491449] , error: 1.7999259517087105\n",
      "Weights: [3.73678414 1.74579816] , error: 1.793884358014497\n",
      "Weights: [3.72907492 1.74667982] , error: 1.7878702875891406\n",
      "Weights: [3.72138328 1.74755947] , error: 1.7818836150467965\n",
      "Weights: [3.71370919 1.74843711] , error: 1.7759242155728299\n",
      "Weights: [3.70605259 1.74931275] , error: 1.7699919649212181\n",
      "Weights: [3.69841345 1.7501864 ] , error: 1.7640867394119573\n",
      "Weights: [3.69079174 1.75105805] , error: 1.7582084159284808\n",
      "Weights: [3.6831874  1.75192771] , error: 1.7523568719151004\n",
      "Weights: [3.67560041 1.75279539] , error: 1.7465319853744425\n",
      "Weights: [3.66803071 1.7536611 ] , error: 1.740733634864909\n",
      "Weights: [3.66047828 1.75452482] , error: 1.734961699498147\n",
      "Weights: [3.65294307 1.75538658] , error: 1.729216058936525\n",
      "Weights: [3.64542505 1.75624637] , error: 1.723496593390625\n",
      "Weights: [3.63792417 1.75710421] , error: 1.7178031836167433\n",
      "Weights: [3.63044039 1.75796008] , error: 1.7121357109144113\n",
      "Weights: [3.62297368 1.75881401] , error: 1.706494057123913\n",
      "Weights: [3.615524   1.75966598] , error: 1.7008781046238226\n",
      "Weights: [3.60809131 1.76051602] , error: 1.6952877363285588\n",
      "Weights: [3.60067556 1.76136411] , error: 1.689722835685935\n",
      "Weights: [3.59327673 1.76221028] , error: 1.684183286674735\n",
      "Weights: [3.58589477 1.76305451] , error: 1.678668973802289\n",
      "Weights: [3.57852964 1.76389682] , error: 1.673179782102077\n",
      "Weights: [3.57118131 1.7647372 ] , error: 1.6677155971313165\n",
      "Weights: [3.56384973 1.76557567] , error: 1.6622763049685871\n",
      "Weights: [3.55653488 1.76641223] , error: 1.656861792211451\n",
      "Weights: [3.54923671 1.76724688] , error: 1.651471945974092\n",
      "Weights: [3.54195517 1.76807963] , error: 1.6461066538849587\n",
      "Weights: [3.53469025 1.76891047] , error: 1.6407658040844226\n",
      "Weights: [3.52744189 1.76973943] , error: 1.6354492852224463\n",
      "Weights: [3.52021006 1.77056649] , error: 1.6301569864562644\n",
      "Weights: [3.51299472 1.77139167] , error: 1.6248887974480657\n",
      "Weights: [3.50579583 1.77221496] , error: 1.619644608362703\n",
      "Weights: [3.49861337 1.77303638] , error: 1.6144243098653905\n",
      "Weights: [3.49144728 1.77385592] , error: 1.6092277931194405\n",
      "Weights: [3.48429753 1.7746736 ] , error: 1.6040549497839762\n",
      "Weights: [3.47716409 1.77548941] , error: 1.5989056720116852\n",
      "Weights: [3.47004691 1.77630336] , error: 1.5937798524465687\n",
      "Weights: [3.46294597 1.77711545] , error: 1.5886773842217017\n",
      "Weights: [3.45586121 1.77792569] , error: 1.5835981609570038\n",
      "Weights: [3.44879262 1.77873409] , error: 1.578542076757026\n",
      "Weights: [3.44174014 1.77954064] , error: 1.5735090262087355\n",
      "Weights: [3.43470374 1.78034535] , error: 1.5684989043793267\n",
      "Weights: [3.4276834  1.78114823] , error: 1.5635116068140271\n",
      "Weights: [3.42067906 1.78194927] , error: 1.558547029533921\n",
      "Weights: [3.41369069 1.78274849] , error: 1.553605069033781\n",
      "Weights: [3.40671826 1.78354589] , error: 1.5486856222799175\n",
      "Weights: [3.39976173 1.78434147] , error: 1.5437885867080168\n",
      "Weights: [3.39282106 1.78513523] , error: 1.5389138602210128\n",
      "Weights: [3.38589622 1.78592718] , error: 1.5340613411869592\n",
      "Weights: [3.37898718 1.78671733] , error: 1.5292309284369046\n",
      "Weights: [3.37209389 1.78750568] , error: 1.5244225212627849\n",
      "Weights: [3.36521631 1.78829223] , error: 1.5196360194153242\n",
      "Weights: [3.35835443 1.78907698] , error: 1.5148713231019502\n",
      "Weights: [3.35150818 1.78985995] , error: 1.5101283329847046\n",
      "Weights: [3.34467756 1.79064113] , error: 1.505406950178176\n",
      "Weights: [3.3378625  1.79142052] , error: 1.500707076247438\n",
      "Weights: [3.33106299 1.79219814] , error: 1.496028613206003\n",
      "Weights: [3.32427899 1.79297399] , error: 1.491371463513766\n",
      "Weights: [3.31751046 1.79374807] , error: 1.4867355300749836\n",
      "Weights: [3.31075736 1.79452038] , error: 1.4821207162362433\n",
      "Weights: [3.30401966 1.79529093] , error: 1.4775269257844488\n",
      "Weights: [3.29729732 1.79605973] , error: 1.472954062944817\n",
      "Weights: [3.29059032 1.79682677] , error: 1.4684020323788776\n",
      "Weights: [3.28389861 1.79759206] , error: 1.4638707391824881\n",
      "Weights: [3.27722216 1.79835561] , error: 1.4593600888838547\n",
      "Weights: [3.27056093 1.79911742] , error: 1.4548699874415612\n",
      "Weights: [3.2639149  1.79987748] , error: 1.4504003412426087\n",
      "Weights: [3.25728402 1.80063582] , error: 1.4459510571004677\n",
      "Weights: [3.25066826 1.80139243] , error: 1.4415220422531274\n",
      "Weights: [3.24406759 1.80214731] , error: 1.4371132043611712\n",
      "Weights: [3.23748197 1.80290046] , error: 1.4327244515058442\n",
      "Weights: [3.23091137 1.80365191] , error: 1.4283556921871383\n",
      "Weights: [3.22435575 1.80440163] , error: 1.4240068353218884\n",
      "Weights: [3.21781508 1.80514965] , error: 1.4196777902418702\n",
      "Weights: [3.21128933 1.80589597] , error: 1.4153684666919073\n",
      "Weights: [3.20477846 1.80664058] , error: 1.4110787748279956\n",
      "Weights: [3.19828244 1.80738349] , error: 1.4068086252154264\n",
      "Weights: [3.19180123 1.80812471] , error: 1.4025579288269228\n",
      "Weights: [3.1853348  1.80886424] , error: 1.398326597040781\n",
      "Weights: [3.17888311 1.80960208] , error: 1.3941145416390295\n",
      "Weights: [3.17244614 1.81033824] , error: 1.3899216748055796\n",
      "Weights: [3.16602385 1.81107272] , error: 1.3857479091244058\n",
      "Weights: [3.1596162  1.81180552] , error: 1.3815931575777127\n",
      "Weights: [3.15322317 1.81253666] , error: 1.3774573335441302\n",
      "Weights: [3.14684471 1.81326612] , error: 1.3733403507969\n",
      "Weights: [3.1404808  1.81399393] , error: 1.3692421235020829\n",
      "Weights: [3.1341314  1.81472007] , error: 1.3651625662167655\n",
      "Weights: [3.12779648 1.81544456] , error: 1.3611015938872826\n",
      "Weights: [3.12147601 1.8161674 ] , error: 1.3570591218474428\n",
      "Weights: [3.11516995 1.81688858] , error: 1.3530350658167594\n",
      "Weights: [3.10887827 1.81760813] , error: 1.3490293418987005\n",
      "Weights: [3.10260094 1.81832603] , error: 1.3450418665789312\n",
      "Weights: [3.09633793 1.81904229] , error: 1.3410725567235808\n",
      "Weights: [3.09008919 1.81975692] , error: 1.3371213295775042\n",
      "Weights: [3.08385471 1.82046993] , error: 1.3331881027625587\n",
      "Weights: [3.07763444 1.8211813 ] , error: 1.3292727942758844\n",
      "Weights: [3.07142836 1.82189106] , error: 1.3253753224881988\n",
      "Weights: [3.06523643 1.82259919] , error: 1.3214956061420908\n",
      "Weights: [3.05905862 1.82330571] , error: 1.3176335643503292\n",
      "Weights: [3.0528949  1.82401062] , error: 1.3137891165941717\n",
      "Weights: [3.04674523 1.82471392] , error: 1.309962182721693\n",
      "Weights: [3.04060959 1.82541562] , error: 1.3061526829461108\n",
      "Weights: [3.03448794 1.82611572] , error: 1.3023605378441188\n",
      "Weights: [3.02838025 1.82681422] , error: 1.298585668354237\n",
      "Weights: [3.02228649 1.82751113] , error: 1.294827995775157\n",
      "Weights: [3.01620662 1.82820645] , error: 1.2910874417641085\n",
      "Weights: [3.01014062 1.82890018] , error: 1.2873639283352194\n",
      "Weights: [3.00408845 1.82959233] , error: 1.2836573778578912\n",
      "Weights: [2.99805008 1.8302829 ] , error: 1.2799677130551852\n",
      "Weights: [2.99202549 1.8309719 ] , error: 1.2762948570022052\n",
      "Weights: [2.98601463 1.83165933] , error: 1.2726387331244988\n",
      "Weights: [2.98001748 1.83234519] , error: 1.2689992651964555\n",
      "Weights: [2.974034   1.83302949] , error: 1.2653763773397233\n",
      "Weights: [2.96806417 1.83371222] , error: 1.2617699940216198\n",
      "Weights: [2.96210795 1.8343934 ] , error: 1.2581800400535679\n",
      "Weights: [2.95616532 1.83507302] , error: 1.2546064405895165\n",
      "Weights: [2.95023624 1.8357511 ] , error: 1.2510491211243884\n",
      "Weights: [2.94432068 1.83642763] , error: 1.2475080074925233\n",
      "Weights: [2.93841861 1.83710261] , error: 1.2439830258661289\n",
      "Weights: [2.93252999 1.83777606] , error: 1.2404741027537511\n",
      "Weights: [2.92665481 1.83844797] , error: 1.2369811649987337\n",
      "Weights: [2.92079302 1.83911835] , error: 1.2335041397776914\n",
      "Weights: [2.9149446 1.8397872] , error: 1.2300429545989982\n",
      "Weights: [2.90910952 1.84045452] , error: 1.226597537301276\n",
      "Weights: [2.90328775 1.84112033] , error: 1.2231678160518806\n",
      "Weights: [2.89747925 1.84178461] , error: 1.2197537193454184\n",
      "Weights: [2.89168399 1.84244738] , error: 1.2163551760022415\n",
      "Weights: [2.88590196 1.84310864] , error: 1.2129721151669746\n",
      "Weights: [2.8801331  1.84376839] , error: 1.2096044663070302\n",
      "Weights: [2.87437741 1.84442663] , error: 1.2062521592111421\n",
      "Weights: [2.86863483 1.84508338] , error: 1.2029151239879026\n",
      "Weights: [2.86290536 1.84573863] , error: 1.1995932910643012\n",
      "Weights: [2.85718895 1.84639238] , error: 1.1962865911842784\n",
      "Weights: [2.85148557 1.84704464] , error: 1.1929949554072767\n",
      "Weights: [2.8457952  1.84769541] , error: 1.189718315106808\n",
      "Weights: [2.84011781 1.84834471] , error: 1.1864566019690226\n",
      "Weights: [2.83445337 1.84899252] , error: 1.1832097479912813\n",
      "Weights: [2.82880184 1.84963885] , error: 1.1799776854807407\n",
      "Weights: [2.8231632  1.85028371] , error: 1.17676034705294\n",
      "Weights: [2.81753741 1.85092709] , error: 1.173557665630398\n",
      "Weights: [2.81192446 1.85156902] , error: 1.170369574441215\n",
      "Weights: [2.80632431 1.85220947] , error: 1.167196007017677\n",
      "Weights: [2.80073693 1.85284847] , error: 1.1640368971948736\n",
      "Weights: [2.79516228 1.85348601] , error: 1.1608921791093174\n",
      "Weights: [2.78960036 1.85412209] , error: 1.1577617871975696\n",
      "Weights: [2.78405111 1.85475673] , error: 1.154645656194876\n",
      "Weights: [2.77851452 1.85538992] , error: 1.151543721133802\n",
      "Weights: [2.77299056 1.85602166] , error: 1.1484559173428837\n",
      "Weights: [2.76747919 1.85665196] , error: 1.1453821804452753\n",
      "Weights: [2.76198039 1.85728083] , error: 1.142322446357406\n",
      "Weights: [2.75649413 1.85790826] , error: 1.1392766512876498\n",
      "Weights: [2.75102038 1.85853426] , error: 1.1362447317349873\n",
      "Weights: [2.74555911 1.85915884] , error: 1.1332266244876918\n",
      "Weights: [2.7401103  1.85978199] , error: 1.130222266622\n",
      "Weights: [2.73467391 1.86040371] , error: 1.1272315955008103\n",
      "Weights: [2.72924992 1.86102402] , error: 1.1242545487723723\n",
      "Weights: [2.7238383  1.86164292] , error: 1.1212910643689848\n",
      "Weights: [2.71843902 1.8622604 ] , error: 1.1183410805057044\n",
      "Weights: [2.71305206 1.86287648] , error: 1.1154045356790605\n",
      "Weights: [2.70767737 1.86349115] , error: 1.1124813686657649\n",
      "Weights: [2.70231495 1.86410442] , error: 1.1095715185214419\n",
      "Weights: [2.69696475 1.86471629] , error: 1.1066749245793595\n",
      "Weights: [2.69162675 1.86532677] , error: 1.1037915264491547\n",
      "Weights: [2.68630093 1.86593585] , error: 1.1009212640155857\n",
      "Weights: [2.68098725 1.86654355] , error: 1.0980640774372696\n",
      "Weights: [2.67568569 1.86714986] , error: 1.095219907145441\n",
      "Weights: [2.67039621 1.86775478] , error: 1.0923886938427079\n",
      "Weights: [2.6651188  1.86835833] , error: 1.089570378501815\n",
      "Weights: [2.65985343 1.8689605 ] , error: 1.0867649023644124\n",
      "Weights: [2.65460006 1.8695613 ] , error: 1.0839722069398345\n",
      "Weights: [2.64935867 1.87016072] , error: 1.0811922340038729\n",
      "Weights: [2.64412924 1.87075878] , error: 1.0784249255975713\n",
      "Weights: [2.63891173 1.87135548] , error: 1.07567022402601\n",
      "Weights: [2.63370611 1.87195082] , error: 1.0729280718571086\n",
      "Weights: [2.62851237 1.8725448 ] , error: 1.0701984119204233\n",
      "Weights: [2.62333047 1.87313742] , error: 1.0674811873059602\n",
      "Weights: [2.61816039 1.87372869] , error: 1.0647763413629865\n",
      "Weights: [2.6130021  1.87431862] , error: 1.062083817698846\n",
      "Weights: [2.60785558 1.87490719] , error: 1.0594035601777916\n",
      "Weights: [2.60272078 1.87549443] , error: 1.056735512919804\n",
      "Weights: [2.5975977  1.87608033] , error: 1.0540796202994358\n",
      "Weights: [2.5924863  1.87666489] , error: 1.0514358269446513\n",
      "Weights: [2.58738656 1.87724812] , error: 1.0488040777356644\n",
      "Weights: [2.58229845 1.87783001] , error: 1.0461843178037957\n",
      "Weights: [2.57722194 1.87841059] , error: 1.0435764925303297\n",
      "Weights: [2.572157   1.87898983] , error: 1.0409805475453697\n",
      "Weights: [2.56710362 1.87956776] , error: 1.0383964287267122\n",
      "Weights: [2.56206176 1.88014437] , error: 1.0358240821987132\n",
      "Weights: [2.5570314  1.88071966] , error: 1.0332634543311643\n",
      "Weights: [2.55201251 1.88129364] , error: 1.0307144917381788\n",
      "Weights: [2.54700506 1.88186632] , error: 1.0281771412770742\n",
      "Weights: [2.54200903 1.88243768] , error: 1.025651350047267\n",
      "Weights: [2.5370244  1.88300775] , error: 1.023137065389173\n",
      "Weights: [2.53205113 1.88357651] , error: 1.020634234883098\n",
      "Weights: [2.52708921 1.88414398] , error: 1.018142806348163\n",
      "Weights: [2.5221386  1.88471015] , error: 1.0156627278411947\n",
      "Weights: [2.51719928 1.88527503] , error: 1.0131939476556606\n",
      "Weights: [2.51227122 1.88583862] , error: 1.0107364143205813\n",
      "Weights: [2.5073544  1.88640093] , error: 1.0082900765994638\n",
      "Weights: [2.50244879 1.88696196] , error: 1.005854883489224\n",
      "Weights: [2.49755437 1.8875217 ] , error: 1.003430784219135\n",
      "Weights: [2.49267111 1.88808017] , error: 1.0010177282497577\n",
      "Weights: [2.48779899 1.88863737] , error: 0.9986156652718935\n",
      "Weights: [2.48293798 1.8891933 ] , error: 0.996224545205536\n",
      "Weights: [2.47808805 1.88974796] , error: 0.9938443181988214\n",
      "Weights: [2.47324918 1.89030135] , error: 0.9914749346269953\n",
      "Weights: [2.46842135 1.89085348] , error: 0.9891163450913735\n",
      "Weights: [2.46360453 1.89140435] , error: 0.9867685004183168\n",
      "Weights: [2.45879869 1.89195397] , error: 0.9844313516581983\n",
      "Weights: [2.45400381 1.89250233] , error: 0.9821048500843932\n",
      "Weights: [2.44921986 1.89304944] , error: 0.9797889471922516\n",
      "Weights: [2.44444683 1.89359531] , error: 0.9774835946980954\n",
      "Weights: [2.43968467 1.89413993] , error: 0.9751887445382115\n",
      "Weights: [2.43493338 1.8946833 ] , error: 0.9729043488678433\n",
      "Weights: [2.43019293 1.89522544] , error: 0.9706303600601984\n",
      "Weights: [2.42546328 1.89576635] , error: 0.9683667307054562\n",
      "Weights: [2.42074442 1.89630601] , error: 0.9661134136097745\n",
      "Weights: [2.41603632 1.89684445] , error: 0.9638703617943151\n",
      "Weights: [2.41133895 1.89738166] , error: 0.9616375284942481\n",
      "Weights: [2.4066523  1.89791765] , error: 0.9594148671577966\n",
      "Weights: [2.40197634 1.89845241] , error: 0.957202331445251\n",
      "Weights: [2.39731104 1.89898595] , error: 0.9549998752280088\n",
      "Weights: [2.39265637 1.89951828] , error: 0.9528074525876147\n",
      "Weights: [2.38801233 1.90004939] , error: 0.9506250178147988\n",
      "Weights: [2.38337887 1.9005793 ] , error: 0.9484525254085258\n",
      "Weights: [2.37875598 1.90110799] , error: 0.9462899300750468\n",
      "Weights: [2.37414363 1.90163548] , error: 0.9441371867269559\n",
      "Weights: [2.3695418  1.90216176] , error: 0.9419942504822449\n",
      "Weights: [2.36495046 1.90268685] , error: 0.9398610766633778\n",
      "Weights: [2.36036959 1.90321073] , error: 0.9377376207963456\n",
      "Weights: [2.35579917 1.90373343] , error: 0.9356238386097521\n",
      "Weights: [2.35123918 1.90425493] , error: 0.9335196860338817\n",
      "Weights: [2.34668958 1.90477524] , error: 0.9314251191997844\n",
      "Weights: [2.34215035 1.90529436] , error: 0.9293400944383654\n",
      "Weights: [2.33762148 1.9058123 ] , error: 0.9272645682794636\n",
      "Weights: [2.33310293 1.90632906] , error: 0.9251984974509582\n",
      "Weights: [2.32859469 1.90684465] , error: 0.9231418388778553\n",
      "Weights: [2.32409673 1.90735905] , error: 0.9210945496813965\n",
      "Weights: [2.31960903 1.90787228] , error: 0.9190565871781634\n",
      "Weights: [2.31513156 1.90838435] , error: 0.9170279088791871\n",
      "Weights: [2.3106643  1.90889524] , error: 0.9150084724890635\n",
      "Weights: [2.30620723 1.90940497] , error: 0.9129982359050705\n",
      "Weights: [2.30176032 1.90991354] , error: 0.9109971572162885\n",
      "Weights: [2.29732355 1.91042094] , error: 0.9090051947027327\n",
      "Weights: [2.2928969 1.9109272] , error: 0.9070223068344745\n",
      "Weights: [2.28848035 1.91143229] , error: 0.9050484522707846\n",
      "Weights: [2.28407387 1.91193623] , error: 0.9030835898592617\n",
      "Weights: [2.27967743 1.91243903] , error: 0.9011276786349853\n",
      "Weights: [2.27529102 1.91294068] , error: 0.899180677819652\n",
      "Weights: [2.27091462 1.91344118] , error: 0.8972425468207299\n",
      "Weights: [2.26654819 1.91394055] , error: 0.8953132452306146\n",
      "Weights: [2.26219172 1.91443877] , error: 0.8933927328257788\n",
      "Weights: [2.25784519 1.91493586] , error: 0.891480969565943\n",
      "Weights: [2.25350857 1.91543181] , error: 0.8895779155932352\n",
      "Weights: [2.24918183 1.91592663] , error: 0.8876835312313599\n",
      "Weights: [2.24486497 1.91642033] , error: 0.8857977769847745\n",
      "Weights: [2.24055795 1.9169129 ] , error: 0.8839206135378584\n",
      "Weights: [2.23626075 1.91740435] , error: 0.882052001754107\n",
      "Weights: [2.23197334 1.91789467] , error: 0.8801919026752991\n",
      "Weights: [2.22769572 1.91838388] , error: 0.878340277520697\n",
      "Weights: [2.22342785 1.91887197] , error: 0.8764970876862324\n",
      "Weights: [2.21916972 1.91935895] , error: 0.8746622947437025\n",
      "Weights: [2.21492129 1.91984482] , error: 0.8728358604399709\n",
      "Weights: [2.21068255 1.92032958] , error: 0.8710177466961657\n",
      "Weights: [2.20645348 1.92081323] , error: 0.8692079156068923\n",
      "Weights: [2.20223405 1.92129578] , error: 0.8674063294394356\n",
      "Weights: [2.19802425 1.92177723] , error: 0.8656129506329752\n",
      "Weights: [2.19382404 1.92225759] , error: 0.8638277417978106\n",
      "Weights: [2.18963341 1.92273684] , error: 0.8620506657145683\n",
      "Weights: [2.18545234 1.92321501] , error: 0.8602816853334355\n",
      "Weights: [2.18128081 1.92369208] , error: 0.8585207637733862\n",
      "Weights: [2.17711878 1.92416807] , error: 0.8567678643214064\n",
      "Weights: [2.17296625 1.92464297] , error: 0.8550229504317353\n",
      "Weights: [2.16882319 1.92511679] , error: 0.8532859857251025\n",
      "Weights: [2.16468957 1.92558953] , error: 0.8515569339879681\n",
      "Weights: [2.16056538 1.92606119] , error: 0.8498357591717643\n",
      "Weights: [2.1564506  1.92653177] , error: 0.8481224253921492\n",
      "Weights: [2.1523452  1.92700128] , error: 0.8464168969282584\n",
      "Weights: [2.14824916 1.92746972] , error: 0.8447191382219552\n",
      "Weights: [2.14416246 1.92793709] , error: 0.8430291138770966\n",
      "Weights: [2.14008508 1.9284034 ] , error: 0.8413467886587886\n",
      "Weights: [2.136017   1.92886864] , error: 0.8396721274926534\n",
      "Weights: [2.1319582  1.92933282] , error: 0.8380050954641036\n",
      "Weights: [2.12790865 1.92979595] , error: 0.8363456578176045\n",
      "Weights: [2.12386834 1.93025801] , error: 0.8346937799559584\n",
      "Weights: [2.11983724 1.93071903] , error: 0.8330494274395777\n",
      "Weights: [2.11581533 1.93117899] , error: 0.8314125659857705\n",
      "Weights: [2.1118026 1.9316379] , error: 0.8297831614680209\n",
      "Weights: [2.10779901 1.93209577] , error: 0.8281611799152861\n",
      "Weights: [2.10380456 1.93255259] , error: 0.8265465875112782\n",
      "Weights: [2.09981921 1.93300837] , error: 0.8249393505937648\n",
      "Weights: [2.09584296 1.93346312] , error: 0.8233394356538696\n",
      "Weights: [2.09187577 1.93391682] , error: 0.8217468093353638\n",
      "Weights: [2.08791762 1.93436949] , error: 0.8201614384339843\n",
      "Weights: [2.08396851 1.93482113] , error: 0.8185832898967303\n",
      "Weights: [2.0800284  1.93527174] , error: 0.8170123308211786\n",
      "Weights: [2.07609727 1.93572132] , error: 0.8154485284547968\n",
      "Weights: [2.07217511 1.93616987] , error: 0.8138918501942645\n",
      "Weights: [2.06826189 1.9366174 ] , error: 0.8123422635847842\n",
      "Weights: [2.0643576  1.93706391] , error: 0.8107997363194168\n",
      "Weights: [2.06046221 1.93750941] , error: 0.8092642362383962\n",
      "Weights: [2.0565757  1.93795388] , error: 0.8077357313284679\n",
      "Weights: [2.05269806 1.93839735] , error: 0.806214189722217\n",
      "Weights: [2.04882925 1.9388398 ] , error: 0.8046995796974024\n",
      "Weights: [2.04496927 1.93928124] , error: 0.8031918696763033\n",
      "Weights: [2.0411181  1.93972168] , error: 0.8016910282250477\n",
      "Weights: [2.0372757  1.94016111] , error: 0.8001970240529721\n",
      "Weights: [2.03344207 1.94059954] , error: 0.7987098260119566\n",
      "Weights: [2.02961718 1.94103697] , error: 0.7972294030957847\n",
      "Weights: [2.02580101 1.94147341] , error: 0.795755724439489\n",
      "Weights: [2.02199355 1.94190885] , error: 0.7942887593187146\n",
      "Weights: [2.01819477 1.94234329] , error: 0.7928284771490712\n",
      "Weights: [2.01440465 1.94277674] , error: 0.7913748474855046\n",
      "Weights: [2.01062317 1.94320921] , error: 0.7899278400216548\n",
      "Weights: [2.00685032 1.94364069] , error: 0.7884874245892262\n",
      "Weights: [2.00308607 1.94407118] , error: 0.7870535711573572\n",
      "Weights: [1.9993304 1.9445007] , error: 0.7856262498320008\n",
      "Weights: [1.9955833  1.94492923] , error: 0.78420543085529\n",
      "Weights: [1.99184474 1.94535679] , error: 0.7827910846049281\n",
      "Weights: [1.98811471 1.94578337] , error: 0.781383181593565\n",
      "Weights: [1.98439319 1.94620898] , error: 0.7799816924681837\n",
      "Weights: [1.98068015 1.94663362] , error: 0.7785865880094894\n",
      "Weights: [1.97697558 1.94705729] , error: 0.777197839131301\n",
      "Weights: [1.97327946 1.94747999] , error: 0.7758154168799399\n",
      "Weights: [1.96959176 1.94790173] , error: 0.7744392924336312\n",
      "Weights: [1.96591248 1.94832251] , error: 0.7730694371019031\n",
      "Weights: [1.96224158 1.94874233] , error: 0.771705822324986\n",
      "Weights: [1.95857906 1.94916119] , error: 0.7703484196732153\n",
      "Weights: [1.95492489 1.9495791 ] , error: 0.7689972008464467\n",
      "Weights: [1.95127905 1.94999605] , error: 0.7676521376734569\n",
      "Weights: [1.94764153 1.95041206] , error: 0.7663132021113601\n",
      "Weights: [1.9440123  1.95082711] , error: 0.764980366245027\n",
      "Weights: [1.94039134 1.95124122] , error: 0.7636536022864946\n",
      "Weights: [1.93677865 1.95165438] , error: 0.762332882574397\n",
      "Weights: [1.93317419 1.9520666 ] , error: 0.7610181795733801\n",
      "Weights: [1.92957795 1.95247788] , error: 0.7597094658735292\n",
      "Weights: [1.92598992 1.95288822] , error: 0.7584067141898019\n",
      "Weights: [1.92241006 1.95329763] , error: 0.7571098973614558\n",
      "Weights: [1.91883837 1.95370611] , error: 0.7558189883514814\n",
      "Weights: [1.91527483 1.95411365] , error: 0.7545339602460414\n",
      "Weights: [1.91171941 1.95452026] , error: 0.7532547862539072\n",
      "Weights: [1.9081721  1.95492595] , error: 0.7519814397059014\n",
      "Weights: [1.90463287 1.95533071] , error: 0.7507138940543419\n",
      "Weights: [1.90110172 1.95573454] , error: 0.7494521228724871\n",
      "Weights: [1.89757862 1.95613746] , error: 0.7481960998539856\n",
      "Weights: [1.89406356 1.95653946] , error: 0.7469457988123303\n",
      "Weights: [1.89055651 1.95694054] , error: 0.7457011936803077\n",
      "Weights: [1.88705746 1.95734071] , error: 0.7444622585094578\n",
      "Weights: [1.88356639 1.95773996] , error: 0.7432289674695324\n",
      "Weights: [1.88008327 1.9581383 ] , error: 0.7420012948479566\n",
      "Weights: [1.87660811 1.95853574] , error: 0.7407792150492911\n",
      "Weights: [1.87314086 1.95893227] , error: 0.739562702594702\n",
      "Weights: [1.86968153 1.95932789] , error: 0.7383517321214257\n",
      "Weights: [1.86623008 1.95972261] , error: 0.7371462783822433\n",
      "Weights: [1.8627865  1.96011643] , error: 0.7359463162449513\n",
      "Weights: [1.85935078 1.96050936] , error: 0.734751820691842\n",
      "Weights: [1.85592289 1.96090139] , error: 0.7335627668191769\n",
      "Weights: [1.85250282 1.96129252] , error: 0.732379129836669\n",
      "Weights: [1.84909054 1.96168276] , error: 0.7312008850669705\n",
      "Weights: [1.84568605 1.96207211] , error: 0.7300280079451489\n",
      "Weights: [1.84228932 1.96246058] , error: 0.7288604740181859\n",
      "Weights: [1.83890034 1.96284816] , error: 0.7276982589444596\n",
      "Weights: [1.83551909 1.96323485] , error: 0.7265413384932367\n",
      "Weights: [1.83214554 1.96362066] , error: 0.7253896885441772\n",
      "Weights: [1.82877969 1.9640056 ] , error: 0.7242432850868175\n",
      "Weights: [1.82542152 1.96438965] , error: 0.723102104220081\n",
      "Weights: [1.822071   1.96477283] , error: 0.7219661221517738\n",
      "Weights: [1.81872813 1.96515514] , error: 0.7208353151980915\n",
      "Weights: [1.81539287 1.96553657] , error: 0.7197096597831237\n",
      "Weights: [1.81206523 1.96591713] , error: 0.7185891324383625\n",
      "Weights: [1.80874517 1.96629683] , error: 0.7174737098022143\n",
      "Weights: [1.80543268 1.96667566] , error: 0.7163633686195133\n",
      "Weights: [1.80212774 1.96705363] , error: 0.7152580857410339\n",
      "Weights: [1.79883035 1.96743073] , error: 0.7141578381230133\n",
      "Weights: [1.79554047 1.96780697] , error: 0.713062602826663\n",
      "Weights: [1.79225809 1.96818236] , error: 0.7119723570176968\n",
      "Weights: [1.7889832  1.96855689] , error: 0.710887077965856\n",
      "Weights: [1.78571578 1.96893057] , error: 0.7098067430444271\n",
      "Weights: [1.78245581 1.96930339] , error: 0.7087313297297803\n",
      "Weights: [1.77920327 1.96967536] , error: 0.7076608156008922\n",
      "Weights: [1.77595815 1.97004649] , error: 0.7065951783388841\n",
      "Weights: [1.77272043 1.97041677] , error: 0.7055343957265507\n",
      "Weights: [1.7694901 1.9707862] , error: 0.704478445647902\n",
      "Weights: [1.76626713 1.9711548 ] , error: 0.7034273060877\n",
      "Weights: [1.76305151 1.97152255] , error: 0.7023809551310006\n",
      "Weights: [1.75984322 1.97188946] , error: 0.7013393709626944\n",
      "Weights: [1.75664225 1.97225554] , error: 0.7003025318670543\n",
      "Weights: [1.75344858 1.97262078] , error: 0.6992704162272824\n",
      "Weights: [1.75026219 1.97298519] , error: 0.698243002525061\n",
      "Weights: [1.74708307 1.97334877] , error: 0.6972202693400962\n",
      "Weights: [1.7439112  1.97371152] , error: 0.6962021953496823\n",
      "Weights: [1.74074656 1.97407344] , error: 0.69518875932825\n",
      "Weights: [1.73758913 1.97443453] , error: 0.694179940146927\n",
      "Weights: [1.73443891 1.97479481] , error: 0.6931757167730929\n",
      "Weights: [1.73129587 1.97515426] , error: 0.6921760682699498\n",
      "Weights: [1.72816    1.97551289] , error: 0.6911809737960747\n",
      "Weights: [1.72503128 1.9758707 ] , error: 0.6901904126049944\n",
      "Weights: [1.7219097 1.9762277] , error: 0.6892043640447466\n",
      "Weights: [1.71879523 1.97658388] , error: 0.6882228075574509\n",
      "Weights: [1.71568787 1.97693925] , error: 0.6872457226788848\n",
      "Weights: [1.71258759 1.97729382] , error: 0.68627308903805\n",
      "Weights: [1.70949438 1.97764757] , error: 0.6853048863567507\n",
      "Weights: [1.70640823 1.97800051] , error: 0.6843410944491742\n",
      "Weights: [1.70332911 1.97835265] , error: 0.6833816932214644\n",
      "Weights: [1.70025701 1.97870399] , error: 0.6824266626713041\n",
      "Weights: [1.69719192 1.97905453] , error: 0.681475982887504\n",
      "Weights: [1.69413382 1.97940427] , error: 0.6805296340495771\n",
      "Weights: [1.6910827  1.97975321] , error: 0.6795875964273372\n",
      "Weights: [1.68803853 1.98010135] , error: 0.6786498503804742\n",
      "Weights: [1.6850013 1.9804487] , error: 0.6777163763581605\n",
      "Weights: [1.681971   1.98079526] , error: 0.6767871548986276\n",
      "Weights: [1.67894761 1.98114102] , error: 0.6758621666287721\n",
      "Weights: [1.67593112 1.981486  ] , error: 0.6749413922637445\n",
      "Weights: [1.6729215 1.9818302] , error: 0.6740248126065531\n",
      "Weights: [1.66991875 1.9821736 ] , error: 0.6731124085476557\n",
      "Weights: [1.66692284 1.98251623] , error: 0.6722041610645721\n",
      "Weights: [1.66393377 1.98285807] , error: 0.6713000512214768\n",
      "Weights: [1.66095151 1.98319913] , error: 0.6704000601688116\n",
      "Weights: [1.65797605 1.98353942] , error: 0.6695041691428878\n",
      "Weights: [1.65500738 1.98387893] , error: 0.6686123594654992\n",
      "Weights: [1.65204548 1.98421767] , error: 0.6677246125435298\n",
      "Weights: [1.64909033 1.98455563] , error: 0.6668409098685666\n",
      "Weights: [1.64614193 1.98489282] , error: 0.6659612330165133\n",
      "Weights: [1.64320024 1.98522924] , error: 0.6650855636472085\n",
      "Weights: [1.64026526 1.9855649 ] , error: 0.6642138835040435\n",
      "Weights: [1.63733698 1.98589979] , error: 0.6633461744135742\n",
      "Weights: [1.63441538 1.98623392] , error: 0.6624824182851542\n",
      "Weights: [1.63150043 1.98656728] , error: 0.6616225971105488\n",
      "Weights: [1.62859214 1.98689989] , error: 0.6607666929635616\n",
      "Weights: [1.62569047 1.98723174] , error: 0.6599146879996604\n",
      "Weights: [1.62279543 1.98756283] , error: 0.6590665644556096\n",
      "Weights: [1.61990698 1.98789316] , error: 0.6582223046490933\n",
      "Weights: [1.61702512 1.98822274] , error: 0.6573818909783508\n",
      "Weights: [1.61414984 1.98855157] , error: 0.6565453059218094\n",
      "Weights: [1.61128111 1.98887965] , error: 0.6557125320377156\n",
      "Weights: [1.60841892 1.98920698] , error: 0.6548835519637778\n",
      "Weights: [1.60556326 1.98953357] , error: 0.6540583484167963\n",
      "Weights: [1.60271411 1.98985941] , error: 0.6532369041923105\n",
      "Weights: [1.59987146 1.99018451] , error: 0.6524192021642368\n",
      "Weights: [1.59703529 1.99050886] , error: 0.6516052252845097\n",
      "Weights: [1.59420559 1.99083248] , error: 0.6507949565827297\n",
      "Weights: [1.59138234 1.99115536] , error: 0.6499883791658092\n",
      "Weights: [1.58856553 1.9914775 ] , error: 0.6491854762176155\n",
      "Weights: [1.58575514 1.99179891] , error: 0.648386230998629\n",
      "Weights: [1.58295117 1.99211958] , error: 0.6475906268455862\n",
      "Weights: [1.58015358 1.99243953] , error: 0.6467986471711356\n",
      "Weights: [1.57736238 1.99275874] , error: 0.6460102754634917\n",
      "Weights: [1.57457754 1.99307723] , error: 0.6452254952860903\n",
      "Weights: [1.57179905 1.99339499] , error: 0.6444442902772478\n",
      "Weights: [1.5690269  1.99371202] , error: 0.6436666441498151\n",
      "Weights: [1.56626107 1.99402833] , error: 0.6428925406908448\n",
      "Weights: [1.56350155 1.99434392] , error: 0.6421219637612484\n",
      "Weights: [1.56074832 1.99465879] , error: 0.6413548972954594\n",
      "Weights: [1.55800136 1.99497295] , error: 0.6405913253011027\n",
      "Weights: [1.55526068 1.99528638] , error: 0.6398312318586575\n",
      "Weights: [1.55252624 1.99559911] , error: 0.6390746011211255\n",
      "Weights: [1.54979804 1.99591111] , error: 0.6383214173137033\n",
      "Weights: [1.54707606 1.99622241] , error: 0.6375716647334511\n",
      "Weights: [1.54436028 1.996533  ] , error: 0.636825327748964\n",
      "Weights: [1.5416507  1.99684288] , error: 0.6360823908000515\n",
      "Weights: [1.5389473  1.99715205] , error: 0.6353428383974056\n",
      "Weights: [1.53625006 1.99746052] , error: 0.6346066551222853\n",
      "Weights: [1.53355898 1.99776828] , error: 0.6338738256261898\n",
      "Weights: [1.53087403 1.99807534] , error: 0.6331443346305407\n",
      "Weights: [1.5281952  1.99838171] , error: 0.6324181669263648\n",
      "Weights: [1.52552249 1.99868737] , error: 0.6316953073739724\n",
      "Weights: [1.52285586 1.99899233] , error: 0.6309757409026455\n",
      "Weights: [1.52019532 1.99929661] , error: 0.6302594525103244\n",
      "Weights: [1.51754085 1.99960018] , error: 0.6295464272632927\n",
      "Weights: [1.51489243 1.99990307] , error: 0.6288366502958657\n",
      "Weights: [1.51225005 2.00020526] , error: 0.6281301068100814\n",
      "Weights: [1.50961369 2.00050677] , error: 0.6274267820753922\n",
      "Weights: [1.50698335 2.00080758] , error: 0.6267266614283562\n",
      "Weights: [1.504359   2.00110771] , error: 0.6260297302723348\n",
      "Weights: [1.50174064 2.00140716] , error: 0.6253359740771853\n",
      "Weights: [1.49912825 2.00170592] , error: 0.6246453783789584\n",
      "Weights: [1.49652182 2.00200401] , error: 0.6239579287795975\n",
      "Weights: [1.49392133 2.00230141] , error: 0.6232736109466395\n",
      "Weights: [1.49132677 2.00259813] , error: 0.622592410612914\n",
      "Weights: [1.48873813 2.00289418] , error: 0.6219143135762446\n",
      "Weights: [1.48615539 2.00318956] , error: 0.6212393056991575\n",
      "Weights: [1.48357854 2.00348425] , error: 0.6205673729085815\n",
      "Weights: [1.48100757 2.00377828] , error: 0.6198985011955607\n",
      "Weights: [1.47844246 2.00407164] , error: 0.619232676614956\n",
      "Weights: [1.4758832  2.00436433] , error: 0.6185698852851559\n",
      "Weights: [1.47332978 2.00465635] , error: 0.6179101133877937\n",
      "Weights: [1.47078218 2.0049477 ] , error: 0.6172533471674468\n",
      "Weights: [1.46824038 2.00523839] , error: 0.6165995729313652\n",
      "Weights: [1.46570439 2.00552842] , error: 0.61594877704917\n",
      "Weights: [1.46317418 2.00581778] , error: 0.6153009459525842\n",
      "Weights: [1.46064973 2.00610649] , error: 0.6146560661351397\n",
      "Weights: [1.45813105 2.00639454] , error: 0.6140141241518963\n",
      "Weights: [1.45561811 2.00668193] , error: 0.6133751066191698\n",
      "Weights: [1.4531109  2.00696866] , error: 0.6127390002142425\n",
      "Weights: [1.4506094  2.00725474] , error: 0.6121057916750926\n",
      "Weights: [1.44811361 2.00754017] , error: 0.6114754678001136\n",
      "Weights: [1.44562351 2.00782495] , error: 0.6108480154478408\n",
      "Weights: [1.4431391  2.00810908] , error: 0.610223421536678\n",
      "Weights: [1.44066034 2.00839256] , error: 0.609601673044624\n",
      "Weights: [1.43818724 2.0086754 ] , error: 0.6089827570090007\n",
      "Weights: [1.43571978 2.00895759] , error: 0.6083666605261824\n",
      "Weights: [1.43325794 2.00923913] , error: 0.6077533707513276\n",
      "Weights: [1.43080172 2.00952003] , error: 0.6071428748981125\n",
      "Weights: [1.4283511 2.0098003] , error: 0.6065351602384627\n",
      "Weights: [1.42590607 2.01007992] , error: 0.605930214102287\n",
      "Weights: [1.42346662 2.01035891] , error: 0.6053280238772156\n",
      "Weights: [1.42103272 2.01063726] , error: 0.6047285770083357\n",
      "Weights: [1.41860438 2.01091497] , error: 0.6041318609979305\n",
      "Weights: [1.41618158 2.01119206] , error: 0.6035378634052165\n",
      "Weights: [1.4137643  2.01146851] , error: 0.6029465718460876\n",
      "Weights: [1.41135253 2.01174433] , error: 0.6023579739928546\n",
      "Weights: [1.40894626 2.01201952] , error: 0.6017720575739891\n",
      "Weights: [1.40654548 2.01229408] , error: 0.6011888103738662\n",
      "Weights: [1.40415018 2.01256802] , error: 0.6006082202325105\n",
      "Weights: [1.40176034 2.01284133] , error: 0.6000302750453457\n",
      "Weights: [1.39937594 2.01311402] , error: 0.5994549627629354\n",
      "Weights: [1.39699699 2.01338609] , error: 0.5988822713907412\n",
      "Weights: [1.39462346 2.01365753] , error: 0.5983121889888633\n",
      "Weights: [1.39225534 2.01392836] , error: 0.5977447036717952\n",
      "Weights: [1.38989262 2.01419857] , error: 0.5971798036081796\n",
      "Weights: [1.38753529 2.01446817] , error: 0.5966174770205555\n",
      "Weights: [1.38518334 2.01473715] , error: 0.5960577121851186\n",
      "Weights: [1.38283675 2.01500551] , error: 0.595500497431471\n",
      "Weights: [1.38049551 2.01527327] , error: 0.5949458211423833\n",
      "Weights: [1.37815961 2.01554041] , error: 0.5943936717535488\n",
      "Weights: [1.37582903 2.01580694] , error: 0.5938440377533428\n",
      "Weights: [1.37350377 2.01607287] , error: 0.5932969076825843\n",
      "Weights: [1.37118382 2.01633819] , error: 0.5927522701342954\n",
      "Weights: [1.36886915 2.0166029 ] , error: 0.5922101137534646\n",
      "Weights: [1.36655976 2.01686702] , error: 0.59167042723681\n",
      "Weights: [1.36425564 2.01713053] , error: 0.5911331993325434\n",
      "Weights: [1.36195677 2.01739343] , error: 0.5905984188401342\n",
      "Weights: [1.35966315 2.01765574] , error: 0.5900660746100782\n",
      "Weights: [1.35737476 2.01791745] , error: 0.5895361555436645\n",
      "Weights: [1.35509158 2.01817857] , error: 0.5890086505927439\n",
      "Weights: [1.35281361 2.01843908] , error: 0.5884835487594967\n",
      "Weights: [1.35054084 2.01869901] , error: 0.587960839096207\n",
      "Weights: [1.34827325 2.01895834] , error: 0.5874405107050334\n",
      "Weights: [1.34601083 2.01921708] , error: 0.5869225527377788\n",
      "Weights: [1.34375356 2.01947523] , error: 0.5864069543956679\n",
      "Weights: [1.34150145 2.01973279] , error: 0.5858937049291211\n",
      "Weights: [1.33925447 2.01998976] , error: 0.585382793637528\n",
      "Weights: [1.33701262 2.02024615] , error: 0.5848742098690275\n",
      "Weights: [1.33477588 2.02050196] , error: 0.5843679430202843\n",
      "Weights: [1.33254424 2.02075717] , error: 0.5838639825362681\n",
      "Weights: [1.33031769 2.02101181] , error: 0.5833623179100341\n",
      "Weights: [1.32809621 2.02126587] , error: 0.5828629386825006\n",
      "Weights: [1.3258798  2.02151935] , error: 0.5823658344422363\n",
      "Weights: [1.32366845 2.02177225] , error: 0.5818709948252406\n",
      "Weights: [1.32146214 2.02202457] , error: 0.5813784095147243\n",
      "Weights: [1.31926086 2.02227632] , error: 0.5808880682409027\n",
      "Weights: [1.3170646  2.02252749] , error: 0.5803999607807719\n",
      "Weights: [1.31487335 2.02277809] , error: 0.5799140769579022\n",
      "Weights: [1.31268709 2.02302812] , error: 0.5794304066422243\n",
      "Weights: [1.31050582 2.02327758] , error: 0.5789489397498162\n",
      "Weights: [1.30832953 2.02352647] , error: 0.578469666242696\n",
      "Weights: [1.30615819 2.02377479] , error: 0.577992576128611\n",
      "Weights: [1.30399181 2.02402255] , error: 0.5775176594608296\n",
      "Weights: [1.30183037 2.02426974] , error: 0.5770449063379323\n",
      "Weights: [1.29967386 2.02451637] , error: 0.5765743069036087\n",
      "Weights: [1.29752227 2.02476243] , error: 0.5761058513464492\n",
      "Weights: [1.29537558 2.02500794] , error: 0.5756395298997407\n",
      "Weights: [1.29323379 2.02525288] , error: 0.5751753328412651\n",
      "Weights: [1.29109688 2.02549727] , error: 0.5747132504930942\n",
      "Weights: [1.28896485 2.0257411 ] , error: 0.574253273221389\n",
      "Weights: [1.28683768 2.02598437] , error: 0.5737953914361995\n",
      "Weights: [1.28471535 2.02622709] , error: 0.5733395955912635\n",
      "Weights: [1.28259787 2.02646925] , error: 0.5728858761838058\n",
      "Weights: [1.28048522 2.02671086] , error: 0.5724342237543464\n",
      "Weights: [1.27837738 2.02695192] , error: 0.5719846288864973\n",
      "Weights: [1.27627435 2.02719244] , error: 0.571537082206766\n",
      "Weights: [1.27417612 2.0274324 ] , error: 0.5710915743843661\n",
      "Weights: [1.27208267 2.02767181] , error: 0.5706480961310161\n",
      "Weights: [1.269994   2.02791068] , error: 0.570206638200748\n",
      "Weights: [1.26791009 2.02814901] , error: 0.5697671913897185\n",
      "Weights: [1.26583093 2.02838679] , error: 0.5693297465360099\n",
      "Weights: [1.26375651 2.02862403] , error: 0.5688942945194445\n",
      "Weights: [1.26168682 2.02886073] , error: 0.5684608262613929\n",
      "Weights: [1.25962186 2.02909689] , error: 0.5680293327245832\n",
      "Weights: [1.2575616  2.02933251] , error: 0.5675998049129167\n",
      "Weights: [1.25550604 2.02956759] , error: 0.5671722338712737\n",
      "Weights: [1.25345517 2.02980213] , error: 0.5667466106853346\n",
      "Weights: [1.25140897 2.03003615] , error: 0.5663229264813876\n",
      "Weights: [1.24936744 2.03026962] , error: 0.5659011724261477\n",
      "Weights: [1.24733057 2.03050257] , error: 0.5654813397265699\n",
      "Weights: [1.24529834 2.03073498] , error: 0.5650634196296673\n",
      "Weights: [1.24327074 2.03096687] , error: 0.5646474034223303\n",
      "Weights: [1.24124777 2.03119822] , error: 0.5642332824311396\n",
      "Weights: [1.23922941 2.03142905] , error: 0.5638210480221915\n",
      "Weights: [1.23721566 2.03165935] , error: 0.5634106916009143\n",
      "Weights: [1.2352065  2.03188913] , error: 0.5630022046118898\n",
      "Weights: [1.23320191 2.03211838] , error: 0.5625955785386744\n",
      "Weights: [1.2312019  2.03234711] , error: 0.5621908049036256\n",
      "Weights: [1.22920646 2.03257532] , error: 0.561787875267717\n",
      "Weights: [1.22721556 2.03280301] , error: 0.561386781230371\n",
      "Weights: [1.2252292  2.03303018] , error: 0.5609875144292783\n",
      "Weights: [1.22324737 2.03325683] , error: 0.5605900665402254\n",
      "Weights: [1.22127006 2.03348296] , error: 0.5601944292769224\n",
      "Weights: [1.21929726 2.03370858] , error: 0.559800594390825\n",
      "Weights: [1.21732896 2.03393368] , error: 0.5594085536709706\n",
      "Weights: [1.21536515 2.03415827] , error: 0.5590182989437996\n",
      "Weights: [1.21340581 2.03438235] , error: 0.55862982207299\n",
      "Weights: [1.21145094 2.03460591] , error: 0.5582431149592829\n",
      "Weights: [1.20950054 2.03482897] , error: 0.5578581695403214\n",
      "Weights: [1.20755457 2.03505152] , error: 0.557474977790474\n",
      "Weights: [1.20561305 2.03527356] , error: 0.5570935317206716\n",
      "Weights: [1.20367596 2.03549509] , error: 0.5567138233782405\n",
      "Weights: [1.20174328 2.03571612] , error: 0.5563358448467394\n",
      "Weights: [1.19981501 2.03593665] , error: 0.5559595882457855\n",
      "Weights: [1.19789113 2.03615667] , error: 0.5555850457309007\n",
      "Weights: [1.19597165 2.03637619] , error: 0.5552122094933432\n",
      "Weights: [1.19405654 2.03659521] , error: 0.5548410717599416\n",
      "Weights: [1.19214579 2.03681373] , error: 0.5544716247929411\n",
      "Weights: [1.19023941 2.03703176] , error: 0.5541038608898328\n",
      "Weights: [1.18833737 2.03724928] , error: 0.5537377723831987\n",
      "Weights: [1.18643967 2.03746631] , error: 0.5533733516405538\n",
      "Weights: [1.1845463  2.03768284] , error: 0.5530105910641804\n",
      "Weights: [1.18265724 2.03789888] , error: 0.5526494830909744\n",
      "Weights: [1.1807725  2.03811443] , error: 0.5522900201922858\n",
      "Weights: [1.17889205 2.03832949] , error: 0.5519321948737625\n",
      "Weights: [1.17701589 2.03854405] , error: 0.5515759996751958\n",
      "Weights: [1.175144   2.03875813] , error: 0.5512214271703612\n",
      "Weights: [1.17327639 2.03897172] , error: 0.550868469966862\n",
      "Weights: [1.17141304 2.03918482] , error: 0.5505171207059876\n",
      "Weights: [1.16955393 2.03939743] , error: 0.5501673720625422\n",
      "Weights: [1.16769906 2.03960956] , error: 0.5498192167447041\n",
      "Weights: [1.16584843 2.03982121] , error: 0.5494726474938723\n",
      "Weights: [1.16400201 2.04003237] , error: 0.5491276570845093\n",
      "Weights: [1.16215981 2.04024306] , error: 0.5487842383239975\n",
      "Weights: [1.1603218  2.04045326] , error: 0.5484423840524861\n",
      "Weights: [1.15848799 2.04066298] , error: 0.548102087142741\n",
      "Weights: [1.15665836 2.04087223] , error: 0.5477633404999958\n",
      "Weights: [1.1548329  2.04108099] , error: 0.5474261370618084\n",
      "Weights: [1.1530116  2.04128928] , error: 0.5470904697979087\n",
      "Weights: [1.15119446 2.0414971 ] , error: 0.5467563317100531\n",
      "Weights: [1.14938146 2.04170444] , error: 0.5464237158318831\n",
      "Weights: [1.1475726  2.04191131] , error: 0.5460926152287711\n",
      "Weights: [1.14576786 2.04211771] , error: 0.5457630229976842\n",
      "Weights: [1.14396723 2.04232364] , error: 0.5454349322670373\n",
      "Weights: [1.14217072 2.04252909] , error: 0.5451083361965492\n",
      "Weights: [1.1403783  2.04273408] , error: 0.5447832279770998\n",
      "Weights: [1.13858996 2.0429386 ] , error: 0.5444596008305896\n",
      "Weights: [1.13680571 2.04314266] , error: 0.5441374480097988\n",
      "Weights: [1.13502552 2.04334625] , error: 0.5438167627982418\n",
      "Weights: [1.13324939 2.04354937] , error: 0.5434975385100345\n",
      "Weights: [1.13147732 2.04375204] , error: 0.5431797684897496\n",
      "Weights: [1.12970928 2.04395424] , error: 0.5428634461122804\n",
      "Weights: [1.12794528 2.04415597] , error: 0.5425485647827007\n",
      "Weights: [1.1261853  2.04435725] , error: 0.5422351179361269\n",
      "Weights: [1.12442933 2.04455807] , error: 0.5419230990375866\n",
      "Weights: [1.12267736 2.04475844] , error: 0.5416125015818749\n",
      "Weights: [1.1209294  2.04495834] , error: 0.5413033190934239\n",
      "Weights: [1.11918542 2.04515779] , error: 0.5409955451261675\n",
      "Weights: [1.11744541 2.04535678] , error: 0.5406891732633989\n",
      "Weights: [1.11570937 2.04555532] , error: 0.5403841971176525\n",
      "Weights: [1.11397729 2.04575341] , error: 0.540080610330554\n",
      "Weights: [1.11224917 2.04595105] , error: 0.5397784065727002\n",
      "Weights: [1.11052498 2.04614823] , error: 0.5394775795435216\n",
      "Weights: [1.10880472 2.04634497] , error: 0.5391781229711489\n",
      "Weights: [1.10708839 2.04654126] , error: 0.5388800306122888\n",
      "Weights: [1.10537597 2.0467371 ] , error: 0.5385832962520881\n",
      "Weights: [1.10366746 2.04693249] , error: 0.5382879137040059\n",
      "Weights: [1.10196284 2.04712744] , error: 0.5379938768096862\n",
      "Weights: [1.10026211 2.04732194] , error: 0.537701179438829\n",
      "Weights: [1.09856526 2.047516  ] , error: 0.5374098154890578\n",
      "Weights: [1.09687228 2.04770961] , error: 0.5371197788857996\n",
      "Weights: [1.09518315 2.04790279] , error: 0.5368310635821553\n",
      "Weights: [1.09349789 2.04809552] , error: 0.5365436635587705\n",
      "Weights: [1.09181646 2.04828782] , error: 0.5362575728237149\n",
      "Weights: [1.09013887 2.04847968] , error: 0.5359727854123538\n",
      "Weights: [1.0884651  2.04867109] , error: 0.5356892953872281\n",
      "Weights: [1.08679515 2.04886208] , error: 0.5354070968379224\n",
      "Weights: [1.08512901 2.04905262] , error: 0.5351261838809529\n",
      "Weights: [1.08346667 2.04924274] , error: 0.5348465506596332\n",
      "Weights: [1.08180811 2.04943242] , error: 0.5345681913439622\n",
      "Weights: [1.08015335 2.04962166] , error: 0.5342911001304964\n",
      "Weights: [1.07850235 2.04981048] , error: 0.5340152712422294\n",
      "Weights: [1.07685512 2.04999886] , error: 0.5337406989284762\n",
      "Weights: [1.07521164 2.05018682] , error: 0.5334673774647445\n",
      "Weights: [1.07357192 2.05037434] , error: 0.5331953011526265\n",
      "Weights: [1.07193593 2.05056144] , error: 0.5329244643196692\n",
      "Weights: [1.07030367 2.05074811] , error: 0.5326548613192651\n",
      "Weights: [1.06867514 2.05093436] , error: 0.5323864865305279\n",
      "Weights: [1.06705032 2.05112018] , error: 0.5321193343581804\n",
      "Weights: [1.0654292  2.05130558] , error: 0.5318533992324328\n",
      "Weights: [1.06381179 2.05149055] , error: 0.5315886756088695\n",
      "Weights: [1.06219806 2.0516751 ] , error: 0.5313251579683365\n",
      "Weights: [1.06058801 2.05185924] , error: 0.5310628408168195\n",
      "Weights: [1.05898163 2.05204295] , error: 0.5308017186853338\n",
      "Weights: [1.05737891 2.05222624] , error: 0.5305417861298091\n",
      "Weights: [1.05577985 2.05240912] , error: 0.5302830377309787\n",
      "Weights: [1.05418444 2.05259158] , error: 0.5300254680942595\n",
      "Weights: [1.05259266 2.05277362] , error: 0.5297690718496499\n",
      "Weights: [1.05100452 2.05295524] , error: 0.5295138436516065\n",
      "Weights: [1.04941999 2.05313646] , error: 0.5292597781789422\n",
      "Weights: [1.04783908 2.05331726] , error: 0.5290068701347077\n",
      "Weights: [1.04626178 2.05349764] , error: 0.5287551142460899\n",
      "Weights: [1.04468807 2.05367762] , error: 0.5285045052642909\n",
      "Weights: [1.04311795 2.05385719] , error: 0.5282550379644261\n",
      "Weights: [1.04155141 2.05403634] , error: 0.5280067071454179\n",
      "Weights: [1.03998844 2.05421509] , error: 0.5277595076298773\n",
      "Weights: [1.03842904 2.05439343] , error: 0.5275134342640029\n",
      "Weights: [1.03687319 2.05457136] , error: 0.5272684819174746\n",
      "Weights: [1.03532089 2.05474889] , error: 0.5270246454833407\n",
      "Weights: [1.03377213 2.05492601] , error: 0.5267819198779183\n",
      "Weights: [1.03222691 2.05510273] , error: 0.5265403000406806\n",
      "Weights: [1.0306852  2.05527905] , error: 0.5262997809341572\n",
      "Weights: [1.02914701 2.05545496] , error: 0.5260603575438252\n",
      "Weights: [1.02761233 2.05563047] , error: 0.5258220248780068\n",
      "Weights: [1.02608115 2.05580559] , error: 0.525584777967764\n",
      "Weights: [1.02455347 2.0559803 ] , error: 0.5253486118667956\n",
      "Weights: [1.02302926 2.05615461] , error: 0.5251135216513338\n",
      "Weights: [1.02150853 2.05632853] , error: 0.5248795024200412\n",
      "Weights: [1.01999127 2.05650205] , error: 0.5246465492939101\n",
      "Weights: [1.01847747 2.05667517] , error: 0.5244146574161594\n",
      "Weights: [1.01696712 2.0568479 ] , error: 0.5241838219521333\n",
      "Weights: [1.01546022 2.05702024] , error: 0.5239540380892004\n",
      "Weights: [1.01395675 2.05719218] , error: 0.5237253010366564\n",
      "Weights: [1.01245671 2.05736373] , error: 0.5234976060256179\n",
      "Weights: [1.01096009 2.05753489] , error: 0.5232709483089306\n",
      "Weights: [1.00946688 2.05770566] , error: 0.5230453231610636\n",
      "Weights: [1.00797708 2.05787604] , error: 0.5228207258780145\n",
      "Weights: [1.00649068 2.05804603] , error: 0.5225971517772132\n",
      "Weights: [1.00500766 2.05821564] , error: 0.522374596197415\n",
      "Weights: [1.00352803 2.05838486] , error: 0.522153054498618\n",
      "Weights: [1.00205177 2.05855369] , error: 0.5219325220619546\n",
      "Weights: [1.00057888 2.05872213] , error: 0.5217129942895992\n",
      "Weights: [0.99910935 2.05889019] , error: 0.5214944666046711\n",
      "Weights: [0.99764317 2.05905787] , error: 0.5212769344511429\n",
      "Weights: [0.99618033 2.05922517] , error: 0.5210603932937405\n",
      "Weights: [0.99472083 2.05939208] , error: 0.5208448386178525\n",
      "Weights: [0.99326465 2.05955862] , error: 0.5206302659294326\n",
      "Weights: [0.9918118  2.05972477] , error: 0.5204166707549086\n",
      "Weights: [0.99036226 2.05989055] , error: 0.5202040486410892\n",
      "Weights: [0.98891602 2.06005595] , error: 0.5199923951550691\n",
      "Weights: [0.98747309 2.06022097] , error: 0.5197817058841385\n",
      "Weights: [0.98603344 2.06038561] , error: 0.5195719764356874\n",
      "Weights: [0.98459708 2.06054988] , error: 0.5193632024371221\n",
      "Weights: [0.98316399 2.06071377] , error: 0.5191553795357643\n",
      "Weights: [0.98173417 2.06087729] , error: 0.5189485033987662\n",
      "Weights: [0.98030761 2.06104044] , error: 0.5187425697130201\n",
      "Weights: [0.97888431 2.06120322] , error: 0.5185375741850653\n",
      "Weights: [0.97746425 2.06136562] , error: 0.5183335125410022\n",
      "Weights: [0.97604743 2.06152765] , error: 0.5181303805264007\n",
      "Weights: [0.97463383 2.06168932] , error: 0.5179281739062128\n",
      "Weights: [0.97322347 2.06185061] , error: 0.5177268884646824\n",
      "Weights: [0.97181632 2.06201154] , error: 0.5175265200052609\n",
      "Weights: [0.97041237 2.0621721 ] , error: 0.517327064350516\n",
      "Weights: [0.96901163 2.0623323 ] , error: 0.5171285173420467\n",
      "Weights: [0.96761409 2.06249213] , error: 0.5169308748403966\n",
      "Weights: [0.96621973 2.06265159] , error: 0.5167341327249667\n",
      "Weights: [0.96482855 2.06281069] , error: 0.5165382868939297\n",
      "Weights: [0.96344054 2.06296943] , error: 0.5163433332641463\n",
      "Weights: [0.9620557  2.06312781] , error: 0.5161492677710755\n",
      "Weights: [0.96067401 2.06328582] , error: 0.5159560863686953\n",
      "Weights: [0.95929548 2.06344348] , error: 0.5157637850294158\n",
      "Weights: [0.95792009 2.06360077] , error: 0.5155723597439934\n",
      "Weights: [0.95654784 2.06375771] , error: 0.515381806521451\n",
      "Weights: [0.95517872 2.06391429] , error: 0.515192121388993\n",
      "Weights: [0.95381271 2.06407051] , error: 0.5150033003919201\n",
      "Weights: [0.95244983 2.06422637] , error: 0.5148153395935515\n",
      "Weights: [0.95109005 2.06438188] , error: 0.5146282350751402\n",
      "Weights: [0.94973337 2.06453704] , error: 0.51444198293579\n",
      "Weights: [0.94837979 2.06469184] , error: 0.5142565792923788\n",
      "Weights: [0.94702929 2.06484629] , error: 0.5140720202794709\n",
      "Weights: [0.94568187 2.06500039] , error: 0.5138883020492407\n",
      "Weights: [0.94433753 2.06515413] , error: 0.5137054207713951\n",
      "Weights: [0.94299625 2.06530753] , error: 0.5135233726330876\n",
      "Weights: [0.94165803 2.06546057] , error: 0.5133421538388431\n",
      "Weights: [0.94032286 2.06561327] , error: 0.5131617606104737\n",
      "Weights: [0.93899074 2.06576561] , error: 0.5129821891870092\n",
      "Weights: [0.93766165 2.06591761] , error: 0.512803435824608\n",
      "Weights: [0.93633559 2.06606927] , error: 0.5126254967964875\n",
      "Weights: [0.93501256 2.06622057] , error: 0.5124483683928411\n",
      "Weights: [0.93369255 2.06637154] , error: 0.5122720469207631\n",
      "Weights: [0.93237554 2.06652215] , error: 0.5120965287041713\n",
      "Weights: [0.93106154 2.06667243] , error: 0.5119218100837309\n",
      "Weights: [0.92975054 2.06682236] , error: 0.5117478874167768\n",
      "Weights: [0.92844252 2.06697195] , error: 0.5115747570772392\n",
      "Weights: [0.92713749 2.0671212 ] , error: 0.5114024154555674\n",
      "Weights: [0.92583544 2.06727011] , error: 0.5112308589586527\n",
      "Weights: [0.92453635 2.06741868] , error: 0.5110600840097586\n",
      "Weights: [0.92324023 2.06756691] , error: 0.5108900870484406\n",
      "Weights: [0.92194706 2.0677148 ] , error: 0.5107208645304736\n",
      "Weights: [0.92065684 2.06786235] , error: 0.5105524129277816\n",
      "Weights: [0.91936956 2.06800957] , error: 0.5103847287283583\n",
      "Weights: [0.91808522 2.06815646] , error: 0.5102178084361979\n",
      "Weights: [0.91680381 2.068303  ] , error: 0.5100516485712211\n",
      "Weights: [0.91552532 2.06844922] , error: 0.5098862456692024\n",
      "Weights: [0.91424974 2.0685951 ] , error: 0.5097215962816999\n",
      "Weights: [0.91297707 2.06874064] , error: 0.509557696975978\n",
      "Weights: [0.91170731 2.06888586] , error: 0.5093945443349417\n",
      "Weights: [0.91044044 2.06903074] , error: 0.5092321349570622\n",
      "Weights: [0.90917646 2.0691753 ] , error: 0.5090704654563082\n",
      "Weights: [0.90791536 2.06931952] , error: 0.5089095324620724\n",
      "Weights: [0.90665714 2.06946342] , error: 0.5087493326191024\n",
      "Weights: [0.90540179 2.06960699] , error: 0.5085898625874331\n",
      "Weights: [0.9041493  2.06975023] , error: 0.5084311190423129\n",
      "Weights: [0.90289967 2.06989314] , error: 0.5082730986741382\n",
      "Weights: [0.90165288 2.07003573] , error: 0.5081157981883813\n",
      "Weights: [0.90040894 2.07017799] , error: 0.507959214305524\n",
      "Weights: [0.89916784 2.07031993] , error: 0.5078033437609888\n",
      "Weights: [0.89792957 2.07046154] , error: 0.507648183305069\n",
      "Weights: [0.89669412 2.07060283] , error: 0.5074937297028641\n",
      "Weights: [0.89546148 2.0707438 ] , error: 0.5073399797342094\n",
      "Weights: [0.89423166 2.07088445] , error: 0.5071869301936108\n",
      "Weights: [0.89300465 2.07102478] , error: 0.5070345778901751\n",
      "Weights: [0.89178043 2.07116478] , error: 0.5068829196475498\n",
      "Weights: [0.890559   2.07130447] , error: 0.5067319523038478\n",
      "Weights: [0.88934036 2.07144384] , error: 0.506581672711591\n",
      "Weights: [0.8881245  2.07158289] , error: 0.506432077737637\n",
      "Weights: [0.88691141 2.07172162] , error: 0.5062831642631171\n",
      "Weights: [0.88570108 2.07186004] , error: 0.5061349291833731\n",
      "Weights: [0.88449352 2.07199814] , error: 0.5059873694078882\n",
      "Weights: [0.88328871 2.07213593] , error: 0.5058404818602252\n",
      "Weights: [0.88208665 2.0722734 ] , error: 0.5056942634779634\n",
      "Weights: [0.88088732 2.07241056] , error: 0.5055487112126315\n",
      "Weights: [0.87969074 2.07254741] , error: 0.5054038220296486\n",
      "Weights: [0.87849688 2.07268394] , error: 0.5052595929082541\n",
      "Weights: [0.87730575 2.07282017] , error: 0.5051160208414536\n",
      "Weights: [0.87611733 2.07295608] , error: 0.5049731028359474\n",
      "Weights: [0.87493162 2.07309168] , error: 0.5048308359120746\n",
      "Weights: [0.87374861 2.07322698] , error: 0.5046892171037474\n",
      "Weights: [0.87256831 2.07336196] , error: 0.5045482434583912\n",
      "Weights: [0.87139069 2.07349664] , error: 0.5044079120368814\n",
      "Weights: [0.87021576 2.07363101] , error: 0.5042682199134839\n",
      "Weights: [0.86904351 2.07376507] , error: 0.5041291641757929\n",
      "Weights: [0.86787393 2.07389883] , error: 0.5039907419246701\n",
      "Weights: [0.86670702 2.07403228] , error: 0.5038529502741844\n",
      "Weights: [0.86554277 2.07416543] , error: 0.5037157863515522\n",
      "Weights: [0.86438118 2.07429828] , error: 0.5035792472970775\n",
      "Weights: [0.86322223 2.07443082] , error: 0.5034433302640924\n",
      "Weights: [0.86206593 2.07456306] , error: 0.5033080324188949\n",
      "Weights: [0.86091226 2.074695  ] , error: 0.5031733509406962\n",
      "Weights: [0.85976123 2.07482663] , error: 0.5030392830215553\n",
      "Weights: [0.85861282 2.07495797] , error: 0.5029058258663236\n",
      "Weights: [0.85746703 2.07508901] , error: 0.5027729766925866\n",
      "Weights: [0.85632385 2.07521975] , error: 0.502640732730605\n",
      "Weights: [0.85518328 2.07535019] , error: 0.5025090912232579\n",
      "Weights: [0.85404531 2.07548033] , error: 0.5023780494259851\n",
      "Weights: [0.85290993 2.07561018] , error: 0.5022476046067282\n",
      "Weights: [0.85177715 2.07573973] , error: 0.5021177540458756\n",
      "Weights: [0.85064694 2.07586898] , error: 0.5019884950362067\n",
      "Weights: [0.84951932 2.07599794] , error: 0.5018598248828311\n",
      "Weights: [0.84839426 2.07612661] , error: 0.5017317409031388\n",
      "Weights: [0.84727178 2.07625498] , error: 0.501604240426739\n",
      "Weights: [0.84615185 2.07638306] , error: 0.5014773207954055\n",
      "Weights: [0.84503447 2.07651085] , error: 0.5013509793630232\n",
      "Weights: [0.84391964 2.07663834] , error: 0.5012252134955303\n",
      "Weights: [0.84280736 2.07676555] , error: 0.5011000205708673\n",
      "Weights: [0.84169761 2.07689246] , error: 0.5009753979789171\n",
      "Weights: [0.84059039 2.07701909] , error: 0.5008513431214553\n",
      "Weights: [0.8394857  2.07714543] , error: 0.5007278534120936\n",
      "Weights: [0.83838353 2.07727148] , error: 0.5006049262762245\n",
      "Weights: [0.83728387 2.07739724] , error: 0.5004825591509725\n",
      "Weights: [0.83618672 2.07752271] , error: 0.5003607494851359\n",
      "Weights: [0.83509207 2.0776479 ] , error: 0.5002394947391351\n",
      "Weights: [0.83399991 2.07777281] , error: 0.5001187923849616\n",
      "Weights: [0.83291025 2.07789742] , error: 0.49999863990611937\n",
      "Weights: [0.83182307 2.07802176] , error: 0.49987903479758317\n",
      "Weights: [0.83073837 2.07814581] , error: 0.4997599745657328\n",
      "Weights: [0.82965614 2.07826958] , error: 0.4996414567283146\n",
      "Weights: [0.82857639 2.07839306] , error: 0.49952347881437753\n",
      "Weights: [0.82749909 2.07851627] , error: 0.49940603836422987\n",
      "Weights: [0.82642425 2.07863919] , error: 0.499289132929386\n",
      "Weights: [0.82535186 2.07876183] , error: 0.49917276007251443\n",
      "Weights: [0.82428192 2.0788842 ] , error: 0.499056917367385\n",
      "Weights: [0.82321442 2.07900628] , error: 0.4989416023988237\n",
      "Weights: [0.82214935 2.07912809] , error: 0.49882681276265683\n",
      "Weights: [0.82108671 2.07924961] , error: 0.4987125460656637\n",
      "Weights: [0.8200265  2.07937086] , error: 0.49859879992552736\n",
      "Weights: [0.8189687  2.07949184] , error: 0.4984855719707829\n",
      "Weights: [0.81791331 2.07961254] , error: 0.49837285984076957\n",
      "Weights: [0.81686033 2.07973296] , error: 0.4982606611855801\n",
      "Weights: [0.81580975 2.07985311] , error: 0.4981489736660128\n",
      "Weights: [0.81476157 2.07997298] , error: 0.49803779495352324\n",
      "Weights: [0.81371578 2.08009258] , error: 0.4979271227301724\n",
      "Weights: [0.81267237 2.08021191] , error: 0.4978169546885857\n",
      "Weights: [0.81163134 2.08033097] , error: 0.4977072885318945\n",
      "Weights: [0.81059269 2.08044975] , error: 0.49759812197369896\n",
      "Weights: [0.80955641 2.08056827] , error: 0.4974894527380115\n",
      "Weights: [0.80852248 2.08068651] , error: 0.4973812785592152\n",
      "Weights: [0.80749092 2.08080449] , error: 0.4972735971820132\n",
      "Weights: [0.80646171 2.08092219] , error: 0.4971664063613839\n",
      "Weights: [0.80543484 2.08103963] , error: 0.4970597038625321\n",
      "Weights: [0.80441032 2.0811568 ] , error: 0.496953487460845\n",
      "Weights: [0.80338813 2.0812737 ] , error: 0.49684775494184447\n",
      "Weights: [0.80236828 2.08139033] , error: 0.49674250410113663\n",
      "Weights: [0.80135075 2.0815067 ] , error: 0.4966377327443761\n",
      "Weights: [0.80033554 2.08162281] , error: 0.4965334386872109\n",
      "Weights: [0.79932264 2.08173864] , error: 0.49642961975523825\n",
      "Weights: [0.79831206 2.08185422] , error: 0.4963262737839655\n",
      "Weights: [0.79730378 2.08196953] , error: 0.4962233986187567\n",
      "Weights: [0.79629779 2.08208458] , error: 0.4961209921147949\n",
      "Weights: [0.79529411 2.08219936] , error: 0.4960190521370315\n",
      "Weights: [0.79429271 2.08231389] , error: 0.49591757656014634\n",
      "Weights: [0.79329359 2.08242815] , error: 0.49581656326850027\n",
      "Weights: [0.79229676 2.08254215] , error: 0.4957160101560924\n",
      "Weights: [0.7913022 2.0826559] , error: 0.49561591512651665\n",
      "Weights: [0.7903099  2.08276938] , error: 0.4955162760929158\n",
      "Weights: [0.78931987 2.0828826 ] , error: 0.4954170909779405\n",
      "Weights: [0.78833209 2.08299557] , error: 0.49531835771370725\n",
      "Weights: [0.78734657 2.08310828] , error: 0.4952200742417485\n",
      "Weights: [0.7863633  2.08322073] , error: 0.4951222385129789\n",
      "Weights: [0.78538227 2.08333292] , error: 0.49502484848764555\n",
      "Weights: [0.78440347 2.08344486] , error: 0.49492790213528703\n",
      "Weights: [0.78342691 2.08355655] , error: 0.4948313974346935\n",
      "Weights: [0.78245257 2.08366798] , error: 0.4947353323738632\n",
      "Weights: [0.78148046 2.08377915] , error: 0.4946397049499596\n",
      "Weights: [0.78051056 2.08389007] , error: 0.49454451316927095\n",
      "Weights: [0.77954287 2.08400074] , error: 0.4944497550471676\n",
      "Weights: [0.7785774  2.08411116] , error: 0.4943554286080602\n",
      "Weights: [0.77761412 2.08422132] , error: 0.4942615318853618\n",
      "Weights: [0.77665304 2.08433124] , error: 0.49416806292144233\n",
      "Weights: [0.77569415 2.0844409 ] , error: 0.4940750197675913\n",
      "Weights: [0.77473745 2.08455031] , error: 0.49398240048397524\n",
      "Weights: [0.77378293 2.08465947] , error: 0.49389020313959786\n",
      "Weights: [0.77283058 2.08476839] , error: 0.49379842581225997\n",
      "Weights: [0.77188041 2.08487705] , error: 0.49370706658851965\n",
      "Weights: [0.77093241 2.08498547] , error: 0.4936161235636506\n",
      "Weights: [0.76998656 2.08509364] , error: 0.49352559484160397\n",
      "Weights: [0.76904288 2.08520157] , error: 0.4934354785349707\n",
      "Weights: [0.76810134 2.08530924] , error: 0.4933457727649372\n",
      "Weights: [0.76716195 2.08541668] , error: 0.4932564756612521\n",
      "Weights: [0.76622471 2.08552386] , error: 0.4931675853621804\n",
      "Weights: [0.7652896  2.08563081] , error: 0.49307910001447164\n",
      "Weights: [0.76435662 2.08573751] , error: 0.4929910177733168\n",
      "Weights: [0.76342578 2.08584396] , error: 0.4929033368023118\n",
      "Weights: [0.76249705 2.08595017] , error: 0.4928160552734176\n",
      "Weights: [0.76157044 2.08605615] , error: 0.4927291713669227\n",
      "Weights: [0.76064595 2.08616187] , error: 0.4926426832714085\n",
      "Weights: [0.75972356 2.08626736] , error: 0.4925565891837047\n",
      "Weights: [0.75880328 2.08637261] , error: 0.4924708873088583\n",
      "Weights: [0.7578851  2.08647762] , error: 0.49238557586009146\n",
      "Weights: [0.75696901 2.08658238] , error: 0.49230065305876725\n",
      "Weights: [0.75605501 2.08668691] , error: 0.4922161171343522\n",
      "Weights: [0.75514309 2.0867912 ] , error: 0.4921319663243777\n",
      "Weights: [0.75423325 2.08689526] , error: 0.492048198874405\n",
      "Weights: [0.75332549 2.08699907] , error: 0.49196481303798656\n",
      "Weights: [0.7524198  2.08710265] , error: 0.49188180707663276\n",
      "Weights: [0.75151617 2.08720599] , error: 0.4917991792597739\n",
      "Weights: [0.7506146 2.0873091] , error: 0.49171692786472154\n",
      "Weights: [0.74971509 2.08741197] , error: 0.4916350511766379\n",
      "Weights: [0.74881764 2.08751461] , error: 0.4915535474884979\n",
      "Weights: [0.74792222 2.08761701] , error: 0.4914724151010491\n",
      "Weights: [0.74702885 2.08771918] , error: 0.4913916523227836\n",
      "Weights: [0.74613752 2.08782112] , error: 0.4913112574698994\n",
      "Weights: [0.74524822 2.08792282] , error: 0.49123122886626436\n",
      "Weights: [0.74436095 2.0880243 ] , error: 0.4911515648433803\n",
      "Weights: [0.7434757  2.08812554] , error: 0.49107226374035406\n",
      "Weights: [0.74259246 2.08822655] , error: 0.490993323903856\n",
      "Weights: [0.74171125 2.08832733] , error: 0.4909147436880892\n",
      "Weights: [0.74083204 2.08842788] , error: 0.4908365214547548\n",
      "Weights: [0.73995484 2.0885282 ] , error: 0.49075865557301745\n",
      "Weights: [0.73907964 2.08862829] , error: 0.490681144419469\n",
      "Weights: [0.73820643 2.08872815] , error: 0.4906039863781013\n",
      "Weights: [0.73733522 2.08882779] , error: 0.4905271798402646\n",
      "Weights: [0.73646599 2.0889272 ] , error: 0.490450723204639\n",
      "Weights: [0.73559874 2.08902638] , error: 0.49037461487719936\n",
      "Weights: [0.73473348 2.08912533] , error: 0.4902988532711806\n",
      "Weights: [0.73387018 2.08922406] , error: 0.4902234368070506\n",
      "Weights: [0.73300885 2.08932257] , error: 0.49014836391246913\n",
      "Weights: [0.73214949 2.08942085] , error: 0.49007363302226\n",
      "Weights: [0.73129209 2.08951891] , error: 0.4899992425783771\n",
      "Weights: [0.73043664 2.08961674] , error: 0.48992519102987453\n",
      "Weights: [0.72958315 2.08971435] , error: 0.4898514768328701\n",
      "Weights: [0.7287316  2.08981173] , error: 0.4897780984505131\n",
      "Weights: [0.72788199 2.0899089 ] , error: 0.48970505435295736\n",
      "Weights: [0.72703432 2.09000584] , error: 0.4896323430173247\n",
      "Weights: [0.72618858 2.09010256] , error: 0.48955996292767373\n",
      "Weights: [0.72534477 2.09019907] , error: 0.4894879125749714\n",
      "Weights: [0.72450289 2.09029535] , error: 0.4894161904570584\n",
      "Weights: [0.72366292 2.09039141] , error: 0.4893447950786172\n",
      "Weights: [0.72282487 2.09048725] , error: 0.4892737249511433\n",
      "Weights: [0.72198874 2.09058288] , error: 0.4892029785929145\n",
      "Weights: [0.7211545  2.09067828] , error: 0.4891325545289567\n",
      "Weights: [0.72032217 2.09077347] , error: 0.4890624512910174\n",
      "Weights: [0.71949174 2.09086844] , error: 0.48899266741753067\n",
      "Weights: [0.71866321 2.0909632 ] , error: 0.4889232014535901\n",
      "Weights: [0.71783656 2.09105774] , error: 0.48885405195091836\n",
      "Weights: [0.7170118  2.09115206] , error: 0.4887852174678329\n",
      "Weights: [0.71618891 2.09124617] , error: 0.4887166965692235\n",
      "Weights: [0.71536791 2.09134006] , error: 0.4886484878265131\n",
      "Weights: [0.71454877 2.09143374] , error: 0.4885805898176353\n",
      "Weights: [0.71373151 2.09152721] , error: 0.48851300112700186\n",
      "Weights: [0.71291611 2.09162046] , error: 0.48844572034547207\n",
      "Weights: [0.71210257 2.0917135 ] , error: 0.48837874607032783\n",
      "Weights: [0.71129088 2.09180633] , error: 0.4883120769052375\n",
      "Weights: [0.71048104 2.09189894] , error: 0.4882457114602332\n",
      "Weights: [0.70967305 2.09199135] , error: 0.48817964835167765\n",
      "Weights: [0.70886691 2.09208354] , error: 0.48811388620223845\n",
      "Weights: [0.7080626  2.09217553] , error: 0.48804842364085693\n",
      "Weights: [0.70726012 2.0922673 ] , error: 0.48798325930272113\n",
      "Weights: [0.70645948 2.09235887] , error: 0.4879183918292342\n",
      "Weights: [0.70566066 2.09245022] , error: 0.48785381986799276\n",
      "Weights: [0.70486367 2.09254137] , error: 0.4877895420727507\n",
      "Weights: [0.70406849 2.09263231] , error: 0.4877255571033969\n",
      "Weights: [0.70327512 2.09272304] , error: 0.4876618636259256\n",
      "Weights: [0.70248356 2.09281357] , error: 0.4875984603124056\n",
      "Weights: [0.70169381 2.09290389] , error: 0.4875353458409589\n",
      "Weights: [0.70090586 2.092994  ] , error: 0.4874725188957267\n",
      "Weights: [0.70011971 2.09308391] , error: 0.48740997816684567\n",
      "Weights: [0.69933535 2.09317361] , error: 0.48734772235042056\n",
      "Weights: [0.69855277 2.09326311] , error: 0.4872857501484955\n",
      "Weights: [0.69777199 2.09335241] , error: 0.48722406026902787\n",
      "Weights: [0.69699298 2.0934415 ] , error: 0.4871626514258588\n",
      "Weights: [0.69621575 2.09353038] , error: 0.4871015223386939\n",
      "Weights: [0.69544029 2.09361907] , error: 0.48704067173306514\n",
      "Weights: [0.6946666  2.09370755] , error: 0.4869800983403149\n",
      "Weights: [0.69389467 2.09379583] , error: 0.4869198008975653\n",
      "Weights: [0.69312451 2.09388391] , error: 0.4868597781476869\n",
      "Weights: [0.6923561  2.09397179] , error: 0.48680002883928297\n",
      "Weights: [0.69158944 2.09405947] , error: 0.4867405517266537\n",
      "Weights: [0.69082453 2.09414695] , error: 0.4866813455697767\n",
      "Weights: [0.69006137 2.09423422] , error: 0.4866224091342761\n",
      "Weights: [0.68929995 2.0943213 ] , error: 0.4865637411914042\n",
      "Weights: [0.68854026 2.09440818] , error: 0.4865053405180034\n",
      "Weights: [0.6877823  2.09449487] , error: 0.4864472058964963\n",
      "Weights: [0.68702608 2.09458135] , error: 0.48638933611484775\n",
      "Weights: [0.68627158 2.09466764] , error: 0.48633172996654406\n",
      "Weights: [0.68551879 2.09475373] , error: 0.48627438625056973\n",
      "Weights: [0.68476773 2.09483963] , error: 0.4862173037713815\n",
      "Weights: [0.68401838 2.09492533] , error: 0.4861604813388785\n",
      "Weights: [0.68327073 2.09501083] , error: 0.4861039177683857\n",
      "Weights: [0.6825248  2.09509614] , error: 0.48604761188062373\n",
      "Weights: [0.68178056 2.09518125] , error: 0.48599156250168424\n",
      "Weights: [0.68103802 2.09526617] , error: 0.48593576846300834\n",
      "Weights: [0.68029717 2.0953509 ] , error: 0.48588022860136026\n",
      "Weights: [0.67955801 2.09543543] , error: 0.4858249417588032\n",
      "Weights: [0.67882054 2.09551977] , error: 0.48576990678267573\n",
      "Weights: [0.67808475 2.09560392] , error: 0.4857151225255666\n",
      "Weights: [0.67735064 2.09568788] , error: 0.4856605878452932\n",
      "Weights: [0.6766182  2.09577164] , error: 0.4856063016048763\n",
      "Weights: [0.67588743 2.09585522] , error: 0.4855522626725151\n",
      "Weights: [0.67515833 2.0959386 ] , error: 0.48549846992156576\n",
      "Weights: [0.67443089 2.09602179] , error: 0.485444922230516\n",
      "Weights: [0.67370511 2.09610479] , error: 0.48539161848296347\n",
      "Weights: [0.67298099 2.09618761] , error: 0.48533855756759336\n",
      "Weights: [0.67225852 2.09627023] , error: 0.4852857383781495\n",
      "Weights: [0.67153769 2.09635267] , error: 0.4852331598134207\n",
      "Weights: [0.67081851 2.09643492] , error: 0.4851808207772082\n",
      "Weights: [0.67010097 2.09651698] , error: 0.4851287201783062\n",
      "Weights: [0.66938506 2.09659885] , error: 0.4850768569304855\n",
      "Weights: [0.66867079 2.09668054] , error: 0.4850252299524627\n",
      "Weights: [0.66795814 2.09676204] , error: 0.4849738381678782\n",
      "Weights: [0.66724712 2.09684336] , error: 0.48492268050527704\n",
      "Weights: [0.66653772 2.09692449] , error: 0.48487175589808906\n",
      "Weights: [0.66582994 2.09700543] , error: 0.4848210632845954\n",
      "Weights: [0.66512378 2.09708619] , error: 0.4847706016079216\n",
      "Weights: [0.66441922 2.09716677] , error: 0.4847203698160034\n",
      "Weights: [0.66371627 2.09724716] , error: 0.48467036686157294\n",
      "Weights: [0.66301493 2.09732737] , error: 0.48462059170212923\n",
      "Weights: [0.66231518 2.0974074 ] , error: 0.48457104329992284\n",
      "Weights: [0.66161703 2.09748724] , error: 0.4845217206219317\n",
      "Weights: [0.66092047 2.0975669 ] , error: 0.48447262263984\n",
      "Weights: [0.6602255  2.09764638] , error: 0.48442374833001484\n",
      "Weights: [0.65953211 2.09772568] , error: 0.4843750966734902\n",
      "Weights: [0.65884031 2.0978048 ] , error: 0.48432666665593893\n",
      "Weights: [0.65815008 2.09788373] , error: 0.4842784572676541\n",
      "Weights: [0.65746143 2.09796249] , error: 0.4842304675035314\n",
      "Weights: [0.65677435 2.09804107] , error: 0.4841826963630466\n",
      "Weights: [0.65608883 2.09811947] , error: 0.48413514285022896\n",
      "Weights: [0.65540488 2.09819769] , error: 0.48408780597364665\n",
      "Weights: [0.65472249 2.09827573] , error: 0.4840406847463856\n",
      "Weights: [0.65404165 2.09835359] , error: 0.4839937781860285\n",
      "Weights: [0.65336237 2.09843128] , error: 0.4839470853146306\n",
      "Weights: [0.65268463 2.09850879] , error: 0.4839006051587039\n",
      "Weights: [0.65200844 2.09858612] , error: 0.4838543367491967\n",
      "Weights: [0.6513338  2.09866327] , error: 0.48380827912147084\n",
      "Weights: [0.65066069 2.09874025] , error: 0.48376243131527974\n",
      "Weights: [0.64998911 2.09881706] , error: 0.48371679237475573\n",
      "Weights: [0.64931907 2.09889369] , error: 0.48367136134838384\n",
      "Weights: [0.64865056 2.09897014] , error: 0.48362613728898374\n",
      "Weights: [0.64798357 2.09904642] , error: 0.4835811192536914\n",
      "Weights: [0.6473181  2.09912253] , error: 0.48353630630393585\n",
      "Weights: [0.64665415 2.09919846] , error: 0.483491697505424\n",
      "Weights: [0.64599171 2.09927422] , error: 0.4834472919281181\n",
      "Weights: [0.64533078 2.0993498 ] , error: 0.4834030886462162\n",
      "Weights: [0.64467136 2.09942522] , error: 0.4833590867381368\n",
      "Weights: [0.64401345 2.09950046] , error: 0.4833152852864937\n",
      "Weights: [0.64335703 2.09957553] , error: 0.48327168337808235\n",
      "Weights: [0.64270211 2.09965043] , error: 0.4832282801038589\n",
      "Weights: [0.64204869 2.09972516] , error: 0.483185074558916\n",
      "Weights: [0.64139675 2.09979972] , error: 0.48314206584247527\n",
      "Weights: [0.6407463 2.0998741] , error: 0.48309925305785706\n",
      "Weights: [0.64009734 2.09994832] , error: 0.48305663531246684\n",
      "Weights: [0.63944985 2.10002237] , error: 0.4830142117177828\n",
      "Weights: [0.63880385 2.10009625] , error: 0.48297198138932185\n",
      "Weights: [0.63815931 2.10016996] , error: 0.482929943446635\n",
      "Weights: [0.63751624 2.10024351] , error: 0.48288809701328583\n",
      "Weights: [0.63687465 2.10031688] , error: 0.4828464412168273\n",
      "Weights: [0.63623451 2.10039009] , error: 0.4828049751887875\n",
      "Weights: [0.63559583 2.10046313] , error: 0.48276369806465214\n",
      "Weights: [0.63495861 2.10053601] , error: 0.48272260898384445\n",
      "Weights: [0.63432285 2.10060872] , error: 0.4826817070897097\n",
      "Weights: [0.63368853 2.10068126] , error: 0.48264099152949264\n",
      "Weights: [0.63305566 2.10075364] , error: 0.4826004614543262\n",
      "Weights: [0.63242423 2.10082585] , error: 0.48256011601920934\n",
      "Weights: [0.63179424 2.1008979 ] , error: 0.48251995438298945\n",
      "Weights: [0.63116569 2.10096978] , error: 0.4824799757083466\n",
      "Weights: [0.63053858 2.1010415 ] , error: 0.4824401791617765\n",
      "Weights: [0.62991289 2.10111306] , error: 0.48240056391356895\n",
      "Weights: [0.62928863 2.10118445] , error: 0.48236112913779766\n",
      "Weights: [0.62866579 2.10125568] , error: 0.4823218740122953\n",
      "Weights: [0.62804438 2.10132675] , error: 0.4822827977186428\n",
      "Weights: [0.62742438 2.10139765] , error: 0.4822438994421474\n",
      "Weights: [0.62680579 2.1014684 ] , error: 0.4822051783718292\n",
      "Weights: [0.62618862 2.10153898] , error: 0.4821666337004022\n",
      "Weights: [0.62557285 2.1016094 ] , error: 0.4821282646242574\n",
      "Weights: [0.62495849 2.10167966] , error: 0.4820900703434509\n",
      "Weights: [0.62434552 2.10174977] , error: 0.48205205006167434\n",
      "Weights: [0.62373396 2.10181971] , error: 0.4820142029862564\n",
      "Weights: [0.62312379 2.10188949] , error: 0.4819765283281314\n",
      "Weights: [0.62251501 2.10195911] , error: 0.48193902530183097\n",
      "Weights: [0.62190762 2.10202857] , error: 0.4819016931254632\n",
      "Weights: [0.62130162 2.10209788] , error: 0.48186453102069804\n",
      "Weights: [0.62069699 2.10216703] , error: 0.48182753821275354\n",
      "Weights: [0.62009375 2.10223602] , error: 0.4817907139303752\n",
      "Weights: [0.61949188 2.10230485] , error: 0.48175405740582233\n",
      "Weights: [0.61889138 2.10237352] , error: 0.48171756787485365\n",
      "Weights: [0.61829226 2.10244204] , error: 0.4816812445767078\n",
      "Weights: [0.6176945 2.1025104] , error: 0.4816450867540885\n",
      "Weights: [0.6170981  2.10257861] , error: 0.4816090936531514\n",
      "Weights: [0.61650306 2.10264666] , error: 0.48157326452348354\n",
      "Weights: [0.61590938 2.10271456] , error: 0.4815375986180944\n",
      "Weights: [0.61531706 2.1027823 ] , error: 0.48150209519339426\n",
      "Weights: [0.61472608 2.10284989] , error: 0.4814667535091798\n",
      "Weights: [0.61413645 2.10291732] , error: 0.48143157282862276\n",
      "Weights: [0.61354817 2.1029846 ] , error: 0.4813965524182481\n",
      "Weights: [0.61296123 2.10305172] , error: 0.4813616915479254\n",
      "Weights: [0.61237562 2.10311869] , error: 0.4813269894908494\n",
      "Weights: [0.61179135 2.10318551] , error: 0.48129244552352485\n",
      "Weights: [0.61120842 2.10325218] , error: 0.4812580589257532\n",
      "Weights: [0.61062681 2.1033187 ] , error: 0.48122382898061733\n",
      "Weights: [0.61004653 2.10338506] , error: 0.48118975497446564\n",
      "Weights: [0.60946758 2.10345127] , error: 0.4811558361968978\n",
      "Weights: [0.60888994 2.10351733] , error: 0.48112207194074885\n",
      "Weights: [0.60831362 2.10358324] , error: 0.48108846150207796\n",
      "Weights: [0.60773862 2.103649  ] , error: 0.48105500418014746\n",
      "Weights: [0.60716492 2.10371461] , error: 0.4810216992774159\n",
      "Weights: [0.60659254 2.10378007] , error: 0.4809885460995176\n",
      "Weights: [0.60602146 2.10384538] , error: 0.4809555439552487\n",
      "Weights: [0.60545168 2.10391055] , error: 0.4809226921565564\n",
      "Weights: [0.6048832  2.10397556] , error: 0.48088999001852245\n",
      "Weights: [0.60431602 2.10404042] , error: 0.48085743685934823\n",
      "Weights: [0.60375013 2.10410514] , error: 0.4808250320003404\n",
      "Weights: [0.60318553 2.10416971] , error: 0.4807927747658992\n",
      "Weights: [0.60262222 2.10423413] , error: 0.4807606644834999\n",
      "Weights: [0.60206019 2.10429841] , error: 0.48072870048368527\n",
      "Weights: [0.60149945 2.10436254] , error: 0.480696882100045\n",
      "Weights: [0.60093998 2.10442652] , error: 0.4806652086692043\n",
      "Weights: [0.60038179 2.10449036] , error: 0.48063367953081476\n",
      "Weights: [0.59982488 2.10455405] , error: 0.4806022940275301\n",
      "Weights: [0.59926923 2.1046176 ] , error: 0.4805710515050037\n",
      "Weights: [0.59871485 2.104681  ] , error: 0.4805399513118685\n",
      "Weights: [0.59816173 2.10474425] , error: 0.4805089927997226\n",
      "Weights: [0.59760988 2.10480737] , error: 0.4804781753231205\n",
      "Weights: [0.59705928 2.10487034] , error: 0.4804474982395571\n",
      "Weights: [0.59650994 2.10493316] , error: 0.4804169609094538\n",
      "Weights: [0.59596185 2.10499584] , error: 0.4803865626961433\n",
      "Weights: [0.59541502 2.10505838] , error: 0.48035630296586296\n",
      "Weights: [0.59486942 2.10512078] , error: 0.48032618108773406\n",
      "Weights: [0.59432508 2.10518303] , error: 0.4802961964337543\n",
      "Weights: [0.59378197 2.10524514] , error: 0.48026634837878\n",
      "Weights: [0.59324011 2.10530711] , error: 0.4802366363005174\n",
      "Weights: [0.59269947 2.10536894] , error: 0.4802070595795066\n",
      "Weights: [0.59216008 2.10543063] , error: 0.48017761759910976\n",
      "Weights: [0.59162191 2.10549218] , error: 0.4801483097454976\n",
      "Weights: [0.59108497 2.10555358] , error: 0.48011913540764006\n",
      "Weights: [0.59054925 2.10561485] , error: 0.4800900939772873\n",
      "Weights: [0.59001476 2.10567598] , error: 0.48006118484896176\n",
      "Weights: [0.58948148 2.10573696] , error: 0.4800324074199457\n",
      "Weights: [0.58894942 2.10579781] , error: 0.4800037610902625\n",
      "Weights: [0.58841857 2.10585852] , error: 0.4799752452626765\n",
      "Weights: [0.58788894 2.10591909] , error: 0.47994685934266523\n",
      "Weights: [0.58736051 2.10597953] , error: 0.47991860273841874\n",
      "Weights: [0.58683329 2.10603982] , error: 0.4798904748608215\n",
      "Weights: [0.58630727 2.10609998] , error: 0.4798624751234443\n",
      "Weights: [0.58578244 2.10616   ] , error: 0.4798346029425249\n",
      "Weights: [0.58525882 2.10621989] , error: 0.47980685773696513\n",
      "Weights: [0.58473639 2.10627963] , error: 0.47977923892831187\n",
      "Weights: [0.58421515 2.10633924] , error: 0.4797517459407471\n",
      "Weights: [0.5836951  2.10639872] , error: 0.4797243782010766\n",
      "Weights: [0.58317623 2.10645806] , error: 0.47969713513871753\n",
      "Weights: [0.58265855 2.10651726] , error: 0.47967001618568494\n",
      "Weights: [0.58214205 2.10657633] , error: 0.4796430207765843\n",
      "Weights: [0.58162673 2.10663527] , error: 0.47961614834859456\n",
      "Weights: [0.58111258 2.10669407] , error: 0.47958939834145853\n",
      "Weights: [0.58059961 2.10675273] , error: 0.4795627701974724\n",
      "Weights: [0.5800878  2.10681127] , error: 0.4795362633614735\n",
      "Weights: [0.57957716 2.10686966] , error: 0.479509877280825\n",
      "Weights: [0.57906769 2.10692793] , error: 0.4794836114054134\n",
      "Weights: [0.57855938 2.10698606] , error: 0.4794574651876255\n",
      "Weights: [0.57805222 2.10704406] , error: 0.4794314380823466\n",
      "Weights: [0.57754623 2.10710193] , error: 0.4794055295469446\n",
      "Weights: [0.57704138 2.10715967] , error: 0.4793797390412575\n",
      "Weights: [0.57653769 2.10721727] , error: 0.47935406602758635\n",
      "Weights: [0.57603515 2.10727474] , error: 0.47932850997068044\n",
      "Weights: [0.57553375 2.10733209] , error: 0.4793030703377287\n",
      "Weights: [0.5750335 2.1073893] , error: 0.47927774659834665\n",
      "Weights: [0.57453439 2.10744638] , error: 0.47925253822456537\n",
      "Weights: [0.57403641 2.10750333] , error: 0.47922744469082174\n",
      "Weights: [0.57353957 2.10756015] , error: 0.47920246547394785\n",
      "Weights: [0.57304387 2.10761684] , error: 0.47917760005315657\n",
      "Weights: [0.57254929 2.1076734 ] , error: 0.47915284791003687\n",
      "Weights: [0.57205585 2.10772983] , error: 0.47912820852853677\n",
      "Weights: [0.57156352 2.10778614] , error: 0.4791036813949556\n",
      "Weights: [0.57107232 2.10784231] , error: 0.47907926599793427\n",
      "Weights: [0.57058224 2.10789836] , error: 0.47905496182844126\n",
      "Weights: [0.57009328 2.10795428] , error: 0.47903076837976555\n",
      "Weights: [0.56960544 2.10801007] , error: 0.4790066851475039\n",
      "Weights: [0.5691187  2.10806574] , error: 0.4789827116295515\n",
      "Weights: [0.56863308 2.10812128] , error: 0.4789588473260901\n",
      "Weights: [0.56814856 2.10817669] , error: 0.47893509173957816\n",
      "Weights: [0.56766515 2.10823197] , error: 0.4789114443747419\n",
      "Weights: [0.56718284 2.10828713] , error: 0.4788879047385635\n",
      "Weights: [0.56670163 2.10834216] , error: 0.4788644723402722\n",
      "Weights: [0.56622152 2.10839707] , error: 0.4788411466913301\n",
      "Weights: [0.5657425  2.10845185] , error: 0.47881792730542627\n",
      "Weights: [0.56526457 2.10850651] , error: 0.4787948136984678\n",
      "Weights: [0.56478774 2.10856104] , error: 0.47877180538856257\n",
      "Weights: [0.56431199 2.10861545] , error: 0.478748901896017\n",
      "Weights: [0.56383733 2.10866974] , error: 0.4787261027433223\n",
      "Weights: [0.56336375 2.1087239 ] , error: 0.4787034074551442\n",
      "Weights: [0.56289125 2.10877794] , error: 0.4786808155583148\n",
      "Weights: [0.56241982 2.10883185] , error: 0.47865832658182017\n",
      "Weights: [0.56194948 2.10888564] , error: 0.4786359400567957\n",
      "Weights: [0.5614802  2.10893931] , error: 0.47861365551650714\n",
      "Weights: [0.56101199 2.10899285] , error: 0.4785914724963521\n",
      "Weights: [0.56054486 2.10904628] , error: 0.4785693905338418\n",
      "Weights: [0.56007878 2.10909958] , error: 0.4785474091685934\n",
      "Weights: [0.55961378 2.10915276] , error: 0.47852552794232556\n",
      "Weights: [0.55914983 2.10920582] , error: 0.47850374639884036\n",
      "Weights: [0.55868694 2.10925876] , error: 0.47848206408402044\n",
      "Weights: [0.5582251  2.10931158] , error: 0.47846048054581547\n",
      "Weights: [0.55776432 2.10936427] , error: 0.47843899533423806\n",
      "Weights: [0.55730459 2.10941685] , error: 0.47841760800134564\n",
      "Weights: [0.5568459  2.10946931] , error: 0.4783963181012415\n",
      "Weights: [0.55638827 2.10952164] , error: 0.47837512519005715\n",
      "Weights: [0.55593167 2.10957386] , error: 0.47835402882594585\n",
      "Weights: [0.55547612 2.10962596] , error: 0.47833302856907584\n",
      "Weights: [0.55502161 2.10967794] , error: 0.478312123981618\n",
      "Weights: [0.55456813 2.1097298 ] , error: 0.4782913146277382\n",
      "Weights: [0.55411569 2.10978155] , error: 0.47827060007358574\n",
      "Weights: [0.55366427 2.10983317] , error: 0.47824997988728957\n",
      "Weights: [0.55321389 2.10988468] , error: 0.4782294536389443\n",
      "Weights: [0.55276454 2.10993607] , error: 0.47820902090060335\n",
      "Weights: [0.55231621 2.10998734] , error: 0.47818868124626857\n",
      "Weights: [0.5518689 2.1100385] , error: 0.47816843425188504\n",
      "Weights: [0.55142261 2.11008954] , error: 0.478148279495329\n",
      "Weights: [0.55097734 2.11014046] , error: 0.47812821655639676\n",
      "Weights: [0.55053309 2.11019127] , error: 0.47810824501680305\n",
      "Weights: [0.55008985 2.11024196] , error: 0.47808836446016434\n",
      "Weights: [0.54964762 2.11029253] , error: 0.4780685744719974\n",
      "Weights: [0.54920639 2.11034299] , error: 0.4780488746397055\n",
      "Weights: [0.54876618 2.11039334] , error: 0.47802926455257116\n",
      "Weights: [0.54832697 2.11044357] , error: 0.4780097438017496\n",
      "Weights: [0.54788876 2.11049368] , error: 0.4779903119802569\n",
      "Weights: [0.54745154 2.11054369] , error: 0.4779709686829635\n",
      "Weights: [0.54701533 2.11059357] , error: 0.4779517135065873\n",
      "Weights: [0.54658011 2.11064335] , error: 0.4779325460496803\n",
      "Weights: [0.54614588 2.11069301] , error: 0.4779134659126263\n",
      "Weights: [0.54571265 2.11074255] , error: 0.47789447269762686\n",
      "Weights: [0.5452804  2.11079199] , error: 0.4778755660086986\n",
      "Weights: [0.54484913 2.11084131] , error: 0.4778567454516599\n",
      "Weights: [0.54441886 2.11089052] , error: 0.4778380106341268\n",
      "Weights: [0.54398956 2.11093961] , error: 0.4778193611655006\n",
      "Weights: [0.54356124 2.1109886 ] , error: 0.4778007966569633\n",
      "Weights: [0.54313389 2.11103747] , error: 0.4777823167214678\n",
      "Weights: [0.54270753 2.11108623] , error: 0.47776392097373177\n",
      "Weights: [0.54228213 2.11113488] , error: 0.4777456090302257\n",
      "Weights: [0.54185771 2.11118342] , error: 0.47772738050917046\n",
      "Weights: [0.54143425 2.11123185] , error: 0.47770923503052165\n",
      "Weights: [0.54101175 2.11128017] , error: 0.4776911722159709\n",
      "Weights: [0.54059023 2.11132837] , error: 0.4776731916889285\n",
      "Weights: [0.54016966 2.11137647] , error: 0.4776552930745258\n",
      "Weights: [0.53975005 2.11142446] , error: 0.47763747599959705\n",
      "Weights: [0.5393314  2.11147234] , error: 0.4776197400926801\n",
      "Weights: [0.5389137  2.11152011] , error: 0.47760208498400214\n",
      "Weights: [0.53849696 2.11156777] , error: 0.4775845103054777\n",
      "Weights: [0.53808116 2.11161532] , error: 0.4775670156906942\n",
      "Weights: [0.53766632 2.11166276] , error: 0.47754960077491415\n",
      "Weights: [0.53725242 2.1117101 ] , error: 0.4775322651950554\n",
      "Weights: [0.53683946 2.11175733] , error: 0.4775150085896942\n",
      "Weights: [0.53642745 2.11180445] , error: 0.4774978305990514\n",
      "Weights: [0.53601637 2.11185146] , error: 0.4774807308649886\n",
      "Weights: [0.53560624 2.11189836] , error: 0.47746370903099633\n",
      "Weights: [0.53519703 2.11194516] , error: 0.477446764742191\n",
      "Weights: [0.53478876 2.11199185] , error: 0.47742989764530647\n",
      "Weights: [0.53438143 2.11203844] , error: 0.4774131073886827\n",
      "Weights: [0.53397502 2.11208492] , error: 0.47739639362226644\n",
      "Weights: [0.53356954 2.11213129] , error: 0.4773797559975942\n",
      "Weights: [0.53316498 2.11217756] , error: 0.4773631941677933\n",
      "Weights: [0.53276134 2.11222372] , error: 0.4773467077875706\n",
      "Weights: [0.53235863 2.11226977] , error: 0.4773302965132053\n",
      "Weights: [0.53195683 2.11231573] , error: 0.4773139600025435\n",
      "Weights: [0.53155595 2.11236157] , error: 0.47729769791498844\n",
      "Weights: [0.53115599 2.11240731] , error: 0.4772815099114964\n",
      "Weights: [0.53075693 2.11245295] , error: 0.4772653956545677\n",
      "Weights: [0.53035879 2.11249848] , error: 0.4772493548082405\n",
      "Weights: [0.52996155 2.11254391] , error: 0.4772333870380831\n",
      "Weights: [0.52956523 2.11258924] , error: 0.4772174920111872\n",
      "Weights: [0.5291698  2.11263446] , error: 0.47720166939616143\n",
      "Weights: [0.52877527 2.11267958] , error: 0.47718591886312534\n",
      "Weights: [0.52838165 2.1127246 ] , error: 0.4771702400836967\n",
      "Weights: [0.52798892 2.11276951] , error: 0.4771546327309961\n",
      "Weights: [0.52759709 2.11281432] , error: 0.4771390964796285\n",
      "Weights: [0.52720615 2.11285903] , error: 0.47712363100568256\n",
      "Weights: [0.52681611 2.11290364] , error: 0.47710823598672214\n",
      "Weights: [0.52642695 2.11294815] , error: 0.47709291110178\n",
      "Weights: [0.52603868 2.11299255] , error: 0.4770776560313529\n",
      "Weights: [0.5256513  2.11303685] , error: 0.4770624704573898\n",
      "Weights: [0.5252648  2.11308106] , error: 0.47704735406329163\n",
      "Weights: [0.52487918 2.11312516] , error: 0.47703230653390083\n",
      "Weights: [0.52449444 2.11316916] , error: 0.477017327555495\n",
      "Weights: [0.52411058 2.11321306] , error: 0.4770024168157807\n",
      "Weights: [0.52372759 2.11325686] , error: 0.4769875740038869\n",
      "Weights: [0.52334548 2.11330056] , error: 0.47697279881036153\n",
      "Weights: [0.52296423 2.11334416] , error: 0.47695809092715896\n",
      "Weights: [0.52258386 2.11338766] , error: 0.4769434500476387\n",
      "Weights: [0.52220435 2.11343106] , error: 0.47692887586655713\n",
      "Weights: [0.52182571 2.11347436] , error: 0.4769143680800594\n",
      "Weights: [0.52144794 2.11351757] , error: 0.476899926385678\n",
      "Weights: [0.52107102 2.11356067] , error: 0.47688555048232006\n",
      "Weights: [0.52069497 2.11360368] , error: 0.4768712400702667\n",
      "Weights: [0.52031977 2.11364659] , error: 0.4768569948511652\n",
      "Weights: [0.51994543 2.1136894 ] , error: 0.4768428145280176\n",
      "Weights: [0.51957194 2.11373211] , error: 0.4768286988051833\n",
      "Weights: [0.5191993  2.11377473] , error: 0.4768146473883689\n",
      "Weights: [0.51882751 2.11381725] , error: 0.4768006599846171\n",
      "Weights: [0.51845657 2.11385967] , error: 0.47678673630231105\n",
      "Weights: [0.51808648 2.113902  ] , error: 0.4767728760511539\n",
      "Weights: [0.51771723 2.11394423] , error: 0.47675907894218367\n",
      "Weights: [0.51734882 2.11398636] , error: 0.47674534468774366\n",
      "Weights: [0.51698126 2.1140284 ] , error: 0.4767316730014934\n",
      "Weights: [0.51661453 2.11407034] , error: 0.47671806359839397\n",
      "Weights: [0.51624863 2.11411218] , error: 0.47670451619470755\n",
      "Weights: [0.51588357 2.11415393] , error: 0.47669103050798667\n",
      "Weights: [0.51551935 2.11419559] , error: 0.4766776062570737\n",
      "Weights: [0.51515595 2.11423715] , error: 0.4766642431620873\n",
      "Weights: [0.51479339 2.11427861] , error: 0.47665094094442556\n",
      "Weights: [0.51443165 2.11431998] , error: 0.4766376993267525\n",
      "Weights: [0.51407073 2.11436126] , error: 0.476624518032998\n",
      "Weights: [0.51371064 2.11440244] , error: 0.4766113967883477\n",
      "Weights: [0.51335137 2.11444353] , error: 0.47659833531924123\n",
      "Weights: [0.51299292 2.11448452] , error: 0.4765853333533617\n",
      "Weights: [0.51263528 2.11452542] , error: 0.47657239061963586\n",
      "Weights: [0.51227846 2.11456623] , error: 0.4765595068482229\n",
      "Weights: [0.51192246 2.11460694] , error: 0.4765466817705132\n",
      "Weights: [0.51156727 2.11464756] , error: 0.47653391511911913\n",
      "Weights: [0.51121288 2.11468809] , error: 0.4765212066278727\n",
      "Weights: [0.51085931 2.11472853] , error: 0.4765085560318157\n",
      "Weights: [0.51050654 2.11476887] , error: 0.47649596306720216\n",
      "Weights: [0.51015457 2.11480912] , error: 0.4764834274714828\n",
      "Weights: [0.50980341 2.11484928] , error: 0.47647094898330655\n",
      "Weights: [0.50945305 2.11488935] , error: 0.4764585273425126\n",
      "Weights: [0.50910349 2.11492933] , error: 0.47644616229012393\n",
      "Weights: [0.50875473 2.11496922] , error: 0.47643385356834655\n",
      "Weights: [0.50840676 2.11500901] , error: 0.4764216009205581\n",
      "Weights: [0.50805958 2.11504872] , error: 0.47640940409130683\n",
      "Weights: [0.5077132  2.11508833] , error: 0.47639726282630235\n",
      "Weights: [0.5073676  2.11512785] , error: 0.47638517687241655\n",
      "Weights: [0.5070228  2.11516729] , error: 0.47637314597767205\n",
      "Weights: [0.50667878 2.11520663] , error: 0.4763611698912385\n",
      "Weights: [0.50633554 2.11524588] , error: 0.47634924836343046\n",
      "Weights: [0.50599309 2.11528505] , error: 0.4763373811456998\n",
      "Weights: [0.50565142 2.11532412] , error: 0.47632556799062764\n",
      "Weights: [0.50531052 2.11536311] , error: 0.4763138086519264\n",
      "Weights: [0.50497041 2.11540201] , error: 0.47630210288442687\n",
      "Weights: [0.50463107 2.11544082] , error: 0.47629045044408086\n",
      "Weights: [0.5042925  2.11547954] , error: 0.4762788510879478\n",
      "Weights: [0.50395471 2.11551817] , error: 0.4762673045741955\n",
      "Weights: [0.50361769 2.11555671] , error: 0.4762558106620939\n",
      "Weights: [0.50328143 2.11559517] , error: 0.47624436911201007\n",
      "Weights: [0.50294594 2.11563353] , error: 0.4762329796854013\n",
      "Weights: [0.50261122 2.11567181] , error: 0.4762216421448128\n",
      "Weights: [0.50227726 2.11571001] , error: 0.4762103562538699\n",
      "Weights: [0.50194406 2.11574811] , error: 0.4761991217772771\n",
      "Weights: [0.50161162 2.11578613] , error: 0.476187938480809\n",
      "Weights: [0.50127994 2.11582406] , error: 0.4761768061313082\n",
      "Weights: [0.50094902 2.11586191] , error: 0.4761657244966794\n",
      "Weights: [0.50061885 2.11589967] , error: 0.4761546933458827\n",
      "Weights: [0.50028944 2.11593734] , error: 0.47614371244893466\n",
      "Weights: [0.49996077 2.11597493] , error: 0.47613278157689676\n",
      "Weights: [0.49963285 2.11601243] , error: 0.4761219005018726\n",
      "Weights: [0.49930569 2.11604985] , error: 0.4761110689970072\n",
      "Weights: [0.49897927 2.11608718] , error: 0.4761002868364757\n",
      "Weights: [0.49865359 2.11612443] , error: 0.47608955379548396\n",
      "Weights: [0.49832865 2.11616159] , error: 0.47607886965026197\n",
      "Weights: [0.49800446 2.11619866] , error: 0.47606823417805866\n",
      "Weights: [0.49768101 2.11623565] , error: 0.47605764715713733\n",
      "Weights: [0.49735829 2.11627256] , error: 0.4760471083667722\n",
      "Weights: [0.49703631 2.11630938] , error: 0.47603661758724236\n",
      "Weights: [0.49671506 2.11634612] , error: 0.4760261745998284\n",
      "Weights: [0.49639455 2.11638278] , error: 0.47601577918680754\n",
      "Weights: [0.49607476 2.11641935] , error: 0.47600543113144783\n",
      "Weights: [0.49575571 2.11645584] , error: 0.4759951302180047\n",
      "Weights: [0.49543738 2.11649224] , error: 0.4759848762317175\n",
      "Weights: [0.49511978 2.11652857] , error: 0.47597466895880386\n",
      "Weights: [0.49480291 2.11656481] , error: 0.475964508186455\n",
      "Weights: [0.49448675 2.11660096] , error: 0.47595439370283044\n",
      "Weights: [0.49417132 2.11663704] , error: 0.47594432529705755\n",
      "Weights: [0.49385661 2.11667303] , error: 0.4759343027592208\n",
      "Weights: [0.49354261 2.11670894] , error: 0.4759243258803638\n",
      "Weights: [0.49322933 2.11674477] , error: 0.47591439445248146\n",
      "Weights: [0.49291677 2.11678051] , error: 0.47590450826851455\n",
      "Weights: [0.49260492 2.11681618] , error: 0.4758946671223501\n",
      "Weights: [0.49229378 2.11685176] , error: 0.47588487080881275\n",
      "Weights: [0.49198334 2.11688726] , error: 0.47587511912365965\n",
      "Weights: [0.49167362 2.11692268] , error: 0.47586541186358133\n",
      "Weights: [0.4913646  2.11695802] , error: 0.47585574882619386\n",
      "Weights: [0.49105629 2.11699328] , error: 0.4758461298100357\n",
      "Weights: [0.49074868 2.11702846] , error: 0.47583655461456015\n",
      "Weights: [0.49044177 2.11706356] , error: 0.4758270230401386\n",
      "Weights: [0.49013556 2.11709858] , error: 0.47581753488804857\n",
      "Weights: [0.48983005 2.11713352] , error: 0.4758080899604737\n",
      "Weights: [0.48952524 2.11716838] , error: 0.47579868806049974\n",
      "Weights: [0.48922112 2.11720316] , error: 0.47578932899210863\n",
      "Weights: [0.4889177  2.11723786] , error: 0.4757800125601757\n",
      "Weights: [0.48861497 2.11727248] , error: 0.4757707385704641\n",
      "Weights: [0.48831292 2.11730703] , error: 0.4757615068296241\n",
      "Weights: [0.48801157 2.11734149] , error: 0.47575231714518385\n",
      "Weights: [0.4877109  2.11737588] , error: 0.4757431693255524\n",
      "Weights: [0.48741092 2.11741018] , error: 0.4757340631800064\n",
      "Weights: [0.48711163 2.11744441] , error: 0.47572499851869576\n",
      "Weights: [0.48681301 2.11747856] , error: 0.4757159751526332\n",
      "Weights: [0.48651508 2.11751264] , error: 0.4757069928936934\n",
      "Weights: [0.48621783 2.11754663] , error: 0.47569805155460615\n",
      "Weights: [0.48592125 2.11758055] , error: 0.4756891509489562\n",
      "Weights: [0.48562535 2.11761439] , error: 0.4756802908911778\n",
      "Weights: [0.48533013 2.11764815] , error: 0.47567147119654934\n",
      "Weights: [0.48503557 2.11768184] , error: 0.47566269168119113\n",
      "Weights: [0.48474169 2.11771545] , error: 0.4756539521620616\n",
      "Weights: [0.48444848 2.11774898] , error: 0.47564525245695277\n",
      "Weights: [0.48415594 2.11778244] , error: 0.4756365923844863\n",
      "Weights: [0.48386407 2.11781582] , error: 0.4756279717641094\n",
      "Weights: [0.48357286 2.11784912] , error: 0.475619390416095\n",
      "Weights: [0.48328232 2.11788235] , error: 0.47561084816153215\n",
      "Weights: [0.48299243 2.1179155 ] , error: 0.47560234482232533\n",
      "Weights: [0.48270321 2.11794858] , error: 0.4755938802211894\n",
      "Weights: [0.48241465 2.11798158] , error: 0.47558545418164966\n",
      "Weights: [0.48212675 2.1180145 ] , error: 0.4755770665280329\n",
      "Weights: [0.4818395  2.11804735] , error: 0.47556871708546844\n",
      "Weights: [0.48155291 2.11808013] , error: 0.47556040567987845\n",
      "Weights: [0.48126697 2.11811283] , error: 0.47555213213798175\n",
      "Weights: [0.48098169 2.11814546] , error: 0.4755438962872855\n",
      "Weights: [0.48069705 2.11817801] , error: 0.47553569795608314\n",
      "Weights: [0.48041307 2.11821049] , error: 0.47552753697344863\n",
      "Weights: [0.48012973 2.11824289] , error: 0.47551941316923574\n",
      "Weights: [0.47984704 2.11827522] , error: 0.47551132637407373\n",
      "Weights: [0.47956499 2.11830748] , error: 0.4755032764193624\n",
      "Weights: [0.47928358 2.11833966] , error: 0.47549526313727064\n",
      "Weights: [0.47900282 2.11837177] , error: 0.47548728636073223\n",
      "Weights: [0.4787227  2.11840381] , error: 0.47547934592344065\n",
      "Weights: [0.47844321 2.11843577] , error: 0.475471441659848\n",
      "Weights: [0.47816437 2.11846766] , error: 0.47546357340515977\n",
      "Weights: [0.47788616 2.11849948] , error: 0.4754557409953334\n",
      "Weights: [0.47760858 2.11853122] , error: 0.4754479442670722\n",
      "Weights: [0.47733164 2.11856289] , error: 0.4754401830578243\n",
      "Weights: [0.47705533 2.11859449] , error: 0.47543245720577976\n",
      "Weights: [0.47677964 2.11862602] , error: 0.4754247665498614\n",
      "Weights: [0.47650459 2.11865748] , error: 0.47541711092973105\n",
      "Weights: [0.47623017 2.11868886] , error: 0.47540949018577694\n",
      "Weights: [0.47595637 2.11872018] , error: 0.4754019041591174\n",
      "Weights: [0.47568319 2.11875142] , error: 0.4753943526915926\n",
      "Weights: [0.47541064 2.11878259] , error: 0.47538683562576417\n",
      "Weights: [0.47513871 2.11881369] , error: 0.47537935280491067\n",
      "Weights: [0.4748674  2.11884471] , error: 0.4753719040730237\n",
      "Weights: [0.4745967  2.11887567] , error: 0.4753644892748087\n",
      "Weights: [0.47432663 2.11890656] , error: 0.47535710825567334\n",
      "Weights: [0.47405717 2.11893738] , error: 0.4753497608617363\n",
      "Weights: [0.47378832 2.11896812] , error: 0.4753424469398103\n",
      "Weights: [0.47352009 2.1189988 ] , error: 0.4753351663374111\n",
      "Weights: [0.47325247 2.1190294 ] , error: 0.47532791890274506\n",
      "Weights: [0.47298546 2.11905994] , error: 0.4753207044847162\n",
      "Weights: [0.47271906 2.11909041] , error: 0.475313522932909\n",
      "Weights: [0.47245327 2.1191208 ] , error: 0.4753063740975988\n",
      "Weights: [0.47218808 2.11915113] , error: 0.47529925782974203\n",
      "Weights: [0.4719235  2.11918139] , error: 0.47529217398097134\n",
      "Weights: [0.47165952 2.11921158] , error: 0.47528512240359977\n",
      "Weights: [0.47139615 2.1192417 ] , error: 0.4752781029506096\n",
      "Weights: [0.47113337 2.11927175] , error: 0.47527111547565354\n",
      "Weights: [0.47087119 2.11930174] , error: 0.4752641598330508\n",
      "Weights: [0.47060961 2.11933165] , error: 0.4752572358777881\n",
      "Weights: [0.47034863 2.1193615 ] , error: 0.4752503434655058\n",
      "Weights: [0.47008824 2.11939128] , error: 0.47524348245250864\n",
      "Weights: [0.46982845 2.11942099] , error: 0.47523665269575194\n",
      "Weights: [0.46956925 2.11945063] , error: 0.4752298540528437\n",
      "Weights: [0.46931064 2.11948021] , error: 0.4752230863820411\n",
      "Weights: [0.46905262 2.11950972] , error: 0.4752163495422454\n",
      "Weights: [0.46879519 2.11953916] , error: 0.4752096433930034\n",
      "Weights: [0.46853834 2.11956853] , error: 0.4752029677945\n",
      "Weights: [0.46828208 2.11959784] , error: 0.4751963226075576\n",
      "Weights: [0.46802641 2.11962708] , error: 0.4751897076936311\n",
      "Weights: [0.46777131 2.11965625] , error: 0.4751831229148091\n",
      "Weights: [0.4675168  2.11968536] , error: 0.4751765681338065\n",
      "Weights: [0.46726287 2.1197144 ] , error: 0.4751700432139647\n",
      "Weights: [0.46700952 2.11974337] , error: 0.47516354801924654\n",
      "Weights: [0.46675675 2.11977228] , error: 0.4751570824142368\n",
      "Weights: [0.46650455 2.11980112] , error: 0.4751506462641349\n",
      "Weights: [0.46625293 2.1198299 ] , error: 0.4751442394347542\n",
      "Weights: [0.46600188 2.11985861] , error: 0.4751378617925211\n",
      "Weights: [0.46575141 2.11988726] , error: 0.4751315132044706\n",
      "Weights: [0.46550151 2.11991584] , error: 0.47512519353824123\n",
      "Weights: [0.46525217 2.11994435] , error: 0.47511890266207685\n",
      "Weights: [0.46500341 2.1199728 ] , error: 0.47511264044482104\n",
      "Weights: [0.46475521 2.12000119] , error: 0.4751064067559125\n",
      "Weights: [0.46450758 2.12002951] , error: 0.475100201465388\n",
      "Weights: [0.46426051 2.12005776] , error: 0.4750940244438742\n",
      "Weights: [0.464014   2.12008595] , error: 0.475087875562588\n",
      "Weights: [0.46376806 2.12011408] , error: 0.4750817546933344\n",
      "Weights: [0.46352268 2.12014214] , error: 0.4750756617084995\n",
      "Weights: [0.46327786 2.12017014] , error: 0.4750695964810513\n",
      "Weights: [0.4630336  2.12019808] , error: 0.4750635588845402\n",
      "Weights: [0.46278989 2.12022595] , error: 0.4750575487930878\n",
      "Weights: [0.46254674 2.12025376] , error: 0.4750515660813912\n",
      "Weights: [0.46230414 2.1202815 ] , error: 0.4750456106247192\n",
      "Weights: [0.4620621  2.12030918] , error: 0.4750396822989078\n",
      "Weights: [0.46182061 2.1203368 ] , error: 0.47503378098035864\n",
      "Weights: [0.46157967 2.12036435] , error: 0.47502790654603594\n",
      "Weights: [0.46133928 2.12039185] , error: 0.47502205887346705\n",
      "Weights: [0.46109944 2.12041928] , error: 0.4750162378407327\n",
      "Weights: [0.46086014 2.12044664] , error: 0.4750104433264733\n",
      "Weights: [0.46062139 2.12047395] , error: 0.47500467520988\n",
      "Weights: [0.46038319 2.12050119] , error: 0.4749989333706951\n",
      "Weights: [0.46014552 2.12052837] , error: 0.47499321768920777\n",
      "Weights: [0.4599084  2.12055549] , error: 0.47498752804625466\n",
      "Weights: [0.45967182 2.12058254] , error: 0.4749818643232131\n",
      "Weights: [0.45943578 2.12060954] , error: 0.474976226402\n",
      "Weights: [0.45920028 2.12063647] , error: 0.4749706141650745\n",
      "Weights: [0.45896532 2.12066334] , error: 0.4749650274954254\n",
      "Weights: [0.45873089 2.12069015] , error: 0.4749594662765798\n",
      "Weights: [0.458497  2.1207169] , error: 0.47495393039259337\n",
      "Weights: [0.45826363 2.12074359] , error: 0.47494841972804924\n",
      "Weights: [0.45803081 2.12077022] , error: 0.47494293416805583\n",
      "Weights: [0.45779851 2.12079678] , error: 0.47493747359824817\n",
      "Weights: [0.45756674 2.12082329] , error: 0.4749320379047793\n",
      "Weights: [0.4573355  2.12084974] , error: 0.4749266269743215\n",
      "Weights: [0.45710479 2.12087612] , error: 0.47492124069406305\n",
      "Weights: [0.4568746  2.12090245] , error: 0.47491587895170806\n",
      "Weights: [0.45664494 2.12092871] , error: 0.47491054163547075\n",
      "Weights: [0.4564158  2.12095492] , error: 0.4749052286340734\n",
      "Weights: [0.45618719 2.12098106] , error: 0.4748999398367494\n",
      "Weights: [0.4559591  2.12100715] , error: 0.4748946751332309\n",
      "Weights: [0.45573152 2.12103317] , error: 0.4748894344137564\n",
      "Weights: [0.45550447 2.12105914] , error: 0.47488421756906346\n",
      "Weights: [0.45527793 2.12108505] , error: 0.47487902449038877\n",
      "Weights: [0.45505191 2.1211109 ] , error: 0.4748738550694609\n",
      "Weights: [0.45482641 2.12113669] , error: 0.47486870919850566\n",
      "Weights: [0.45460142 2.12116242] , error: 0.4748635867702366\n",
      "Weights: [0.45437694 2.12118809] , error: 0.47485848767785993\n",
      "Weights: [0.45415297 2.1212137 ] , error: 0.47485341181506235\n",
      "Weights: [0.45392952 2.12123926] , error: 0.4748483590760219\n",
      "Weights: [0.45370657 2.12126476] , error: 0.4748433293553935\n",
      "Weights: [0.45348414 2.12129019] , error: 0.47483832254831315\n",
      "Weights: [0.45326221 2.12131557] , error: 0.47483333855039656\n",
      "Weights: [0.45304078 2.1213409 ] , error: 0.47482837725773464\n",
      "Weights: [0.45281986 2.12136616] , error: 0.47482343856688797\n",
      "Weights: [0.45259945 2.12139137] , error: 0.4748185223748915\n",
      "Weights: [0.45237954 2.12141652] , error: 0.4748136285792506\n",
      "Weights: [0.45216013 2.12144161] , error: 0.47480875707793446\n",
      "Weights: [0.45194122 2.12146665] , error: 0.47480390776937853\n",
      "Weights: [0.45172281 2.12149163] , error: 0.47479908055248055\n",
      "Weights: [0.45150489 2.12151655] , error: 0.47479427532660023\n",
      "Weights: [0.45128748 2.12154141] , error: 0.4747894919915529\n",
      "Weights: [0.45107056 2.12156622] , error: 0.4747847304476136\n",
      "Weights: [0.45085413 2.12159097] , error: 0.47477999059550896\n",
      "Weights: [0.4506382  2.12161567] , error: 0.47477527233641903\n",
      "Weights: [0.45042276 2.12164031] , error: 0.47477057557197483\n",
      "Weights: [0.45020781 2.12166489] , error: 0.47476590020425413\n",
      "Weights: [0.44999335 2.12168941] , error: 0.47476124613578136\n",
      "Weights: [0.44977939 2.12171389] , error: 0.4747566132695258\n",
      "Weights: [0.4495659 2.1217383] , error: 0.47475200150889607\n",
      "Weights: [0.44935291 2.12176266] , error: 0.47474741075774507\n",
      "Weights: [0.4491404  2.12178696] , error: 0.47474284092035957\n",
      "Weights: [0.44892838 2.12181121] , error: 0.47473829190146577\n",
      "Weights: [0.44871684 2.1218354 ] , error: 0.4747337636062212\n",
      "Weights: [0.44850578 2.12185954] , error: 0.474729255940216\n",
      "Weights: [0.4482952  2.12188362] , error: 0.47472476880947306\n",
      "Weights: [0.44808511 2.12190765] , error: 0.47472030212043903\n",
      "Weights: [0.44787549 2.12193162] , error: 0.4747158557799914\n",
      "Weights: [0.44766635 2.12195554] , error: 0.4747114296954269\n",
      "Weights: [0.44745769 2.1219794 ] , error: 0.47470702377446844\n",
      "Weights: [0.4472495  2.12200321] , error: 0.4747026379252591\n",
      "Weights: [0.44704179 2.12202697] , error: 0.4746982720563577\n",
      "Weights: [0.44683455 2.12205067] , error: 0.47469392607674277\n",
      "Weights: [0.44662778 2.12207432] , error: 0.47468959989580495\n",
      "Weights: [0.44642149 2.12209791] , error: 0.4746852934233491\n",
      "Weights: [0.44621567 2.12212145] , error: 0.47468100656959067\n",
      "Weights: [0.44601031 2.12214493] , error: 0.4746767392451546\n",
      "Weights: [0.44580543 2.12216836] , error: 0.4746724913610717\n",
      "Weights: [0.44560101 2.12219174] , error: 0.4746682628287797\n",
      "Weights: [0.44539705 2.12221507] , error: 0.47466405356011837\n",
      "Weights: [0.44519357 2.12223834] , error: 0.47465986346732947\n",
      "Weights: [0.44499054 2.12226156] , error: 0.4746556924630567\n",
      "Weights: [0.44478798 2.12228472] , error: 0.4746515404603373\n",
      "Weights: [0.44458588 2.12230784] , error: 0.47464740737260885\n",
      "Weights: [0.44438425 2.1223309 ] , error: 0.4746432931137018\n",
      "Weights: [0.44418307 2.1223539 ] , error: 0.4746391975978375\n",
      "Weights: [0.44398235 2.12237686] , error: 0.47463512073963016\n",
      "Weights: [0.44378209 2.12239976] , error: 0.47463106245408293\n",
      "Weights: [0.44358228 2.12242261] , error: 0.47462702265658585\n",
      "Weights: [0.44338293 2.12244541] , error: 0.47462300126291374\n",
      "Weights: [0.44318404 2.12246816] , error: 0.47461899818922454\n",
      "Weights: [0.4429856  2.12249085] , error: 0.47461501335206097\n",
      "Weights: [0.44278761 2.12251349] , error: 0.4746110466683435\n",
      "Weights: [0.44259007 2.12253609] , error: 0.47460709805537044\n",
      "Weights: [0.44239299 2.12255862] , error: 0.4746031674308213\n",
      "Weights: [0.44219635 2.12258111] , error: 0.47459925471274367\n",
      "Weights: [0.44200016 2.12260355] , error: 0.47459535981956524\n",
      "Weights: [0.44180442 2.12262594] , error: 0.47459148267008067\n",
      "Weights: [0.44160912 2.12264827] , error: 0.4745876231834558\n",
      "Weights: [0.44141428 2.12267055] , error: 0.4745837812792274\n",
      "Weights: [0.44121987 2.12269279] , error: 0.47457995687729465\n",
      "Weights: [0.44102591 2.12271497] , error: 0.4745761498979246\n",
      "Weights: [0.44083239 2.1227371 ] , error: 0.47457236026174626\n",
      "Weights: [0.44063931 2.12275918] , error: 0.47456858788975037\n",
      "Weights: [0.44044667 2.12278121] , error: 0.4745648327032873\n",
      "Weights: [0.44025447 2.12280319] , error: 0.47456109462406665\n",
      "Weights: [0.44006271 2.12282512] , error: 0.4745573735741532\n",
      "Weights: [0.43987139 2.12284701] , error: 0.47455366947596783\n",
      "Weights: [0.4396805  2.12286884] , error: 0.47454998225228817\n",
      "Weights: [0.43949005 2.12289062] , error: 0.47454631182623525\n",
      "Weights: [0.43930003 2.12291235] , error: 0.4745426581212884\n",
      "Weights: [0.43911045 2.12293403] , error: 0.4745390210612705\n",
      "Weights: [0.4389213  2.12295566] , error: 0.4745354005703549\n",
      "Weights: [0.43873258 2.12297724] , error: 0.4745317965730584\n",
      "Weights: [0.43854429 2.12299878] , error: 0.4745282089942414\n",
      "Weights: [0.43835643 2.12302026] , error: 0.4745246377591088\n",
      "Weights: [0.438169  2.1230417] , error: 0.4745210827932047\n",
      "Weights: [0.43798199 2.12306308] , error: 0.4745175440224115\n",
      "Weights: [0.43779541 2.12308442] , error: 0.4745140213729505\n",
      "Weights: [0.43760926 2.12310571] , error: 0.47451051477137834\n",
      "Weights: [0.43742353 2.12312695] , error: 0.47450702414458856\n",
      "Weights: [0.43723823 2.12314814] , error: 0.47450354941980405\n",
      "Weights: [0.43705335 2.12316929] , error: 0.4745000905245818\n",
      "Weights: [0.43686889 2.12319038] , error: 0.47449664738680897\n",
      "Weights: [0.43668485 2.12321143] , error: 0.47449321993469945\n",
      "Weights: [0.43650123 2.12323243] , error: 0.47448980809679553\n",
      "Weights: [0.43631803 2.12325338] , error: 0.4744864118019646\n",
      "Weights: [0.43613524 2.12327429] , error: 0.47448303097939876\n",
      "Weights: [0.43595287 2.12329514] , error: 0.47447966555861076\n",
      "Weights: [0.43577092 2.12331595] , error: 0.4744763154694365\n",
      "Weights: [0.43558939 2.12333671] , error: 0.4744729806420315\n",
      "Weights: [0.43540827 2.12335743] , error: 0.47446966100686794\n",
      "Weights: [0.43522756 2.12337809] , error: 0.474466356494735\n",
      "Weights: [0.43504726 2.12339871] , error: 0.47446306703673985\n",
      "Weights: [0.43486737 2.12341929] , error: 0.4744597925642996\n",
      "Weights: [0.4346879  2.12343981] , error: 0.47445653300914536\n",
      "Weights: [0.43450883 2.12346029] , error: 0.4744532883033205\n",
      "Weights: [0.43433017 2.12348072] , error: 0.47445005837917686\n",
      "Weights: [0.43415192 2.12350111] , error: 0.47444684316937485\n",
      "Weights: [0.43397408 2.12352145] , error: 0.47444364260687977\n",
      "Weights: [0.43379664 2.12354174] , error: 0.47444045662496637\n",
      "Weights: [0.43361961 2.12356199] , error: 0.47443728515720823\n",
      "Weights: [0.43344298 2.12358219] , error: 0.4744341281374858\n",
      "Weights: [0.43326675 2.12360234] , error: 0.47443098549997925\n",
      "Weights: [0.43309093 2.12362245] , error: 0.47442785717916863\n",
      "Weights: [0.4329155  2.12364251] , error: 0.4744247431098303\n",
      "Weights: [0.43274048 2.12366253] , error: 0.4744216432270424\n",
      "Weights: [0.43256585 2.1236825 ] , error: 0.4744185574661758\n",
      "Weights: [0.43239162 2.12370242] , error: 0.47441548576289516\n",
      "Weights: [0.43221779 2.1237223 ] , error: 0.4744124280531589\n",
      "Weights: [0.43204436 2.12374214] , error: 0.4744093842732199\n",
      "Weights: [0.43187132 2.12376193] , error: 0.474406354359618\n",
      "Weights: [0.43169868 2.12378167] , error: 0.47440333824918224\n",
      "Weights: [0.43152643 2.12380137] , error: 0.4744003358790318\n",
      "Weights: [0.43135457 2.12382102] , error: 0.47439734718657023\n",
      "Weights: [0.43118311 2.12384063] , error: 0.4743943721094878\n",
      "Weights: [0.43101203 2.1238602 ] , error: 0.4743914105857563\n",
      "Weights: [0.43084135 2.12387972] , error: 0.4743884625536338\n",
      "Weights: [0.43067106 2.12389919] , error: 0.474385527951657\n",
      "Weights: [0.43050115 2.12391863] , error: 0.4743826067186421\n",
      "Weights: [0.43033163 2.12393801] , error: 0.4743796987936849\n",
      "Weights: [0.4301625  2.12395735] , error: 0.4743768041161611\n",
      "Weights: [0.42999375 2.12397665] , error: 0.4743739226257164\n",
      "Weights: [0.42982539 2.12399591] , error: 0.4743710542622794\n",
      "Weights: [0.42965741 2.12401512] , error: 0.47436819896604593\n",
      "Weights: [0.42948982 2.12403429] , error: 0.474365356677487\n",
      "Weights: [0.42932261 2.12405341] , error: 0.474362527337346\n",
      "Weights: [0.42915578 2.12407249] , error: 0.47435971088663237\n",
      "Weights: [0.42898932 2.12409152] , error: 0.47435690726662777\n",
      "Weights: [0.42882325 2.12411052] , error: 0.4743541164188795\n",
      "Weights: [0.42865756 2.12412947] , error: 0.4743513382852035\n",
      "Weights: [0.42849225 2.12414837] , error: 0.47434857280767784\n",
      "Weights: [0.42832731 2.12416723] , error: 0.474345819928646\n",
      "Weights: [0.42816275 2.12418605] , error: 0.47434307959071353\n",
      "Weights: [0.42799856 2.12420483] , error: 0.47434035173674954\n",
      "Weights: [0.42783475 2.12422357] , error: 0.4743376363098792\n",
      "Weights: [0.42767131 2.12424226] , error: 0.4743349332534916\n",
      "Weights: [0.42750825 2.12426091] , error: 0.4743322425112295\n",
      "Weights: [0.42734555 2.12427951] , error: 0.47432956402699566\n",
      "Weights: [0.42718323 2.12429808] , error: 0.47432689774494563\n",
      "Weights: [0.42702128 2.1243166 ] , error: 0.4743242436094913\n",
      "Weights: [0.42685969 2.12433508] , error: 0.4743216015652992\n",
      "Weights: [0.42669848 2.12435351] , error: 0.47431897155728364\n",
      "Weights: [0.42653763 2.12437191] , error: 0.47431635353061197\n",
      "Weights: [0.42637715 2.12439026] , error: 0.4743137474307034\n",
      "Weights: [0.42621704 2.12440857] , error: 0.47431115320322326\n",
      "Weights: [0.42605729 2.12442684] , error: 0.4743085707940848\n",
      "Weights: [0.4258979  2.12444507] , error: 0.4743060001494488\n",
      "Weights: [0.42573888 2.12446326] , error: 0.47430344121572043\n",
      "Weights: [0.42558022 2.1244814 ] , error: 0.4743008939395473\n",
      "Weights: [0.42542193 2.12449951] , error: 0.47429835826782435\n",
      "Weights: [0.42526399 2.12451757] , error: 0.4742958341476854\n",
      "Weights: [0.42510641 2.12453559] , error: 0.47429332152650383\n",
      "Weights: [0.4249492  2.12455357] , error: 0.47429082035189774\n",
      "Weights: [0.42479234 2.12457151] , error: 0.4742883305717183\n",
      "Weights: [0.42463584 2.12458941] , error: 0.4742858521340577\n",
      "Weights: [0.4244797  2.12460726] , error: 0.4742833849872433\n",
      "Weights: [0.42432391 2.12462508] , error: 0.47428092907983854\n",
      "Weights: [0.42416848 2.12464286] , error: 0.4742784843606398\n",
      "Weights: [0.4240134  2.12466059] , error: 0.47427605077868\n",
      "Weights: [0.42385868 2.12467829] , error: 0.47427362828322\n",
      "Weights: [0.4237043  2.12469594] , error: 0.4742712168237538\n",
      "Weights: [0.42355029 2.12471356] , error: 0.4742688163500062\n",
      "Weights: [0.42339662 2.12473113] , error: 0.4742664268119305\n",
      "Weights: [0.4232433  2.12474866] , error: 0.4742640481597065\n",
      "Weights: [0.42309033 2.12476616] , error: 0.4742616803437447\n",
      "Weights: [0.42293771 2.12478361] , error: 0.4742593233146767\n",
      "Weights: [0.42278544 2.12480103] , error: 0.4742569770233621\n",
      "Weights: [0.42263352 2.1248184 ] , error: 0.47425464142088447\n",
      "Weights: [0.42248194 2.12483574] , error: 0.4742523164585488\n",
      "Weights: [0.42233071 2.12485303] , error: 0.4742500020878816\n",
      "Weights: [0.42217982 2.12487029] , error: 0.4742476982606337\n",
      "Weights: [0.42202928 2.1248875 ] , error: 0.4742454049287723\n",
      "Weights: [0.42187908 2.12490468] , error: 0.4742431220444816\n",
      "Weights: [0.42172922 2.12492182] , error: 0.4742408495601693\n",
      "Weights: [0.42157971 2.12493892] , error: 0.4742385874284562\n",
      "Weights: [0.42143054 2.12495598] , error: 0.4742363356021784\n",
      "Weights: [0.4212817 2.124973 ] , error: 0.47423409403438954\n",
      "Weights: [0.42113321 2.12498998] , error: 0.47423186267835643\n",
      "Weights: [0.42098505 2.12500693] , error: 0.4742296414875564\n",
      "Weights: [0.42083723 2.12502383] , error: 0.4742274304156806\n",
      "Weights: [0.42068975 2.1250407 ] , error: 0.4742252294166312\n",
      "Weights: [0.42054261 2.12505753] , error: 0.47422303844452135\n",
      "Weights: [0.4203958  2.12507432] , error: 0.4742208574536703\n",
      "Weights: [0.42024932 2.12509107] , error: 0.4742186863986077\n",
      "Weights: [0.42010318 2.12510778] , error: 0.47421652523407043\n",
      "Weights: [0.41995738 2.12512446] , error: 0.47421437391500115\n",
      "Weights: [0.4198119  2.12514109] , error: 0.47421223239654564\n",
      "Weights: [0.41966676 2.12515769] , error: 0.4742101006340568\n",
      "Weights: [0.41952195 2.12517425] , error: 0.4742079785830906\n",
      "Weights: [0.41937747 2.12519078] , error: 0.474205866199405\n",
      "Weights: [0.41923331 2.12520726] , error: 0.47420376343895826\n",
      "Weights: [0.41908949 2.12522371] , error: 0.47420167025791204\n",
      "Weights: [0.418946   2.12524012] , error: 0.47419958661262535\n",
      "Weights: [0.41880283 2.12525649] , error: 0.47419751245965636\n",
      "Weights: [0.41865999 2.12527283] , error: 0.4741954477557627\n",
      "Weights: [0.41851747 2.12528913] , error: 0.47419339245789643\n",
      "Weights: [0.41837528 2.12530539] , error: 0.47419134652320855\n",
      "Weights: [0.41823341 2.12532162] , error: 0.47418930990904307\n",
      "Weights: [0.41809187 2.1253378 ] , error: 0.4741872825729388\n",
      "Weights: [0.41795065 2.12535395] , error: 0.4741852644726292\n",
      "Weights: [0.41780975 2.12537007] , error: 0.4741832555660398\n",
      "Weights: [0.41766917 2.12538614] , error: 0.474181255811285\n",
      "Weights: [0.41752892 2.12540218] , error: 0.47417926516667547\n",
      "Weights: [0.41738898 2.12541819] , error: 0.4741772835907064\n",
      "Weights: [0.41724936 2.12543416] , error: 0.4741753110420658\n",
      "Weights: [0.41711006 2.12545009] , error: 0.47417334747962825\n",
      "Weights: [0.41697108 2.12546598] , error: 0.47417139286245613\n",
      "Weights: [0.41683242 2.12548184] , error: 0.47416944714979625\n",
      "Weights: [0.41669407 2.12549766] , error: 0.4741675103010863\n",
      "Weights: [0.41655604 2.12551345] , error: 0.47416558227594274\n",
      "Weights: [0.41641832 2.1255292 ] , error: 0.47416366303416857\n",
      "Weights: [0.41628091 2.12554491] , error: 0.4741617525357523\n",
      "Weights: [0.41614382 2.12556059] , error: 0.47415985074085976\n",
      "Weights: [0.41600705 2.12557623] , error: 0.47415795760984336\n",
      "Weights: [0.41587058 2.12559184] , error: 0.4741560731032308\n",
      "Weights: [0.41573442 2.12560741] , error: 0.474154197181736\n",
      "Weights: [0.41559858 2.12562295] , error: 0.4741523298062448\n",
      "Weights: [0.41546305 2.12563845] , error: 0.4741504709378275\n",
      "Weights: [0.41532782 2.12565391] , error: 0.4741486205377273\n",
      "Weights: [0.4151929  2.12566934] , error: 0.47414677856736676\n",
      "Weights: [0.41505829 2.12568474] , error: 0.4741449449883429\n",
      "Weights: [0.41492399 2.12570009] , error: 0.4741431197624279\n",
      "Weights: [0.41478999 2.12571542] , error: 0.4741413028515677\n",
      "Weights: [0.4146563  2.12573071] , error: 0.47413949421788115\n",
      "Weights: [0.41452292 2.12574596] , error: 0.47413769382366255\n",
      "Weights: [0.41438984 2.12576118] , error: 0.47413590163137476\n",
      "Weights: [0.41425706 2.12577637] , error: 0.4741341176036525\n",
      "Weights: [0.41412458 2.12579152] , error: 0.4741323417033015\n",
      "Weights: [0.41399241 2.12580663] , error: 0.47413057389329694\n",
      "Weights: [0.41386054 2.12582172] , error: 0.47412881413678143\n",
      "Weights: [0.41372897 2.12583676] , error: 0.4741270623970665\n",
      "Weights: [0.41359769 2.12585178] , error: 0.4741253186376301\n",
      "Weights: [0.41346672 2.12586675] , error: 0.4741235828221174\n",
      "Weights: [0.41333605 2.1258817 ] , error: 0.4741218549143397\n",
      "Weights: [0.41320567 2.12589661] , error: 0.47412013487827054\n",
      "Weights: [0.4130756  2.12591149] , error: 0.47411842267805127\n",
      "Weights: [0.41294582 2.12592633] , error: 0.47411671827798274\n",
      "Weights: [0.41281633 2.12594114] , error: 0.474115021642531\n",
      "Weights: [0.41268714 2.12595591] , error: 0.47411333273632494\n",
      "Weights: [0.41255824 2.12597065] , error: 0.4741116515241505\n",
      "Weights: [0.41242964 2.12598536] , error: 0.47410997797095866\n",
      "Weights: [0.41230134 2.12600003] , error: 0.474108312041856\n",
      "Weights: [0.41217332 2.12601467] , error: 0.47410665370211114\n",
      "Weights: [0.4120456  2.12602928] , error: 0.47410500291714874\n",
      "Weights: [0.41191816 2.12604385] , error: 0.4741033596525537\n",
      "Weights: [0.41179102 2.12605839] , error: 0.4741017238740657\n",
      "Weights: [0.41166417 2.1260729 ] , error: 0.47410009554757826\n",
      "Weights: [0.41153761 2.12608738] , error: 0.4740984746391463\n",
      "Weights: [0.41141133 2.12610182] , error: 0.4740968611149734\n",
      "Weights: [0.41128535 2.12611623] , error: 0.4740952549414217\n",
      "Weights: [0.41115965 2.1261306 ] , error: 0.47409365608500237\n",
      "Weights: [0.41103424 2.12614494] , error: 0.4740920645123821\n",
      "Weights: [0.41090911 2.12615925] , error: 0.47409048019037886\n",
      "Weights: [0.41078427 2.12617353] , error: 0.47408890308596147\n",
      "Weights: [0.41065971 2.12618778] , error: 0.47408733316624896\n",
      "Weights: [0.41053544 2.12620199] , error: 0.4740857703985106\n",
      "Weights: [0.41041145 2.12621617] , error: 0.4740842147501651\n",
      "Weights: [0.41028775 2.12623032] , error: 0.47408266618877903\n",
      "Weights: [0.41016432 2.12624443] , error: 0.4740811246820655\n",
      "Weights: [0.41004118 2.12625851] , error: 0.4740795901978874\n",
      "Weights: [0.40991832 2.12627256] , error: 0.474078062704253\n",
      "Weights: [0.40979574 2.12628658] , error: 0.47407654216931516\n",
      "Weights: [0.40967344 2.12630057] , error: 0.4740750285613715\n",
      "Weights: [0.40955141 2.12631453] , error: 0.4740735218488672\n",
      "Weights: [0.40942967 2.12632845] , error: 0.47407202200038934\n",
      "Weights: [0.4093082  2.12634234] , error: 0.4740705289846659\n",
      "Weights: [0.40918701 2.1263562 ] , error: 0.4740690427705709\n",
      "Weights: [0.4090661  2.12637003] , error: 0.4740675633271184\n",
      "Weights: [0.40894546 2.12638382] , error: 0.47406609062346367\n",
      "Weights: [0.4088251  2.12639759] , error: 0.4740646246289024\n",
      "Weights: [0.40870501 2.12641132] , error: 0.47406316531287085\n",
      "Weights: [0.4085852  2.12642503] , error: 0.47406171264494457\n",
      "Weights: [0.40846565 2.1264387 ] , error: 0.4740602665948356\n",
      "Weights: [0.40834639 2.12645234] , error: 0.47405882713239733\n",
      "Weights: [0.40822739 2.12646595] , error: 0.4740573942276186\n",
      "Weights: [0.40810866 2.12647952] , error: 0.47405596785062365\n",
      "Weights: [0.40799021 2.12649307] , error: 0.474054547971676\n",
      "Weights: [0.40787202 2.12650659] , error: 0.4740531345611728\n",
      "Weights: [0.40775411 2.12652007] , error: 0.47405172758964426\n",
      "Weights: [0.40763646 2.12653353] , error: 0.47405032702775896\n",
      "Weights: [0.40751909 2.12654695] , error: 0.4740489328463159\n",
      "Weights: [0.40740198 2.12656034] , error: 0.4740475450162489\n",
      "Weights: [0.40728513 2.12657371] , error: 0.47404616350862294\n",
      "Weights: [0.40716856 2.12658704] , error: 0.47404478829463564\n",
      "Weights: [0.40705225 2.12660034] , error: 0.4740434193456147\n",
      "Weights: [0.4069362  2.12661361] , error: 0.4740420566330189\n",
      "Weights: [0.40682042 2.12662685] , error: 0.4740407001284399\n",
      "Weights: [0.4067049  2.12664006] , error: 0.4740393498035934\n",
      "Weights: [0.40658965 2.12665325] , error: 0.4740380056303289\n",
      "Weights: [0.40647466 2.1266664 ] , error: 0.4740366675806204\n",
      "Weights: [0.40635993 2.12667952] , error: 0.4740353356265727\n",
      "Weights: [0.40624546 2.12669261] , error: 0.47403400974041543\n",
      "Weights: [0.40613126 2.12670567] , error: 0.4740326898945048\n",
      "Weights: [0.40601731 2.1267187 ] , error: 0.47403137606132584\n",
      "Weights: [0.40590363 2.1267317 ] , error: 0.4740300682134846\n",
      "Weights: [0.4057902  2.12674467] , error: 0.4740287663237155\n",
      "Weights: [0.40567703 2.12675762] , error: 0.4740274703648748\n",
      "Weights: [0.40556412 2.12677053] , error: 0.474026180309944\n",
      "Weights: [0.40545147 2.12678341] , error: 0.4740248961320267\n",
      "Weights: [0.40533908 2.12679627] , error: 0.4740236178043495\n",
      "Weights: [0.40522694 2.12680909] , error: 0.4740223453002616\n",
      "Weights: [0.40511506 2.12682189] , error: 0.4740210785932317\n",
      "Weights: [0.40500343 2.12683465] , error: 0.47401981765685053\n",
      "Weights: [0.40489205 2.12684739] , error: 0.4740185624648302\n",
      "Weights: [0.40478094 2.1268601 ] , error: 0.47401731299100197\n",
      "Weights: [0.40467007 2.12687278] , error: 0.4740160692093128\n",
      "Weights: [0.40455946 2.12688543] , error: 0.4740148310938346\n",
      "Weights: [0.4044491  2.12689805] , error: 0.47401359861875336\n",
      "Weights: [0.40433899 2.12691064] , error: 0.47401237175837374\n",
      "Weights: [0.40422913 2.1269232 ] , error: 0.47401115048711573\n",
      "Weights: [0.40411952 2.12693574] , error: 0.4740099347795185\n",
      "Weights: [0.40401016 2.12694825] , error: 0.4740087246102358\n",
      "Weights: [0.40390105 2.12696072] , error: 0.4740075199540379\n",
      "Weights: [0.40379219 2.12697317] , error: 0.4740063207858082\n",
      "Weights: [0.40368358 2.1269856 ] , error: 0.4740051270805459\n",
      "Weights: [0.40357522 2.12699799] , error: 0.4740039388133642\n",
      "Weights: [0.4034671  2.12701035] , error: 0.4740027559594877\n",
      "Weights: [0.40335923 2.12702269] , error: 0.4740015784942586\n",
      "Weights: [0.40325161 2.127035  ] , error: 0.4740004063931242\n",
      "Weights: [0.40314423 2.12704728] , error: 0.4739992396316496\n",
      "Weights: [0.4030371  2.12705953] , error: 0.4739980781855095\n",
      "Weights: [0.40293021 2.12707175] , error: 0.47399692203049004\n",
      "Weights: [0.40282356 2.12708395] , error: 0.47399577114248403\n",
      "Weights: [0.40271716 2.12709612] , error: 0.47399462549749943\n",
      "Weights: [0.402611   2.12710826] , error: 0.4739934850716504\n",
      "Weights: [0.40250508 2.12712037] , error: 0.47399234984116034\n",
      "Weights: [0.40239941 2.12713246] , error: 0.47399121978236\n",
      "Weights: [0.40229397 2.12714452] , error: 0.47399009487169097\n",
      "Weights: [0.40218878 2.12715655] , error: 0.4739889750856994\n",
      "Weights: [0.40208382 2.12716855] , error: 0.47398786040103774\n",
      "Weights: [0.40197911 2.12718053] , error: 0.4739867507944687\n",
      "Weights: [0.40187463 2.12719247] , error: 0.47398564624285744\n",
      "Weights: [0.40177039 2.1272044 ] , error: 0.47398454672317514\n",
      "Weights: [0.40166639 2.12721629] , error: 0.4739834522124975\n",
      "Weights: [0.40156263 2.12722816] , error: 0.4739823626880063\n",
      "Weights: [0.4014591 2.12724  ] , error: 0.47398127812698665\n",
      "Weights: [0.40135581 2.12725181] , error: 0.4739801985068268\n",
      "Weights: [0.40125276 2.12726359] , error: 0.4739791238050167\n",
      "Weights: [0.40114994 2.12727535] , error: 0.47397805399915166\n",
      "Weights: [0.40104735 2.12728709] , error: 0.4739769890669262\n",
      "Weights: [0.400945   2.12729879] , error: 0.47397592898613916\n",
      "Weights: [0.40084288 2.12731047] , error: 0.4739748737346886\n",
      "Weights: [0.40074099 2.12732212] , error: 0.4739738232905732\n",
      "Weights: [0.40063934 2.12733375] , error: 0.4739727776318931\n",
      "Weights: [0.40053792 2.12734535] , error: 0.47397173673684834\n",
      "Weights: [0.40043673 2.12735692] , error: 0.4739707005837366\n",
      "Weights: [0.40033577 2.12736847] , error: 0.4739696691509555\n",
      "Weights: [0.40023504 2.12737999] , error: 0.47396864241700115\n",
      "Weights: [0.40013454 2.12739148] , error: 0.47396762036046697\n",
      "Weights: [0.40003427 2.12740295] , error: 0.473966602960045\n",
      "Weights: [0.39993423 2.12741439] , error: 0.47396559019452345\n",
      "Weights: [0.39983442 2.1274258 ] , error: 0.47396458204278746\n",
      "Weights: [0.39973483 2.12743719] , error: 0.4739635784838193\n",
      "Weights: [0.39963547 2.12744855] , error: 0.47396257949669446\n",
      "Weights: [0.39953634 2.12745989] , error: 0.47396158506058494\n",
      "Weights: [0.39943743 2.1274712 ] , error: 0.4739605951547597\n",
      "Weights: [0.39933875 2.12748249] , error: 0.4739596097585798\n",
      "Weights: [0.3992403  2.12749375] , error: 0.473958628851501\n",
      "Weights: [0.39914207 2.12750498] , error: 0.47395765241307153\n",
      "Weights: [0.39904406 2.12751619] , error: 0.4739566804229357\n",
      "Weights: [0.39894628 2.12752737] , error: 0.473955712860828\n",
      "Weights: [0.39884872 2.12753853] , error: 0.47395474970657525\n",
      "Weights: [0.39875138 2.12754966] , error: 0.4739537909400972\n",
      "Weights: [0.39865426 2.12756077] , error: 0.4739528365414052\n",
      "Weights: [0.39855737 2.12757185] , error: 0.4739518864906017\n",
      "Weights: [0.39846069 2.12758291] , error: 0.47395094076787864\n",
      "Weights: [0.39836424 2.12759394] , error: 0.4739499993535178\n",
      "Weights: [0.39826801 2.12760494] , error: 0.4739490622278936\n",
      "Weights: [0.39817199 2.12761592] , error: 0.47394812937146724\n",
      "Weights: [0.3980762  2.12762688] , error: 0.47394720076479085\n",
      "Weights: [0.39798062 2.12763781] , error: 0.47394627638850334\n",
      "Weights: [0.39788526 2.12764872] , error: 0.47394535622333206\n",
      "Weights: [0.39779012 2.1276596 ] , error: 0.4739444402500935\n",
      "Weights: [0.3976952  2.12767045] , error: 0.4739435284496913\n",
      "Weights: [0.39760049 2.12768128] , error: 0.4739426208031142\n",
      "Weights: [0.397506   2.12769209] , error: 0.4739417172914404\n",
      "Weights: [0.39741172 2.12770287] , error: 0.4739408178958305\n",
      "Weights: [0.39731766 2.12771363] , error: 0.4739399225975357\n",
      "Weights: [0.39722382 2.12772436] , error: 0.47393903137788973\n",
      "Weights: [0.39713018 2.12773507] , error: 0.47393814421831015\n",
      "Weights: [0.39703676 2.12774575] , error: 0.4739372611003021\n",
      "Weights: [0.39694356 2.12775641] , error: 0.47393638200545307\n",
      "Weights: [0.39685057 2.12776705] , error: 0.4739355069154362\n",
      "Weights: [0.39675778 2.12777766] , error: 0.47393463581200607\n",
      "Weights: [0.39666521 2.12778825] , error: 0.4739337686770017\n",
      "Weights: [0.39657286 2.12779881] , error: 0.4739329054923437\n",
      "Weights: [0.39648071 2.12780935] , error: 0.47393204624003504\n",
      "Weights: [0.39638877 2.12781986] , error: 0.47393119090216373\n",
      "Weights: [0.39629704 2.12783035] , error: 0.4739303394608945\n",
      "Weights: [0.39620552 2.12784082] , error: 0.47392949189847855\n",
      "Weights: [0.39611421 2.12785126] , error: 0.4739286481972432\n",
      "Weights: [0.39602311 2.12786168] , error: 0.47392780833959947\n",
      "Weights: [0.39593221 2.12787207] , error: 0.47392697230803665\n",
      "Weights: [0.39584153 2.12788245] , error: 0.47392614008512357\n",
      "Weights: [0.39575105 2.12789279] , error: 0.4739253116535122\n",
      "Weights: [0.39566077 2.12790312] , error: 0.47392448699592854\n",
      "Weights: [0.3955707  2.12791342] , error: 0.4739236660951799\n",
      "Weights: [0.39548084 2.1279237 ] , error: 0.4739228489341529\n",
      "Weights: [0.39539118 2.12793395] , error: 0.4739220354958091\n",
      "Weights: [0.39530173 2.12794418] , error: 0.47392122576318985\n",
      "Weights: [0.39521248 2.12795439] , error: 0.4739204197194125\n",
      "Weights: [0.39512344 2.12796457] , error: 0.4739196173476741\n",
      "Weights: [0.39503459 2.12797473] , error: 0.47391881863124385\n",
      "Weights: [0.39494595 2.12798487] , error: 0.4739180235534711\n",
      "Weights: [0.39485751 2.12799498] , error: 0.47391723209777864\n",
      "Weights: [0.39476928 2.12800507] , error: 0.47391644424766627\n",
      "Weights: [0.39468124 2.12801514] , error: 0.47391565998670765\n",
      "Weights: [0.39459341 2.12802519] , error: 0.473914879298552\n",
      "Weights: [0.39450577 2.12803521] , error: 0.4739141021669241\n",
      "Weights: [0.39441834 2.12804521] , error: 0.4739133285756199\n",
      "Weights: [0.3943311  2.12805518] , error: 0.4739125585085121\n",
      "Weights: [0.39424407 2.12806514] , error: 0.4739117919495459\n",
      "Weights: [0.39415723 2.12807507] , error: 0.47391102888273856\n",
      "Weights: [0.39407059 2.12808498] , error: 0.47391026929218133\n",
      "Weights: [0.39398415 2.12809486] , error: 0.47390951316203883\n",
      "Weights: [0.39389791 2.12810473] , error: 0.47390876047654634\n",
      "Weights: [0.39381186 2.12811457] , error: 0.4739080112200109\n",
      "Weights: [0.39372601 2.12812439] , error: 0.47390726537680994\n",
      "Weights: [0.39364035 2.12813418] , error: 0.4739065229313967\n",
      "Weights: [0.39355489 2.12814396] , error: 0.47390578386829063\n",
      "Weights: [0.39346962 2.12815371] , error: 0.4739050481720812\n",
      "Weights: [0.39338455 2.12816344] , error: 0.4739043158274333\n",
      "Weights: [0.39329967 2.12817314] , error: 0.47390358681907624\n",
      "Weights: [0.39321499 2.12818283] , error: 0.4739028611318119\n",
      "Weights: [0.3931305  2.12819249] , error: 0.4739021387505117\n",
      "Weights: [0.3930462  2.12820213] , error: 0.4739014196601125\n",
      "Weights: [0.3929621  2.12821175] , error: 0.4739007038456246\n",
      "Weights: [0.39287818 2.12822135] , error: 0.4738999912921228\n",
      "Weights: [0.39279446 2.12823092] , error: 0.4738992819847508\n",
      "Weights: [0.39271093 2.12824047] , error: 0.4738985759087219\n",
      "Weights: [0.39262759 2.12825001] , error: 0.4738978730493149\n",
      "Weights: [0.39254443 2.12825952] , error: 0.47389717339187454\n",
      "Weights: [0.39246147 2.128269  ] , error: 0.4738964769218153\n",
      "Weights: [0.3923787  2.12827847] , error: 0.47389578362461676\n",
      "Weights: [0.39229612 2.12828791] , error: 0.47389509348582426\n",
      "Weights: [0.39221372 2.12829734] , error: 0.47389440649104886\n",
      "Weights: [0.39213151 2.12830674] , error: 0.47389372262596735\n",
      "Weights: [0.39204949 2.12831612] , error: 0.4738930418763239\n",
      "Weights: [0.39196766 2.12832548] , error: 0.47389236422792314\n",
      "Weights: [0.39188601 2.12833482] , error: 0.4738916896666382\n",
      "Weights: [0.39180455 2.12834413] , error: 0.4738910181784044\n",
      "Weights: [0.39172328 2.12835343] , error: 0.4738903497492249\n",
      "Weights: [0.39164219 2.1283627 ] , error: 0.4738896843651612\n",
      "Weights: [0.39156129 2.12837195] , error: 0.47388902201234134\n",
      "Weights: [0.39148057 2.12838118] , error: 0.47388836267695617\n",
      "Weights: [0.39140003 2.12839039] , error: 0.4738877063452591\n",
      "Weights: [0.39131968 2.12839958] , error: 0.47388705300356754\n",
      "Weights: [0.39123951 2.12840875] , error: 0.47388640263825793\n",
      "Weights: [0.39115952 2.1284179 ] , error: 0.4738857552357727\n",
      "Weights: [0.39107972 2.12842703] , error: 0.4738851107826148\n",
      "Weights: [0.3910001  2.12843613] , error: 0.4738844692653477\n",
      "Weights: [0.39092066 2.12844522] , error: 0.47388383067059564\n",
      "Weights: [0.3908414  2.12845428] , error: 0.47388319498504494\n",
      "Weights: [0.39076232 2.12846333] , error: 0.4738825621954441\n",
      "Weights: [0.39068343 2.12847235] , error: 0.4738819322885974\n",
      "Weights: [0.39060471 2.12848135] , error: 0.47388130525137495\n",
      "Weights: [0.39052617 2.12849033] , error: 0.473880681070702\n",
      "Weights: [0.39044781 2.12849929] , error: 0.4738800597335652\n",
      "Weights: [0.39036963 2.12850824] , error: 0.4738794412270102\n",
      "Weights: [0.39029163 2.12851716] , error: 0.4738788255381435\n",
      "Weights: [0.3902138  2.12852606] , error: 0.4738782126541286\n",
      "Weights: [0.39013616 2.12853494] , error: 0.47387760256218564\n",
      "Weights: [0.39005869 2.1285438 ] , error: 0.47387699524959603\n",
      "Weights: [0.38998139 2.12855264] , error: 0.4738763907036988\n",
      "Weights: [0.38990428 2.12856145] , error: 0.4738757889118893\n",
      "Weights: [0.38982734 2.12857025] , error: 0.473875189861621\n",
      "Weights: [0.38975057 2.12857903] , error: 0.4738745935404042\n",
      "Weights: [0.38967398 2.12858779] , error: 0.4738739999358069\n",
      "Weights: [0.38959756 2.12859653] , error: 0.4738734090354505\n",
      "Weights: [0.38952132 2.12860525] , error: 0.47387282082702065\n",
      "Weights: [0.38944525 2.12861395] , error: 0.4738722352982511\n",
      "Weights: [0.38936936 2.12862263] , error: 0.4738716524369336\n",
      "Weights: [0.38929364 2.12863129] , error: 0.4738710722309161\n",
      "Weights: [0.38921809 2.12863993] , error: 0.47387049466810405\n",
      "Weights: [0.38914271 2.12864855] , error: 0.4738699197364546\n",
      "Weights: [0.38906751 2.12865715] , error: 0.47386934742398124\n",
      "Weights: [0.38899248 2.12866573] , error: 0.4738687777187521\n",
      "Weights: [0.38891762 2.12867429] , error: 0.47386821060888845\n",
      "Weights: [0.38884293 2.12868284] , error: 0.47386764608256876\n",
      "Weights: [0.3887684  2.12869136] , error: 0.47386708412802236\n",
      "Weights: [0.38869405 2.12869986] , error: 0.47386652473353313\n",
      "Weights: [0.38861987 2.12870834] , error: 0.47386596788743907\n",
      "Weights: [0.38854586 2.12871681] , error: 0.47386541357812956\n",
      "Weights: [0.38847202 2.12872525] , error: 0.47386486179404885\n",
      "Weights: [0.38839834 2.12873368] , error: 0.4738643125236921\n",
      "Weights: [0.38832484 2.12874209] , error: 0.4738637657556084\n",
      "Weights: [0.3882515  2.12875047] , error: 0.47386322147839827\n",
      "Weights: [0.38817832 2.12875884] , error: 0.47386267968071416\n",
      "Weights: [0.38810532 2.12876719] , error: 0.4738621403512594\n",
      "Weights: [0.38803248 2.12877552] , error: 0.4738616034787907\n",
      "Weights: [0.38795981 2.12878383] , error: 0.47386106905211545\n",
      "Weights: [0.3878873  2.12879212] , error: 0.4738605370600891\n",
      "Weights: [0.38781496 2.1288004 ] , error: 0.4738600074916234\n",
      "Weights: [0.38774278 2.12880865] , error: 0.47385948033567554\n",
      "Weights: [0.38767077 2.12881689] , error: 0.4738589555812549\n",
      "Weights: [0.38759892 2.1288251 ] , error: 0.4738584332174221\n",
      "Weights: [0.38752724 2.1288333 ] , error: 0.4738579132332861\n",
      "Weights: [0.38745572 2.12884148] , error: 0.473857395618005\n",
      "Weights: [0.38738436 2.12884964] , error: 0.47385688036078777\n",
      "Weights: [0.38731317 2.12885778] , error: 0.47385636745089277\n",
      "Weights: [0.38724214 2.12886591] , error: 0.4738558568776255\n",
      "Weights: [0.38717127 2.12887401] , error: 0.47385534863034084\n",
      "Weights: [0.38710056 2.1288821 ] , error: 0.47385484269844436\n",
      "Weights: [0.38703001 2.12889017] , error: 0.4738543390713857\n",
      "Weights: [0.38695962 2.12889822] , error: 0.47385383773866596\n",
      "Weights: [0.3868894  2.12890625] , error: 0.47385333868983354\n",
      "Weights: [0.38681933 2.12891426] , error: 0.4738528419144825\n",
      "Weights: [0.38674943 2.12892226] , error: 0.47385234740225685\n",
      "Weights: [0.38667968 2.12893023] , error: 0.47385185514284545\n",
      "Weights: [0.38661009 2.12893819] , error: 0.4738513651259867\n",
      "Weights: [0.38654066 2.12894613] , error: 0.4738508773414637\n",
      "Weights: [0.38647139 2.12895405] , error: 0.47385039177910704\n",
      "Weights: [0.38640228 2.12896196] , error: 0.47384990842879277\n",
      "Weights: [0.38633332 2.12896984] , error: 0.4738494272804438\n",
      "Weights: [0.38626453 2.12897771] , error: 0.4738489483240292\n",
      "Weights: [0.38619589 2.12898556] , error: 0.47384847154956267\n",
      "Weights: [0.3861274  2.12899339] , error: 0.47384799694710467\n",
      "Weights: [0.38605907 2.12900121] , error: 0.47384752450676076\n",
      "Weights: [0.3859909  2.12900901] , error: 0.47384705421868023\n",
      "Weights: [0.38592288 2.12901678] , error: 0.4738465860730564\n",
      "Weights: [0.38585502 2.12902454] , error: 0.4738461200601339\n",
      "Weights: [0.38578732 2.12903229] , error: 0.47384565617019314\n",
      "Weights: [0.38571976 2.12904001] , error: 0.4738451943935642\n",
      "Weights: [0.38565236 2.12904772] , error: 0.47384473472061817\n",
      "Weights: [0.38558512 2.12905541] , error: 0.47384427714177235\n",
      "Weights: [0.38551803 2.12906308] , error: 0.47384382164748695\n",
      "Weights: [0.38545109 2.12907074] , error: 0.47384336822826434\n",
      "Weights: [0.3853843  2.12907838] , error: 0.47384291687465363\n",
      "Weights: [0.38531767 2.129086  ] , error: 0.4738424675772427\n",
      "Weights: [0.38525119 2.1290936 ] , error: 0.47384202032666456\n",
      "Weights: [0.38518486 2.12910119] , error: 0.473841575113594\n",
      "Weights: [0.38511868 2.12910876] , error: 0.4738411319287512\n",
      "Weights: [0.38505265 2.12911631] , error: 0.473840690762894\n",
      "Weights: [0.38498677 2.12912384] , error: 0.4738402516068265\n",
      "Weights: [0.38492105 2.12913136] , error: 0.47383981445139056\n",
      "Weights: [0.38485547 2.12913886] , error: 0.4738393792874733\n",
      "Weights: [0.38479004 2.12914634] , error: 0.4738389461060029\n",
      "Weights: [0.38472476 2.12915381] , error: 0.4738385148979467\n",
      "Weights: [0.38465964 2.12916125] , error: 0.47383808565431484\n",
      "Weights: [0.38459465 2.12916869] , error: 0.4738376583661586\n",
      "Weights: [0.38452982 2.1291761 ] , error: 0.47383723302456954\n",
      "Weights: [0.38446514 2.1291835 ] , error: 0.47383680962067953\n",
      "Weights: [0.3844006  2.12919088] , error: 0.4738363881456631\n",
      "Weights: [0.38433621 2.12919824] , error: 0.47383596859072774\n",
      "Weights: [0.38427197 2.12920559] , error: 0.4738355509471309\n",
      "Weights: [0.38420787 2.12921292] , error: 0.4738351352061646\n",
      "Weights: [0.38414392 2.12922023] , error: 0.4738347213591608\n",
      "Weights: [0.38408011 2.12922753] , error: 0.47383430939749016\n",
      "Weights: [0.38401645 2.12923481] , error: 0.4738338993125647\n",
      "Weights: [0.38395294 2.12924207] , error: 0.4738334910958346\n",
      "Weights: [0.38388957 2.12924932] , error: 0.47383308473879004\n",
      "Weights: [0.38382634 2.12925655] , error: 0.47383268023295727\n",
      "Weights: [0.38376326 2.12926377] , error: 0.47383227756990415\n",
      "Weights: [0.38370033 2.12927096] , error: 0.4738318767412343\n",
      "Weights: [0.38363753 2.12927815] , error: 0.4738314777385928\n",
      "Weights: [0.38357488 2.12928531] , error: 0.47383108055365925\n",
      "Weights: [0.38351238 2.12929246] , error: 0.47383068517815385\n",
      "Weights: [0.38345001 2.12929959] , error: 0.4738302916038334\n",
      "Weights: [0.38338779 2.12930671] , error: 0.47382989982249185\n",
      "Weights: [0.38332571 2.12931381] , error: 0.47382950982596117\n",
      "Weights: [0.38326377 2.12932089] , error: 0.4738291216061111\n",
      "Weights: [0.38320197 2.12932796] , error: 0.47382873515484647\n",
      "Weights: [0.38314031 2.12933501] , error: 0.47382835046411165\n",
      "Weights: [0.3830788  2.12934205] , error: 0.47382796752588635\n",
      "Weights: [0.38301742 2.12934906] , error: 0.47382758633218475\n",
      "Weights: [0.38295619 2.12935607] , error: 0.47382720687506164\n",
      "Weights: [0.38289509 2.12936306] , error: 0.47382682914660423\n",
      "Weights: [0.38283413 2.12937003] , error: 0.4738264531389392\n",
      "Weights: [0.38277331 2.12937698] , error: 0.4738260788442251\n",
      "Weights: [0.38271263 2.12938392] , error: 0.47382570625466003\n",
      "Weights: [0.38265209 2.12939085] , error: 0.47382533536247584\n",
      "Weights: [0.38259169 2.12939775] , error: 0.47382496615993797\n",
      "Weights: [0.38253143 2.12940465] , error: 0.47382459863935156\n",
      "Weights: [0.3824713  2.12941152] , error: 0.4738242327930532\n",
      "Weights: [0.38241131 2.12941838] , error: 0.4738238686134146\n",
      "Weights: [0.38235145 2.12942523] , error: 0.4738235060928455\n",
      "Weights: [0.38229174 2.12943206] , error: 0.47382314522378444\n",
      "Weights: [0.38223215 2.12943887] , error: 0.47382278599871014\n",
      "Weights: [0.38217271 2.12944567] , error: 0.47382242841013367\n",
      "Weights: [0.3821134  2.12945245] , error: 0.47382207245059693\n",
      "Weights: [0.38205422 2.12945922] , error: 0.4738217181126807\n",
      "Weights: [0.38199518 2.12946597] , error: 0.47382136538899744\n",
      "Weights: [0.38193628 2.12947271] , error: 0.47382101427219286\n",
      "Weights: [0.38187751 2.12947943] , error: 0.47382066475494755\n",
      "Weights: [0.38181887 2.12948614] , error: 0.47382031682997305\n",
      "Weights: [0.38176037 2.12949283] , error: 0.473819970490015\n",
      "Weights: [0.381702  2.1294995] , error: 0.4738196257278555\n",
      "Weights: [0.38164376 2.12950616] , error: 0.47381928253630445\n",
      "Weights: [0.38158566 2.12951281] , error: 0.473818940908208\n",
      "Weights: [0.38152769 2.12951944] , error: 0.4738186008364419\n",
      "Weights: [0.38146985 2.12952605] , error: 0.4738182623139174\n",
      "Weights: [0.38141214 2.12953265] , error: 0.4738179253335764\n",
      "Weights: [0.38135457 2.12953924] , error: 0.4738175898883944\n",
      "Weights: [0.38129712 2.12954581] , error: 0.47381725597137553\n",
      "Weights: [0.38123981 2.12955236] , error: 0.47381692357555916\n",
      "Weights: [0.38118263 2.1295589 ] , error: 0.4738165926940163\n",
      "Weights: [0.38112558 2.12956542] , error: 0.4738162633198465\n",
      "Weights: [0.38106865 2.12957193] , error: 0.47381593544618467\n",
      "Weights: [0.38101186 2.12957843] , error: 0.473815609066193\n",
      "Weights: [0.3809552  2.12958491] , error: 0.47381528417306856\n",
      "Weights: [0.38089867 2.12959137] , error: 0.4738149607600379\n",
      "Weights: [0.38084226 2.12959783] , error: 0.47381463882035596\n",
      "Weights: [0.38078599 2.12960426] , error: 0.4738143183473129\n",
      "Weights: [0.38072984 2.12961068] , error: 0.47381399933422713\n",
      "Weights: [0.38067382 2.12961709] , error: 0.47381368177444744\n",
      "Weights: [0.38061793 2.12962348] , error: 0.47381336566135135\n",
      "Weights: [0.38056216 2.12962986] , error: 0.4738130509883516\n",
      "Weights: [0.38050653 2.12963622] , error: 0.4738127377488849\n",
      "Weights: [0.38045102 2.12964257] , error: 0.47381242593642015\n",
      "Weights: [0.38039563 2.1296489 ] , error: 0.4738121155444601\n",
      "Weights: [0.38034038 2.12965522] , error: 0.4738118065665298\n",
      "Weights: [0.38028524 2.12966153] , error: 0.473811498996189\n",
      "Weights: [0.38023024 2.12966782] , error: 0.47381119282702505\n",
      "Weights: [0.38017536 2.1296741 ] , error: 0.4738108880526559\n",
      "Weights: [0.3801206  2.12968036] , error: 0.4738105846667239\n",
      "Weights: [0.38006597 2.1296866 ] , error: 0.4738102826629078\n",
      "Weights: [0.38001147 2.12969284] , error: 0.47380998203490854\n",
      "Weights: [0.37995709 2.12969906] , error: 0.47380968277645935\n",
      "Weights: [0.37990283 2.12970526] , error: 0.47380938488132246\n",
      "Weights: [0.3798487  2.12971145] , error: 0.473809088343284\n",
      "Weights: [0.37979469 2.12971763] , error: 0.47380879315616414\n",
      "Weights: [0.3797408  2.12972379] , error: 0.4738084993138083\n",
      "Weights: [0.37968703 2.12972994] , error: 0.47380820681008873\n",
      "Weights: [0.37963339 2.12973608] , error: 0.4738079156389089\n",
      "Weights: [0.37957987 2.1297422 ] , error: 0.47380762579419666\n",
      "Weights: [0.37952648 2.1297483 ] , error: 0.47380733726991037\n",
      "Weights: [0.3794732 2.1297544] , error: 0.47380705006003404\n",
      "Weights: [0.37942005 2.12976048] , error: 0.4738067641585791\n",
      "Weights: [0.37936702 2.12976654] , error: 0.4738064795595861\n",
      "Weights: [0.3793141  2.12977259] , error: 0.473806196257121\n",
      "Weights: [0.37926131 2.12977863] , error: 0.47380591424527724\n",
      "Weights: [0.37920864 2.12978465] , error: 0.47380563351817473\n",
      "Weights: [0.37915609 2.12979066] , error: 0.4738053540699622\n",
      "Weights: [0.37910366 2.12979666] , error: 0.4738050758948122\n",
      "Weights: [0.37905135 2.12980264] , error: 0.47380479898692524\n",
      "Weights: [0.37899916 2.12980861] , error: 0.4738045233405288\n",
      "Weights: [0.37894709 2.12981457] , error: 0.4738042489498744\n",
      "Weights: [0.37889513 2.12982051] , error: 0.473803975809243\n",
      "Weights: [0.3788433  2.12982644] , error: 0.4738037039129392\n",
      "Weights: [0.37879158 2.12983235] , error: 0.4738034332552953\n",
      "Weights: [0.37873998 2.12983825] , error: 0.473803163830667\n",
      "Weights: [0.3786885  2.12984414] , error: 0.473802895633438\n",
      "Weights: [0.37863713 2.12985001] , error: 0.47380262865801615\n",
      "Weights: [0.37858589 2.12985587] , error: 0.47380236289883537\n",
      "Weights: [0.37853476 2.12986172] , error: 0.47380209835035664\n",
      "Weights: [0.37848374 2.12986756] , error: 0.47380183500706147\n",
      "Weights: [0.37843284 2.12987338] , error: 0.4738015728634622\n",
      "Weights: [0.37838206 2.12987918] , error: 0.473801311914092\n",
      "Weights: [0.3783314  2.12988498] , error: 0.4738010521535099\n",
      "Weights: [0.37828085 2.12989076] , error: 0.4738007935763021\n",
      "Weights: [0.37823041 2.12989653] , error: 0.4738005361770757\n",
      "Weights: [0.37818009 2.12990228] , error: 0.4738002799504668\n",
      "Weights: [0.37812989 2.12990802] , error: 0.47380002489112966\n",
      "Weights: [0.3780798  2.12991375] , error: 0.47379977099374954\n",
      "Weights: [0.37802982 2.12991947] , error: 0.4737995182530318\n",
      "Weights: [0.37797996 2.12992517] , error: 0.4737992666637079\n",
      "Weights: [0.37793021 2.12993086] , error: 0.47379901622053217\n",
      "Weights: [0.37788058 2.12993654] , error: 0.4737987669182821\n",
      "Weights: [0.37783105 2.1299422 ] , error: 0.47379851875176093\n",
      "Weights: [0.37778164 2.12994785] , error: 0.4737982717157958\n",
      "Weights: [0.37773235 2.12995349] , error: 0.473798025805234\n",
      "Weights: [0.37768316 2.12995911] , error: 0.47379778101495074\n",
      "Weights: [0.37763409 2.12996472] , error: 0.47379753733984215\n",
      "Weights: [0.37758513 2.12997032] , error: 0.4737972947748267\n",
      "Weights: [0.37753628 2.12997591] , error: 0.47379705331484734\n",
      "Weights: [0.37748755 2.12998148] , error: 0.4737968129548701\n",
      "Weights: [0.37743892 2.12998705] , error: 0.4737965736898846\n",
      "Weights: [0.37739041 2.12999259] , error: 0.47379633551490297\n",
      "Weights: [0.377342   2.12999813] , error: 0.47379609842495746\n",
      "Weights: [0.37729371 2.13000365] , error: 0.47379586241510696\n",
      "Weights: [0.37724553 2.13000916] , error: 0.4737956274804296\n",
      "Weights: [0.37719745 2.13001466] , error: 0.473795393616028\n",
      "Weights: [0.37714949 2.13002015] , error: 0.47379516081702594\n",
      "Weights: [0.37710163 2.13002562] , error: 0.4737949290785696\n",
      "Weights: [0.37705389 2.13003108] , error: 0.47379469839582994\n",
      "Weights: [0.37700625 2.13003653] , error: 0.4737944687639941\n",
      "Weights: [0.37695872 2.13004196] , error: 0.47379424017827604\n",
      "Weights: [0.3769113  2.13004739] , error: 0.47379401263391085\n",
      "Weights: [0.37686399 2.1300528 ] , error: 0.4737937861261531\n",
      "Weights: [0.37681679 2.1300582 ] , error: 0.4737935606502812\n",
      "Weights: [0.37676969 2.13006358] , error: 0.4737933362015938\n",
      "Weights: [0.3767227  2.13006896] , error: 0.473793112775412\n",
      "Weights: [0.37667582 2.13007432] , error: 0.47379289036707706\n",
      "Weights: [0.37662905 2.13007967] , error: 0.4737926689719533\n",
      "Weights: [0.37658238 2.130085  ] , error: 0.4737924485854238\n",
      "Weights: [0.37653582 2.13009033] , error: 0.4737922292028923\n",
      "Weights: [0.37648936 2.13009564] , error: 0.4737920108197872\n",
      "Weights: [0.37644301 2.13010094] , error: 0.47379179343155586\n",
      "Weights: [0.37639677 2.13010623] , error: 0.4737915770336649\n",
      "Weights: [0.37635063 2.13011151] , error: 0.47379136162160174\n",
      "Weights: [0.3763046  2.13011677] , error: 0.473791147190877\n",
      "Weights: [0.37625867 2.13012202] , error: 0.4737909337370199\n",
      "Weights: [0.37621285 2.13012726] , error: 0.4737907212555784\n",
      "Weights: [0.37616713 2.13013249] , error: 0.4737905097421245\n",
      "Weights: [0.37612151 2.13013771] , error: 0.47379029919224813\n",
      "Weights: [0.376076   2.13014291] , error: 0.47379008960155833\n",
      "Weights: [0.3760306  2.13014811] , error: 0.47378988096568797\n",
      "Weights: [0.37598529 2.13015329] , error: 0.47378967328028376\n",
      "Weights: [0.37594009 2.13015846] , error: 0.47378946654101806\n",
      "Weights: [0.375895   2.13016362] , error: 0.4737892607435805\n",
      "Weights: [0.37585    2.13016876] , error: 0.47378905588367937\n",
      "Weights: [0.37580511 2.1301739 ] , error: 0.4737888519570462\n",
      "Weights: [0.37576032 2.13017902] , error: 0.47378864895942446\n",
      "Weights: [0.37571563 2.13018413] , error: 0.4737884468865869\n",
      "Weights: [0.37567105 2.13018923] , error: 0.47378824573431755\n",
      "Weights: [0.37562657 2.13019431] , error: 0.4737880454984243\n",
      "Weights: [0.37558218 2.13019939] , error: 0.47378784617473113\n",
      "Weights: [0.3755379  2.13020445] , error: 0.4737876477590833\n",
      "Weights: [0.37549372 2.13020951] , error: 0.4737874502473447\n",
      "Weights: [0.37544964 2.13021455] , error: 0.47378725363539564\n",
      "Weights: [0.37540567 2.13021958] , error: 0.47378705791913867\n",
      "Weights: [0.37536179 2.1302246 ] , error: 0.47378686309449236\n",
      "Weights: [0.37531801 2.1302296 ] , error: 0.47378666915739465\n",
      "Weights: [0.37527433 2.1302346 ] , error: 0.4737864761038032\n",
      "Weights: [0.37523075 2.13023958] , error: 0.4737862839296926\n",
      "Weights: [0.37518727 2.13024455] , error: 0.4737860926310561\n",
      "Weights: [0.37514389 2.13024951] , error: 0.4737859022039058\n",
      "Weights: [0.37510061 2.13025446] , error: 0.47378571264427094\n",
      "Weights: [0.37505743 2.1302594 ] , error: 0.4737855239481998\n",
      "Weights: [0.37501435 2.13026433] , error: 0.4737853361117582\n",
      "Weights: [0.37497136 2.13026925] , error: 0.4737851491310301\n",
      "Weights: [0.37492847 2.13027415] , error: 0.47378496300211825\n",
      "Weights: [0.37488568 2.13027904] , error: 0.47378477772113886\n",
      "Weights: [0.37484299 2.13028393] , error: 0.4737845932842317\n",
      "Weights: [0.3748004 2.1302888] , error: 0.4737844096875516\n",
      "Weights: [0.3747579  2.13029366] , error: 0.4737842269272705\n",
      "Weights: [0.3747155  2.13029851] , error: 0.4737840449995773\n",
      "Weights: [0.37467319 2.13030335] , error: 0.4737838639006786\n",
      "Weights: [0.37463098 2.13030817] , error: 0.4737836836268006\n",
      "Weights: [0.37458887 2.13031299] , error: 0.47378350417418413\n",
      "Weights: [0.37454686 2.13031779] , error: 0.47378332553908586\n",
      "Weights: [0.37450494 2.13032259] , error: 0.47378314771778435\n",
      "Weights: [0.37446311 2.13032737] , error: 0.4737829707065711\n",
      "Weights: [0.37442139 2.13033214] , error: 0.47378279450175464\n",
      "Weights: [0.37437975 2.13033691] , error: 0.4737826190996628\n",
      "Weights: [0.37433821 2.13034166] , error: 0.47378244449663803\n",
      "Weights: [0.37429677 2.1303464 ] , error: 0.4737822706890409\n",
      "Weights: [0.37425542 2.13035112] , error: 0.47378209767324536\n",
      "Weights: [0.37421416 2.13035584] , error: 0.47378192544564696\n",
      "Weights: [0.374173   2.13036055] , error: 0.4737817540026543\n",
      "Weights: [0.37413194 2.13036525] , error: 0.4737815833406913\n",
      "Weights: [0.37409096 2.13036993] , error: 0.4737814134562015\n",
      "Weights: [0.37405008 2.13037461] , error: 0.473781244345643\n",
      "Weights: [0.3740093  2.13037927] , error: 0.47378107600549035\n",
      "Weights: [0.3739686  2.13038393] , error: 0.4737809084322317\n",
      "Weights: [0.373928   2.13038857] , error: 0.4737807416223764\n",
      "Weights: [0.37388749 2.1303932 ] , error: 0.47378057557244413\n",
      "Weights: [0.37384708 2.13039782] , error: 0.473780410278975\n",
      "Weights: [0.37380675 2.13040244] , error: 0.47378024573852084\n",
      "Weights: [0.37376652 2.13040704] , error: 0.47378008194765264\n",
      "Weights: [0.37372638 2.13041163] , error: 0.473779918902955\n",
      "Weights: [0.37368633 2.13041621] , error: 0.47377975660102944\n",
      "Weights: [0.37364637 2.13042078] , error: 0.47377959503849076\n",
      "Weights: [0.37360651 2.13042534] , error: 0.4737794342119714\n",
      "Weights: [0.37356673 2.13042989] , error: 0.47377927411811843\n",
      "Weights: [0.37352705 2.13043442] , error: 0.4737791147535939\n",
      "Weights: [0.37348745 2.13043895] , error: 0.47377895611507514\n",
      "Weights: [0.37344795 2.13044347] , error: 0.4737787981992548\n",
      "Weights: [0.37340854 2.13044798] , error: 0.4737786410028404\n",
      "Weights: [0.37336921 2.13045247] , error: 0.47377848452255583\n",
      "Weights: [0.37332998 2.13045696] , error: 0.4737783287551366\n",
      "Weights: [0.37329083 2.13046144] , error: 0.4737781736973362\n",
      "Weights: [0.37325178 2.1304659 ] , error: 0.47377801934592273\n",
      "Weights: [0.37321281 2.13047036] , error: 0.4737778656976764\n",
      "Weights: [0.37317394 2.13047481] , error: 0.4737777127493946\n",
      "Weights: [0.37313515 2.13047924] , error: 0.4737775604978897\n",
      "Weights: [0.37309645 2.13048367] , error: 0.4737774089399857\n",
      "Weights: [0.37305783 2.13048809] , error: 0.4737772580725233\n",
      "Weights: [0.37301931 2.13049249] , error: 0.4737771078923578\n",
      "Weights: [0.37298087 2.13049689] , error: 0.47377695839635703\n",
      "Weights: [0.37294253 2.13050127] , error: 0.47377680958140567\n",
      "Weights: [0.37290426 2.13050565] , error: 0.47377666144439934\n",
      "Weights: [0.37286609 2.13051001] , error: 0.4737765139822511\n",
      "Weights: [0.372828   2.13051437] , error: 0.47377636719188587\n",
      "Weights: [0.37279    2.13051872] , error: 0.47377622107024386\n",
      "Weights: [0.37275209 2.13052305] , error: 0.4737760756142764\n",
      "Weights: [0.37271426 2.13052738] , error: 0.47377593082095415\n",
      "Weights: [0.37267652 2.13053169] , error: 0.47377578668725645\n",
      "Weights: [0.37263887 2.130536  ] , error: 0.47377564321017773\n",
      "Weights: [0.3726013 2.1305403] , error: 0.47377550038672916\n",
      "Weights: [0.37256382 2.13054458] , error: 0.4737753582139304\n",
      "Weights: [0.37252642 2.13054886] , error: 0.47377521668881883\n",
      "Weights: [0.37248911 2.13055313] , error: 0.4737750758084426\n",
      "Weights: [0.37245188 2.13055738] , error: 0.47377493556986605\n",
      "Weights: [0.37241474 2.13056163] , error: 0.47377479597016414\n",
      "Weights: [0.37237768 2.13056587] , error: 0.47377465700642735\n",
      "Weights: [0.37234071 2.1305701 ] , error: 0.4737745186757585\n",
      "Weights: [0.37230382 2.13057432] , error: 0.47377438097527164\n",
      "Weights: [0.37226701 2.13057853] , error: 0.4737742439020981\n",
      "Weights: [0.37223029 2.13058273] , error: 0.47377410745338033\n",
      "Weights: [0.37219366 2.13058692] , error: 0.4737739716262709\n",
      "Weights: [0.3721571 2.1305911] , error: 0.4737738364179398\n",
      "Weights: [0.37212063 2.13059527] , error: 0.47377370182556866\n",
      "Weights: [0.37208425 2.13059943] , error: 0.4737735678463506\n",
      "Weights: [0.37204794 2.13060358] , error: 0.4737734344774919\n",
      "Weights: [0.37201172 2.13060772] , error: 0.47377330171621246\n",
      "Weights: [0.37197558 2.13061186] , error: 0.47377316955974447\n",
      "Weights: [0.37193953 2.13061598] , error: 0.47377303800533255\n",
      "Weights: [0.37190355 2.13062009] , error: 0.47377290705023406\n",
      "Weights: [0.37186766 2.1306242 ] , error: 0.47377277669171847\n",
      "Weights: [0.37183185 2.13062829] , error: 0.47377264692706755\n",
      "Weights: [0.37179612 2.13063238] , error: 0.47377251775357665\n",
      "Weights: [0.37176047 2.13063646] , error: 0.4737723891685531\n",
      "Weights: [0.37172491 2.13064052] , error: 0.4737722611693158\n",
      "Weights: [0.37168942 2.13064458] , error: 0.4737721337531945\n",
      "Weights: [0.37165402 2.13064863] , error: 0.4737720069175343\n",
      "Weights: [0.3716187  2.13065267] , error: 0.4737718806596909\n",
      "Weights: [0.37158346 2.1306567 ] , error: 0.47377175497703217\n",
      "Weights: [0.37154829 2.13066072] , error: 0.4737716298669363\n",
      "Weights: [0.37151321 2.13066473] , error: 0.47377150532679563\n",
      "Weights: [0.37147821 2.13066874] , error: 0.47377138135401387\n",
      "Weights: [0.37144329 2.13067273] , error: 0.4737712579460074\n",
      "Weights: [0.37140845 2.13067672] , error: 0.4737711351002005\n",
      "Weights: [0.37137368 2.13068069] , error: 0.47377101281403555\n",
      "Weights: [0.371339   2.13068466] , error: 0.47377089108495996\n",
      "Weights: [0.3713044  2.13068862] , error: 0.473770769910437\n",
      "Weights: [0.37126987 2.13069256] , error: 0.4737706492879413\n",
      "Weights: [0.37123542 2.1306965 ] , error: 0.47377052921495666\n",
      "Weights: [0.37120106 2.13070043] , error: 0.47377040968897943\n",
      "Weights: [0.37116677 2.13070436] , error: 0.4737702907075186\n",
      "Weights: [0.37113255 2.13070827] , error: 0.47377017226809537\n",
      "Weights: [0.37109842 2.13071217] , error: 0.47377005436823655\n",
      "Weights: [0.37106436 2.13071607] , error: 0.4737699370054863\n",
      "Weights: [0.37103039 2.13071995] , error: 0.47376982017739716\n",
      "Weights: [0.37099649 2.13072383] , error: 0.4737697038815343\n",
      "Weights: [0.37096266 2.1307277 ] , error: 0.47376958811547143\n",
      "Weights: [0.37092892 2.13073156] , error: 0.4737694728767966\n",
      "Weights: [0.37089525 2.13073541] , error: 0.4737693581631066\n",
      "Weights: [0.37086165 2.13073925] , error: 0.47376924397200965\n",
      "Weights: [0.37082814 2.13074308] , error: 0.47376913030112505\n",
      "Weights: [0.3707947  2.13074691] , error: 0.4737690171480835\n",
      "Weights: [0.37076134 2.13075072] , error: 0.47376890451052506\n",
      "Weights: [0.37072805 2.13075453] , error: 0.4737687923861014\n",
      "Weights: [0.37069484 2.13075833] , error: 0.4737686807724758\n",
      "Weights: [0.3706617  2.13076212] , error: 0.47376856966731973\n",
      "Weights: [0.37062864 2.1307659 ] , error: 0.473768459068318\n",
      "Weights: [0.37059566 2.13076967] , error: 0.4737683489731652\n",
      "Weights: [0.37056275 2.13077343] , error: 0.47376823937956425\n",
      "Weights: [0.37052991 2.13077719] , error: 0.47376813028523224\n",
      "Weights: [0.37049715 2.13078094] , error: 0.473768021687893\n",
      "Weights: [0.37046447 2.13078467] , error: 0.47376791358528375\n",
      "Weights: [0.37043186 2.1307884 ] , error: 0.4737678059751499\n",
      "Weights: [0.37039932 2.13079212] , error: 0.4737676988552472\n",
      "Weights: [0.37036686 2.13079584] , error: 0.4737675922233439\n",
      "Weights: [0.37033447 2.13079954] , error: 0.4737674860772168\n",
      "Weights: [0.37030216 2.13080324] , error: 0.47376738041465116\n",
      "Weights: [0.37026992 2.13080692] , error: 0.47376727523344486\n",
      "Weights: [0.37023775 2.1308106 ] , error: 0.4737671705314067\n",
      "Weights: [0.37020566 2.13081427] , error: 0.47376706630635135\n",
      "Weights: [0.37017364 2.13081793] , error: 0.4737669625561071\n",
      "Weights: [0.37014169 2.13082159] , error: 0.4737668592785109\n",
      "Weights: [0.37010982 2.13082523] , error: 0.47376675647140937\n",
      "Weights: [0.37007802 2.13082887] , error: 0.4737666541326581\n",
      "Weights: [0.37004629 2.1308325 ] , error: 0.4737665522601252\n",
      "Weights: [0.37001463 2.13083612] , error: 0.4737664508516855\n",
      "Weights: [0.36998305 2.13083973] , error: 0.4737663499052252\n",
      "Weights: [0.36995154 2.13084333] , error: 0.4737662494186394\n",
      "Weights: [0.3699201  2.13084693] , error: 0.473766149389834\n",
      "Weights: [0.36988873 2.13085052] , error: 0.4737660498167231\n",
      "Weights: [0.36985743 2.1308541 ] , error: 0.4737659506972295\n",
      "Weights: [0.3698262  2.13085767] , error: 0.4737658520292879\n",
      "Weights: [0.36979505 2.13086123] , error: 0.4737657538108421\n",
      "Weights: [0.36976397 2.13086479] , error: 0.47376565603984255\n",
      "Weights: [0.36973295 2.13086833] , error: 0.47376555871425163\n",
      "Weights: [0.36970201 2.13087187] , error: 0.47376546183203944\n",
      "Weights: [0.36967114 2.1308754 ] , error: 0.4737653653911875\n",
      "Weights: [0.36964034 2.13087892] , error: 0.4737652693896842\n",
      "Weights: [0.36960961 2.13088244] , error: 0.4737651738255292\n",
      "Weights: [0.36957895 2.13088595] , error: 0.47376507869672824\n",
      "Weights: [0.36954836 2.13088944] , error: 0.4737649840012984\n",
      "Weights: [0.36951784 2.13089293] , error: 0.47376488973726694\n",
      "Weights: [0.36948738 2.13089642] , error: 0.4737647959026674\n",
      "Weights: [0.369457   2.13089989] , error: 0.4737647024955435\n",
      "Weights: [0.36942669 2.13090336] , error: 0.47376460951394794\n",
      "Weights: [0.36939645 2.13090682] , error: 0.47376451695594246\n",
      "Weights: [0.36936627 2.13091027] , error: 0.4737644248195966\n",
      "Weights: [0.36933617 2.13091371] , error: 0.47376433310298977\n",
      "Weights: [0.36930613 2.13091715] , error: 0.4737642418042102\n",
      "Weights: [0.36927616 2.13092057] , error: 0.4737641509213546\n",
      "Weights: [0.36924626 2.13092399] , error: 0.47376406045252806\n",
      "Weights: [0.36921643 2.1309274 ] , error: 0.47376397039584245\n",
      "Weights: [0.36918666 2.13093081] , error: 0.473763880749423\n",
      "Weights: [0.36915697 2.1309342 ] , error: 0.4737637915113992\n",
      "Weights: [0.36912734 2.13093759] , error: 0.4737637026799105\n",
      "Weights: [0.36909778 2.13094097] , error: 0.4737636142531066\n",
      "Weights: [0.36906828 2.13094435] , error: 0.47376352622914053\n",
      "Weights: [0.36903886 2.13094771] , error: 0.4737634386061811\n",
      "Weights: [0.3690095  2.13095107] , error: 0.4737633513823979\n",
      "Weights: [0.36898021 2.13095442] , error: 0.4737632645559751\n",
      "Weights: [0.36895098 2.13095776] , error: 0.47376317812510105\n",
      "Weights: [0.36892182 2.1309611 ] , error: 0.4737630920879744\n",
      "Weights: [0.36889273 2.13096442] , error: 0.47376300644280084\n",
      "Weights: [0.3688637  2.13096774] , error: 0.47376292118779406\n",
      "Weights: [0.36883475 2.13097106] , error: 0.4737628363211791\n",
      "Weights: [0.36880585 2.13097436] , error: 0.4737627518411851\n",
      "Weights: [0.36877702 2.13097766] , error: 0.4737626677460492\n",
      "Weights: [0.36874826 2.13098095] , error: 0.4737625840340207\n",
      "Weights: [0.36871957 2.13098423] , error: 0.47376250070335363\n",
      "Weights: [0.36869093 2.1309875 ] , error: 0.47376241775231004\n",
      "Weights: [0.36866237 2.13099077] , error: 0.4737623351791602\n",
      "Weights: [0.36863387 2.13099403] , error: 0.4737622529821839\n",
      "Weights: [0.36860543 2.13099728] , error: 0.47376217115966457\n",
      "Weights: [0.36857706 2.13100053] , error: 0.4737620897099017\n",
      "Weights: [0.36854876 2.13100376] , error: 0.47376200863119217\n",
      "Weights: [0.36852051 2.13100699] , error: 0.47376192792184824\n",
      "Weights: [0.36849234 2.13101021] , error: 0.47376184758018486\n",
      "Weights: [0.36846422 2.13101343] , error: 0.4737617676045291\n",
      "Weights: [0.36843618 2.13101664] , error: 0.47376168799321183\n",
      "Weights: [0.36840819 2.13101984] , error: 0.4737616087445758\n",
      "Weights: [0.36838027 2.13102303] , error: 0.4737615298569669\n",
      "Weights: [0.36835241 2.13102622] , error: 0.473761451328741\n",
      "Weights: [0.36832462 2.1310294 ] , error: 0.47376137315825984\n",
      "Weights: [0.36829689 2.13103257] , error: 0.47376129534389544\n",
      "Weights: [0.36826922 2.13103573] , error: 0.47376121788402314\n",
      "Weights: [0.36824162 2.13103889] , error: 0.4737611407770308\n",
      "Weights: [0.36821408 2.13104204] , error: 0.47376106402130946\n",
      "Weights: [0.3681866  2.13104518] , error: 0.473760987615258\n",
      "Weights: [0.36815918 2.13104832] , error: 0.47376091155728495\n",
      "Weights: [0.36813183 2.13105144] , error: 0.47376083584580364\n",
      "Weights: [0.36810454 2.13105456] , error: 0.47376076047923527\n",
      "Weights: [0.36807731 2.13105768] , error: 0.47376068545600986\n",
      "Weights: [0.36805014 2.13106079] , error: 0.47376061077456266\n",
      "Weights: [0.36802304 2.13106389] , error: 0.4737605364333356\n",
      "Weights: [0.367996   2.13106698] , error: 0.4737604624307808\n",
      "Weights: [0.36796901 2.13107006] , error: 0.47376038876535476\n",
      "Weights: [0.3679421  2.13107314] , error: 0.4737603154355198\n",
      "Weights: [0.36791524 2.13107621] , error: 0.47376024243974924\n",
      "Weights: [0.36788844 2.13107928] , error: 0.47376016977651925\n",
      "Weights: [0.3678617  2.13108234] , error: 0.4737600974443177\n",
      "Weights: [0.36783503 2.13108539] , error: 0.4737600254416344\n",
      "Weights: [0.36780842 2.13108843] , error: 0.47375995376696833\n",
      "Weights: [0.36778186 2.13109147] , error: 0.47375988241882566\n",
      "Weights: [0.36775537 2.1310945 ] , error: 0.473759811395719\n",
      "Weights: [0.36772894 2.13109752] , error: 0.47375974069616755\n",
      "Weights: [0.36770257 2.13110054] , error: 0.47375967031869665\n",
      "Weights: [0.36767625 2.13110355] , error: 0.4737596002618397\n",
      "Weights: [0.36765    2.13110655] , error: 0.47375953052413544\n",
      "Weights: [0.36762381 2.13110954] , error: 0.47375946110413125\n",
      "Weights: [0.36759768 2.13111253] , error: 0.47375939200037925\n",
      "Weights: [0.36757161 2.13111551] , error: 0.4737593232114372\n",
      "Weights: [0.36754559 2.13111849] , error: 0.4737592547358732\n",
      "Weights: [0.36751964 2.13112146] , error: 0.4737591865722586\n",
      "Weights: [0.36749374 2.13112442] , error: 0.4737591187191714\n",
      "Weights: [0.36746791 2.13112737] , error: 0.47375905117519834\n",
      "Weights: [0.36744213 2.13113032] , error: 0.4737589839389298\n",
      "Weights: [0.36741641 2.13113326] , error: 0.473758917008966\n",
      "Weights: [0.36739075 2.1311362 ] , error: 0.47375885038391014\n",
      "Weights: [0.36736515 2.13113912] , error: 0.47375878406237304\n",
      "Weights: [0.36733961 2.13114205] , error: 0.4737587180429729\n",
      "Weights: [0.36731413 2.13114496] , error: 0.4737586523243313\n",
      "Weights: [0.3672887  2.13114787] , error: 0.47375858690508144\n",
      "Weights: [0.36726333 2.13115077] , error: 0.4737585217838559\n",
      "Weights: [0.36723802 2.13115366] , error: 0.47375845695930013\n",
      "Weights: [0.36721277 2.13115655] , error: 0.4737583924300595\n",
      "Weights: [0.36718757 2.13115943] , error: 0.47375832819479213\n",
      "Weights: [0.36716244 2.13116231] , error: 0.4737582642521559\n",
      "Weights: [0.36713736 2.13116518] , error: 0.473758200600819\n",
      "Weights: [0.36711233 2.13116804] , error: 0.473758137239453\n",
      "Weights: [0.36708737 2.13117089] , error: 0.4737580741667397\n",
      "Weights: [0.36706246 2.13117374] , error: 0.47375801138136\n",
      "Weights: [0.36703761 2.13117658] , error: 0.47375794888200934\n",
      "Weights: [0.36701281 2.13117942] , error: 0.4737578866673817\n",
      "Weights: [0.36698807 2.13118225] , error: 0.4737578247361819\n",
      "Weights: [0.36696339 2.13118507] , error: 0.4737577630871167\n",
      "Weights: [0.36693876 2.13118789] , error: 0.47375770171890264\n",
      "Weights: [0.36691419 2.1311907 ] , error: 0.4737576406302591\n",
      "Weights: [0.36688968 2.1311935 ] , error: 0.473757579819913\n",
      "Weights: [0.36686522 2.1311963 ] , error: 0.47375751928659543\n",
      "Weights: [0.36684082 2.13119909] , error: 0.4737574590290469\n",
      "Weights: [0.36681647 2.13120187] , error: 0.4737573990460081\n",
      "Weights: [0.36679218 2.13120465] , error: 0.4737573393362311\n",
      "Weights: [0.36676795 2.13120742] , error: 0.4737572798984686\n",
      "Weights: [0.36674377 2.13121019] , error: 0.47375722073148374\n",
      "Weights: [0.36671964 2.13121295] , error: 0.4737571618340413\n",
      "Weights: [0.36669557 2.1312157 ] , error: 0.4737571032049134\n",
      "Weights: [0.36667155 2.13121845] , error: 0.4737570448428787\n",
      "Weights: [0.36664759 2.13122119] , error: 0.47375698674671896\n",
      "Weights: [0.36662369 2.13122392] , error: 0.4737569289152248\n",
      "Weights: [0.36659984 2.13122665] , error: 0.47375687134718936\n",
      "Weights: [0.36657604 2.13122937] , error: 0.4737568140414128\n",
      "Weights: [0.3665523  2.13123209] , error: 0.47375675699670033\n",
      "Weights: [0.36652861 2.1312348 ] , error: 0.4737567002118617\n",
      "Weights: [0.36650497 2.1312375 ] , error: 0.47375664368571474\n",
      "Weights: [0.36648139 2.13124019] , error: 0.47375658741707893\n",
      "Weights: [0.36645786 2.13124289] , error: 0.473756531404783\n",
      "Weights: [0.36643439 2.13124557] , error: 0.47375647564765855\n",
      "Weights: [0.36641097 2.13124825] , error: 0.4737564201445432\n",
      "Weights: [0.3663876  2.13125092] , error: 0.4737563648942779\n",
      "Weights: [0.36636429 2.13125359] , error: 0.47375630989571366\n",
      "Weights: [0.36634103 2.13125625] , error: 0.4737562551477027\n",
      "Weights: [0.36631782 2.1312589 ] , error: 0.4737562006491034\n",
      "Weights: [0.36629467 2.13126155] , error: 0.4737561463987795\n",
      "Weights: [0.36627157 2.13126419] , error: 0.47375609239559996\n",
      "Weights: [0.36624852 2.13126683] , error: 0.47375603863843874\n",
      "Weights: [0.36622552 2.13126946] , error: 0.47375598512617473\n",
      "Weights: [0.36620258 2.13127208] , error: 0.47375593185769405\n",
      "Weights: [0.36617969 2.1312747 ] , error: 0.47375587883188386\n",
      "Weights: [0.36615685 2.13127731] , error: 0.4737558260476402\n",
      "Weights: [0.36613406 2.13127992] , error: 0.47375577350386233\n",
      "Weights: [0.36611133 2.13128252] , error: 0.473755721199454\n",
      "Weights: [0.36608865 2.13128511] , error: 0.47375566913332595\n",
      "Weights: [0.36606601 2.1312877 ] , error: 0.4737556173043913\n",
      "Weights: [0.36604343 2.13129028] , error: 0.4737555657115697\n",
      "Weights: [0.36602091 2.13129286] , error: 0.47375551435378643\n",
      "Weights: [0.36599843 2.13129543] , error: 0.4737554632299707\n",
      "Weights: [0.365976   2.13129799] , error: 0.47375541233905566\n",
      "Weights: [0.36595363 2.13130055] , error: 0.47375536167998067\n",
      "Weights: [0.3659313  2.13130311] , error: 0.47375531125168996\n",
      "Weights: [0.36590903 2.13130565] , error: 0.4737552610531325\n",
      "Weights: [0.36588681 2.13130819] , error: 0.47375521108326035\n",
      "Weights: [0.36586464 2.13131073] , error: 0.4737551613410323\n",
      "Weights: [0.36584252 2.13131326] , error: 0.4737551118254125\n",
      "Weights: [0.36582045 2.13131578] , error: 0.4737550625353659\n",
      "Weights: [0.36579843 2.1313183 ] , error: 0.47375501346986804\n",
      "Weights: [0.36577646 2.13132081] , error: 0.47375496462789424\n",
      "Weights: [0.36575454 2.13132332] , error: 0.4737549160084254\n",
      "Weights: [0.36573267 2.13132582] , error: 0.47375486761045016\n",
      "Weights: [0.36571085 2.13132832] , error: 0.4737548194329576\n",
      "Weights: [0.36568908 2.13133081] , error: 0.47375477147494466\n",
      "Weights: [0.36566736 2.13133329] , error: 0.4737547237354094\n",
      "Weights: [0.36564569 2.13133577] , error: 0.4737546762133589\n",
      "Weights: [0.36562407 2.13133824] , error: 0.47375462890780085\n",
      "Weights: [0.3656025  2.13134071] , error: 0.47375458181774954\n",
      "Weights: [0.36558097 2.13134317] , error: 0.4737545349422232\n",
      "Weights: [0.3655595  2.13134563] , error: 0.4737544882802435\n",
      "Weights: [0.36553807 2.13134808] , error: 0.4737544418308399\n",
      "Weights: [0.3655167  2.13135052] , error: 0.47375439559304133\n",
      "Weights: [0.36549537 2.13135296] , error: 0.47375434956588525\n",
      "Weights: [0.36547409 2.13135539] , error: 0.47375430374841343\n",
      "Weights: [0.36545286 2.13135782] , error: 0.47375425813966854\n",
      "Weights: [0.36543168 2.13136024] , error: 0.4737542127386993\n",
      "Weights: [0.36541055 2.13136266] , error: 0.47375416754456057\n",
      "Weights: [0.36538946 2.13136507] , error: 0.47375412255631033\n",
      "Weights: [0.36536843 2.13136748] , error: 0.473754077773009\n",
      "Weights: [0.36534744 2.13136988] , error: 0.4737540331937242\n",
      "Weights: [0.3653265  2.13137227] , error: 0.4737539888175263\n",
      "Weights: [0.3653056  2.13137466] , error: 0.47375394464348974\n",
      "Weights: [0.36528476 2.13137705] , error: 0.47375390067069323\n",
      "Weights: [0.36526396 2.13137943] , error: 0.47375385689822136\n",
      "Weights: [0.36524321 2.1313818 ] , error: 0.4737538133251604\n",
      "Weights: [0.3652225  2.13138417] , error: 0.47375376995060176\n",
      "Weights: [0.36520185 2.13138653] , error: 0.4737537267736421\n",
      "Weights: [0.36518124 2.13138889] , error: 0.4737536837933812\n",
      "Weights: [0.36516068 2.13139124] , error: 0.4737536410089218\n",
      "Weights: [0.36514016 2.13139358] , error: 0.47375359841937303\n",
      "Weights: [0.36511969 2.13139592] , error: 0.4737535560238464\n",
      "Weights: [0.36509927 2.13139826] , error: 0.4737535138214579\n",
      "Weights: [0.3650789  2.13140059] , error: 0.47375347181132793\n",
      "Weights: [0.36505857 2.13140292] , error: 0.4737534299925802\n",
      "Weights: [0.36503828 2.13140523] , error: 0.47375338836434394\n",
      "Weights: [0.36501805 2.13140755] , error: 0.47375334692575044\n",
      "Weights: [0.36499786 2.13140986] , error: 0.47375330567593577\n",
      "Weights: [0.36497771 2.13141216] , error: 0.47375326461403894\n",
      "Weights: [0.36495762 2.13141446] , error: 0.473753223739207\n",
      "Weights: [0.36493756 2.13141675] , error: 0.4737531830505836\n",
      "Weights: [0.36491756 2.13141904] , error: 0.47375314254732454\n",
      "Weights: [0.3648976  2.13142132] , error: 0.4737531022285828\n",
      "Weights: [0.36487768 2.1314236 ] , error: 0.4737530620935177\n",
      "Weights: [0.36485781 2.13142587] , error: 0.4737530221412927\n",
      "Weights: [0.36483799 2.13142814] , error: 0.4737529823710762\n",
      "Weights: [0.36481821 2.1314304 ] , error: 0.473752942782038\n",
      "Weights: [0.36479847 2.13143266] , error: 0.4737529033733525\n",
      "Weights: [0.36477878 2.13143491] , error: 0.47375286414419976\n",
      "Weights: [0.36475914 2.13143716] , error: 0.4737528250937584\n",
      "Weights: [0.36473954 2.1314394 ] , error: 0.47375278622121725\n",
      "Weights: [0.36471998 2.13144164] , error: 0.4737527475257655\n",
      "Weights: [0.36470047 2.13144387] , error: 0.4737527090065955\n",
      "Weights: [0.36468101 2.13144609] , error: 0.47375267066290416\n",
      "Weights: [0.36466159 2.13144832] , error: 0.4737526324938938\n",
      "Weights: [0.36464221 2.13145053] , error: 0.4737525944987666\n",
      "Weights: [0.36462288 2.13145274] , error: 0.4737525566767309\n",
      "Weights: [0.36460359 2.13145495] , error: 0.4737525190269985\n",
      "Weights: [0.36458434 2.13145715] , error: 0.4737524815487848\n",
      "Weights: [0.36456514 2.13145935] , error: 0.47375244424130847\n",
      "Weights: [0.36454598 2.13146154] , error: 0.4737524071037895\n",
      "Weights: [0.36452687 2.13146372] , error: 0.47375237013545707\n",
      "Weights: [0.3645078 2.1314659] , error: 0.4737523333355381\n",
      "Weights: [0.36448878 2.13146808] , error: 0.4737522967032658\n",
      "Weights: [0.36446979 2.13147025] , error: 0.47375226023787664\n",
      "Weights: [0.36445085 2.13147242] , error: 0.47375222393861105\n",
      "Weights: [0.36443196 2.13147458] , error: 0.47375218780471023\n",
      "Weights: [0.3644131  2.13147673] , error: 0.47375215183542185\n",
      "Weights: [0.36439429 2.13147888] , error: 0.4737521160299979\n",
      "Weights: [0.36437552 2.13148103] , error: 0.47375208038768923\n",
      "Weights: [0.3643568  2.13148317] , error: 0.4737520449077537\n",
      "Weights: [0.36433812 2.13148531] , error: 0.4737520095894523\n",
      "Weights: [0.36431948 2.13148744] , error: 0.4737519744320477\n",
      "Weights: [0.36430088 2.13148957] , error: 0.4737519394348072\n",
      "Weights: [0.36428233 2.13149169] , error: 0.473751904597001\n",
      "Weights: [0.36426381 2.13149381] , error: 0.4737518699179041\n",
      "Weights: [0.36424534 2.13149592] , error: 0.4737518353967901\n",
      "Weights: [0.36422692 2.13149803] , error: 0.4737518010329431\n",
      "Weights: [0.36420853 2.13150013] , error: 0.47375176682564524\n",
      "Weights: [0.36419019 2.13150223] , error: 0.47375173277418303\n",
      "Weights: [0.36417188 2.13150432] , error: 0.47375169887784624\n",
      "Weights: [0.36415362 2.13150641] , error: 0.4737516651359293\n",
      "Weights: [0.3641354  2.13150849] , error: 0.473751631547727\n",
      "Weights: [0.36411723 2.13151057] , error: 0.4737515981125416\n",
      "Weights: [0.36409909 2.13151264] , error: 0.47375156482967273\n",
      "Weights: [0.364081   2.13151471] , error: 0.47375153169843\n",
      "Weights: [0.36406294 2.13151678] , error: 0.47375149871811967\n",
      "Weights: [0.36404493 2.13151884] , error: 0.4737514658880569\n",
      "Weights: [0.36402696 2.13152089] , error: 0.4737514332075542\n",
      "Weights: [0.36400903 2.13152294] , error: 0.4737514006759334\n",
      "Weights: [0.36399114 2.13152499] , error: 0.4737513682925135\n",
      "Weights: [0.36397329 2.13152703] , error: 0.4737513360566209\n",
      "Weights: [0.36395549 2.13152907] , error: 0.47375130396758236\n",
      "Weights: [0.36393772 2.1315311 ] , error: 0.47375127202473055\n",
      "Weights: [0.36391999 2.13153313] , error: 0.4737512402273989\n",
      "Weights: [0.36390231 2.13153515] , error: 0.4737512085749232\n",
      "Weights: [0.36388466 2.13153717] , error: 0.4737511770666444\n",
      "Weights: [0.36386706 2.13153918] , error: 0.4737511457019059\n",
      "Weights: [0.36384949 2.13154119] , error: 0.4737511144800537\n",
      "Weights: [0.36383196 2.13154319] , error: 0.47375108340043687\n",
      "Weights: [0.36381448 2.13154519] , error: 0.47375105246240734\n",
      "Weights: [0.36379703 2.13154719] , error: 0.47375102166532007\n",
      "Weights: [0.36377963 2.13154918] , error: 0.4737509910085331\n",
      "Weights: [0.36376226 2.13155117] , error: 0.47375096049140636\n",
      "Weights: [0.36374494 2.13155315] , error: 0.47375093011330555\n",
      "Weights: [0.36372765 2.13155512] , error: 0.47375089987359476\n",
      "Weights: [0.3637104 2.1315571] , error: 0.47375086977164627\n",
      "Weights: [0.36369319 2.13155906] , error: 0.47375083980682975\n",
      "Weights: [0.36367603 2.13156103] , error: 0.4737508099785231\n",
      "Weights: [0.3636589  2.13156299] , error: 0.4737507802861025\n",
      "Weights: [0.36364181 2.13156494] , error: 0.4737507507289495\n",
      "Weights: [0.36362475 2.13156689] , error: 0.4737507213064484\n",
      "Weights: [0.36360774 2.13156884] , error: 0.47375069201798475\n",
      "Weights: [0.36359077 2.13157078] , error: 0.47375066286294937\n",
      "Weights: [0.36357383 2.13157272] , error: 0.47375063384073296\n",
      "Weights: [0.36355693 2.13157465] , error: 0.4737506049507315\n",
      "Weights: [0.36354008 2.13157658] , error: 0.47375057619234157\n",
      "Weights: [0.36352326 2.1315785 ] , error: 0.4737505475649646\n",
      "Weights: [0.36350648 2.13158042] , error: 0.47375051906800325\n",
      "Weights: [0.36348973 2.13158233] , error: 0.4737504907008646\n",
      "Weights: [0.36347303 2.13158424] , error: 0.47375046246295477\n",
      "Weights: [0.36345636 2.13158615] , error: 0.47375043435368647\n",
      "Weights: [0.36343973 2.13158805] , error: 0.473750406372474\n",
      "Weights: [0.36342314 2.13158995] , error: 0.4737503785187339\n",
      "Weights: [0.36340659 2.13159184] , error: 0.47375035079188466\n",
      "Weights: [0.36339007 2.13159373] , error: 0.4737503231913488\n",
      "Weights: [0.3633736  2.13159562] , error: 0.4737502957165506\n",
      "Weights: [0.36335716 2.1315975 ] , error: 0.47375026836691825\n",
      "Weights: [0.36334075 2.13159937] , error: 0.47375024114188014\n",
      "Weights: [0.36332439 2.13160124] , error: 0.4737502140408691\n",
      "Weights: [0.36330806 2.13160311] , error: 0.4737501870633208\n",
      "Weights: [0.36329177 2.13160497] , error: 0.47375016020867144\n",
      "Weights: [0.36327552 2.13160683] , error: 0.47375013347636286\n",
      "Weights: [0.3632593  2.13160869] , error: 0.4737501068658356\n",
      "Weights: [0.36324312 2.13161054] , error: 0.47375008037653754\n",
      "Weights: [0.36322698 2.13161238] , error: 0.47375005400791337\n",
      "Weights: [0.36321087 2.13161423] , error: 0.4737500277594162\n",
      "Weights: [0.3631948  2.13161606] , error: 0.47375000163049724\n",
      "Weights: [0.36317877 2.1316179 ] , error: 0.47374997562061216\n",
      "Weights: [0.36316278 2.13161973] , error: 0.4737499497292179\n",
      "Weights: [0.36314682 2.13162155] , error: 0.4737499239557752\n",
      "Weights: [0.36313089 2.13162337] , error: 0.473749898299747\n",
      "Weights: [0.36311501 2.13162519] , error: 0.47374987276059843\n",
      "Weights: [0.36309916 2.131627  ] , error: 0.4737498473377969\n",
      "Weights: [0.36308334 2.13162881] , error: 0.473749822030812\n",
      "Weights: [0.36306756 2.13163061] , error: 0.47374979683911594\n",
      "Weights: [0.36305182 2.13163241] , error: 0.4737497717621848\n",
      "Weights: [0.36303612 2.13163421] , error: 0.4737497467994939\n",
      "Weights: [0.36302045 2.131636  ] , error: 0.4737497219505251\n",
      "Weights: [0.36300481 2.13163779] , error: 0.4737496972147577\n",
      "Weights: [0.36298921 2.13163958] , error: 0.4737496725916779\n",
      "Weights: [0.36297365 2.13164136] , error: 0.4737496480807721\n",
      "Weights: [0.36295812 2.13164313] , error: 0.4737496236815276\n",
      "Weights: [0.36294263 2.1316449 ] , error: 0.4737495993934379\n",
      "Weights: [0.36292717 2.13164667] , error: 0.47374957521599625\n",
      "Weights: [0.36291175 2.13164843] , error: 0.47374955114869766\n",
      "Weights: [0.36289636 2.13165019] , error: 0.47374952719104146\n",
      "Weights: [0.36288101 2.13165195] , error: 0.4737495033425265\n",
      "Weights: [0.36286569 2.1316537 ] , error: 0.473749479602657\n",
      "Weights: [0.36285041 2.13165545] , error: 0.47374945597093765\n",
      "Weights: [0.36283517 2.13165719] , error: 0.47374943244687484\n",
      "Weights: [0.36281995 2.13165893] , error: 0.47374940902998053\n",
      "Weights: [0.36280478 2.13166067] , error: 0.47374938571976366\n",
      "Weights: [0.36278963 2.1316624 ] , error: 0.47374936251573996\n",
      "Weights: [0.36277452 2.13166413] , error: 0.47374933941742586\n",
      "Weights: [0.36275945 2.13166585] , error: 0.4737493164243376\n",
      "Weights: [0.36274441 2.13166757] , error: 0.47374929353599804\n",
      "Weights: [0.36272941 2.13166929] , error: 0.4737492707519298\n",
      "Weights: [0.36271443 2.131671  ] , error: 0.47374924807165764\n",
      "Weights: [0.3626995  2.13167271] , error: 0.473749225494708\n",
      "Weights: [0.3626846  2.13167441] , error: 0.47374920302060974\n",
      "Weights: [0.36266973 2.13167611] , error: 0.47374918064889615\n",
      "Weights: [0.36265489 2.13167781] , error: 0.473749158379099\n",
      "Weights: [0.36264009 2.1316795 ] , error: 0.4737491362107563\n",
      "Weights: [0.36262532 2.13168119] , error: 0.47374911414340337\n",
      "Weights: [0.36261059 2.13168288] , error: 0.47374909217658095\n",
      "Weights: [0.36259589 2.13168456] , error: 0.4737490703098312\n",
      "Weights: [0.36258122 2.13168623] , error: 0.473749048542699\n",
      "Weights: [0.36256659 2.13168791] , error: 0.47374902687472936\n",
      "Weights: [0.36255199 2.13168958] , error: 0.4737490053054709\n",
      "Weights: [0.36253742 2.13169124] , error: 0.4737489838344746\n",
      "Weights: [0.36252289 2.13169291] , error: 0.47374896246129194\n",
      "Weights: [0.36250839 2.13169456] , error: 0.4737489411854769\n",
      "Weights: [0.36249392 2.13169622] , error: 0.47374892000658747\n",
      "Weights: [0.36247949 2.13169787] , error: 0.47374889892418065\n",
      "Weights: [0.36246509 2.13169952] , error: 0.47374887793781806\n",
      "Weights: [0.36245072 2.13170116] , error: 0.4737488570470608\n",
      "Weights: [0.36243639 2.1317028 ] , error: 0.4737488362514748\n",
      "Weights: [0.36242208 2.13170443] , error: 0.4737488155506255\n",
      "Weights: [0.36240781 2.13170607] , error: 0.47374879494408273\n",
      "Weights: [0.36239357 2.13170769] , error: 0.4737487744314137\n",
      "Weights: [0.36237937 2.13170932] , error: 0.4737487540121945\n",
      "Weights: [0.3623652  2.13171094] , error: 0.4737487336859968\n",
      "Weights: [0.36235106 2.13171256] , error: 0.4737487134523985\n",
      "Weights: [0.36233695 2.13171417] , error: 0.47374869331097597\n",
      "Weights: [0.36232287 2.13171578] , error: 0.47374867326131076\n",
      "Weights: [0.36230883 2.13171739] , error: 0.47374865330298493\n",
      "Weights: [0.36229482 2.13171899] , error: 0.4737486334355808\n",
      "Weights: [0.36228084 2.13172059] , error: 0.47374861365868637\n",
      "Weights: [0.36226689 2.13172218] , error: 0.47374859397188773\n",
      "Weights: [0.36225297 2.13172377] , error: 0.4737485743747752\n",
      "Weights: [0.36223909 2.13172536] , error: 0.47374855486693973\n",
      "Weights: [0.36222523 2.13172695] , error: 0.473748535447974\n",
      "Weights: [0.36221141 2.13172853] , error: 0.47374851611747415\n",
      "Weights: [0.36219762 2.1317301 ] , error: 0.47374849687503723\n",
      "Weights: [0.36218387 2.13173168] , error: 0.47374847772026174\n",
      "Weights: [0.36217014 2.13173325] , error: 0.47374845865274845\n",
      "Weights: [0.36215644 2.13173481] , error: 0.47374843967210034\n",
      "Weights: [0.36214278 2.13173638] , error: 0.47374842077791934\n",
      "Weights: [0.36212915 2.13173794] , error: 0.47374840196981416\n",
      "Weights: [0.36211554 2.13173949] , error: 0.4737483832473923\n",
      "Weights: [0.36210197 2.13174104] , error: 0.4737483646102619\n",
      "Weights: [0.36208843 2.13174259] , error: 0.47374834605803606\n",
      "Weights: [0.36207492 2.13174414] , error: 0.47374832759032726\n",
      "Weights: [0.36206144 2.13174568] , error: 0.4737483092067503\n",
      "Weights: [0.362048   2.13174722] , error: 0.4737482909069222\n",
      "Weights: [0.36203458 2.13174875] , error: 0.47374827269046094\n",
      "Weights: [0.36202119 2.13175028] , error: 0.4737482545569879\n",
      "Weights: [0.36200784 2.13175181] , error: 0.47374823650612385\n",
      "Weights: [0.36199451 2.13175333] , error: 0.4737482185374925\n",
      "Weights: [0.36198122 2.13175485] , error: 0.47374820065071976\n",
      "Weights: [0.36196795 2.13175637] , error: 0.4737481828454331\n",
      "Weights: [0.36195472 2.13175788] , error: 0.4737481651212606\n",
      "Weights: [0.36194151 2.13175939] , error: 0.4737481474778327\n",
      "Weights: [0.36192834 2.1317609 ] , error: 0.47374812991478177\n",
      "Weights: [0.36191519 2.1317624 ] , error: 0.47374811243174164\n",
      "Weights: [0.36190208 2.1317639 ] , error: 0.47374809502834764\n",
      "Weights: [0.361889  2.1317654] , error: 0.473748077704237\n",
      "Weights: [0.36187594 2.13176689] , error: 0.47374806045904894\n",
      "Weights: [0.36186292 2.13176838] , error: 0.4737480432924234\n",
      "Weights: [0.36184992 2.13176987] , error: 0.473748026204003\n",
      "Weights: [0.36183696 2.13177135] , error: 0.47374800919343046\n",
      "Weights: [0.36182402 2.13177283] , error: 0.47374799226035186\n",
      "Weights: [0.36181111 2.13177431] , error: 0.47374797540441527\n",
      "Weights: [0.36179824 2.13177578] , error: 0.4737479586252674\n",
      "Weights: [0.36178539 2.13177725] , error: 0.473747941922559\n",
      "Weights: [0.36177257 2.13177872] , error: 0.47374792529594195\n",
      "Weights: [0.36175978 2.13178018] , error: 0.4737479087450689\n",
      "Weights: [0.36174702 2.13178164] , error: 0.47374789226959657\n",
      "Weights: [0.36173429 2.13178309] , error: 0.47374787586918005\n",
      "Weights: [0.36172159 2.13178455] , error: 0.4737478595434782\n",
      "Weights: [0.36170892 2.131786  ] , error: 0.4737478432921495\n",
      "Weights: [0.36169627 2.13178744] , error: 0.4737478271148555\n",
      "Weights: [0.36168366 2.13178888] , error: 0.4737478110112608\n",
      "Weights: [0.36167107 2.13179032] , error: 0.4737477949810268\n",
      "Weights: [0.36165851 2.13179176] , error: 0.47374777902382154\n",
      "Weights: [0.36164599 2.13179319] , error: 0.4737477631393111\n",
      "Weights: [0.36163349 2.13179462] , error: 0.4737477473271636\n",
      "Weights: [0.36162101 2.13179605] , error: 0.47374773158705186\n",
      "Weights: [0.36160857 2.13179747] , error: 0.4737477159186453\n",
      "Weights: [0.36159615 2.13179889] , error: 0.4737477003216187\n",
      "Weights: [0.36158377 2.13180031] , error: 0.4737476847956466\n",
      "Weights: [0.36157141 2.13180172] , error: 0.47374766934040424\n",
      "Weights: [0.36155908 2.13180313] , error: 0.4737476539555713\n",
      "Weights: [0.36154678 2.13180454] , error: 0.4737476386408248\n",
      "Weights: [0.3615345  2.13180594] , error: 0.4737476233958481\n",
      "Weights: [0.36152226 2.13180734] , error: 0.47374760822032036\n",
      "Weights: [0.36151004 2.13180874] , error: 0.4737475931139278\n",
      "Weights: [0.36149785 2.13181013] , error: 0.47374757807635426\n",
      "Weights: [0.36148569 2.13181152] , error: 0.4737475631072866\n",
      "Weights: [0.36147355 2.13181291] , error: 0.4737475482064117\n",
      "Weights: [0.36146144 2.1318143 ] , error: 0.47374753337342\n",
      "Weights: [0.36144936 2.13181568] , error: 0.47374751860800135\n",
      "Weights: [0.36143731 2.13181706] , error: 0.47374750390984954\n",
      "Weights: [0.36142529 2.13181843] , error: 0.47374748927865606\n",
      "Weights: [0.36141329 2.1318198 ] , error: 0.47374747471411816\n",
      "Weights: [0.36140132 2.13182117] , error: 0.4737474602159294\n",
      "Weights: [0.36138938 2.13182254] , error: 0.47374744578379024\n",
      "Weights: [0.36137746 2.1318239 ] , error: 0.4737474314173977\n",
      "Weights: [0.36136558 2.13182526] , error: 0.4737474171164542\n",
      "Weights: [0.36135372 2.13182662] , error: 0.473747402880659\n",
      "Weights: [0.36134188 2.13182797] , error: 0.4737473887097184\n",
      "Weights: [0.36133007 2.13182932] , error: 0.4737473746033341\n",
      "Weights: [0.36131829 2.13183067] , error: 0.4737473605612143\n",
      "Weights: [0.36130654 2.13183201] , error: 0.47374734658306505\n",
      "Weights: [0.36129482 2.13183335] , error: 0.4737473326685948\n",
      "Weights: [0.36128312 2.13183469] , error: 0.47374731881751353\n",
      "Weights: [0.36127144 2.13183603] , error: 0.47374730502953305\n",
      "Weights: [0.3612598  2.13183736] , error: 0.4737472913043648\n",
      "Weights: [0.36124818 2.13183869] , error: 0.47374727764172386\n",
      "Weights: [0.36123658 2.13184001] , error: 0.4737472640413246\n",
      "Weights: [0.36122502 2.13184134] , error: 0.47374725050288574\n",
      "Weights: [0.36121348 2.13184266] , error: 0.47374723702611987\n",
      "Weights: [0.36120196 2.13184397] , error: 0.47374722361075045\n",
      "Weights: [0.36119047 2.13184529] , error: 0.47374721025649635\n",
      "Weights: [0.36117901 2.1318466 ] , error: 0.47374719696307976\n",
      "Weights: [0.36116758 2.1318479 ] , error: 0.4737471837302234\n",
      "Weights: [0.36115617 2.13184921] , error: 0.47374717055765\n",
      "Weights: [0.36114479 2.13185051] , error: 0.4737471574450866\n",
      "Weights: [0.36113343 2.13185181] , error: 0.4737471443922588\n",
      "Weights: [0.3611221  2.13185311] , error: 0.47374713139889535\n",
      "Weights: [0.36111079 2.1318544 ] , error: 0.47374711846472545\n",
      "Weights: [0.36109951 2.13185569] , error: 0.4737471055894778\n",
      "Weights: [0.36108826 2.13185698] , error: 0.4737470927728854\n",
      "Weights: [0.36107703 2.13185826] , error: 0.4737470800146802\n",
      "Weights: [0.36106583 2.13185954] , error: 0.47374706731459704\n",
      "Weights: [0.36105465 2.13186082] , error: 0.47374705467237127\n",
      "Weights: [0.3610435 2.1318621] , error: 0.4737470420877382\n",
      "Weights: [0.36103237 2.13186337] , error: 0.4737470295604358\n",
      "Weights: [0.36102127 2.13186464] , error: 0.4737470170902038\n",
      "Weights: [0.36101019 2.1318659 ] , error: 0.47374700467678194\n",
      "Weights: [0.36099914 2.13186717] , error: 0.47374699231990985\n",
      "Weights: [0.36098812 2.13186843] , error: 0.47374698001933124\n",
      "Weights: [0.36097712 2.13186969] , error: 0.4737469677747902\n",
      "Weights: [0.36096614 2.13187094] , error: 0.4737469555860302\n",
      "Weights: [0.36095519 2.13187219] , error: 0.47374694345279855\n",
      "Weights: [0.36094427 2.13187344] , error: 0.47374693137484086\n",
      "Weights: [0.36093337 2.13187469] , error: 0.4737469193519053\n",
      "Weights: [0.36092249 2.13187593] , error: 0.4737469073837424\n",
      "Weights: [0.36091164 2.13187717] , error: 0.4737468954701021\n",
      "Weights: [0.36090082 2.13187841] , error: 0.47374688361073575\n",
      "Weights: [0.36089001 2.13187965] , error: 0.47374687180539654\n",
      "Weights: [0.36087924 2.13188088] , error: 0.4737468600538386\n",
      "Weights: [0.36086849 2.13188211] , error: 0.47374684835581454\n",
      "Weights: [0.36085776 2.13188334] , error: 0.4737468367110844\n",
      "Weights: [0.36084706 2.13188456] , error: 0.47374682511940164\n",
      "Weights: [0.36083638 2.13188578] , error: 0.4737468135805275\n",
      "Weights: [0.36082572 2.131887  ] , error: 0.4737468020942202\n",
      "Weights: [0.36081509 2.13188822] , error: 0.47374679066023995\n",
      "Weights: [0.36080449 2.13188943] , error: 0.473746779278349\n",
      "Weights: [0.36079391 2.13189064] , error: 0.4737467679483093\n",
      "Weights: [0.36078335 2.13189185] , error: 0.4737467566698847\n",
      "Weights: [0.36077282 2.13189305] , error: 0.4737467454428412\n",
      "Weights: [0.36076231 2.13189425] , error: 0.4737467342669445\n",
      "Weights: [0.36075182 2.13189545] , error: 0.4737467231419592\n",
      "Weights: [0.36074136 2.13189665] , error: 0.4737467120676566\n",
      "Weights: [0.36073092 2.13189784] , error: 0.47374670104380384\n",
      "Weights: [0.36072051 2.13189903] , error: 0.4737466900701728\n",
      "Weights: [0.36071012 2.13190022] , error: 0.4737466791465328\n",
      "Weights: [0.36069975 2.13190141] , error: 0.473746668272656\n",
      "Weights: [0.36068941 2.13190259] , error: 0.47374665744831845\n",
      "Weights: [0.36067909 2.13190377] , error: 0.4737466466732907\n",
      "Weights: [0.3606688  2.13190495] , error: 0.47374663594735106\n",
      "Weights: [0.36065853 2.13190612] , error: 0.473746625270275\n",
      "Weights: [0.36064828 2.13190729] , error: 0.4737466146418392\n",
      "Weights: [0.36063805 2.13190846] , error: 0.47374660406182273\n",
      "Weights: [0.36062785 2.13190963] , error: 0.47374659353000526\n",
      "Weights: [0.36061767 2.13191079] , error: 0.4737465830461658\n",
      "Weights: [0.36060752 2.13191196] , error: 0.47374657261008785\n",
      "Weights: [0.36059738 2.13191311] , error: 0.47374656222155265\n",
      "Weights: [0.36058727 2.13191427] , error: 0.47374655188034326\n",
      "Weights: [0.36057719 2.13191542] , error: 0.47374654158624563\n",
      "Weights: [0.36056713 2.13191658] , error: 0.4737465313390436\n",
      "Weights: [0.36055709 2.13191772] , error: 0.47374652113852306\n",
      "Weights: [0.36054707 2.13191887] , error: 0.47374651098447335\n",
      "Weights: [0.36053707 2.13192001] , error: 0.47374650087668213\n",
      "Weights: [0.3605271  2.13192115] , error: 0.47374649081493747\n",
      "Weights: [0.36051715 2.13192229] , error: 0.4737464807990299\n",
      "Weights: [0.36050723 2.13192343] , error: 0.4737464708287529\n",
      "Weights: [0.36049732 2.13192456] , error: 0.47374646090389533\n",
      "Weights: [0.36048744 2.13192569] , error: 0.47374645102425156\n",
      "Weights: [0.36047758 2.13192682] , error: 0.47374644118961645\n",
      "Weights: [0.36046775 2.13192794] , error: 0.4737464313997847\n",
      "Weights: [0.36045794 2.13192906] , error: 0.47374642165455144\n",
      "Weights: [0.36044814 2.13193018] , error: 0.47374641195371225\n",
      "Weights: [0.36043838 2.1319313 ] , error: 0.4737464022970693\n",
      "Weights: [0.36042863 2.13193241] , error: 0.4737463926844172\n",
      "Weights: [0.3604189  2.13193353] , error: 0.4737463831155569\n",
      "Weights: [0.3604092  2.13193464] , error: 0.473746373590289\n",
      "Weights: [0.36039952 2.13193574] , error: 0.4737463641084143\n",
      "Weights: [0.36038986 2.13193685] , error: 0.4737463546697348\n",
      "Weights: [0.36038023 2.13193795] , error: 0.4737463452740559\n",
      "Weights: [0.36037061 2.13193905] , error: 0.4737463359211793\n",
      "Weights: [0.36036102 2.13194015] , error: 0.4737463266109113\n",
      "Weights: [0.36035145 2.13194124] , error: 0.47374631734305767\n",
      "Weights: [0.3603419  2.13194233] , error: 0.4737463081174248\n",
      "Weights: [0.36033238 2.13194342] , error: 0.4737462989338205\n",
      "Weights: [0.36032287 2.13194451] , error: 0.473746289792053\n",
      "Weights: [0.36031339 2.13194559] , error: 0.47374628069193203\n",
      "Weights: [0.36030393 2.13194668] , error: 0.4737462716332673\n",
      "Weights: [0.36029449 2.13194776] , error: 0.4737462626158716\n",
      "Weights: [0.36028507 2.13194883] , error: 0.473746253639554\n",
      "Weights: [0.36027567 2.13194991] , error: 0.473746244704132\n",
      "Weights: [0.3602663  2.13195098] , error: 0.4737462358094157\n",
      "Weights: [0.36025694 2.13195205] , error: 0.4737462269552194\n",
      "Weights: [0.36024761 2.13195312] , error: 0.47374621814136\n",
      "Weights: [0.3602383  2.13195418] , error: 0.47374620936765327\n",
      "Weights: [0.36022901 2.13195524] , error: 0.47374620063391637\n",
      "Weights: [0.36021974 2.1319563 ] , error: 0.4737461919399667\n",
      "Weights: [0.36021049 2.13195736] , error: 0.4737461832856247\n",
      "Weights: [0.36020127 2.13195842] , error: 0.4737461746707067\n",
      "Weights: [0.36019206 2.13195947] , error: 0.4737461660950367\n",
      "Weights: [0.36018288 2.13196052] , error: 0.47374615755843397\n",
      "Weights: [0.36017371 2.13196157] , error: 0.4737461490607204\n",
      "Weights: [0.36016457 2.13196261] , error: 0.4737461406017196\n",
      "Weights: [0.36015545 2.13196366] , error: 0.47374613218125494\n",
      "Weights: [0.36014635 2.1319647 ] , error: 0.473746123799151\n",
      "Weights: [0.36013726 2.13196574] , error: 0.473746115455232\n",
      "Weights: [0.36012821 2.13196677] , error: 0.47374610714932514\n",
      "Weights: [0.36011917 2.13196781] , error: 0.47374609888125785\n",
      "Weights: [0.36011015 2.13196884] , error: 0.4737460906508556\n",
      "Weights: [0.36010115 2.13196987] , error: 0.47374608245794875\n",
      "Weights: [0.36009217 2.13197089] , error: 0.4737460743023649\n",
      "Weights: [0.36008321 2.13197192] , error: 0.4737460661839357\n",
      "Weights: [0.36007428 2.13197294] , error: 0.4737460581024906\n",
      "Weights: [0.36006536 2.13197396] , error: 0.4737460500578617\n",
      "Weights: [0.36005647 2.13197498] , error: 0.4737460420498818\n",
      "Weights: [0.36004759 2.13197599] , error: 0.47374603407838245\n",
      "Weights: [0.36003874 2.131977  ] , error: 0.47374602614319855\n",
      "Weights: [0.3600299  2.13197801] , error: 0.47374601824416496\n",
      "Weights: [0.36002109 2.13197902] , error: 0.4737460103811157\n",
      "Weights: [0.36001229 2.13198003] , error: 0.47374600255388827\n",
      "Weights: [0.36000352 2.13198103] , error: 0.47374599476231843\n",
      "Weights: [0.35999476 2.13198203] , error: 0.47374598700624415\n",
      "Weights: [0.35998603 2.13198303] , error: 0.4737459792855032\n",
      "Weights: [0.35997731 2.13198403] , error: 0.47374597159993553\n",
      "Weights: [0.35996862 2.13198502] , error: 0.47374596394938034\n",
      "Weights: [0.35995994 2.13198602] , error: 0.4737459563336786\n",
      "Weights: [0.35995129 2.13198701] , error: 0.4737459487526707\n",
      "Weights: [0.35994265 2.13198799] , error: 0.4737459412061993\n",
      "Weights: [0.35993403 2.13198898] , error: 0.4737459336941074\n",
      "Weights: [0.35992544 2.13198996] , error: 0.47374592621623685\n",
      "Weights: [0.35991686 2.13199094] , error: 0.47374591877243355\n",
      "Weights: [0.3599083  2.13199192] , error: 0.47374591136254085\n",
      "Weights: [0.35989977 2.1319929 ] , error: 0.47374590398640526\n",
      "Weights: [0.35989125 2.13199387] , error: 0.47374589664387184\n",
      "Weights: [0.35988275 2.13199484] , error: 0.4737458893347892\n",
      "Weights: [0.35987427 2.13199581] , error: 0.473745882059004\n",
      "Weights: [0.35986581 2.13199678] , error: 0.4737458748163639\n",
      "Weights: [0.35985737 2.13199775] , error: 0.473745867606719\n",
      "Weights: [0.35984895 2.13199871] , error: 0.47374586042991856\n",
      "Weights: [0.35984054 2.13199967] , error: 0.47374585328581287\n",
      "Weights: [0.35983216 2.13200063] , error: 0.47374584617425364\n",
      "Weights: [0.3598238  2.13200159] , error: 0.4737458390950914\n",
      "Weights: [0.35981545 2.13200254] , error: 0.47374583204817944\n",
      "Weights: [0.35980713 2.13200349] , error: 0.47374582503337104\n",
      "Weights: [0.35979882 2.13200444] , error: 0.47374581805051824\n",
      "Weights: [0.35979053 2.13200539] , error: 0.47374581109947855\n",
      "Weights: [0.35978226 2.13200634] , error: 0.47374580418010326\n",
      "Weights: [0.35977401 2.13200728] , error: 0.4737457972922522\n",
      "Weights: [0.35976578 2.13200822] , error: 0.47374579043577814\n",
      "Weights: [0.35975757 2.13200916] , error: 0.4737457836105399\n",
      "Weights: [0.35974937 2.1320101 ] , error: 0.4737457768163954\n",
      "Weights: [0.3597412  2.13201103] , error: 0.4737457700532009\n",
      "Weights: [0.35973304 2.13201196] , error: 0.4737457633208191\n",
      "Weights: [0.3597249 2.1320129] , error: 0.4737457566191059\n",
      "Weights: [0.35971678 2.13201382] , error: 0.473745749947925\n",
      "Weights: [0.35970868 2.13201475] , error: 0.47374574330713465\n",
      "Weights: [0.3597006  2.13201567] , error: 0.4737457366965976\n",
      "Weights: [0.35969254 2.1320166 ] , error: 0.4737457301161746\n",
      "Weights: [0.35968449 2.13201752] , error: 0.47374572356573064\n",
      "Weights: [0.35967646 2.13201844] , error: 0.47374571704512747\n",
      "Weights: [0.35966845 2.13201935] , error: 0.4737457105542302\n",
      "Weights: [0.35966046 2.13202026] , error: 0.47374570409290245\n",
      "Weights: [0.35965249 2.13202118] , error: 0.47374569766101104\n",
      "Weights: [0.35964454 2.13202209] , error: 0.47374569125842003\n",
      "Weights: [0.3596366  2.13202299] , error: 0.4737456848849974\n",
      "Weights: [0.35962868 2.1320239 ] , error: 0.4737456785406093\n",
      "Weights: [0.35962078 2.1320248 ] , error: 0.4737456722251246\n",
      "Weights: [0.3596129 2.1320257] , error: 0.47374566593841094\n",
      "Weights: [0.35960504 2.1320266 ] , error: 0.47374565968033666\n",
      "Weights: [0.35959719 2.1320275 ] , error: 0.4737456534507717\n",
      "Weights: [0.35958936 2.1320284 ] , error: 0.4737456472495867\n",
      "Weights: [0.35958155 2.13202929] , error: 0.4737456410766519\n",
      "Weights: [0.35957376 2.13203018] , error: 0.47374563493183874\n",
      "Weights: [0.35956598 2.13203107] , error: 0.47374562881501947\n",
      "Weights: [0.35955823 2.13203196] , error: 0.47374562272606513\n",
      "Weights: [0.35955049 2.13203284] , error: 0.47374561666485127\n",
      "Weights: [0.35954277 2.13203373] , error: 0.4737456106312492\n",
      "Weights: [0.35953506 2.13203461] , error: 0.4737456046251341\n",
      "Weights: [0.35952738 2.13203549] , error: 0.47374559864638077\n",
      "Weights: [0.35951971 2.13203636] , error: 0.4737455926948641\n",
      "Weights: [0.35951206 2.13203724] , error: 0.4737455867704604\n",
      "Weights: [0.35950442 2.13203811] , error: 0.4737455808730458\n",
      "Weights: [0.3594968  2.13203898] , error: 0.47374557500249836\n",
      "Weights: [0.35948921 2.13203985] , error: 0.473745569158695\n",
      "Weights: [0.35948162 2.13204072] , error: 0.47374556334151363\n",
      "Weights: [0.35947406 2.13204158] , error: 0.4737455575508327\n",
      "Weights: [0.35946651 2.13204245] , error: 0.47374555178653255\n",
      "Weights: [0.35945898 2.13204331] , error: 0.473745546048492\n",
      "Weights: [0.35945147 2.13204417] , error: 0.4737455403365918\n",
      "Weights: [0.35944397 2.13204502] , error: 0.47374553465071345\n",
      "Weights: [0.35943649 2.13204588] , error: 0.4737455289907373\n",
      "Weights: [0.35942903 2.13204673] , error: 0.4737455233565473\n",
      "Weights: [0.35942159 2.13204758] , error: 0.47374551774802354\n",
      "Weights: [0.35941416 2.13204843] , error: 0.47374551216504934\n",
      "Weights: [0.35940675 2.13204928] , error: 0.4737455066075103\n",
      "Weights: [0.35939935 2.13205013] , error: 0.47374550107528857\n",
      "Weights: [0.35939198 2.13205097] , error: 0.4737454955682703\n",
      "Weights: [0.35938462 2.13205181] , error: 0.4737454900863395\n",
      "Weights: [0.35937727 2.13205265] , error: 0.473745484629382\n",
      "Weights: [0.35936995 2.13205349] , error: 0.4737454791972847\n",
      "Weights: [0.35936264 2.13205433] , error: 0.4737454737899342\n",
      "Weights: [0.35935534 2.13205516] , error: 0.4737454684072182\n",
      "Weights: [0.35934807 2.13205599] , error: 0.4737454630490231\n",
      "Weights: [0.35934081 2.13205682] , error: 0.473745457715238\n",
      "Weights: [0.35933356 2.13205765] , error: 0.47374545240575155\n",
      "Weights: [0.35932634 2.13205848] , error: 0.47374544712045374\n",
      "Weights: [0.35931913 2.1320593 ] , error: 0.4737454418592332\n",
      "Weights: [0.35931193 2.13206012] , error: 0.4737454366219816\n",
      "Weights: [0.35930475 2.13206095] , error: 0.4737454314085877\n",
      "Weights: [0.35929759 2.13206176] , error: 0.4737454262189454\n",
      "Weights: [0.35929045 2.13206258] , error: 0.4737454210529442\n",
      "Weights: [0.35928332 2.1320634 ] , error: 0.47374541591047725\n",
      "Weights: [0.35927621 2.13206421] , error: 0.47374541079143884\n",
      "Weights: [0.35926911 2.13206502] , error: 0.47374540569571966\n",
      "Weights: [0.35926203 2.13206583] , error: 0.47374540062321513\n",
      "Weights: [0.35925497 2.13206664] , error: 0.47374539557381873\n",
      "Weights: [0.35924792 2.13206745] , error: 0.47374539054742654\n",
      "Weights: [0.35924089 2.13206825] , error: 0.47374538554393175\n",
      "Weights: [0.35923387 2.13206905] , error: 0.47374538056323157\n",
      "Weights: [0.35922687 2.13206985] , error: 0.47374537560522106\n",
      "Weights: [0.35921989 2.13207065] , error: 0.473745370669797\n",
      "Weights: [0.35921292 2.13207145] , error: 0.4737453657568589\n",
      "Weights: [0.35920597 2.13207224] , error: 0.47374536086630037\n",
      "Weights: [0.35919903 2.13207304] , error: 0.4737453559980219\n",
      "Weights: [0.35919211 2.13207383] , error: 0.47374535115192185\n",
      "Weights: [0.35918521 2.13207462] , error: 0.47374534632789855\n",
      "Weights: [0.35917832 2.13207541] , error: 0.4737453415258521\n",
      "Weights: [0.35917144 2.13207619] , error: 0.4737453367456815\n",
      "Weights: [0.35916459 2.13207698] , error: 0.4737453319872882\n",
      "Weights: [0.35915775 2.13207776] , error: 0.4737453272505723\n",
      "Weights: [0.35915092 2.13207854] , error: 0.47374532253543494\n",
      "Weights: [0.35914411 2.13207932] , error: 0.4737453178417778\n",
      "Weights: [0.35913731 2.13208009] , error: 0.4737453131695031\n",
      "Weights: [0.35913053 2.13208087] , error: 0.4737453085185142\n",
      "Weights: [0.35912377 2.13208164] , error: 0.4737453038887122\n",
      "Weights: [0.35911702 2.13208242] , error: 0.4737452992800031\n",
      "Weights: [0.35911029 2.13208319] , error: 0.4737452946922891\n",
      "Weights: [0.35910357 2.13208395] , error: 0.47374529012547534\n",
      "Weights: [0.35909687 2.13208472] , error: 0.4737452855794662\n",
      "Weights: [0.35909018 2.13208548] , error: 0.47374528105416625\n",
      "Weights: [0.35908351 2.13208625] , error: 0.47374527654948295\n",
      "Weights: [0.35907685 2.13208701] , error: 0.47374527206532113\n",
      "Weights: [0.35907021 2.13208777] , error: 0.4737452676015874\n",
      "Weights: [0.35906358 2.13208853] , error: 0.47374526315818855\n",
      "Weights: [0.35905697 2.13208928] , error: 0.4737452587350332\n",
      "Weights: [0.35905038 2.13209004] , error: 0.47374525433202685\n",
      "Weights: [0.35904379 2.13209079] , error: 0.4737452499490802\n",
      "Weights: [0.35903723 2.13209154] , error: 0.4737452455860992\n",
      "Weights: [0.35903068 2.13209229] , error: 0.473745241242994\n",
      "Weights: [0.35902414 2.13209304] , error: 0.4737452369196755\n",
      "Weights: [0.35901762 2.13209378] , error: 0.47374523261605245\n",
      "Weights: [0.35901111 2.13209453] , error: 0.4737452283320349\n",
      "Weights: [0.35900462 2.13209527] , error: 0.47374522406753383\n",
      "Weights: [0.35899814 2.13209601] , error: 0.4737452198224603\n",
      "Weights: [0.35899168 2.13209675] , error: 0.47374521559672605\n",
      "Weights: [0.35898523 2.13209749] , error: 0.47374521139024145\n",
      "Weights: [0.3589788  2.13209822] , error: 0.473745207202921\n",
      "Weights: [0.35897238 2.13209896] , error: 0.47374520303467593\n",
      "Weights: [0.35896598 2.13209969] , error: 0.4737451988854206\n",
      "Weights: [0.35895959 2.13210042] , error: 0.47374519475506793\n",
      "Weights: [0.35895322 2.13210115] , error: 0.47374519064353104\n",
      "Weights: [0.35894686 2.13210188] , error: 0.4737451865507246\n",
      "Weights: [0.35894051 2.1321026 ] , error: 0.47374518247656333\n",
      "Weights: [0.35893418 2.13210333] , error: 0.47374517842096314\n",
      "Weights: [0.35892787 2.13210405] , error: 0.4737451743838385\n",
      "Weights: [0.35892156 2.13210477] , error: 0.473745170365105\n",
      "Weights: [0.35891528 2.13210549] , error: 0.47374516636467967\n",
      "Weights: [0.358909   2.13210621] , error: 0.47374516238247893\n",
      "Weights: [0.35890274 2.13210692] , error: 0.4737451584184201\n",
      "Weights: [0.3588965  2.13210764] , error: 0.47374515447241966\n",
      "Weights: [0.35889027 2.13210835] , error: 0.4737451505443951\n",
      "Weights: [0.35888405 2.13210906] , error: 0.47374514663426565\n",
      "Weights: [0.35887785 2.13210977] , error: 0.47374514274194984\n",
      "Weights: [0.35887166 2.13211048] , error: 0.4737451388673657\n",
      "Weights: [0.35886549 2.13211118] , error: 0.4737451350104318\n",
      "Weights: [0.35885933 2.13211189] , error: 0.4737451311710701\n",
      "Weights: [0.35885318 2.13211259] , error: 0.4737451273491986\n",
      "Weights: [0.35884705 2.13211329] , error: 0.47374512354473824\n",
      "Weights: [0.35884094 2.13211399] , error: 0.47374511975760836\n",
      "Weights: [0.35883483 2.13211469] , error: 0.4737451159877319\n",
      "Weights: [0.35882874 2.13211538] , error: 0.47374511223503035\n",
      "Weights: [0.35882267 2.13211608] , error: 0.4737451084994249\n",
      "Weights: [0.3588166  2.13211677] , error: 0.4737451047808361\n",
      "Weights: [0.35881056 2.13211746] , error: 0.4737451010791885\n",
      "Weights: [0.35880452 2.13211815] , error: 0.47374509739440485\n",
      "Weights: [0.3587985  2.13211884] , error: 0.4737450937264068\n",
      "Weights: [0.35879249 2.13211953] , error: 0.4737450900751192\n",
      "Weights: [0.3587865  2.13212021] , error: 0.47374508644046587\n",
      "Weights: [0.35878052 2.1321209 ] , error: 0.47374508282237004\n",
      "Weights: [0.35877456 2.13212158] , error: 0.47374507922075737\n",
      "Weights: [0.3587686  2.13212226] , error: 0.47374507563555235\n",
      "Weights: [0.35876266 2.13212294] , error: 0.4737450720666796\n",
      "Weights: [0.35875674 2.13212362] , error: 0.4737450685140652\n",
      "Weights: [0.35875083 2.13212429] , error: 0.473745064977636\n",
      "Weights: [0.35874493 2.13212497] , error: 0.4737450614573176\n",
      "Weights: [0.35873904 2.13212564] , error: 0.47374505795303545\n",
      "Weights: [0.35873317 2.13212631] , error: 0.4737450544647184\n",
      "Weights: [0.35872732 2.13212698] , error: 0.4737450509922921\n",
      "Weights: [0.35872147 2.13212765] , error: 0.47374504753568586\n",
      "Weights: [0.35871564 2.13212832] , error: 0.4737450440948256\n",
      "Weights: [0.35870982 2.13212898] , error: 0.4737450406696418\n",
      "Weights: [0.35870402 2.13212965] , error: 0.47374503726006095\n",
      "Weights: [0.35869823 2.13213031] , error: 0.47374503386601274\n",
      "Weights: [0.35869245 2.13213097] , error: 0.4737450304874275\n",
      "Weights: [0.35868668 2.13213163] , error: 0.47374502712423355\n",
      "Weights: [0.35868093 2.13213229] , error: 0.47374502377636074\n",
      "Weights: [0.35867519 2.13213294] , error: 0.47374502044373984\n",
      "Weights: [0.35866947 2.1321336 ] , error: 0.47374501712630035\n",
      "Weights: [0.35866375 2.13213425] , error: 0.4737450138239751\n",
      "Weights: [0.35865805 2.1321349 ] , error: 0.4737450105366933\n",
      "Weights: [0.35865237 2.13213556] , error: 0.47374500726438745\n",
      "Weights: [0.35864669 2.1321362 ] , error: 0.4737450040069887\n",
      "Weights: [0.35864103 2.13213685] , error: 0.47374500076442916\n",
      "Weights: [0.35863539 2.1321375 ] , error: 0.4737449975366417\n",
      "Weights: [0.35862975 2.13213814] , error: 0.47374499432355943\n",
      "Weights: [0.35862413 2.13213878] , error: 0.4737449911251144\n",
      "Weights: [0.35861852 2.13213943] , error: 0.47374498794124126\n",
      "Weights: [0.35861292 2.13214007] , error: 0.47374498477187155\n",
      "Weights: [0.35860734 2.1321407 ] , error: 0.47374498161694023\n",
      "Weights: [0.35860177 2.13214134] , error: 0.4737449784763815\n",
      "Weights: [0.35859621 2.13214198] , error: 0.47374497535013066\n",
      "Weights: [0.35859066 2.13214261] , error: 0.47374497223812173\n",
      "Weights: [0.35858513 2.13214324] , error: 0.47374496914029046\n",
      "Weights: [0.35857961 2.13214388] , error: 0.4737449660565708\n",
      "Weights: [0.3585741  2.13214451] , error: 0.4737449629868997\n",
      "Weights: [0.35856861 2.13214513] , error: 0.47374495993121246\n",
      "Weights: [0.35856313 2.13214576] , error: 0.47374495688944646\n",
      "Weights: [0.35855766 2.13214639] , error: 0.47374495386153787\n",
      "Weights: [0.3585522  2.13214701] , error: 0.47374495084742285\n",
      "Weights: [0.35854675 2.13214763] , error: 0.4737449478470393\n",
      "Weights: [0.35854132 2.13214825] , error: 0.4737449448603233\n",
      "Weights: [0.3585359  2.13214887] , error: 0.47374494188721494\n",
      "Weights: [0.35853049 2.13214949] , error: 0.47374493892765146\n",
      "Weights: [0.3585251  2.13215011] , error: 0.4737449359815692\n",
      "Weights: [0.35851971 2.13215073] , error: 0.47374493304890863\n",
      "Weights: [0.35851434 2.13215134] , error: 0.4737449301296089\n",
      "Weights: [0.35850898 2.13215195] , error: 0.47374492722360717\n",
      "Weights: [0.35850364 2.13215256] , error: 0.47374492433084436\n",
      "Weights: [0.3584983  2.13215317] , error: 0.47374492145126146\n",
      "Weights: [0.35849298 2.13215378] , error: 0.47374491858479506\n",
      "Weights: [0.35848767 2.13215439] , error: 0.47374491573138794\n",
      "Weights: [0.35848237 2.132155  ] , error: 0.4737449128909802\n",
      "Weights: [0.35847708 2.1321556 ] , error: 0.4737449100635115\n",
      "Weights: [0.35847181 2.1321562 ] , error: 0.4737449072489249\n",
      "Weights: [0.35846655 2.13215681] , error: 0.4737449044471595\n",
      "Weights: [0.3584613  2.13215741] , error: 0.4737449016581581\n",
      "Weights: [0.35845606 2.13215801] , error: 0.47374489888186216\n",
      "Weights: [0.35845083 2.1321586 ] , error: 0.4737448961182146\n",
      "Weights: [0.35844562 2.1321592 ] , error: 0.4737448933671572\n",
      "Weights: [0.35844042 2.13215979] , error: 0.4737448906286321\n",
      "Weights: [0.35843523 2.13216039] , error: 0.4737448879025828\n",
      "Weights: [0.35843005 2.13216098] , error: 0.473744885188953\n",
      "Weights: [0.35842488 2.13216157] , error: 0.47374488248768476\n",
      "Weights: [0.35841973 2.13216216] , error: 0.47374487979872226\n",
      "Weights: [0.35841459 2.13216275] , error: 0.4737448771220106\n",
      "Weights: [0.35840945 2.13216334] , error: 0.4737448744574923\n",
      "Weights: [0.35840433 2.13216392] , error: 0.47374487180511343\n",
      "Weights: [0.35839923 2.13216451] , error: 0.47374486916481623\n",
      "Weights: [0.35839413 2.13216509] , error: 0.4737448665365484\n",
      "Weights: [0.35838904 2.13216567] , error: 0.4737448639202543\n",
      "Weights: [0.35838397 2.13216625] , error: 0.47374486131587845\n",
      "Weights: [0.35837891 2.13216683] , error: 0.47374485872336725\n",
      "Weights: [0.35837386 2.13216741] , error: 0.4737448561426667\n",
      "Weights: [0.35836882 2.13216798] , error: 0.47374485357372276\n",
      "Weights: [0.35836379 2.13216856] , error: 0.4737448510164818\n",
      "Weights: [0.35835878 2.13216913] , error: 0.4737448484708909\n",
      "Weights: [0.35835377 2.1321697 ] , error: 0.4737448459368971\n",
      "Weights: [0.35834878 2.13217027] , error: 0.4737448434144477\n",
      "Weights: [0.3583438  2.13217084] , error: 0.4737448409034887\n",
      "Weights: [0.35833883 2.13217141] , error: 0.4737448384039687\n",
      "Weights: [0.35833387 2.13217198] , error: 0.47374483591583566\n",
      "Weights: [0.35832892 2.13217255] , error: 0.47374483343903745\n",
      "Weights: [0.35832399 2.13217311] , error: 0.47374483097352366\n",
      "Weights: [0.35831906 2.13217367] , error: 0.47374482851924055\n",
      "Weights: [0.35831415 2.13217423] , error: 0.4737448260761388\n",
      "Weights: [0.35830925 2.1321748 ] , error: 0.47374482364416737\n",
      "Weights: [0.35830436 2.13217535] , error: 0.47374482122327466\n",
      "Weights: [0.35829948 2.13217591] , error: 0.47374481881341063\n",
      "Weights: [0.35829461 2.13217647] , error: 0.47374481641452426\n",
      "Weights: [0.35828975 2.13217703] , error: 0.4737448140265684\n",
      "Weights: [0.3582849  2.13217758] , error: 0.4737448116494886\n",
      "Weights: [0.35828007 2.13217813] , error: 0.47374480928323986\n",
      "Weights: [0.35827524 2.13217868] , error: 0.4737448069277709\n",
      "Weights: [0.35827043 2.13217924] , error: 0.4737448045830307\n",
      "Weights: [0.35826563 2.13217978] , error: 0.47374480224897364\n",
      "Weights: [0.35826084 2.13218033] , error: 0.47374479992554963\n",
      "Weights: [0.35825605 2.13218088] , error: 0.4737447976127108\n",
      "Weights: [0.35825128 2.13218142] , error: 0.4737447953104072\n",
      "Weights: [0.35824653 2.13218197] , error: 0.47374479301859296\n",
      "Weights: [0.35824178 2.13218251] , error: 0.4737447907372183\n",
      "Weights: [0.35823704 2.13218305] , error: 0.4737447884662381\n",
      "Weights: [0.35823231 2.13218359] , error: 0.473744786205603\n",
      "Weights: [0.3582276  2.13218413] , error: 0.4737447839552664\n",
      "Weights: [0.35822289 2.13218467] , error: 0.4737447817151814\n",
      "Weights: [0.3582182  2.13218521] , error: 0.4737447794853019\n",
      "Weights: [0.35821351 2.13218574] , error: 0.47374477726558056\n",
      "Weights: [0.35820884 2.13218628] , error: 0.4737447750559715\n",
      "Weights: [0.35820418 2.13218681] , error: 0.47374477285642885\n",
      "Weights: [0.35819953 2.13218734] , error: 0.47374477066690573\n",
      "Weights: [0.35819489 2.13218787] , error: 0.47374476848735797\n",
      "Weights: [0.35819026 2.1321884 ] , error: 0.47374476631773876\n",
      "Weights: [0.35818564 2.13218893] , error: 0.4737447641580051\n",
      "Weights: [0.35818103 2.13218946] , error: 0.47374476200811017\n",
      "Weights: [0.35817643 2.13218999] , error: 0.4737447598680081\n",
      "Weights: [0.35817184 2.13219051] , error: 0.47374475773765573\n",
      "Weights: [0.35816726 2.13219103] , error: 0.473744755617009\n",
      "Weights: [0.3581627  2.13219156] , error: 0.4737447535060225\n",
      "Weights: [0.35815814 2.13219208] , error: 0.473744751404653\n",
      "Weights: [0.35815359 2.1321926 ] , error: 0.47374474931285754\n",
      "Weights: [0.35814906 2.13219312] , error: 0.47374474723058996\n",
      "Weights: [0.35814453 2.13219363] , error: 0.4737447451578097\n",
      "Weights: [0.35814001 2.13219415] , error: 0.47374474309447234\n",
      "Weights: [0.35813551 2.13219467] , error: 0.47374474104053377\n",
      "Weights: [0.35813101 2.13219518] , error: 0.4737447389959528\n",
      "Weights: [0.35812653 2.13219569] , error: 0.4737447369606859\n",
      "Weights: [0.35812205 2.1321962 ] , error: 0.4737447349346917\n",
      "Weights: [0.35811759 2.13219671] , error: 0.4737447329179259\n",
      "Weights: [0.35811314 2.13219722] , error: 0.4737447309103492\n",
      "Weights: [0.35810869 2.13219773] , error: 0.4737447289119173\n",
      "Weights: [0.35810426 2.13219824] , error: 0.47374472692258957\n",
      "Weights: [0.35809983 2.13219874] , error: 0.4737447249423244\n",
      "Weights: [0.35809542 2.13219925] , error: 0.47374472297108133\n",
      "Weights: [0.35809102 2.13219975] , error: 0.47374472100881737\n",
      "Weights: [0.35808662 2.13220026] , error: 0.4737447190554942\n",
      "Weights: [0.35808224 2.13220076] , error: 0.47374471711106825\n",
      "Weights: [0.35807787 2.13220126] , error: 0.47374471517550126\n",
      "Weights: [0.3580735  2.13220176] , error: 0.47374471324875156\n",
      "Weights: [0.35806915 2.13220225] , error: 0.4737447113307795\n",
      "Weights: [0.35806481 2.13220275] , error: 0.47374470942154545\n",
      "Weights: [0.35806047 2.13220325] , error: 0.47374470752100845\n",
      "Weights: [0.35805615 2.13220374] , error: 0.4737447056291295\n",
      "Weights: [0.35805183 2.13220423] , error: 0.47374470374587024\n",
      "Weights: [0.35804753 2.13220473] , error: 0.47374470187118933\n",
      "Weights: [0.35804324 2.13220522] , error: 0.4737447000050494\n",
      "Weights: [0.35803895 2.13220571] , error: 0.4737446981474106\n",
      "Weights: [0.35803468 2.1322062 ] , error: 0.47374469629823535\n",
      "Weights: [0.35803041 2.13220668] , error: 0.473744694457484\n",
      "Weights: [0.35802616 2.13220717] , error: 0.47374469262511815\n",
      "Weights: [0.35802191 2.13220766] , error: 0.47374469080109877\n",
      "Weights: [0.35801767 2.13220814] , error: 0.4737446889853912\n",
      "Weights: [0.35801345 2.13220862] , error: 0.47374468717795326\n",
      "Weights: [0.35800923 2.13220911] , error: 0.47374468537875036\n",
      "Weights: [0.35800502 2.13220959] , error: 0.4737446835877439\n",
      "Weights: [0.35800083 2.13221007] , error: 0.4737446818048967\n",
      "Weights: [0.35799664 2.13221055] , error: 0.4737446800301716\n",
      "Weights: [0.35799246 2.13221102] , error: 0.47374467826353006\n",
      "Weights: [0.35798829 2.1322115 ] , error: 0.47374467650493846\n",
      "Weights: [0.35798413 2.13221198] , error: 0.4737446747543582\n",
      "Weights: [0.35797998 2.13221245] , error: 0.47374467301175194\n",
      "Weights: [0.35797584 2.13221293] , error: 0.47374467127708464\n",
      "Weights: [0.35797171 2.1322134 ] , error: 0.4737446695503202\n",
      "Weights: [0.35796759 2.13221387] , error: 0.473744667831422\n",
      "Weights: [0.35796348 2.13221434] , error: 0.473744666120355\n",
      "Weights: [0.35795938 2.13221481] , error: 0.47374466441708235\n",
      "Weights: [0.35795528 2.13221528] , error: 0.47374466272156995\n",
      "Weights: [0.3579512  2.13221574] , error: 0.4737446610337809\n",
      "Weights: [0.35794712 2.13221621] , error: 0.4737446593536808\n",
      "Weights: [0.35794306 2.13221667] , error: 0.47374465768123514\n",
      "Weights: [0.357939   2.13221714] , error: 0.4737446560164076\n",
      "Weights: [0.35793496 2.1322176 ] , error: 0.4737446543591656\n",
      "Weights: [0.35793092 2.13221806] , error: 0.47374465270947264\n",
      "Weights: [0.35792689 2.13221852] , error: 0.47374465106729585\n",
      "Weights: [0.35792287 2.13221898] , error: 0.4737446494325993\n",
      "Weights: [0.35791886 2.13221944] , error: 0.47374464780534953\n",
      "Weights: [0.35791486 2.1322199 ] , error: 0.4737446461855135\n",
      "Weights: [0.35791087 2.13222036] , error: 0.4737446445730569\n",
      "Weights: [0.35790688 2.13222081] , error: 0.4737446429679465\n",
      "Weights: [0.35790291 2.13222127] , error: 0.4737446413701471\n",
      "Weights: [0.35789895 2.13222172] , error: 0.47374463977962816\n",
      "Weights: [0.35789499 2.13222217] , error: 0.4737446381963545\n",
      "Weights: [0.35789104 2.13222262] , error: 0.47374463662029315\n",
      "Weights: [0.35788711 2.13222307] , error: 0.47374463505141207\n",
      "Weights: [0.35788318 2.13222352] , error: 0.47374463348967827\n",
      "Weights: [0.35787926 2.13222397] , error: 0.47374463193505917\n",
      "Weights: [0.35787535 2.13222442] , error: 0.4737446303875219\n",
      "Weights: [0.35787145 2.13222486] , error: 0.4737446288470359\n",
      "Weights: [0.35786755 2.13222531] , error: 0.4737446273135669\n",
      "Weights: [0.35786367 2.13222575] , error: 0.47374462578708343\n",
      "Weights: [0.35785979 2.1322262 ] , error: 0.4737446242675548\n",
      "Weights: [0.35785593 2.13222664] , error: 0.47374462275494844\n",
      "Weights: [0.35785207 2.13222708] , error: 0.47374462124923306\n",
      "Weights: [0.35784822 2.13222752] , error: 0.4737446197503763\n",
      "Weights: [0.35784438 2.13222796] , error: 0.4737446182583489\n",
      "Weights: [0.35784055 2.1322284 ] , error: 0.47374461677311824\n",
      "Weights: [0.35783673 2.13222883] , error: 0.473744615294653\n",
      "Weights: [0.35783292 2.13222927] , error: 0.4737446138229239\n",
      "Weights: [0.35782911 2.13222971] , error: 0.47374461235789905\n",
      "Weights: [0.35782531 2.13223014] , error: 0.47374461089954867\n",
      "Weights: [0.35782153 2.13223057] , error: 0.47374460944784225\n",
      "Weights: [0.35781775 2.13223101] , error: 0.4737446080027485\n",
      "Weights: [0.35781398 2.13223144] , error: 0.4737446065642387\n",
      "Weights: [0.35781022 2.13223187] , error: 0.4737446051322812\n",
      "Weights: [0.35780646 2.1322323 ] , error: 0.47374460370684834\n",
      "Weights: [0.35780272 2.13223272] , error: 0.47374460228790843\n",
      "Weights: [0.35779898 2.13223315] , error: 0.4737446008754337\n",
      "Weights: [0.35779525 2.13223358] , error: 0.4737445994693929\n",
      "Weights: [0.35779154 2.132234  ] , error: 0.4737445980697571\n",
      "Weights: [0.35778782 2.13223443] , error: 0.4737445966764985\n",
      "Weights: [0.35778412 2.13223485] , error: 0.4737445952895863\n",
      "Weights: [0.35778043 2.13223527] , error: 0.47374459390899276\n",
      "Weights: [0.35777674 2.1322357 ] , error: 0.4737445925346886\n",
      "Weights: [0.35777307 2.13223612] , error: 0.4737445911666456\n",
      "Weights: [0.3577694  2.13223654] , error: 0.4737445898048345\n",
      "Weights: [0.35776574 2.13223695] , error: 0.473744588449228\n",
      "Weights: [0.35776209 2.13223737] , error: 0.473744587099796\n",
      "Weights: [0.35775844 2.13223779] , error: 0.473744585756512\n",
      "Weights: [0.35775481 2.1322382 ] , error: 0.47374458441934747\n",
      "Weights: [0.35775118 2.13223862] , error: 0.4737445830882744\n",
      "Weights: [0.35774756 2.13223903] , error: 0.47374458176326617\n",
      "Weights: [0.35774395 2.13223945] , error: 0.47374458044429335\n",
      "Weights: [0.35774035 2.13223986] , error: 0.4737445791313292\n",
      "Weights: [0.35773676 2.13224027] , error: 0.47374457782434654\n",
      "Weights: [0.35773317 2.13224068] , error: 0.4737445765233176\n",
      "Weights: [0.35772959 2.13224109] , error: 0.47374457522821656\n",
      "Weights: [0.35772602 2.1322415 ] , error: 0.4737445739390158\n",
      "Weights: [0.35772246 2.1322419 ] , error: 0.4737445726556868\n",
      "Weights: [0.35771891 2.13224231] , error: 0.47374457137820497\n",
      "Weights: [0.35771536 2.13224271] , error: 0.47374457010654347\n",
      "Weights: [0.35771183 2.13224312] , error: 0.47374456884067373\n",
      "Weights: [0.3577083  2.13224352] , error: 0.4737445675805716\n",
      "Weights: [0.35770478 2.13224393] , error: 0.47374456632621076\n",
      "Weights: [0.35770127 2.13224433] , error: 0.47374456507756346\n",
      "Weights: [0.35769776 2.13224473] , error: 0.47374456383460434\n",
      "Weights: [0.35769426 2.13224513] , error: 0.47374456259730763\n",
      "Weights: [0.35769078 2.13224553] , error: 0.4737445613656484\n",
      "Weights: [0.35768729 2.13224592] , error: 0.4737445601395984\n",
      "Weights: [0.35768382 2.13224632] , error: 0.473744558919136\n",
      "Weights: [0.35768036 2.13224672] , error: 0.4737445577042333\n",
      "Weights: [0.3576769  2.13224711] , error: 0.4737445564948651\n",
      "Weights: [0.35767345 2.13224751] , error: 0.4737445552910052\n",
      "Weights: [0.35767001 2.1322479 ] , error: 0.47374455409263017\n",
      "Weights: [0.35766658 2.13224829] , error: 0.4737445528997152\n",
      "Weights: [0.35766315 2.13224869] , error: 0.4737445517122342\n",
      "Weights: [0.35765973 2.13224908] , error: 0.47374455053016207\n",
      "Weights: [0.35765632 2.13224947] , error: 0.4737445493534763\n",
      "Weights: [0.35765292 2.13224986] , error: 0.4737445481821505\n",
      "Weights: [0.35764953 2.13225024] , error: 0.47374454701616164\n",
      "Weights: [0.35764614 2.13225063] , error: 0.47374454585548376\n",
      "Weights: [0.35764276 2.13225102] , error: 0.4737445447000936\n",
      "Weights: [0.35763939 2.1322514 ] , error: 0.4737445435499664\n",
      "Weights: [0.35763602 2.13225179] , error: 0.4737445424050797\n",
      "Weights: [0.35763267 2.13225217] , error: 0.473744541265407\n",
      "Weights: [0.35762932 2.13225255] , error: 0.47374454013092915\n",
      "Weights: [0.35762598 2.13225294] , error: 0.47374453900161784\n",
      "Weights: [0.35762265 2.13225332] , error: 0.4737445378774514\n",
      "Weights: [0.35761932 2.1322537 ] , error: 0.47374453675840683\n",
      "Weights: [0.357616   2.13225408] , error: 0.47374453564445923\n",
      "Weights: [0.35761269 2.13225446] , error: 0.4737445345355863\n",
      "Weights: [0.35760939 2.13225483] , error: 0.4737445334317665\n",
      "Weights: [0.3576061  2.13225521] , error: 0.4737445323329736\n",
      "Weights: [0.35760281 2.13225559] , error: 0.47374453123918736\n",
      "Weights: [0.35759953 2.13225596] , error: 0.4737445301503837\n",
      "Weights: [0.35759625 2.13225634] , error: 0.4737445290665402\n",
      "Weights: [0.35759299 2.13225671] , error: 0.47374452798763406\n",
      "Weights: [0.35758973 2.13225708] , error: 0.47374452691364277\n",
      "Weights: [0.35758648 2.13225745] , error: 0.4737445258445455\n",
      "Weights: [0.35758324 2.13225783] , error: 0.4737445247803178\n",
      "Weights: [0.35758   2.1322582] , error: 0.4737445237209383\n",
      "Weights: [0.35757677 2.13225856] , error: 0.4737445226663847\n",
      "Weights: [0.35757355 2.13225893] , error: 0.47374452161663577\n",
      "Weights: [0.35757034 2.1322593 ] , error: 0.47374452057166944\n",
      "Weights: [0.35756713 2.13225967] , error: 0.4737445195314629\n",
      "Weights: [0.35756393 2.13226003] , error: 0.47374451849599486\n",
      "Weights: [0.35756074 2.1322604 ] , error: 0.47374451746524493\n",
      "Weights: [0.35755756 2.13226076] , error: 0.47374451643919047\n",
      "Weights: [0.35755438 2.13226113] , error: 0.47374451541781015\n",
      "Weights: [0.35755121 2.13226149] , error: 0.4737445144010821\n",
      "Weights: [0.35754805 2.13226185] , error: 0.4737445133889868\n",
      "Weights: [0.35754489 2.13226221] , error: 0.4737445123815024\n",
      "Weights: [0.35754175 2.13226257] , error: 0.4737445113786073\n",
      "Weights: [0.35753861 2.13226293] , error: 0.47374451038028087\n",
      "Weights: [0.35753547 2.13226329] , error: 0.4737445093865029\n",
      "Weights: [0.35753234 2.13226365] , error: 0.47374450839725224\n",
      "Weights: [0.35752923 2.132264  ] , error: 0.4737445074125073\n",
      "Weights: [0.35752611 2.13226436] , error: 0.4737445064322502\n",
      "Weights: [0.35752301 2.13226471] , error: 0.47374450545645747\n",
      "Weights: [0.35751991 2.13226507] , error: 0.47374450448510996\n",
      "Weights: [0.35751682 2.13226542] , error: 0.47374450351818786\n",
      "Weights: [0.35751373 2.13226577] , error: 0.4737445025556709\n",
      "Weights: [0.35751066 2.13226613] , error: 0.4737445015975388\n",
      "Weights: [0.35750759 2.13226648] , error: 0.47374450064377205\n",
      "Weights: [0.35750452 2.13226683] , error: 0.4737444996943495\n",
      "Weights: [0.35750147 2.13226718] , error: 0.4737444987492522\n",
      "Weights: [0.35749842 2.13226753] , error: 0.4737444978084613\n",
      "Weights: [0.35749538 2.13226787] , error: 0.47374449687195563\n",
      "Weights: [0.35749234 2.13226822] , error: 0.4737444959397161\n",
      "Weights: [0.35748931 2.13226857] , error: 0.4737444950117244\n",
      "Weights: [0.35748629 2.13226891] , error: 0.4737444940879594\n",
      "Weights: [0.35748328 2.13226926] , error: 0.4737444931684026\n",
      "Weights: [0.35748027 2.1322696 ] , error: 0.47374449225303583\n",
      "Weights: [0.35747727 2.13226994] , error: 0.4737444913418391\n",
      "Weights: [0.35747427 2.13227029] , error: 0.4737444904347927\n",
      "Weights: [0.35747129 2.13227063] , error: 0.4737444895318784\n",
      "Weights: [0.35746831 2.13227097] , error: 0.47374448863307783\n",
      "Weights: [0.35746533 2.13227131] , error: 0.473744487738372\n",
      "Weights: [0.35746237 2.13227165] , error: 0.473744486847742\n",
      "Weights: [0.35745941 2.13227199] , error: 0.47374448596116914\n",
      "Weights: [0.35745645 2.13227232] , error: 0.47374448507863565\n",
      "Weights: [0.35745351 2.13227266] , error: 0.4737444842001226\n",
      "Weights: [0.35745057 2.132273  ] , error: 0.473744483325611\n",
      "Weights: [0.35744763 2.13227333] , error: 0.4737444824550848\n",
      "Weights: [0.35744471 2.13227367] , error: 0.4737444815885231\n",
      "Weights: [0.35744179 2.132274  ] , error: 0.47374448072590936\n",
      "Weights: [0.35743888 2.13227434] , error: 0.4737444798672249\n",
      "Weights: [0.35743597 2.13227467] , error: 0.4737444790124539\n",
      "Weights: [0.35743307 2.132275  ] , error: 0.47374447816157594\n",
      "Weights: [0.35743018 2.13227533] , error: 0.47374447731457403\n",
      "Weights: [0.35742729 2.13227566] , error: 0.4737444764714316\n",
      "Weights: [0.35742441 2.13227599] , error: 0.4737444756321283\n",
      "Weights: [0.35742154 2.13227632] , error: 0.4737444747966505\n",
      "Weights: [0.35741867 2.13227665] , error: 0.47374447396497865\n",
      "Weights: [0.35741581 2.13227697] , error: 0.47374447313709434\n",
      "Weights: [0.35741296 2.1322773 ] , error: 0.4737444723129824\n",
      "Weights: [0.35741011 2.13227762] , error: 0.4737444714926248\n",
      "Weights: [0.35740727 2.13227795] , error: 0.4737444706760042\n",
      "Weights: [0.35740443 2.13227827] , error: 0.4737444698631045\n",
      "Weights: [0.35740161 2.1322786 ] , error: 0.47374446905390805\n",
      "Weights: [0.35739878 2.13227892] , error: 0.473744468248397\n",
      "Weights: [0.35739597 2.13227924] , error: 0.47374446744655596\n",
      "Weights: [0.35739316 2.13227956] , error: 0.4737444666483682\n",
      "Weights: [0.35739036 2.13227988] , error: 0.47374446585381613\n",
      "Weights: [0.35738756 2.1322802 ] , error: 0.47374446506288415\n",
      "Weights: [0.35738477 2.13228052] , error: 0.4737444642755553\n",
      "Weights: [0.35738199 2.13228084] , error: 0.4737444634918133\n",
      "Weights: [0.35737921 2.13228116] , error: 0.4737444627116425\n",
      "Weights: [0.35737644 2.13228148] , error: 0.4737444619350246\n",
      "Weights: [0.35737368 2.13228179] , error: 0.4737444611619447\n",
      "Weights: [0.35737092 2.13228211] , error: 0.47374446039238693\n",
      "Weights: [0.35736817 2.13228242] , error: 0.4737444596263354\n",
      "Weights: [0.35736543 2.13228274] , error: 0.4737444588637742\n",
      "Weights: [0.35736269 2.13228305] , error: 0.47374445810468574\n",
      "Weights: [0.35735995 2.13228336] , error: 0.47374445734905546\n",
      "Weights: [0.35735723 2.13228367] , error: 0.47374445659686826\n",
      "Weights: [0.35735451 2.13228398] , error: 0.4737444558481077\n",
      "Weights: [0.35735179 2.13228429] , error: 0.4737444551027578\n",
      "Weights: [0.35734909 2.1322846 ] , error: 0.4737444543608039\n",
      "Weights: [0.35734638 2.13228491] , error: 0.47374445362222917\n",
      "Weights: [0.35734369 2.13228522] , error: 0.47374445288701994\n",
      "Weights: [0.357341   2.13228553] , error: 0.4737444521551595\n",
      "Weights: [0.35733832 2.13228584] , error: 0.47374445142663374\n",
      "Weights: [0.35733564 2.13228614] , error: 0.47374445070142635\n",
      "Weights: [0.35733297 2.13228645] , error: 0.47374444997952303\n",
      "Weights: [0.3573303  2.13228675] , error: 0.4737444492609087\n",
      "Weights: [0.35732764 2.13228706] , error: 0.47374444854556735\n",
      "Weights: [0.35732499 2.13228736] , error: 0.47374444783348546\n",
      "Weights: [0.35732234 2.13228766] , error: 0.4737444471246471\n",
      "Weights: [0.3573197  2.13228796] , error: 0.4737444464190382\n",
      "Weights: [0.35731707 2.13228827] , error: 0.47374444571664426\n",
      "Weights: [0.35731444 2.13228857] , error: 0.47374444501744967\n",
      "Weights: [0.35731182 2.13228887] , error: 0.4737444443214397\n",
      "Weights: [0.3573092  2.13228917] , error: 0.4737444436286021\n",
      "Weights: [0.35730659 2.13228946] , error: 0.47374444293891954\n",
      "Weights: [0.35730399 2.13228976] , error: 0.4737444422523792\n",
      "Weights: [0.35730139 2.13229006] , error: 0.47374444156896645\n",
      "Weights: [0.35729879 2.13229036] , error: 0.4737444408886676\n",
      "Weights: [0.35729621 2.13229065] , error: 0.47374444021146744\n",
      "Weights: [0.35729363 2.13229095] , error: 0.47374443953735257\n",
      "Weights: [0.35729105 2.13229124] , error: 0.47374443886630874\n",
      "Weights: [0.35728848 2.13229153] , error: 0.47374443819832146\n",
      "Weights: [0.35728592 2.13229183] , error: 0.4737444375333778\n",
      "Weights: [0.35728336 2.13229212] , error: 0.4737444368714627\n",
      "Weights: [0.35728081 2.13229241] , error: 0.4737444362125632\n",
      "Weights: [0.35727826 2.1322927 ] , error: 0.4737444355566663\n",
      "Weights: [0.35727572 2.13229299] , error: 0.47374443490375673\n",
      "Weights: [0.35727319 2.13229328] , error: 0.4737444342538223\n",
      "Weights: [0.35727066 2.13229357] , error: 0.4737444336068478\n",
      "Weights: [0.35726814 2.13229386] , error: 0.47374443296282087\n",
      "Weights: [0.35726562 2.13229415] , error: 0.47374443232172875\n",
      "Weights: [0.35726311 2.13229444] , error: 0.4737444316835553\n",
      "Weights: [0.3572606  2.13229472] , error: 0.4737444310482907\n",
      "Weights: [0.3572581  2.13229501] , error: 0.47374443041592007\n",
      "Weights: [0.35725561 2.13229529] , error: 0.4737444297864303\n",
      "Weights: [0.35725312 2.13229558] , error: 0.47374442915980747\n",
      "Weights: [0.35725064 2.13229586] , error: 0.4737444285360402\n",
      "Weights: [0.35724816 2.13229615] , error: 0.4737444279151132\n",
      "Weights: [0.35724569 2.13229643] , error: 0.47374442729701605\n",
      "Weights: [0.35724322 2.13229671] , error: 0.473744426681735\n",
      "Weights: [0.35724076 2.13229699] , error: 0.4737444260692566\n",
      "Weights: [0.35723831 2.13229727] , error: 0.47374442545956785\n",
      "Weights: [0.35723586 2.13229755] , error: 0.4737444248526568\n",
      "Weights: [0.35723342 2.13229783] , error: 0.4737444242485119\n",
      "Weights: [0.35723098 2.13229811] , error: 0.4737444236471179\n",
      "Weights: [0.35722855 2.13229839] , error: 0.4737444230484637\n",
      "Weights: [0.35722612 2.13229867] , error: 0.4737444224525377\n",
      "Weights: [0.3572237  2.13229894] , error: 0.4737444218593254\n",
      "Weights: [0.35722128 2.13229922] , error: 0.4737444212688162\n",
      "Weights: [0.35721887 2.1322995 ] , error: 0.4737444206809966\n",
      "Weights: [0.35721647 2.13229977] , error: 0.47374442009585527\n",
      "Weights: [0.35721407 2.13230004] , error: 0.4737444195133794\n",
      "Weights: [0.35721168 2.13230032] , error: 0.4737444189335571\n",
      "Weights: [0.35720929 2.13230059] , error: 0.47374441835637626\n",
      "Weights: [0.3572069  2.13230086] , error: 0.47374441778182574\n",
      "Weights: [0.35720453 2.13230114] , error: 0.4737444172098912\n",
      "Weights: [0.35720216 2.13230141] , error: 0.4737444166405636\n",
      "Weights: [0.35719979 2.13230168] , error: 0.47374441607382883\n",
      "Weights: [0.35719743 2.13230195] , error: 0.47374441550967555\n",
      "Weights: [0.35719507 2.13230222] , error: 0.4737444149480935\n",
      "Weights: [0.35719272 2.13230249] , error: 0.47374441438906867\n",
      "Weights: [0.35719038 2.13230275] , error: 0.47374441383259075\n",
      "Weights: [0.35718804 2.13230302] , error: 0.4737444132786479\n",
      "Weights: [0.3571857  2.13230329] , error: 0.47374441272722917\n",
      "Weights: [0.35718337 2.13230356] , error: 0.4737444121783222\n",
      "Weights: [0.35718105 2.13230382] , error: 0.47374441163191644\n",
      "Weights: [0.35717873 2.13230409] , error: 0.4737444110879985\n",
      "Weights: [0.35717642 2.13230435] , error: 0.4737444105465598\n",
      "Weights: [0.35717411 2.13230461] , error: 0.4737444100075866\n",
      "Weights: [0.35717181 2.13230488] , error: 0.47374440947106966\n",
      "Weights: [0.35716951 2.13230514] , error: 0.473744408936997\n",
      "Weights: [0.35716722 2.1323054 ] , error: 0.4737444084053569\n",
      "Weights: [0.35716493 2.13230566] , error: 0.4737444078761389\n",
      "Weights: [0.35716265 2.13230593] , error: 0.4737444073493312\n",
      "Weights: [0.35716037 2.13230619] , error: 0.47374440682492464\n",
      "Weights: [0.3571581  2.13230645] , error: 0.4737444063029063\n",
      "Weights: [0.35715584 2.1323067 ] , error: 0.4737444057832656\n",
      "Weights: [0.35715358 2.13230696] , error: 0.4737444052659928\n",
      "Weights: [0.35715132 2.13230722] , error: 0.47374440475107693\n",
      "Weights: [0.35714907 2.13230748] , error: 0.4737444042385064\n",
      "Weights: [0.35714682 2.13230774] , error: 0.4737444037282709\n",
      "Weights: [0.35714458 2.13230799] , error: 0.4737444032203597\n",
      "Weights: [0.35714235 2.13230825] , error: 0.4737444027147628\n",
      "Weights: [0.35714012 2.1323085 ] , error: 0.47374440221146885\n",
      "Weights: [0.35713789 2.13230876] , error: 0.47374440171046706\n",
      "Weights: [0.35713567 2.13230901] , error: 0.4737444012117489\n",
      "Weights: [0.35713346 2.13230926] , error: 0.4737444007153025\n",
      "Weights: [0.35713125 2.13230952] , error: 0.47374440022111675\n",
      "Weights: [0.35712904 2.13230977] , error: 0.47374439972918386\n",
      "Weights: [0.35712684 2.13231002] , error: 0.4737443992394902\n",
      "Weights: [0.35712465 2.13231027] , error: 0.4737443987520285\n",
      "Weights: [0.35712246 2.13231052] , error: 0.4737443982667877\n",
      "Weights: [0.35712027 2.13231077] , error: 0.4737443977837575\n",
      "Weights: [0.35711809 2.13231102] , error: 0.4737443973029279\n",
      "Weights: [0.35711592 2.13231127] , error: 0.4737443968242878\n",
      "Weights: [0.35711375 2.13231152] , error: 0.47374439634782867\n",
      "Weights: [0.35711158 2.13231177] , error: 0.47374439587354084\n",
      "Weights: [0.35710942 2.13231201] , error: 0.47374439540141294\n",
      "Weights: [0.35710727 2.13231226] , error: 0.47374439493143616\n",
      "Weights: [0.35710512 2.1323125 ] , error: 0.4737443944635999\n",
      "Weights: [0.35710297 2.13231275] , error: 0.47374439399789553\n",
      "Weights: [0.35710083 2.132313  ] , error: 0.47374439353431236\n",
      "Weights: [0.3570987  2.13231324] , error: 0.4737443930728412\n",
      "Weights: [0.35709657 2.13231348] , error: 0.47374439261347195\n",
      "Weights: [0.35709444 2.13231373] , error: 0.4737443921561965\n",
      "Weights: [0.35709232 2.13231397] , error: 0.4737443917010035\n",
      "Weights: [0.3570902  2.13231421] , error: 0.4737443912478833\n",
      "Weights: [0.35708809 2.13231445] , error: 0.47374439079682873\n",
      "Weights: [0.35708599 2.13231469] , error: 0.47374439034782884\n",
      "Weights: [0.35708388 2.13231493] , error: 0.47374438990087353\n",
      "Weights: [0.35708179 2.13231517] , error: 0.473744389455956\n",
      "Weights: [0.3570797  2.13231541] , error: 0.47374438901306437\n",
      "Weights: [0.35707761 2.13231565] , error: 0.4737443885721902\n",
      "Weights: [0.35707553 2.13231589] , error: 0.4737443881333243\n",
      "Weights: [0.35707345 2.13231613] , error: 0.47374438769645805\n",
      "Weights: [0.35707138 2.13231636] , error: 0.47374438726158263\n",
      "Weights: [0.35706931 2.1323166 ] , error: 0.4737443868286876\n",
      "Weights: [0.35706724 2.13231684] , error: 0.47374438639776445\n",
      "Weights: [0.35706518 2.13231707] , error: 0.4737443859688055\n",
      "Weights: [0.35706313 2.13231731] , error: 0.4737443855417995\n",
      "Weights: [0.35706108 2.13231754] , error: 0.4737443851167397\n",
      "Weights: [0.35705904 2.13231778] , error: 0.4737443846936157\n",
      "Weights: [0.357057   2.13231801] , error: 0.4737443842724197\n",
      "Weights: [0.35705496 2.13231824] , error: 0.47374438385314244\n",
      "Weights: [0.35705293 2.13231847] , error: 0.47374438343577485\n",
      "Weights: [0.3570509  2.13231871] , error: 0.4737443830203087\n",
      "Weights: [0.35704888 2.13231894] , error: 0.4737443826067359\n",
      "Weights: [0.35704686 2.13231917] , error: 0.4737443821950474\n",
      "Weights: [0.35704485 2.1323194 ] , error: 0.4737443817852328\n",
      "Weights: [0.35704284 2.13231963] , error: 0.4737443813772867\n",
      "Weights: [0.35704084 2.13231986] , error: 0.47374438097119836\n",
      "Weights: [0.35703884 2.13232008] , error: 0.47374438056696055\n",
      "Weights: [0.35703685 2.13232031] , error: 0.4737443801645634\n",
      "Weights: [0.35703486 2.13232054] , error: 0.4737443797640003\n",
      "Weights: [0.35703287 2.13232077] , error: 0.4737443793652612\n",
      "Weights: [0.35703089 2.13232099] , error: 0.4737443789683392\n",
      "Weights: [0.35702892 2.13232122] , error: 0.473744378573225\n",
      "Weights: [0.35702695 2.13232145] , error: 0.4737443781799111\n",
      "Weights: [0.35702498 2.13232167] , error: 0.47374437778838907\n",
      "Weights: [0.35702302 2.13232189] , error: 0.4737443773986507\n",
      "Weights: [0.35702106 2.13232212] , error: 0.4737443770106873\n",
      "Weights: [0.3570191  2.13232234] , error: 0.47374437662449276\n",
      "Weights: [0.35701716 2.13232256] , error: 0.4737443762400555\n",
      "Weights: [0.35701521 2.13232279] , error: 0.4737443758573708\n",
      "Weights: [0.35701327 2.13232301] , error: 0.47374437547642956\n",
      "Weights: [0.35701133 2.13232323] , error: 0.47374437509722334\n",
      "Weights: [0.3570094  2.13232345] , error: 0.47374437471974534\n",
      "Weights: [0.35700748 2.13232367] , error: 0.4737443743439863\n",
      "Weights: [0.35700555 2.13232389] , error: 0.4737443739699394\n",
      "Weights: [0.35700364 2.13232411] , error: 0.473744373597596\n",
      "Weights: [0.35700172 2.13232433] , error: 0.47374437322694885\n",
      "Weights: [0.35699981 2.13232455] , error: 0.47374437285799\n",
      "Weights: [0.35699791 2.13232477] , error: 0.47374437249071366\n",
      "Weights: [0.35699601 2.13232498] , error: 0.47374437212510856\n",
      "Weights: [0.35699411 2.1323252 ] , error: 0.4737443717611706\n",
      "Weights: [0.35699222 2.13232542] , error: 0.4737443713988898\n",
      "Weights: [0.35699033 2.13232563] , error: 0.4737443710382591\n",
      "Weights: [0.35698845 2.13232585] , error: 0.4737443706792721\n",
      "Weights: [0.35698657 2.13232606] , error: 0.47374437032191974\n",
      "Weights: [0.35698469 2.13232628] , error: 0.47374436996619573\n",
      "Weights: [0.35698282 2.13232649] , error: 0.4737443696120922\n",
      "Weights: [0.35698095 2.1323267 ] , error: 0.4737443692596036\n",
      "Weights: [0.35697909 2.13232692] , error: 0.4737443689087174\n",
      "Weights: [0.35697723 2.13232713] , error: 0.4737443685594315\n",
      "Weights: [0.35697538 2.13232734] , error: 0.4737443682117366\n",
      "Weights: [0.35697353 2.13232755] , error: 0.4737443678656257\n",
      "Weights: [0.35697169 2.13232776] , error: 0.47374436752109184\n",
      "Weights: [0.35696985 2.13232798] , error: 0.47374436717812685\n",
      "Weights: [0.35696801 2.13232819] , error: 0.47374436683672483\n",
      "Weights: [0.35696618 2.13232839] , error: 0.4737443664968783\n",
      "Weights: [0.35696435 2.1323286 ] , error: 0.4737443661585803\n",
      "Weights: [0.35696252 2.13232881] , error: 0.47374436582182233\n",
      "Weights: [0.3569607  2.13232902] , error: 0.4737443654866009\n",
      "Weights: [0.35695889 2.13232923] , error: 0.473744365152903\n",
      "Weights: [0.35695708 2.13232944] , error: 0.47374436482072707\n",
      "Weights: [0.35695527 2.13232964] , error: 0.473744364490065\n",
      "Weights: [0.35695346 2.13232985] , error: 0.47374436416090876\n",
      "Weights: [0.35695167 2.13233005] , error: 0.473744363833252\n",
      "Weights: [0.35694987 2.13233026] , error: 0.4737443635070879\n",
      "Weights: [0.35694808 2.13233046] , error: 0.47374436318240926\n",
      "Weights: [0.35694629 2.13233067] , error: 0.4737443628592102\n",
      "Weights: [0.35694451 2.13233087] , error: 0.4737443625374839\n",
      "Weights: [0.35694273 2.13233108] , error: 0.47374436221722277\n",
      "Weights: [0.35694095 2.13233128] , error: 0.47374436189842056\n",
      "Weights: [0.35693918 2.13233148] , error: 0.47374436158107125\n",
      "Weights: [0.35693742 2.13233168] , error: 0.4737443612651674\n",
      "Weights: [0.35693565 2.13233189] , error: 0.4737443609507025\n",
      "Weights: [0.3569339  2.13233209] , error: 0.4737443606376698\n",
      "Weights: [0.35693214 2.13233229] , error: 0.4737443603260642\n",
      "Weights: [0.35693039 2.13233249] , error: 0.4737443600158766\n",
      "Weights: [0.35692864 2.13233269] , error: 0.47374435970710355\n",
      "Weights: [0.3569269  2.13233289] , error: 0.4737443593997367\n",
      "Weights: [0.35692516 2.13233309] , error: 0.47374435909377105\n",
      "Weights: [0.35692343 2.13233328] , error: 0.4737443587891975\n",
      "Weights: [0.3569217  2.13233348] , error: 0.4737443584860126\n",
      "Weights: [0.35691997 2.13233368] , error: 0.47374435818420896\n",
      "Weights: [0.35691825 2.13233388] , error: 0.47374435788377933\n",
      "Weights: [0.35691653 2.13233407] , error: 0.4737443575847187\n",
      "Weights: [0.35691481 2.13233427] , error: 0.47374435728702097\n",
      "Weights: [0.3569131  2.13233447] , error: 0.47374435699067885\n",
      "Weights: [0.35691139 2.13233466] , error: 0.4737443566956878\n",
      "Weights: [0.35690969 2.13233486] , error: 0.4737443564020395\n",
      "Weights: [0.35690799 2.13233505] , error: 0.47374435610972915\n",
      "Weights: [0.35690629 2.13233524] , error: 0.47374435581875063\n",
      "Weights: [0.3569046  2.13233544] , error: 0.47374435552909755\n",
      "Weights: [0.35690291 2.13233563] , error: 0.47374435524076364\n",
      "Weights: [0.35690123 2.13233582] , error: 0.4737443549537441\n",
      "Weights: [0.35689955 2.13233601] , error: 0.4737443546680323\n",
      "Weights: [0.35689787 2.13233621] , error: 0.473744354383621\n",
      "Weights: [0.3568962 2.1323364] , error: 0.4737443541005065\n",
      "Weights: [0.35689453 2.13233659] , error: 0.4737443538186813\n",
      "Weights: [0.35689287 2.13233678] , error: 0.47374435353814004\n",
      "Weights: [0.3568912  2.13233697] , error: 0.47374435325887654\n",
      "Weights: [0.35688955 2.13233716] , error: 0.4737443529808851\n",
      "Weights: [0.35688789 2.13233735] , error: 0.4737443527041601\n",
      "Weights: [0.35688624 2.13233754] , error: 0.47374435242869634\n",
      "Weights: [0.3568846  2.13233772] , error: 0.47374435215448735\n",
      "Weights: [0.35688296 2.13233791] , error: 0.4737443518815274\n",
      "Weights: [0.35688132 2.1323381 ] , error: 0.473744351609811\n",
      "Weights: [0.35687968 2.13233829] , error: 0.47374435133933257\n",
      "Weights: [0.35687805 2.13233847] , error: 0.47374435107008606\n",
      "Weights: [0.35687642 2.13233866] , error: 0.4737443508020667\n",
      "Weights: [0.3568748  2.13233885] , error: 0.47374435053526737\n",
      "Weights: [0.35687318 2.13233903] , error: 0.47374435026968387\n",
      "Weights: [0.35687156 2.13233922] , error: 0.47374435000531046\n",
      "Weights: [0.35686995 2.1323394 ] , error: 0.4737443497421422\n",
      "Weights: [0.35686834 2.13233958] , error: 0.4737443494801712\n",
      "Weights: [0.35686674 2.13233977] , error: 0.4737443492193941\n",
      "Weights: [0.35686513 2.13233995] , error: 0.47374434895980644\n",
      "Weights: [0.35686354 2.13234013] , error: 0.4737443487013996\n",
      "Weights: [0.35686194 2.13234032] , error: 0.47374434844417057\n",
      "Weights: [0.35686035 2.1323405 ] , error: 0.47374434818811406\n",
      "Weights: [0.35685876 2.13234068] , error: 0.47374434793322306\n",
      "Weights: [0.35685718 2.13234086] , error: 0.4737443476794934\n",
      "Weights: [0.3568556  2.13234104] , error: 0.4737443474269208\n",
      "Weights: [0.35685402 2.13234122] , error: 0.4737443471754977\n",
      "Weights: [0.35685245 2.1323414 ] , error: 0.4737443469252204\n",
      "Weights: [0.35685088 2.13234158] , error: 0.4737443466760829\n",
      "Weights: [0.35684932 2.13234176] , error: 0.47374434642808066\n",
      "Weights: [0.35684776 2.13234194] , error: 0.4737443461812081\n",
      "Weights: [0.3568462  2.13234212] , error: 0.4737443459354598\n",
      "Weights: [0.35684464 2.13234229] , error: 0.47374434569083124\n",
      "Weights: [0.35684309 2.13234247] , error: 0.4737443454473179\n",
      "Weights: [0.35684154 2.13234265] , error: 0.4737443452049134\n",
      "Weights: [0.35684    2.13234283] , error: 0.473744344963613\n",
      "Weights: [0.35683846 2.132343  ] , error: 0.4737443447234123\n",
      "Weights: [0.35683692 2.13234318] , error: 0.4737443444843056\n",
      "Weights: [0.35683539 2.13234335] , error: 0.473744344246288\n",
      "Weights: [0.35683386 2.13234353] , error: 0.4737443440093556\n",
      "Weights: [0.35683233 2.1323437 ] , error: 0.47374434377350094\n",
      "Weights: [0.35683081 2.13234388] , error: 0.4737443435387224\n",
      "Weights: [0.35682929 2.13234405] , error: 0.47374434330501214\n",
      "Weights: [0.35682777 2.13234422] , error: 0.4737443430723669\n",
      "Weights: [0.35682626 2.1323444 ] , error: 0.4737443428407827\n",
      "Weights: [0.35682475 2.13234457] , error: 0.4737443426102522\n",
      "Weights: [0.35682324 2.13234474] , error: 0.4737443423807719\n",
      "Weights: [0.35682174 2.13234491] , error: 0.4737443421523382\n",
      "Weights: [0.35682024 2.13234508] , error: 0.47374434192494375\n",
      "Weights: [0.35681875 2.13234526] , error: 0.47374434169858626\n",
      "Weights: [0.35681725 2.13234543] , error: 0.4737443414732595\n",
      "Weights: [0.35681577 2.1323456 ] , error: 0.47374434124895853\n",
      "Weights: [0.35681428 2.13234577] , error: 0.47374434102568086\n",
      "Weights: [0.3568128  2.13234594] , error: 0.4737443408034198\n",
      "Weights: [0.35681132 2.13234611] , error: 0.47374434058217013\n",
      "Weights: [0.35680984 2.13234627] , error: 0.47374434036192986\n",
      "Weights: [0.35680837 2.13234644] , error: 0.4737443401426932\n",
      "Weights: [0.3568069  2.13234661] , error: 0.47374433992445386\n",
      "Weights: [0.35680544 2.13234678] , error: 0.4737443397072093\n",
      "Weights: [0.35680398 2.13234694] , error: 0.4737443394909549\n",
      "Weights: [0.35680252 2.13234711] , error: 0.47374433927568577\n",
      "Weights: [0.35680106 2.13234728] , error: 0.47374433906139735\n",
      "Weights: [0.35679961 2.13234744] , error: 0.47374433884808387\n",
      "Weights: [0.35679816 2.13234761] , error: 0.4737443386357429\n",
      "Weights: [0.35679672 2.13234778] , error: 0.4737443384243698\n",
      "Weights: [0.35679527 2.13234794] , error: 0.4737443382139593\n",
      "Weights: [0.35679384 2.1323481 ] , error: 0.4737443380045072\n",
      "Weights: [0.3567924  2.13234827] , error: 0.47374433779600866\n",
      "Weights: [0.35679097 2.13234843] , error: 0.4737443375884609\n",
      "Weights: [0.35678954 2.1323486 ] , error: 0.4737443373818587\n",
      "Weights: [0.35678811 2.13234876] , error: 0.47374433717619774\n",
      "Weights: [0.35678669 2.13234892] , error: 0.47374433697147245\n",
      "Weights: [0.35678527 2.13234908] , error: 0.47374433676768124\n",
      "Weights: [0.35678386 2.13234925] , error: 0.473744336564818\n",
      "Weights: [0.35678244 2.13234941] , error: 0.47374433636287877\n",
      "Weights: [0.35678103 2.13234957] , error: 0.4737443361618595\n",
      "Weights: [0.35677963 2.13234973] , error: 0.4737443359617568\n",
      "Weights: [0.35677823 2.13234989] , error: 0.4737443357625645\n",
      "Weights: [0.35677683 2.13235005] , error: 0.47374433556427953\n",
      "Weights: [0.35677543 2.13235021] , error: 0.47374433536689864\n",
      "Weights: [0.35677404 2.13235037] , error: 0.4737443351704169\n",
      "Weights: [0.35677265 2.13235053] , error: 0.4737443349748309\n",
      "Weights: [0.35677126 2.13235069] , error: 0.4737443347801348\n",
      "Weights: [0.35676987 2.13235084] , error: 0.47374433458632514\n",
      "Weights: [0.35676849 2.132351  ] , error: 0.47374433439339997\n",
      "Weights: [0.35676712 2.13235116] , error: 0.47374433420135326\n",
      "Weights: [0.35676574 2.13235132] , error: 0.4737443340101804\n",
      "Weights: [0.35676437 2.13235147] , error: 0.4737443338198795\n",
      "Weights: [0.356763   2.13235163] , error: 0.4737443336304457\n",
      "Weights: [0.35676164 2.13235179] , error: 0.47374433344187444\n",
      "Weights: [0.35676027 2.13235194] , error: 0.47374433325416276\n",
      "Weights: [0.35675892 2.1323521 ] , error: 0.4737443330673049\n",
      "Weights: [0.35675756 2.13235225] , error: 0.47374433288129997\n",
      "Weights: [0.35675621 2.13235241] , error: 0.4737443326961407\n",
      "Weights: [0.35675486 2.13235256] , error: 0.4737443325118268\n",
      "Weights: [0.35675351 2.13235272] , error: 0.4737443323283508\n",
      "Weights: [0.35675217 2.13235287] , error: 0.47374433214571154\n",
      "Weights: [0.35675083 2.13235302] , error: 0.4737443319639043\n",
      "Weights: [0.35674949 2.13235318] , error: 0.4737443317829245\n",
      "Weights: [0.35674816 2.13235333] , error: 0.4737443316027705\n",
      "Weights: [0.35674682 2.13235348] , error: 0.47374433142343664\n",
      "Weights: [0.3567455  2.13235363] , error: 0.4737443312449201\n",
      "Weights: [0.35674417 2.13235378] , error: 0.47374433106721625\n",
      "Weights: [0.35674285 2.13235394] , error: 0.47374433089032225\n",
      "Weights: [0.35674153 2.13235409] , error: 0.47374433071423383\n",
      "Weights: [0.35674021 2.13235424] , error: 0.47374433053894754\n",
      "Weights: [0.3567389  2.13235439] , error: 0.47374433036446006\n",
      "Weights: [0.35673759 2.13235454] , error: 0.47374433019076817\n",
      "Weights: [0.35673628 2.13235469] , error: 0.473744330017867\n",
      "Weights: [0.35673498 2.13235484] , error: 0.4737443298457527\n",
      "Weights: [0.35673368 2.13235498] , error: 0.4737443296744229\n",
      "Weights: [0.35673238 2.13235513] , error: 0.4737443295038743\n",
      "Weights: [0.35673108 2.13235528] , error: 0.47374432933410215\n",
      "Weights: [0.35672979 2.13235543] , error: 0.47374432916510373\n",
      "Weights: [0.3567285  2.13235558] , error: 0.47374432899687413\n",
      "Weights: [0.35672722 2.13235572] , error: 0.47374432882941175\n",
      "Weights: [0.35672593 2.13235587] , error: 0.4737443286627128\n",
      "Weights: [0.35672465 2.13235602] , error: 0.4737443284967729\n",
      "Weights: [0.35672337 2.13235616] , error: 0.4737443283315878\n",
      "Weights: [0.3567221  2.13235631] , error: 0.47374432816715717\n",
      "Weights: [0.35672083 2.13235645] , error: 0.47374432800347355\n",
      "Weights: [0.35671956 2.1323566 ] , error: 0.4737443278405369\n",
      "Weights: [0.35671829 2.13235674] , error: 0.47374432767834274\n",
      "Weights: [0.35671703 2.13235689] , error: 0.473744327516887\n",
      "Weights: [0.35671577 2.13235703] , error: 0.47374432735616717\n",
      "Weights: [0.35671451 2.13235718] , error: 0.47374432719617976\n",
      "Weights: [0.35671326 2.13235732] , error: 0.47374432703692027\n",
      "Weights: [0.35671201 2.13235746] , error: 0.4737443268783873\n",
      "Weights: [0.35671076 2.13235761] , error: 0.4737443267205753\n",
      "Weights: [0.35670951 2.13235775] , error: 0.4737443265634826\n",
      "Weights: [0.35670827 2.13235789] , error: 0.47374432640710606\n",
      "Weights: [0.35670703 2.13235803] , error: 0.47374432625144136\n",
      "Weights: [0.35670579 2.13235817] , error: 0.4737443260964859\n",
      "Weights: [0.35670456 2.13235831] , error: 0.47374432594223703\n",
      "Weights: [0.35670332 2.13235846] , error: 0.47374432578869075\n",
      "Weights: [0.35670209 2.1323586 ] , error: 0.4737443256358437\n",
      "Weights: [0.35670087 2.13235874] , error: 0.47374432548369216\n",
      "Weights: [0.35669965 2.13235888] , error: 0.4737443253322354\n",
      "Weights: [0.35669842 2.13235902] , error: 0.4737443251814675\n",
      "Weights: [0.35669721 2.13235916] , error: 0.4737443250313871\n",
      "Weights: [0.35669599 2.13235929] , error: 0.4737443248819897\n",
      "Weights: [0.35669478 2.13235943] , error: 0.4737443247332731\n",
      "Weights: [0.35669357 2.13235957] , error: 0.47374432458523336\n",
      "Weights: [0.35669236 2.13235971] , error: 0.47374432443786957\n",
      "Weights: [0.35669116 2.13235985] , error: 0.47374432429117636\n",
      "Weights: [0.35668996 2.13235998] , error: 0.473744324145151\n",
      "Weights: [0.35668876 2.13236012] , error: 0.47374432399979105\n",
      "Weights: [0.35668756 2.13236026] , error: 0.4737443238550938\n",
      "Weights: [0.35668637 2.13236039] , error: 0.47374432371105596\n",
      "Weights: [0.35668518 2.13236053] , error: 0.47374432356767404\n",
      "Weights: [0.35668399 2.13236067] , error: 0.47374432342494516\n",
      "Weights: [0.35668281 2.1323608 ] , error: 0.47374432328286564\n",
      "Weights: [0.35668163 2.13236094] , error: 0.4737443231414345\n",
      "Weights: [0.35668045 2.13236107] , error: 0.47374432300064606\n",
      "Weights: [0.35667927 2.13236121] , error: 0.47374432286050083\n",
      "Weights: [0.35667809 2.13236134] , error: 0.47374432272099376\n",
      "Weights: [0.35667692 2.13236148] , error: 0.4737443225821225\n",
      "Weights: [0.35667575 2.13236161] , error: 0.47374432244388337\n",
      "Weights: [0.35667459 2.13236174] , error: 0.4737443223062739\n",
      "Weights: [0.35667342 2.13236188] , error: 0.4737443221692906\n",
      "Weights: [0.35667226 2.13236201] , error: 0.4737443220329327\n",
      "Weights: [0.35667111 2.13236214] , error: 0.47374432189719573\n",
      "Weights: [0.35666995 2.13236227] , error: 0.47374432176207626\n",
      "Weights: [0.3566688 2.1323624] , error: 0.47374432162757324\n",
      "Weights: [0.35666765 2.13236254] , error: 0.47374432149368306\n",
      "Weights: [0.3566665  2.13236267] , error: 0.47374432136040234\n",
      "Weights: [0.35666535 2.1323628 ] , error: 0.4737443212277282\n",
      "Weights: [0.35666421 2.13236293] , error: 0.47374432109565967\n",
      "Weights: [0.35666307 2.13236306] , error: 0.4737443209641923\n",
      "Weights: [0.35666194 2.13236319] , error: 0.4737443208333244\n",
      "Weights: [0.3566608  2.13236332] , error: 0.4737443207030513\n",
      "Weights: [0.35665967 2.13236345] , error: 0.4737443205733725\n",
      "Weights: [0.35665854 2.13236358] , error: 0.473744320444285\n",
      "Weights: [0.35665741 2.13236371] , error: 0.47374432031578495\n",
      "Weights: [0.35665629 2.13236384] , error: 0.47374432018787027\n",
      "Weights: [0.35665517 2.13236396] , error: 0.47374432006053846\n",
      "Weights: [0.35665405 2.13236409] , error: 0.4737443199337866\n",
      "Weights: [0.35665293 2.13236422] , error: 0.47374431980761234\n",
      "Weights: [0.35665182 2.13236435] , error: 0.47374431968201264\n",
      "Weights: [0.3566507  2.13236447] , error: 0.4737443195569853\n",
      "Weights: [0.3566496 2.1323646] , error: 0.4737443194325279\n",
      "Weights: [0.35664849 2.13236473] , error: 0.47374431930863664\n",
      "Weights: [0.35664739 2.13236485] , error: 0.47374431918531057\n",
      "Weights: [0.35664628 2.13236498] , error: 0.47374431906254544\n",
      "Weights: [0.35664518 2.1323651 ] , error: 0.4737443189403414\n",
      "Weights: [0.35664409 2.13236523] , error: 0.4737443188186921\n",
      "Weights: [0.35664299 2.13236536] , error: 0.47374431869759775\n",
      "Weights: [0.3566419  2.13236548] , error: 0.47374431857705573\n",
      "Weights: [0.35664081 2.1323656 ] , error: 0.4737443184570615\n",
      "Weights: [0.35663973 2.13236573] , error: 0.47374431833761443\n",
      "Weights: [0.35663864 2.13236585] , error: 0.47374431821871216\n",
      "Weights: [0.35663756 2.13236598] , error: 0.47374431810035145\n",
      "Weights: [0.35663648 2.1323661 ] , error: 0.4737443179825293\n",
      "Weights: [0.35663541 2.13236622] , error: 0.4737443178652448\n",
      "Weights: [0.35663433 2.13236635] , error: 0.4737443177484934\n",
      "Weights: [0.35663326 2.13236647] , error: 0.47374431763227437\n",
      "Weights: [0.35663219 2.13236659] , error: 0.4737443175165848\n",
      "Weights: [0.35663112 2.13236671] , error: 0.47374431740142253\n",
      "Weights: [0.35663006 2.13236683] , error: 0.473744317286785\n",
      "Weights: [0.356629   2.13236696] , error: 0.4737443171726686\n",
      "Weights: [0.35662794 2.13236708] , error: 0.47374431705907316\n",
      "Weights: [0.35662688 2.1323672 ] , error: 0.47374431694599545\n",
      "Weights: [0.35662583 2.13236732] , error: 0.4737443168334328\n",
      "Weights: [0.35662477 2.13236744] , error: 0.47374431672138195\n",
      "Weights: [0.35662372 2.13236756] , error: 0.4737443166098418\n",
      "Weights: [0.35662268 2.13236768] , error: 0.47374431649881016\n",
      "Weights: [0.35662163 2.1323678 ] , error: 0.47374431638828507\n",
      "Weights: [0.35662059 2.13236792] , error: 0.47374431627826274\n",
      "Weights: [0.35661955 2.13236804] , error: 0.4737443161687418\n",
      "Weights: [0.35661851 2.13236816] , error: 0.4737443160597195\n",
      "Weights: [0.35661748 2.13236827] , error: 0.47374431595119354\n",
      "Weights: [0.35661644 2.13236839] , error: 0.47374431584316246\n",
      "Weights: [0.35661541 2.13236851] , error: 0.4737443157356239\n",
      "Weights: [0.35661438 2.13236863] , error: 0.473744315628574\n",
      "Weights: [0.35661336 2.13236874] , error: 0.47374431552201335\n",
      "Weights: [0.35661233 2.13236886] , error: 0.47374431541593715\n",
      "Weights: [0.35661131 2.13236898] , error: 0.47374431531034505\n",
      "Weights: [0.35661029 2.1323691 ] , error: 0.4737443152052326\n",
      "Weights: [0.35660928 2.13236921] , error: 0.47374431510059983\n",
      "Weights: [0.35660826 2.13236933] , error: 0.47374431499644387\n",
      "Weights: [0.35660725 2.13236944] , error: 0.47374431489276253\n",
      "Weights: [0.35660624 2.13236956] , error: 0.47374431478955353\n",
      "Weights: [0.35660523 2.13236967] , error: 0.47374431468681377\n",
      "Weights: [0.35660423 2.13236979] , error: 0.4737443145845436\n",
      "Weights: [0.35660322 2.1323699 ] , error: 0.47374431448273796\n",
      "Weights: [0.35660222 2.13237002] , error: 0.4737443143813962\n",
      "Weights: [0.35660122 2.13237013] , error: 0.4737443142805171\n",
      "Weights: [0.35660023 2.13237025] , error: 0.4737443141800969\n",
      "Weights: [0.35659923 2.13237036] , error: 0.47374431408013395\n",
      "Weights: [0.35659824 2.13237047] , error: 0.473744313980627\n",
      "Weights: [0.35659725 2.13237059] , error: 0.4737443138815731\n",
      "Weights: [0.35659627 2.1323707 ] , error: 0.4737443137829709\n",
      "Weights: [0.35659528 2.13237081] , error: 0.4737443136848173\n",
      "Weights: [0.3565943  2.13237092] , error: 0.4737443135871105\n",
      "Weights: [0.35659332 2.13237104] , error: 0.47374431348984924\n",
      "Weights: [0.35659234 2.13237115] , error: 0.4737443133930312\n",
      "Weights: [0.35659136 2.13237126] , error: 0.4737443132966542\n",
      "Weights: [0.35659039 2.13237137] , error: 0.47374431320071675\n",
      "Weights: [0.35658942 2.13237148] , error: 0.4737443131052157\n",
      "Weights: [0.35658845 2.13237159] , error: 0.47374431301014985\n",
      "Weights: [0.35658748 2.1323717 ] , error: 0.47374431291551716\n",
      "Weights: [0.35658652 2.13237181] , error: 0.47374431282131535\n",
      "Weights: [0.35658555 2.13237192] , error: 0.4737443127275424\n",
      "Weights: [0.35658459 2.13237203] , error: 0.4737443126341969\n",
      "Weights: [0.35658364 2.13237214] , error: 0.473744312541277\n",
      "Weights: [0.35658268 2.13237225] , error: 0.47374431244878057\n",
      "Weights: [0.35658173 2.13237236] , error: 0.47374431235670533\n",
      "Weights: [0.35658077 2.13237247] , error: 0.4737443122650491\n",
      "Weights: [0.35657982 2.13237258] , error: 0.4737443121738113\n",
      "Weights: [0.35657888 2.13237269] , error: 0.47374431208298773\n",
      "Weights: [0.35657793 2.1323728 ] , error: 0.473744311992579\n",
      "Weights: [0.35657699 2.1323729 ] , error: 0.47374431190258204\n",
      "Weights: [0.35657605 2.13237301] , error: 0.47374431181299526\n",
      "Weights: [0.35657511 2.13237312] , error: 0.47374431172381604\n",
      "Weights: [0.35657417 2.13237323] , error: 0.47374431163504394\n",
      "Weights: [0.35657324 2.13237333] , error: 0.4737443115466745\n",
      "Weights: [0.35657231 2.13237344] , error: 0.473744311458709\n",
      "Weights: [0.35657138 2.13237355] , error: 0.4737443113711442\n",
      "Weights: [0.35657045 2.13237365] , error: 0.47374431128397787\n",
      "Weights: [0.35656952 2.13237376] , error: 0.4737443111972094\n",
      "Weights: [0.3565686  2.13237386] , error: 0.4737443111108355\n",
      "Weights: [0.35656768 2.13237397] , error: 0.4737443110248553\n",
      "Weights: [0.35656676 2.13237407] , error: 0.4737443109392665\n",
      "Weights: [0.35656584 2.13237418] , error: 0.4737443108540679\n",
      "Weights: [0.35656492 2.13237428] , error: 0.473744310769258\n",
      "Weights: [0.35656401 2.13237439] , error: 0.47374431068483347\n",
      "Weights: [0.3565631  2.13237449] , error: 0.47374431060079425\n",
      "Weights: [0.35656219 2.1323746 ] , error: 0.47374431051713733\n",
      "Weights: [0.35656128 2.1323747 ] , error: 0.4737443104338619\n",
      "Weights: [0.35656038 2.1323748 ] , error: 0.47374431035096576\n",
      "Weights: [0.35655947 2.13237491] , error: 0.47374431026844693\n",
      "Weights: [0.35655857 2.13237501] , error: 0.4737443101863041\n",
      "Weights: [0.35655767 2.13237511] , error: 0.47374431010453655\n",
      "Weights: [0.35655678 2.13237522] , error: 0.47374431002314066\n",
      "Weights: [0.35655588 2.13237532] , error: 0.4737443099421153\n",
      "Weights: [0.35655499 2.13237542] , error: 0.4737443098614591\n",
      "Weights: [0.3565541  2.13237552] , error: 0.4737443097811707\n",
      "Weights: [0.35655321 2.13237562] , error: 0.473744309701248\n",
      "Weights: [0.35655232 2.13237572] , error: 0.47374430962169\n",
      "Weights: [0.35655144 2.13237583] , error: 0.47374430954249397\n",
      "Weights: [0.35655056 2.13237593] , error: 0.47374430946365753\n",
      "Weights: [0.35654968 2.13237603] , error: 0.47374430938518086\n",
      "Weights: [0.3565488  2.13237613] , error: 0.4737443093070622\n",
      "Weights: [0.35654792 2.13237623] , error: 0.47374430922930016\n",
      "Weights: [0.35654705 2.13237633] , error: 0.4737443091518914\n",
      "Weights: [0.35654617 2.13237643] , error: 0.47374430907483506\n",
      "Weights: [0.3565453  2.13237653] , error: 0.4737443089981305\n",
      "Weights: [0.35654443 2.13237663] , error: 0.47374430892177505\n",
      "Weights: [0.35654357 2.13237673] , error: 0.47374430884576685\n",
      "Weights: [0.3565427  2.13237683] , error: 0.47374430877010587\n",
      "Weights: [0.35654184 2.13237692] , error: 0.473744308694789\n",
      "Weights: [0.35654098 2.13237702] , error: 0.4737443086198156\n",
      "Weights: [0.35654012 2.13237712] , error: 0.4737443085451837\n",
      "Weights: [0.35653926 2.13237722] , error: 0.4737443084708918\n",
      "Weights: [0.35653841 2.13237732] , error: 0.4737443083969376\n",
      "Weights: [0.35653756 2.13237741] , error: 0.4737443083233213\n",
      "Weights: [0.3565367  2.13237751] , error: 0.4737443082500401\n",
      "Weights: [0.35653586 2.13237761] , error: 0.47374430817709295\n",
      "Weights: [0.35653501 2.13237771] , error: 0.4737443081044771\n",
      "Weights: [0.35653416 2.1323778 ] , error: 0.4737443080321926\n",
      "Weights: [0.35653332 2.1323779 ] , error: 0.4737443079602377\n",
      "Weights: [0.35653248 2.13237799] , error: 0.4737443078886109\n",
      "Weights: [0.35653164 2.13237809] , error: 0.4737443078173098\n",
      "Weights: [0.3565308  2.13237819] , error: 0.47374430774633325\n",
      "Weights: [0.35652997 2.13237828] , error: 0.47374430767568104\n",
      "Weights: [0.35652913 2.13237838] , error: 0.47374430760535013\n",
      "Weights: [0.3565283  2.13237847] , error: 0.4737443075353398\n",
      "Weights: [0.35652747 2.13237857] , error: 0.4737443074656475\n",
      "Weights: [0.35652664 2.13237866] , error: 0.473744307396274\n",
      "Weights: [0.35652582 2.13237876] , error: 0.4737443073272156\n",
      "Weights: [0.35652499 2.13237885] , error: 0.4737443072584725\n",
      "Weights: [0.35652417 2.13237894] , error: 0.47374430719004257\n",
      "Weights: [0.35652335 2.13237904] , error: 0.4737443071219228\n",
      "Weights: [0.35652253 2.13237913] , error: 0.47374430705411585\n",
      "Weights: [0.35652171 2.13237923] , error: 0.4737443069866164\n",
      "Weights: [0.3565209  2.13237932] , error: 0.47374430691942376\n",
      "Weights: [0.35652009 2.13237941] , error: 0.4737443068525382\n",
      "Weights: [0.35651928 2.1323795 ] , error: 0.47374430678595714\n",
      "Weights: [0.35651847 2.1323796 ] , error: 0.4737443067196801\n",
      "Weights: [0.35651766 2.13237969] , error: 0.47374430665370365\n",
      "Weights: [0.35651685 2.13237978] , error: 0.4737443065880293\n",
      "Weights: [0.35651605 2.13237987] , error: 0.4737443065226535\n",
      "Weights: [0.35651525 2.13237997] , error: 0.4737443064575749\n",
      "Weights: [0.35651445 2.13238006] , error: 0.4737443063927926\n",
      "Weights: [0.35651365 2.13238015] , error: 0.4737443063283073\n",
      "Weights: [0.35651285 2.13238024] , error: 0.4737443062641137\n",
      "Weights: [0.35651206 2.13238033] , error: 0.4737443062002132\n",
      "Weights: [0.35651126 2.13238042] , error: 0.4737443061366041\n",
      "Weights: [0.35651047 2.13238051] , error: 0.47374430607328466\n",
      "Weights: [0.35650968 2.1323806 ] , error: 0.4737443060102534\n",
      "Weights: [0.3565089  2.13238069] , error: 0.47374430594750994\n",
      "Weights: [0.35650811 2.13238078] , error: 0.4737443058850521\n",
      "Weights: [0.35650733 2.13238087] , error: 0.47374430582287874\n",
      "Weights: [0.35650655 2.13238096] , error: 0.47374430576098825\n",
      "Weights: [0.35650577 2.13238105] , error: 0.4737443056993803\n",
      "Weights: [0.35650499 2.13238114] , error: 0.4737443056380527\n",
      "Weights: [0.35650421 2.13238123] , error: 0.4737443055770041\n",
      "Weights: [0.35650343 2.13238132] , error: 0.47374430551623364\n",
      "Weights: [0.35650266 2.1323814 ] , error: 0.47374430545574164\n",
      "Weights: [0.35650189 2.13238149] , error: 0.4737443053955231\n",
      "Weights: [0.35650112 2.13238158] , error: 0.47374430533557976\n",
      "Weights: [0.35650035 2.13238167] , error: 0.4737443052759095\n",
      "Weights: [0.35649959 2.13238176] , error: 0.4737443052165109\n",
      "Weights: [0.35649882 2.13238184] , error: 0.4737443051573832\n",
      "Weights: [0.35649806 2.13238193] , error: 0.4737443050985243\n",
      "Weights: [0.3564973  2.13238202] , error: 0.4737443050399348\n",
      "Weights: [0.35649654 2.1323821 ] , error: 0.47374430498161135\n",
      "Weights: [0.35649578 2.13238219] , error: 0.4737443049235535\n",
      "Weights: [0.35649503 2.13238228] , error: 0.47374430486576014\n",
      "Weights: [0.35649427 2.13238236] , error: 0.47374430480822993\n",
      "Weights: [0.35649352 2.13238245] , error: 0.4737443047509622\n",
      "Weights: [0.35649277 2.13238254] , error: 0.47374430469395534\n",
      "Weights: [0.35649202 2.13238262] , error: 0.47374430463720796\n",
      "Weights: [0.35649127 2.13238271] , error: 0.4737443045807194\n",
      "Weights: [0.35649053 2.13238279] , error: 0.4737443045244886\n",
      "Weights: [0.35648978 2.13238288] , error: 0.47374430446851257\n",
      "Weights: [0.35648904 2.13238296] , error: 0.4737443044127923\n",
      "Weights: [0.3564883  2.13238305] , error: 0.4737443043573258\n",
      "Weights: [0.35648756 2.13238313] , error: 0.4737443043021127\n",
      "Weights: [0.35648683 2.13238322] , error: 0.4737443042471504\n",
      "Weights: [0.35648609 2.1323833 ] , error: 0.47374430419243824\n",
      "Weights: [0.35648536 2.13238338] , error: 0.47374430413797614\n",
      "Weights: [0.35648463 2.13238347] , error: 0.473744304083762\n",
      "Weights: [0.3564839  2.13238355] , error: 0.47374430402979345\n",
      "Weights: [0.35648317 2.13238363] , error: 0.47374430397607215\n",
      "Weights: [0.35648244 2.13238372] , error: 0.4737443039225949\n",
      "Weights: [0.35648171 2.1323838 ] , error: 0.4737443038693624\n",
      "Weights: [0.35648099 2.13238388] , error: 0.47374430381637167\n",
      "Weights: [0.35648027 2.13238397] , error: 0.47374430376362164\n",
      "Weights: [0.35647955 2.13238405] , error: 0.4737443037111135\n",
      "Weights: [0.35647883 2.13238413] , error: 0.4737443036588431\n",
      "Weights: [0.35647811 2.13238421] , error: 0.4737443036068113\n",
      "Weights: [0.3564774  2.13238429] , error: 0.47374430355501695\n",
      "Weights: [0.35647668 2.13238438] , error: 0.4737443035034588\n",
      "Weights: [0.35647597 2.13238446] , error: 0.4737443034521339\n",
      "Weights: [0.35647526 2.13238454] , error: 0.47374430340104434\n",
      "Weights: [0.35647455 2.13238462] , error: 0.47374430335018763\n",
      "Weights: [0.35647384 2.1323847 ] , error: 0.47374430329956124\n",
      "Weights: [0.35647314 2.13238478] , error: 0.47374430324916683\n",
      "Weights: [0.35647243 2.13238486] , error: 0.4737443031990021\n",
      "Weights: [0.35647173 2.13238494] , error: 0.4737443031490654\n",
      "Weights: [0.35647103 2.13238502] , error: 0.47374430309935583\n",
      "Weights: [0.35647033 2.1323851 ] , error: 0.47374430304987225\n",
      "Weights: [0.35646963 2.13238518] , error: 0.47374430300061543\n",
      "Weights: [0.35646894 2.13238526] , error: 0.47374430295158193\n",
      "Weights: [0.35646824 2.13238534] , error: 0.47374430290277164\n",
      "Weights: [0.35646755 2.13238542] , error: 0.47374430285418456\n",
      "Weights: [0.35646686 2.1323855 ] , error: 0.47374430280581903\n",
      "Weights: [0.35646617 2.13238558] , error: 0.4737443027576741\n",
      "Weights: [0.35646548 2.13238566] , error: 0.47374430270974743\n",
      "Weights: [0.35646479 2.13238574] , error: 0.47374430266203915\n",
      "Weights: [0.35646411 2.13238581] , error: 0.4737443026145486\n",
      "Weights: [0.35646343 2.13238589] , error: 0.4737443025672743\n",
      "Weights: [0.35646274 2.13238597] , error: 0.4737443025202158\n",
      "Weights: [0.35646206 2.13238605] , error: 0.4737443024733712\n",
      "Weights: [0.35646138 2.13238612] , error: 0.4737443024267402\n",
      "Weights: [0.35646071 2.1323862 ] , error: 0.47374430238032095\n",
      "Weights: [0.35646003 2.13238628] , error: 0.4737443023341139\n",
      "Weights: [0.35645936 2.13238636] , error: 0.4737443022881179\n",
      "Weights: [0.35645869 2.13238643] , error: 0.47374430224233\n",
      "Weights: [0.35645801 2.13238651] , error: 0.47374430219675145\n",
      "Weights: [0.35645734 2.13238659] , error: 0.47374430215138014\n",
      "Weights: [0.35645668 2.13238666] , error: 0.4737443021062161\n",
      "Weights: [0.35645601 2.13238674] , error: 0.47374430206125795\n",
      "Weights: [0.35645534 2.13238682] , error: 0.4737443020165045\n",
      "Weights: [0.35645468 2.13238689] , error: 0.47374430197195494\n",
      "Weights: [0.35645402 2.13238697] , error: 0.47374430192760836\n",
      "Weights: [0.35645336 2.13238704] , error: 0.47374430188346267\n",
      "Weights: [0.3564527  2.13238712] , error: 0.47374430183951904\n",
      "Weights: [0.35645204 2.13238719] , error: 0.4737443017957752\n",
      "Weights: [0.35645139 2.13238727] , error: 0.47374430175223087\n",
      "Weights: [0.35645073 2.13238734] , error: 0.4737443017088858\n",
      "Weights: [0.35645008 2.13238742] , error: 0.4737443016657374\n",
      "Weights: [0.35644943 2.13238749] , error: 0.4737443016227853\n",
      "Weights: [0.35644878 2.13238757] , error: 0.473744301580029\n",
      "Weights: [0.35644813 2.13238764] , error: 0.4737443015374678\n",
      "Weights: [0.35644748 2.13238772] , error: 0.4737443014951003\n",
      "Weights: [0.35644684 2.13238779] , error: 0.47374430145292584\n",
      "Weights: [0.35644619 2.13238786] , error: 0.4737443014109432\n",
      "Weights: [0.35644555 2.13238794] , error: 0.4737443013691526\n",
      "Weights: [0.35644491 2.13238801] , error: 0.4737443013275522\n",
      "Weights: [0.35644427 2.13238808] , error: 0.47374430128614087\n",
      "Weights: [0.35644363 2.13238816] , error: 0.4737443012449182\n",
      "Weights: [0.35644299 2.13238823] , error: 0.4737443012038828\n",
      "Weights: [0.35644236 2.1323883 ] , error: 0.47374430116303623\n",
      "Weights: [0.35644172 2.13238837] , error: 0.4737443011223733\n",
      "Weights: [0.35644109 2.13238845] , error: 0.47374430108189736\n",
      "Weights: [0.35644046 2.13238852] , error: 0.4737443010416054\n",
      "Weights: [0.35643983 2.13238859] , error: 0.4737443010014965\n",
      "Weights: [0.3564392  2.13238866] , error: 0.4737443009615707\n",
      "Weights: [0.35643858 2.13238873] , error: 0.47374430092182696\n",
      "Weights: [0.35643795 2.13238881] , error: 0.4737443008822643\n",
      "Weights: [0.35643733 2.13238888] , error: 0.47374430084288177\n",
      "Weights: [0.3564367  2.13238895] , error: 0.4737443008036785\n",
      "Weights: [0.35643608 2.13238902] , error: 0.4737443007646538\n",
      "Weights: [0.35643546 2.13238909] , error: 0.47374430072580725\n",
      "Weights: [0.35643485 2.13238916] , error: 0.4737443006871367\n",
      "Weights: [0.35643423 2.13238923] , error: 0.47374430064864403\n",
      "Weights: [0.35643361 2.1323893 ] , error: 0.4737443006103254\n",
      "Weights: [0.356433   2.13238937] , error: 0.47374430057218153\n",
      "Weights: [0.35643239 2.13238944] , error: 0.4737443005342115\n",
      "Weights: [0.35643178 2.13238951] , error: 0.4737443004964148\n",
      "Weights: [0.35643117 2.13238958] , error: 0.47374430045878957\n",
      "Weights: [0.35643056 2.13238965] , error: 0.47374430042133586\n",
      "Weights: [0.35642995 2.13238972] , error: 0.4737443003840539\n",
      "Weights: [0.35642935 2.13238979] , error: 0.4737443003469402\n",
      "Weights: [0.35642874 2.13238986] , error: 0.47374430030999626\n",
      "Weights: [0.35642814 2.13238993] , error: 0.4737443002732217\n",
      "Weights: [0.35642754 2.13239   ] , error: 0.47374430023661307\n",
      "Weights: [0.35642694 2.13239006] , error: 0.47374430020017166\n",
      "Weights: [0.35642634 2.13239013] , error: 0.47374430016389635\n",
      "Weights: [0.35642574 2.1323902 ] , error: 0.4737443001277868\n",
      "Weights: [0.35642514 2.13239027] , error: 0.47374430009184104\n",
      "Weights: [0.35642455 2.13239034] , error: 0.4737443000560597\n",
      "Weights: [0.35642396 2.13239041] , error: 0.4737443000204407\n",
      "Weights: [0.35642336 2.13239047] , error: 0.47374429998498385\n",
      "Weights: [0.35642277 2.13239054] , error: 0.4737442999496892\n",
      "Weights: [0.35642218 2.13239061] , error: 0.4737442999145547\n",
      "Weights: [0.3564216  2.13239068] , error: 0.4737442998795807\n",
      "Weights: [0.35642101 2.13239074] , error: 0.4737442998447667\n",
      "Weights: [0.35642043 2.13239081] , error: 0.4737442998101102\n",
      "Weights: [0.35641984 2.13239088] , error: 0.47374429977561144\n",
      "Weights: [0.35641926 2.13239094] , error: 0.47374429974127036\n",
      "Weights: [0.35641868 2.13239101] , error: 0.4737442997070856\n",
      "Weights: [0.3564181  2.13239108] , error: 0.4737442996730569\n",
      "Weights: [0.35641752 2.13239114] , error: 0.47374429963918296\n",
      "Weights: [0.35641694 2.13239121] , error: 0.4737442996054634\n",
      "Weights: [0.35641637 2.13239127] , error: 0.4737442995718977\n",
      "Weights: [0.35641579 2.13239134] , error: 0.47374429953848407\n",
      "Weights: [0.35641522 2.1323914 ] , error: 0.4737442995052237\n",
      "Weights: [0.35641465 2.13239147] , error: 0.47374429947211466\n",
      "Weights: [0.35641408 2.13239154] , error: 0.47374429943915586\n",
      "Weights: [0.35641351 2.1323916 ] , error: 0.4737442994063473\n",
      "Weights: [0.35641294 2.13239167] , error: 0.4737442993736878\n",
      "Weights: [0.35641237 2.13239173] , error: 0.47374429934117823\n",
      "Weights: [0.35641181 2.1323918 ] , error: 0.4737442993088164\n",
      "Weights: [0.35641124 2.13239186] , error: 0.47374429927660217\n",
      "Weights: [0.35641068 2.13239192] , error: 0.4737442992445342\n",
      "Weights: [0.35641012 2.13239199] , error: 0.47374429921261246\n",
      "Weights: [0.35640956 2.13239205] , error: 0.4737442991808359\n",
      "Weights: [0.356409   2.13239212] , error: 0.4737442991492039\n",
      "Weights: [0.35640844 2.13239218] , error: 0.4737442991177175\n",
      "Weights: [0.35640788 2.13239224] , error: 0.47374429908637267\n",
      "Weights: [0.35640733 2.13239231] , error: 0.47374429905517157\n",
      "Weights: [0.35640677 2.13239237] , error: 0.47374429902411286\n",
      "Weights: [0.35640622 2.13239243] , error: 0.47374429899319537\n",
      "Weights: [0.35640567 2.1323925 ] , error: 0.47374429896241876\n",
      "Weights: [0.35640512 2.13239256] , error: 0.47374429893178194\n",
      "Weights: [0.35640457 2.13239262] , error: 0.4737442989012852\n",
      "Weights: [0.35640402 2.13239269] , error: 0.47374429887092695\n",
      "Weights: [0.35640348 2.13239275] , error: 0.47374429884070685\n",
      "Weights: [0.35640293 2.13239281] , error: 0.4737442988106251\n",
      "Weights: [0.35640239 2.13239287] , error: 0.47374429878067964\n",
      "Weights: [0.35640184 2.13239293] , error: 0.4737442987508715\n",
      "Weights: [0.3564013 2.132393 ] , error: 0.47374429872119955\n",
      "Weights: [0.35640076 2.13239306] , error: 0.473744298691662\n",
      "Weights: [0.35640022 2.13239312] , error: 0.4737442986622584\n",
      "Weights: [0.35639969 2.13239318] , error: 0.47374429863298917\n",
      "Weights: [0.35639915 2.13239324] , error: 0.4737442986038535\n",
      "Weights: [0.35639861 2.1323933 ] , error: 0.47374429857484984\n",
      "Weights: [0.35639808 2.13239336] , error: 0.4737442985459798\n",
      "Weights: [0.35639755 2.13239343] , error: 0.4737442985172403\n",
      "Weights: [0.35639701 2.13239349] , error: 0.473744298488632\n",
      "Weights: [0.35639648 2.13239355] , error: 0.4737442984601533\n",
      "Weights: [0.35639595 2.13239361] , error: 0.47374429843180593\n",
      "Weights: [0.35639543 2.13239367] , error: 0.4737442984035862\n",
      "Weights: [0.3563949  2.13239373] , error: 0.4737442983754955\n",
      "Weights: [0.35639437 2.13239379] , error: 0.47374429834753273\n",
      "Weights: [0.35639385 2.13239385] , error: 0.47374429831969794\n",
      "Weights: [0.35639333 2.13239391] , error: 0.4737442982919895\n",
      "Weights: [0.3563928  2.13239397] , error: 0.47374429826440645\n",
      "Weights: [0.35639228 2.13239403] , error: 0.47374429823694963\n",
      "Weights: [0.35639176 2.13239409] , error: 0.4737442982096182\n",
      "Weights: [0.35639125 2.13239415] , error: 0.47374429818241126\n",
      "Weights: [0.35639073 2.13239421] , error: 0.4737442981553286\n",
      "Weights: [0.35639021 2.13239426] , error: 0.47374429812836893\n",
      "Weights: [0.3563897  2.13239432] , error: 0.4737442981015321\n",
      "Weights: [0.35638918 2.13239438] , error: 0.47374429807481655\n",
      "Weights: [0.35638867 2.13239444] , error: 0.47374429804822443\n",
      "Weights: [0.35638816 2.1323945 ] , error: 0.47374429802175266\n",
      "Weights: [0.35638765 2.13239456] , error: 0.4737442979954011\n",
      "Weights: [0.35638714 2.13239462] , error: 0.4737442979691695\n",
      "Weights: [0.35638663 2.13239467] , error: 0.4737442979430587\n",
      "Weights: [0.35638612 2.13239473] , error: 0.4737442979170656\n",
      "Weights: [0.35638562 2.13239479] , error: 0.47374429789119177\n",
      "Weights: [0.35638511 2.13239485] , error: 0.47374429786543526\n",
      "Weights: [0.35638461 2.13239491] , error: 0.4737442978397961\n",
      "Weights: [0.35638411 2.13239496] , error: 0.4737442978142737\n",
      "Weights: [0.35638361 2.13239502] , error: 0.47374429778886823\n",
      "Weights: [0.35638311 2.13239508] , error: 0.47374429776357785\n",
      "Weights: [0.35638261 2.13239513] , error: 0.47374429773840243\n",
      "Weights: [0.35638211 2.13239519] , error: 0.47374429771334237\n",
      "Weights: [0.35638161 2.13239525] , error: 0.4737442976883963\n",
      "Weights: [0.35638112 2.1323953 ] , error: 0.4737442976635639\n",
      "Weights: [0.35638063 2.13239536] , error: 0.473744297638844\n",
      "Weights: [0.35638013 2.13239542] , error: 0.47374429761423675\n",
      "Weights: [0.35637964 2.13239547] , error: 0.4737442975897429\n",
      "Weights: [0.35637915 2.13239553] , error: 0.4737442975653599\n",
      "Weights: [0.35637866 2.13239559] , error: 0.4737442975410874\n",
      "Weights: [0.35637817 2.13239564] , error: 0.4737442975169265\n",
      "Weights: [0.35637768 2.1323957 ] , error: 0.4737442974928751\n",
      "Weights: [0.3563772  2.13239575] , error: 0.47374429746893315\n",
      "Weights: [0.35637671 2.13239581] , error: 0.4737442974451008\n",
      "Weights: [0.35637623 2.13239586] , error: 0.47374429742137536\n",
      "Weights: [0.35637574 2.13239592] , error: 0.4737442973977599\n",
      "Weights: [0.35637526 2.13239597] , error: 0.47374429737425194\n",
      "Weights: [0.35637478 2.13239603] , error: 0.47374429735085066\n",
      "Weights: [0.3563743  2.13239608] , error: 0.47374429732755535\n",
      "Weights: [0.35637382 2.13239614] , error: 0.47374429730436635\n",
      "Weights: [0.35637335 2.13239619] , error: 0.4737442972812838\n",
      "Weights: [0.35637287 2.13239625] , error: 0.4737442972583061\n",
      "Weights: [0.35637239 2.1323963 ] , error: 0.47374429723543227\n",
      "Weights: [0.35637192 2.13239636] , error: 0.47374429721266353\n",
      "Weights: [0.35637145 2.13239641] , error: 0.47374429718999855\n",
      "Weights: [0.35637097 2.13239646] , error: 0.4737442971674365\n",
      "Weights: [0.3563705  2.13239652] , error: 0.47374429714497734\n",
      "Weights: [0.35637003 2.13239657] , error: 0.4737442971226202\n",
      "Weights: [0.35636956 2.13239663] , error: 0.47374429710036436\n",
      "Weights: [0.3563691  2.13239668] , error: 0.4737442970782116\n",
      "Weights: [0.35636863 2.13239673] , error: 0.4737442970561585\n",
      "Weights: [0.35636816 2.13239679] , error: 0.47374429703420656\n",
      "Weights: [0.3563677  2.13239684] , error: 0.4737442970123538\n",
      "Weights: [0.35636723 2.13239689] , error: 0.4737442969906014\n",
      "Weights: [0.35636677 2.13239695] , error: 0.47374429696894743\n",
      "Weights: [0.35636631 2.132397  ] , error: 0.473744296947392\n",
      "Weights: [0.35636585 2.13239705] , error: 0.47374429692593567\n",
      "Weights: [0.35636539 2.1323971 ] , error: 0.4737442969045765\n",
      "Weights: [0.35636493 2.13239716] , error: 0.4737442968833145\n",
      "Weights: [0.35636447 2.13239721] , error: 0.4737442968621505\n",
      "Weights: [0.35636402 2.13239726] , error: 0.4737442968410818\n",
      "Weights: [0.35636356 2.13239731] , error: 0.47374429682010905\n",
      "Weights: [0.35636311 2.13239736] , error: 0.4737442967992326\n",
      "Weights: [0.35636266 2.13239742] , error: 0.47374429677845115\n",
      "Weights: [0.3563622  2.13239747] , error: 0.4737442967577633\n",
      "Weights: [0.35636175 2.13239752] , error: 0.4737442967371702\n",
      "Weights: [0.3563613  2.13239757] , error: 0.4737442967166713\n",
      "Weights: [0.35636085 2.13239762] , error: 0.47374429669626517\n",
      "Weights: [0.35636041 2.13239767] , error: 0.47374429667595314\n",
      "Weights: [0.35635996 2.13239772] , error: 0.47374429665573314\n",
      "Weights: [0.35635951 2.13239778] , error: 0.4737442966356048\n",
      "Weights: [0.35635907 2.13239783] , error: 0.47374429661556844\n",
      "Weights: [0.35635862 2.13239788] , error: 0.473744296595623\n",
      "Weights: [0.35635818 2.13239793] , error: 0.4737442965757704\n",
      "Weights: [0.35635774 2.13239798] , error: 0.47374429655600453\n",
      "Weights: [0.3563573  2.13239803] , error: 0.47374429653633143\n",
      "Weights: [0.35635686 2.13239808] , error: 0.4737442965167471\n",
      "Weights: [0.35635642 2.13239813] , error: 0.47374429649725197\n",
      "Weights: [0.35635598 2.13239818] , error: 0.4737442964778461\n",
      "Weights: [0.35635554 2.13239823] , error: 0.4737442964585283\n",
      "Weights: [0.35635511 2.13239828] , error: 0.4737442964392987\n",
      "Weights: [0.35635467 2.13239833] , error: 0.47374429642015714\n",
      "Weights: [0.35635424 2.13239838] , error: 0.4737442964011018\n",
      "Weights: [0.35635381 2.13239843] , error: 0.4737442963821337\n",
      "Weights: [0.35635337 2.13239848] , error: 0.4737442963632525\n",
      "Weights: [0.35635294 2.13239853] , error: 0.47374429634445653\n",
      "Weights: [0.35635251 2.13239858] , error: 0.47374429632574633\n",
      "Weights: [0.35635208 2.13239863] , error: 0.4737442963071214\n",
      "Weights: [0.35635166 2.13239867] , error: 0.4737442962885809\n",
      "Weights: [0.35635123 2.13239872] , error: 0.47374429627012526\n",
      "Weights: [0.3563508  2.13239877] , error: 0.47374429625175485\n",
      "Weights: [0.35635038 2.13239882] , error: 0.4737442962334671\n",
      "Weights: [0.35634995 2.13239887] , error: 0.4737442962152618\n",
      "Weights: [0.35634953 2.13239892] , error: 0.47374429619714153\n",
      "Weights: [0.35634911 2.13239897] , error: 0.47374429617910246\n",
      "Weights: [0.35634869 2.13239901] , error: 0.4737442961611446\n",
      "Weights: [0.35634827 2.13239906] , error: 0.47374429614326996\n",
      "Weights: [0.35634785 2.13239911] , error: 0.4737442961254763\n",
      "Weights: [0.35634743 2.13239916] , error: 0.4737442961077647\n",
      "Weights: [0.35634701 2.13239921] , error: 0.47374429609013335\n",
      "Weights: [0.3563466  2.13239925] , error: 0.4737442960725817\n",
      "Weights: [0.35634618 2.1323993 ] , error: 0.4737442960551098\n",
      "Weights: [0.35634577 2.13239935] , error: 0.4737442960377173\n",
      "Weights: [0.35634535 2.1323994 ] , error: 0.47374429602040463\n",
      "Weights: [0.35634494 2.13239944] , error: 0.4737442960031708\n",
      "Weights: [0.35634453 2.13239949] , error: 0.4737442959860163\n",
      "Weights: [0.35634412 2.13239954] , error: 0.4737442959689391\n",
      "Weights: [0.35634371 2.13239958] , error: 0.4737442959519399\n",
      "Weights: [0.3563433  2.13239963] , error: 0.4737442959350177\n",
      "Weights: [0.35634289 2.13239968] , error: 0.47374429591817296\n",
      "Weights: [0.35634248 2.13239972] , error: 0.4737442959014053\n",
      "Weights: [0.35634208 2.13239977] , error: 0.4737442958847136\n",
      "Weights: [0.35634167 2.13239982] , error: 0.4737442958680976\n",
      "Weights: [0.35634127 2.13239986] , error: 0.47374429585155714\n",
      "Weights: [0.35634086 2.13239991] , error: 0.4737442958350927\n",
      "Weights: [0.35634046 2.13239995] , error: 0.4737442958187029\n",
      "Weights: [0.35634006 2.1324    ] , error: 0.47374429580238825\n",
      "Weights: [0.35633966 2.13240005] , error: 0.4737442957861478\n",
      "Weights: [0.35633926 2.13240009] , error: 0.4737442957699816\n",
      "Weights: [0.35633886 2.13240014] , error: 0.4737442957538881\n",
      "Weights: [0.35633846 2.13240018] , error: 0.47374429573786875\n",
      "Weights: [0.35633807 2.13240023] , error: 0.47374429572192256\n",
      "Weights: [0.35633767 2.13240027] , error: 0.4737442957060477\n",
      "Weights: [0.35633727 2.13240032] , error: 0.4737442956902473\n",
      "Weights: [0.35633688 2.13240036] , error: 0.47374429567451704\n",
      "Weights: [0.35633649 2.13240041] , error: 0.47374429565885956\n",
      "Weights: [0.35633609 2.13240045] , error: 0.473744295643272\n",
      "Weights: [0.3563357 2.1324005] , error: 0.47374429562775644\n",
      "Weights: [0.35633531 2.13240054] , error: 0.4737442956123113\n",
      "Weights: [0.35633492 2.13240059] , error: 0.4737442955969368\n",
      "Weights: [0.35633453 2.13240063] , error: 0.473744295581632\n",
      "Weights: [0.35633415 2.13240068] , error: 0.4737442955663975\n",
      "Weights: [0.35633376 2.13240072] , error: 0.47374429555123165\n",
      "Weights: [0.35633337 2.13240077] , error: 0.47374429553613523\n",
      "Weights: [0.35633299 2.13240081] , error: 0.4737442955211073\n",
      "Weights: [0.3563326  2.13240085] , error: 0.47374429550614855\n",
      "Weights: [0.35633222 2.1324009 ] , error: 0.47374429549125774\n",
      "Weights: [0.35633184 2.13240094] , error: 0.4737442954764344\n",
      "Weights: [0.35633145 2.13240098] , error: 0.4737442954616792\n",
      "Weights: [0.35633107 2.13240103] , error: 0.47374429544699076\n",
      "Weights: [0.35633069 2.13240107] , error: 0.47374429543236934\n",
      "Weights: [0.35633031 2.13240111] , error: 0.473744295417814\n",
      "Weights: [0.35632994 2.13240116] , error: 0.47374429540332513\n",
      "Weights: [0.35632956 2.1324012 ] , error: 0.4737442953889027\n",
      "Weights: [0.35632918 2.13240124] , error: 0.47374429537454554\n",
      "Weights: [0.35632881 2.13240129] , error: 0.47374429536025464\n",
      "Weights: [0.35632843 2.13240133] , error: 0.473744295346028\n",
      "Weights: [0.35632806 2.13240137] , error: 0.4737442953318663\n",
      "Weights: [0.35632768 2.13240142] , error: 0.47374429531776924\n",
      "Weights: [0.35632731 2.13240146] , error: 0.4737442953037364\n",
      "Weights: [0.35632694 2.1324015 ] , error: 0.47374429528976747\n",
      "Weights: [0.35632657 2.13240154] , error: 0.4737442952758623\n",
      "Weights: [0.3563262  2.13240159] , error: 0.4737442952620202\n",
      "Weights: [0.35632583 2.13240163] , error: 0.473744295248241\n",
      "Weights: [0.35632546 2.13240167] , error: 0.4737442952345254\n",
      "Weights: [0.35632509 2.13240171] , error: 0.473744295220872\n",
      "Weights: [0.35632473 2.13240175] , error: 0.4737442952072806\n",
      "Weights: [0.35632436 2.1324018 ] , error: 0.47374429519375166\n",
      "Weights: [0.356324   2.13240184] , error: 0.473744295180284\n",
      "Weights: [0.35632363 2.13240188] , error: 0.473744295166877\n",
      "Weights: [0.35632327 2.13240192] , error: 0.47374429515353145\n",
      "Weights: [0.35632291 2.13240196] , error: 0.473744295140246\n",
      "Weights: [0.35632255 2.132402  ] , error: 0.4737442951270224\n",
      "Weights: [0.35632219 2.13240204] , error: 0.47374429511385896\n",
      "Weights: [0.35632183 2.13240209] , error: 0.4737442951007556\n",
      "Weights: [0.35632147 2.13240213] , error: 0.4737442950877113\n",
      "Weights: [0.35632111 2.13240217] , error: 0.47374429507472604\n",
      "Weights: [0.35632075 2.13240221] , error: 0.47374429506180077\n",
      "Weights: [0.35632039 2.13240225] , error: 0.4737442950489332\n",
      "Weights: [0.35632004 2.13240229] , error: 0.4737442950361255\n",
      "Weights: [0.35631968 2.13240233] , error: 0.47374429502337556\n",
      "Weights: [0.35631933 2.13240237] , error: 0.4737442950106838\n",
      "Weights: [0.35631898 2.13240241] , error: 0.4737442949980502\n",
      "Weights: [0.35631862 2.13240245] , error: 0.47374429498547443\n",
      "Weights: [0.35631827 2.13240249] , error: 0.47374429497295484\n",
      "Weights: [0.35631792 2.13240253] , error: 0.47374429496049236\n",
      "Weights: [0.35631757 2.13240257] , error: 0.4737442949480878\n",
      "Weights: [0.35631722 2.13240261] , error: 0.4737442949357387\n",
      "Weights: [0.35631687 2.13240265] , error: 0.4737442949234463\n",
      "Weights: [0.35631653 2.13240269] , error: 0.4737442949112101\n",
      "Weights: [0.35631618 2.13240273] , error: 0.4737442948990294\n",
      "Weights: [0.35631583 2.13240277] , error: 0.47374429488690406\n",
      "Weights: [0.35631549 2.13240281] , error: 0.4737442948748345\n",
      "Weights: [0.35631514 2.13240285] , error: 0.47374429486281955\n",
      "Weights: [0.3563148  2.13240289] , error: 0.4737442948508586\n",
      "Weights: [0.35631446 2.13240293] , error: 0.4737442948389537\n",
      "Weights: [0.35631411 2.13240297] , error: 0.47374429482710145\n",
      "Weights: [0.35631377 2.13240301] , error: 0.47374429481530395\n",
      "Weights: [0.35631343 2.13240305] , error: 0.4737442948035611\n",
      "Weights: [0.35631309 2.13240308] , error: 0.47374429479187\n",
      "Weights: [0.35631275 2.13240312] , error: 0.4737442947802331\n",
      "Weights: [0.35631241 2.13240316] , error: 0.47374429476864927\n",
      "Weights: [0.35631208 2.1324032 ] , error: 0.4737442947571178\n",
      "Weights: [0.35631174 2.13240324] , error: 0.4737442947456389\n",
      "Weights: [0.3563114  2.13240328] , error: 0.4737442947342126\n",
      "Weights: [0.35631107 2.13240332] , error: 0.47374429472283863\n",
      "Weights: [0.35631073 2.13240335] , error: 0.47374429471151636\n",
      "Weights: [0.3563104  2.13240339] , error: 0.47374429470024476\n",
      "Weights: [0.35631007 2.13240343] , error: 0.4737442946890255\n",
      "Weights: [0.35630973 2.13240347] , error: 0.47374429467785667\n",
      "Weights: [0.3563094  2.13240351] , error: 0.4737442946667397\n",
      "Weights: [0.35630907 2.13240354] , error: 0.473744294655672\n",
      "Weights: [0.35630874 2.13240358] , error: 0.47374429464465506\n",
      "Weights: [0.35630841 2.13240362] , error: 0.47374429463368906\n",
      "Weights: [0.35630808 2.13240366] , error: 0.4737442946227727\n",
      "Weights: [0.35630776 2.13240369] , error: 0.47374429461190615\n",
      "Weights: [0.35630743 2.13240373] , error: 0.47374429460108824\n",
      "Weights: [0.3563071  2.13240377] , error: 0.47374429459032036\n",
      "Weights: [0.35630678 2.13240381] , error: 0.4737442945796025\n",
      "Weights: [0.35630645 2.13240384] , error: 0.47374429456893247\n",
      "Weights: [0.35630613 2.13240388] , error: 0.4737442945583104\n",
      "Weights: [0.35630581 2.13240392] , error: 0.4737442945477378\n",
      "Weights: [0.35630548 2.13240395] , error: 0.4737442945372135\n",
      "Weights: [0.35630516 2.13240399] , error: 0.47374429452673605\n",
      "Weights: [0.35630484 2.13240403] , error: 0.47374429451630684\n",
      "Weights: [0.35630452 2.13240406] , error: 0.4737442945059252\n",
      "Weights: [0.3563042 2.1324041] , error: 0.47374429449558964\n",
      "Weights: [0.35630388 2.13240414] , error: 0.47374429448530336\n",
      "Weights: [0.35630356 2.13240417] , error: 0.47374429447506283\n",
      "Weights: [0.35630325 2.13240421] , error: 0.4737442944648692\n",
      "Weights: [0.35630293 2.13240425] , error: 0.4737442944547222\n",
      "Weights: [0.35630261 2.13240428] , error: 0.47374429444462074\n",
      "Weights: [0.3563023  2.13240432] , error: 0.47374429443456567\n",
      "Weights: [0.35630198 2.13240435] , error: 0.4737442944245564\n",
      "Weights: [0.35630167 2.13240439] , error: 0.47374429441459287\n",
      "Weights: [0.35630136 2.13240443] , error: 0.4737442944046747\n",
      "Weights: [0.35630105 2.13240446] , error: 0.47374429439480203\n",
      "Weights: [0.35630073 2.1324045 ] , error: 0.4737442943849732\n",
      "Weights: [0.35630042 2.13240453] , error: 0.4737442943751897\n",
      "Weights: [0.35630011 2.13240457] , error: 0.4737442943654515\n",
      "Weights: [0.3562998 2.1324046] , error: 0.4737442943557569\n",
      "Weights: [0.35629949 2.13240464] , error: 0.47374429434610593\n",
      "Weights: [0.35629919 2.13240467] , error: 0.4737442943365004\n",
      "Weights: [0.35629888 2.13240471] , error: 0.473744294326938\n",
      "Weights: [0.35629857 2.13240474] , error: 0.47374429431741943\n",
      "Weights: [0.35629827 2.13240478] , error: 0.47374429430794374\n",
      "Weights: [0.35629796 2.13240481] , error: 0.4737442942985101\n",
      "Weights: [0.35629766 2.13240485] , error: 0.4737442942891218\n",
      "Weights: [0.35629735 2.13240488] , error: 0.4737442942797741\n",
      "Weights: [0.35629705 2.13240492] , error: 0.4737442942704707\n",
      "Weights: [0.35629675 2.13240495] , error: 0.4737442942612085\n",
      "Weights: [0.35629644 2.13240499] , error: 0.4737442942519899\n",
      "Weights: [0.35629614 2.13240502] , error: 0.47374429424281134\n",
      "Weights: [0.35629584 2.13240506] , error: 0.4737442942336758\n",
      "Weights: [0.35629554 2.13240509] , error: 0.4737442942245817\n",
      "Weights: [0.35629524 2.13240513] , error: 0.47374429421552877\n",
      "Weights: [0.35629495 2.13240516] , error: 0.4737442942065174\n",
      "Weights: [0.35629465 2.13240519] , error: 0.4737442941975468\n",
      "Weights: [0.35629435 2.13240523] , error: 0.4737442941886176\n",
      "Weights: [0.35629405 2.13240526] , error: 0.4737442941797287\n",
      "Weights: [0.35629376 2.1324053 ] , error: 0.47374429417087993\n",
      "Weights: [0.35629346 2.13240533] , error: 0.4737442941620722\n",
      "Weights: [0.35629317 2.13240536] , error: 0.4737442941533042\n",
      "Weights: [0.35629288 2.1324054 ] , error: 0.47374429414457697\n",
      "Weights: [0.35629258 2.13240543] , error: 0.4737442941358889\n",
      "Weights: [0.35629229 2.13240546] , error: 0.47374429412723973\n",
      "Weights: [0.356292  2.1324055] , error: 0.4737442941186305\n",
      "Weights: [0.35629171 2.13240553] , error: 0.4737442941100606\n",
      "Weights: [0.35629142 2.13240556] , error: 0.4737442941015302\n",
      "Weights: [0.35629113 2.1324056 ] , error: 0.4737442940930374\n",
      "Weights: [0.35629084 2.13240563] , error: 0.47374429408458457\n",
      "Weights: [0.35629055 2.13240566] , error: 0.47374429407616997\n",
      "Weights: [0.35629026 2.1324057 ] , error: 0.4737442940677927\n",
      "Weights: [0.35628998 2.13240573] , error: 0.4737442940594542\n",
      "Weights: [0.35628969 2.13240576] , error: 0.47374429405115415\n",
      "Weights: [0.3562894  2.13240579] , error: 0.47374429404289176\n",
      "Weights: [0.35628912 2.13240583] , error: 0.4737442940346664\n",
      "Weights: [0.35628883 2.13240586] , error: 0.473744294026479\n",
      "Weights: [0.35628855 2.13240589] , error: 0.47374429401832896\n",
      "Weights: [0.35628827 2.13240592] , error: 0.4737442940102156\n",
      "Weights: [0.35628798 2.13240596] , error: 0.47374429400213997\n",
      "Weights: [0.3562877  2.13240599] , error: 0.47374429399410006\n",
      "Weights: [0.35628742 2.13240602] , error: 0.4737442939860976\n",
      "Weights: [0.35628714 2.13240605] , error: 0.4737442939781311\n",
      "Weights: [0.35628686 2.13240608] , error: 0.47374429397020196\n",
      "Weights: [0.35628658 2.13240612] , error: 0.4737442939623071\n"
     ]
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "    weights = weights - alpha*fullgrad(X,y,weights)\n",
    "    newerror = error(X,y,weights)\n",
    "    print(\"Weights:\", weights, \", error:\", newerror)\n",
    "    if newerror >= currenterror:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm curious, what does sklearn get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit_intercept is set to false as we already have the intercept included. (The columns of 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(fit_intercept=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression(fit_intercept=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35616438, 2.13242009])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close! They spent a lot more time writing better code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to do more stuff but I'm writing a function now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcoefficients(X,y,w,alpha,epochs=500,printing=False, plotting=False, showall=False):\n",
    "    weights = w\n",
    "    currenterror = error(X,y,w)\n",
    "    if plotting:\n",
    "        recorderrors = []\n",
    "        recorderrors.append(currenterror)\n",
    "        maxepoch=0\n",
    "    for i in range(epochs):\n",
    "        weights = weights - alpha*fullgrad(X,y,weights)\n",
    "        if printing:\n",
    "            print(\"Step:\", i, \"Weights:\", weights, \", error:\", error(X,y,weights))\n",
    "        #if error(X,y,weights) >= currenterror:\n",
    "        #    break\n",
    "        currenterror = error(X,y,weights)\n",
    "        if plotting:\n",
    "            maxepoch +=1\n",
    "            recorderrors.append(currenterror)\n",
    "    if plotting:\n",
    "        fig,ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "        ax.set_ylabel('MSE')\n",
    "        ax.set_xlabel('Iterations')\n",
    "        _=ax.plot(range(maxepoch+1),recorderrors,'b.')\n",
    "        if not showall:\n",
    "            ax.set_ylim(0, min(recorderrors)+20)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to see, what happens if we pick completely different weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([-20, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Weights: [-33.1525  84.1375] , error: 181236.87581171875\n",
      "Step: 1 Weights: [-38.35275625  37.811325  ] , error: 29139.45226704825\n",
      "Step: 2 Weights: [-40.37399313  19.28442598] , error: 4829.787718598396\n",
      "Step: 3 Weights: [-41.12445195  11.87114812] , error: 943.7261847437571\n",
      "Step: 4 Weights: [-41.36700993   8.90089337] , error: 321.85792516350455\n",
      "Step: 5 Weights: [-41.40665013   7.70688722] , error: 221.6908910783225\n",
      "Step: 6 Weights: [-41.36529852   7.22300542] , error: 204.9079733987772\n",
      "Step: 7 Weights: [-41.2916984    7.02303236] , error: 201.45539554397214\n",
      "Step: 8 Weights: [-41.2053361    6.93657533] , error: 200.1368400071467\n",
      "Step: 9 Weights: [-41.11400157   6.89551463] , error: 199.16284629247866\n",
      "Step: 10 Weights: [-41.02080879   6.87261732] , error: 198.247399071748\n",
      "Step: 11 Weights: [-40.92700237   6.85699615] , error: 197.3447702818442\n",
      "Step: 12 Weights: [-40.83307959   6.84429859] , error: 196.44763569512233\n",
      "Step: 13 Weights: [-40.73923895   6.83278455] , error: 195.55480902498613\n",
      "Step: 14 Weights: [-40.64555952   6.82175833] , error: 194.6660850489728\n",
      "Step: 15 Weights: [-40.55207261   6.81094179] , error: 193.78141541376803\n",
      "Step: 16 Weights: [-40.45879045   6.80022368] , error: 192.90077690842975\n",
      "Step: 17 Weights: [-40.36571765   6.78955951] , error: 192.0241504109137\n",
      "Step: 18 Weights: [-40.27285574   6.77893144] , error: 191.1515175228948\n",
      "Step: 19 Weights: [-40.18020505   6.76833232] , error: 190.2828600316089\n",
      "Step: 20 Weights: [-40.08776543   6.75775926] , error: 189.41815982352367\n",
      "Step: 21 Weights: [-39.99553653   6.74721107] , error: 188.55739887022457\n",
      "Step: 22 Weights: [-39.90351791   6.73668723] , error: 187.70055922584302\n",
      "Step: 23 Weights: [-39.81170912   6.7261875 ] , error: 186.8476230263317\n",
      "Step: 24 Weights: [-39.72010969   6.71571177] , error: 185.9985724890358\n",
      "Step: 25 Weights: [-39.62871913   6.70525995] , error: 185.15338991231354\n",
      "Step: 26 Weights: [-39.53753699   6.69483197] , error: 184.31205767516545\n",
      "Step: 27 Weights: [-39.44656278   6.68442778] , error: 183.4745582368668\n",
      "Step: 28 Weights: [-39.35579602   6.67404731] , error: 182.64087413660224\n",
      "Step: 29 Weights: [-39.26523626   6.66369051] , error: 181.81098799310115\n",
      "Step: 30 Weights: [-39.174883     6.65335733] , error: 180.98488250427548\n",
      "Step: 31 Weights: [-39.08473579   6.64304771] , error: 180.1625404468594\n",
      "Step: 32 Weights: [-38.99479416   6.63276161] , error: 179.34394467604983\n",
      "Step: 33 Weights: [-38.90505762   6.62249896] , error: 178.52907812514894\n",
      "Step: 34 Weights: [-38.81552573   6.61225972] , error: 177.71792380520847\n",
      "Step: 35 Weights: [-38.726198     6.60204382] , error: 176.91046480467577\n",
      "Step: 36 Weights: [-38.63707398   6.59185122] , error: 176.1066842890407\n",
      "Step: 37 Weights: [-38.5481532    6.58168187] , error: 175.30656550048516\n",
      "Step: 38 Weights: [-38.45943519   6.5715357 ] , error: 174.51009175753327\n",
      "Step: 39 Weights: [-38.3709195    6.56141267] , error: 173.717246454704\n",
      "Step: 40 Weights: [-38.28260566   6.55131273] , error: 172.92801306216452\n",
      "Step: 41 Weights: [-38.19449321   6.54123582] , error: 172.14237512538602\n",
      "Step: 42 Weights: [-38.1065817    6.53118189] , error: 171.36031626480036\n",
      "Step: 43 Weights: [-38.01887066   6.52115088] , error: 170.58182017545863\n",
      "Step: 44 Weights: [-37.93135964   6.51114275] , error: 169.8068706266913\n",
      "Step: 45 Weights: [-37.84404817   6.50115745] , error: 169.03545146176978\n",
      "Step: 46 Weights: [-37.75693582   6.49119491] , error: 168.26754659756946\n",
      "Step: 47 Weights: [-37.67002212   6.48125509] , error: 167.5031400242346\n",
      "Step: 48 Weights: [-37.58330662   6.47133794] , error: 166.7422158048446\n",
      "Step: 49 Weights: [-37.49678886   6.46144341] , error: 165.9847580750811\n",
      "Step: 50 Weights: [-37.4104684    6.45157144] , error: 165.23075104289828\n",
      "Step: 51 Weights: [-37.32434479   6.44172198] , error: 164.48017898819273\n",
      "Step: 52 Weights: [-37.23841758   6.43189498] , error: 163.73302626247602\n",
      "Step: 53 Weights: [-37.15268631   6.42209039] , error: 162.98927728854855\n",
      "Step: 54 Weights: [-37.06715055   6.41230816] , error: 162.24891656017476\n",
      "Step: 55 Weights: [-36.98180985   6.40254824] , error: 161.51192864175954\n",
      "Step: 56 Weights: [-36.89666375   6.39281057] , error: 160.77829816802674\n",
      "Step: 57 Weights: [-36.81171183   6.38309511] , error: 160.04800984369894\n",
      "Step: 58 Weights: [-36.72695363   6.37340181] , error: 159.3210484431781\n",
      "Step: 59 Weights: [-36.64238872   6.36373061] , error: 158.59739881022838\n",
      "Step: 60 Weights: [-36.55801665   6.35408146] , error: 157.87704585766025\n",
      "Step: 61 Weights: [-36.47383698   6.34445432] , error: 157.1599745670159\n",
      "Step: 62 Weights: [-36.38984927   6.33484913] , error: 156.44616998825583\n",
      "Step: 63 Weights: [-36.3060531    6.32526585] , error: 155.73561723944786\n",
      "Step: 64 Weights: [-36.22244801   6.31570442] , error: 155.0283015064557\n",
      "Step: 65 Weights: [-36.13903358   6.30616479] , error: 154.32420804263157\n",
      "Step: 66 Weights: [-36.05580937   6.29664692] , error: 153.6233221685073\n",
      "Step: 67 Weights: [-35.97277494   6.28715075] , error: 152.9256292714893\n",
      "Step: 68 Weights: [-35.88992987   6.27767624] , error: 152.23111480555346\n",
      "Step: 69 Weights: [-35.80727371   6.26822333] , error: 151.53976429094217\n",
      "Step: 70 Weights: [-35.72480605   6.25879198] , error: 150.8515633138619\n",
      "Step: 71 Weights: [-35.64252645   6.24938214] , error: 150.16649752618332\n",
      "Step: 72 Weights: [-35.56043448   6.23999376] , error: 149.4845526451418\n",
      "Step: 73 Weights: [-35.47852971   6.23062678] , error: 148.8057144530397\n",
      "Step: 74 Weights: [-35.39681173   6.22128117] , error: 148.12996879694984\n",
      "Step: 75 Weights: [-35.31528009   6.21195687] , error: 147.4573015884208\n",
      "Step: 76 Weights: [-35.23393438   6.20265383] , error: 146.78769880318276\n",
      "Step: 77 Weights: [-35.15277416   6.19337201] , error: 146.12114648085532\n",
      "Step: 78 Weights: [-35.07179903   6.18411135] , error: 145.4576307246564\n",
      "Step: 79 Weights: [-34.99100856   6.17487181] , error: 144.7971377011125\n",
      "Step: 80 Weights: [-34.91040232   6.16565334] , error: 144.13965363977053\n",
      "Step: 81 Weights: [-34.8299799    6.15645589] , error: 143.4851648329102\n",
      "Step: 82 Weights: [-34.74974087   6.14727942] , error: 142.83365763525865\n",
      "Step: 83 Weights: [-34.66968482   6.13812387] , error: 142.18511846370592\n",
      "Step: 84 Weights: [-34.58981134   6.1289892 ] , error: 141.5395337970216\n",
      "Step: 85 Weights: [-34.51011999   6.11987537] , error: 140.89689017557308\n",
      "Step: 86 Weights: [-34.43061038   6.11078231] , error: 140.25717420104476\n",
      "Step: 87 Weights: [-34.35128208   6.10170999] , error: 139.62037253615873\n",
      "Step: 88 Weights: [-34.27213469   6.09265836] , error: 138.9864719043972\n",
      "Step: 89 Weights: [-34.19316778   6.08362737] , error: 138.35545908972483\n",
      "Step: 90 Weights: [-34.11438095   6.07461698] , error: 137.72732093631384\n",
      "Step: 91 Weights: [-34.03577379   6.06562713] , error: 137.10204434826957\n",
      "Step: 92 Weights: [-33.95734588   6.05665779] , error: 136.47961628935747\n",
      "Step: 93 Weights: [-33.87909682   6.0477089 ] , error: 135.86002378273108\n",
      "Step: 94 Weights: [-33.8010262    6.03878041] , error: 135.24325391066185\n",
      "Step: 95 Weights: [-33.72313362   6.02987229] , error: 134.6292938142695\n",
      "Step: 96 Weights: [-33.64541866   6.02098448] , error: 134.01813069325397\n",
      "Step: 97 Weights: [-33.56788093   6.01211693] , error: 133.40975180562887\n",
      "Step: 98 Weights: [-33.49052001   6.00326961] , error: 132.8041444674555\n",
      "Step: 99 Weights: [-33.41333551   5.99444247] , error: 132.20129605257847\n",
      "Step: 100 Weights: [-33.33632702   5.98563545] , error: 131.60119399236245\n",
      "Step: 101 Weights: [-33.25949415   5.97684852] , error: 131.0038257754303\n",
      "Step: 102 Weights: [-33.18283648   5.96808163] , error: 130.4091789474019\n",
      "Step: 103 Weights: [-33.10635362   5.95933473] , error: 129.8172411106349\n",
      "Step: 104 Weights: [-33.03004518   5.95060777] , error: 129.22799992396602\n",
      "Step: 105 Weights: [-32.95391076   5.94190072] , error: 128.64144310245342\n",
      "Step: 106 Weights: [-32.87794995   5.93321352] , error: 128.05755841712127\n",
      "Step: 107 Weights: [-32.80216236   5.92454613] , error: 127.47633369470441\n",
      "Step: 108 Weights: [-32.7265476    5.91589851] , error: 126.89775681739444\n",
      "Step: 109 Weights: [-32.65110527   5.9072706 ] , error: 126.3218157225872\n",
      "Step: 110 Weights: [-32.57583499   5.89866238] , error: 125.74849840263157\n",
      "Step: 111 Weights: [-32.50073635   5.89007378] , error: 125.17779290457841\n",
      "Step: 112 Weights: [-32.42580896   5.88150477] , error: 124.6096873299322\n",
      "Step: 113 Weights: [-32.35105244   5.8729553 ] , error: 124.04416983440247\n",
      "Step: 114 Weights: [-32.2764664    5.86442532] , error: 123.48122862765678\n",
      "Step: 115 Weights: [-32.20205045   5.8559148 ] , error: 122.9208519730752\n",
      "Step: 116 Weights: [-32.12780419   5.84742369] , error: 122.36302818750573\n",
      "Step: 117 Weights: [-32.05372725   5.83895194] , error: 121.80774564102\n",
      "Step: 118 Weights: [-31.97981923   5.8304995 ] , error: 121.25499275667181\n",
      "Step: 119 Weights: [-31.90607976   5.82206635] , error: 120.70475801025492\n",
      "Step: 120 Weights: [-31.83250844   5.81365242] , error: 120.15702993006327\n",
      "Step: 121 Weights: [-31.75910489   5.80525768] , error: 119.61179709665156\n",
      "Step: 122 Weights: [-31.68586874   5.79688209] , error: 119.06904814259727\n",
      "Step: 123 Weights: [-31.61279959   5.78852559] , error: 118.52877175226385\n",
      "Step: 124 Weights: [-31.53989707   5.78018815] , error: 117.99095666156425\n",
      "Step: 125 Weights: [-31.4671608    5.77186972] , error: 117.4555916577268\n",
      "Step: 126 Weights: [-31.3945904    5.76357027] , error: 116.92266557906089\n",
      "Step: 127 Weights: [-31.32218549   5.75528974] , error: 116.39216731472445\n",
      "Step: 128 Weights: [-31.24994569   5.74702809] , error: 115.86408580449223\n",
      "Step: 129 Weights: [-31.17787063   5.73878528] , error: 115.33841003852561\n",
      "Step: 130 Weights: [-31.10595993   5.73056127] , error: 114.81512905714236\n",
      "Step: 131 Weights: [-31.03421322   5.72235601] , error: 114.29423195058858\n",
      "Step: 132 Weights: [-30.96263011   5.71416947] , error: 113.77570785881137\n",
      "Step: 133 Weights: [-30.89121025   5.70600159] , error: 113.25954597123203\n",
      "Step: 134 Weights: [-30.81995326   5.69785234] , error: 112.74573552652097\n",
      "Step: 135 Weights: [-30.74885876   5.68972167] , error: 112.23426581237322\n",
      "Step: 136 Weights: [-30.67792638   5.68160955] , error: 111.72512616528508\n",
      "Step: 137 Weights: [-30.60715576   5.67351592] , error: 111.21830597033184\n",
      "Step: 138 Weights: [-30.53654653   5.66544075] , error: 110.7137946609464\n",
      "Step: 139 Weights: [-30.46609832   5.657384  ] , error: 110.21158171869924\n",
      "Step: 140 Weights: [-30.39581075   5.64934562] , error: 109.71165667307875\n",
      "Step: 141 Weights: [-30.32568347   5.64132556] , error: 109.21400910127306\n",
      "Step: 142 Weights: [-30.25571612   5.6333238 ] , error: 108.71862862795292\n",
      "Step: 143 Weights: [-30.18590831   5.62534029] , error: 108.22550492505528\n",
      "Step: 144 Weights: [-30.1162597    5.61737498] , error: 107.7346277115677\n",
      "Step: 145 Weights: [-30.04676991   5.60942783] , error: 107.24598675331445\n",
      "Step: 146 Weights: [-29.97743859   5.60149881] , error: 106.7595718627428\n",
      "Step: 147 Weights: [-29.90826537   5.59358787] , error: 106.27537289871091\n",
      "Step: 148 Weights: [-29.8392499    5.58569497] , error: 105.7933797662759\n",
      "Step: 149 Weights: [-29.77039181   5.57782007] , error: 105.31358241648418\n",
      "Step: 150 Weights: [-29.70169075   5.56996313] , error: 104.83597084616105\n",
      "Step: 151 Weights: [-29.63314635   5.5621241 ] , error: 104.3605350977029\n",
      "Step: 152 Weights: [-29.56475827   5.55430295] , error: 103.88726525886908\n",
      "Step: 153 Weights: [-29.49652613   5.54649963] , error: 103.41615146257553\n",
      "Step: 154 Weights: [-29.4284496    5.53871412] , error: 102.94718388668903\n",
      "Step: 155 Weights: [-29.3605283    5.53094635] , error: 102.48035275382225\n",
      "Step: 156 Weights: [-29.2927619   5.5231963] , error: 102.01564833113002\n",
      "Step: 157 Weights: [-29.22515003   5.51546392] , error: 101.55306093010661\n",
      "Step: 158 Weights: [-29.15769234   5.50774917] , error: 101.09258090638335\n",
      "Step: 159 Weights: [-29.09038849   5.50005202] , error: 100.63419865952781\n",
      "Step: 160 Weights: [-29.02323812   5.49237242] , error: 100.17790463284354\n",
      "Step: 161 Weights: [-28.95624087   5.48471033] , error: 99.72368931317101\n",
      "Step: 162 Weights: [-28.88939641   5.47706572] , error: 99.27154323068903\n",
      "Step: 163 Weights: [-28.82270439   5.46943854] , error: 98.82145695871728\n",
      "Step: 164 Weights: [-28.75616444   5.46182875] , error: 98.3734211135202\n",
      "Step: 165 Weights: [-28.68977624   5.45423632] , error: 97.9274263541109\n",
      "Step: 166 Weights: [-28.62353943   5.44666119] , error: 97.48346338205656\n",
      "Step: 167 Weights: [-28.55745366   5.43910335] , error: 97.04152294128463\n",
      "Step: 168 Weights: [-28.4915186    5.43156274] , error: 96.60159581788972\n",
      "Step: 169 Weights: [-28.4257339    5.42403932] , error: 96.16367283994177\n",
      "Step: 170 Weights: [-28.36009922   5.41653306] , error: 95.7277448772945\n",
      "Step: 171 Weights: [-28.29461421   5.40904392] , error: 95.29380284139522\n",
      "Step: 172 Weights: [-28.22927853   5.40157186] , error: 94.86183768509538\n",
      "Step: 173 Weights: [-28.16409184   5.39411683] , error: 94.43184040246189\n",
      "Step: 174 Weights: [-28.09905381   5.38667881] , error: 94.0038020285892\n",
      "Step: 175 Weights: [-28.03416409   5.37925775] , error: 93.57771363941289\n",
      "Step: 176 Weights: [-27.96942235   5.37185361] , error: 93.15356635152298\n",
      "Step: 177 Weights: [-27.90482825   5.36446635] , error: 92.73135132197915\n",
      "Step: 178 Weights: [-27.84038144   5.35709595] , error: 92.31105974812624\n",
      "Step: 179 Weights: [-27.7760816    5.34974235] , error: 91.89268286741067\n",
      "Step: 180 Weights: [-27.7119284    5.34240551] , error: 91.47621195719796\n",
      "Step: 181 Weights: [-27.64792148   5.33508541] , error: 91.06163833459061\n",
      "Step: 182 Weights: [-27.58406054   5.32778201] , error: 90.64895335624723\n",
      "Step: 183 Weights: [-27.52034522   5.32049525] , error: 90.23814841820227\n",
      "Step: 184 Weights: [-27.45677519   5.31322512] , error: 89.82921495568672\n",
      "Step: 185 Weights: [-27.39335014   5.30597156] , error: 89.42214444294945\n",
      "Step: 186 Weights: [-27.33006972   5.29873455] , error: 89.01692839307955\n",
      "Step: 187 Weights: [-27.2669336    5.29151403] , error: 88.61355835782926\n",
      "Step: 188 Weights: [-27.20394146   5.28430999] , error: 88.21202592743803\n",
      "Step: 189 Weights: [-27.14109297   5.27712237] , error: 87.812322730457\n",
      "Step: 190 Weights: [-27.0783878    5.26995114] , error: 87.41444043357451\n",
      "Step: 191 Weights: [-27.01582562   5.26279627] , error: 87.01837074144245\n",
      "Step: 192 Weights: [-26.95340612   5.25565771] , error: 86.62410539650318\n",
      "Step: 193 Weights: [-26.89112895   5.24853543] , error: 86.23163617881758\n",
      "Step: 194 Weights: [-26.8289938    5.24142939] , error: 85.84095490589335\n",
      "Step: 195 Weights: [-26.76700035   5.23433956] , error: 85.45205343251479\n",
      "Step: 196 Weights: [-26.70514827   5.22726589] , error: 85.06492365057265\n",
      "Step: 197 Weights: [-26.64343723   5.22020836] , error: 84.6795574888953\n",
      "Step: 198 Weights: [-26.58186692   5.21316692] , error: 84.29594691308034\n",
      "Step: 199 Weights: [-26.52043702   5.20614154] , error: 83.91408392532718\n",
      "Step: 200 Weights: [-26.4591472    5.19913218] , error: 83.53396056427027\n",
      "Step: 201 Weights: [-26.39799715   5.1921388 ] , error: 83.15556890481304\n",
      "Step: 202 Weights: [-26.33698655   5.18516137] , error: 82.77890105796277\n",
      "Step: 203 Weights: [-26.27611508   5.17819985] , error: 82.4039491706661\n",
      "Step: 204 Weights: [-26.21538242   5.17125421] , error: 82.0307054256452\n",
      "Step: 205 Weights: [-26.15478825   5.1643244 ] , error: 81.65916204123498\n",
      "Step: 206 Weights: [-26.09433227   5.1574104 ] , error: 81.28931127122058\n",
      "Step: 207 Weights: [-26.03401415   5.15051217] , error: 80.92114540467624\n",
      "Step: 208 Weights: [-25.97383358   5.14362966] , error: 80.55465676580418\n",
      "Step: 209 Weights: [-25.91379024   5.13676285] , error: 80.18983771377475\n",
      "Step: 210 Weights: [-25.85388383   5.1299117 ] , error: 79.82668064256711\n",
      "Step: 211 Weights: [-25.79411403   5.12307618] , error: 79.4651779808107\n",
      "Step: 212 Weights: [-25.73448054   5.11625624] , error: 79.1053221916272\n",
      "Step: 213 Weights: [-25.67498303   5.10945185] , error: 78.74710577247357\n",
      "Step: 214 Weights: [-25.6156212    5.10266298] , error: 78.39052125498569\n",
      "Step: 215 Weights: [-25.55639474   5.0958896 ] , error: 78.03556120482244\n",
      "Step: 216 Weights: [-25.49730334   5.08913166] , error: 77.68221822151078\n",
      "Step: 217 Weights: [-25.43834669   5.08238912] , error: 77.33048493829158\n",
      "Step: 218 Weights: [-25.37952449   5.07566197] , error: 76.9803540219659\n",
      "Step: 219 Weights: [-25.32083643   5.06895016] , error: 76.6318181727422\n",
      "Step: 220 Weights: [-25.2622822    5.06225365] , error: 76.28487012408398\n",
      "Step: 221 Weights: [-25.2038615    5.05557241] , error: 75.93950264255851\n",
      "Step: 222 Weights: [-25.14557402   5.04890641] , error: 75.59570852768584\n",
      "Step: 223 Weights: [-25.08741946   5.04225561] , error: 75.25348061178876\n",
      "Step: 224 Weights: [-25.02939752   5.03561997] , error: 74.91281175984338\n",
      "Step: 225 Weights: [-24.97150789   5.02899947] , error: 74.57369486933032\n",
      "Step: 226 Weights: [-24.91375028   5.02239407] , error: 74.2361228700866\n",
      "Step: 227 Weights: [-24.85612438   5.01580373] , error: 73.90008872415837\n",
      "Step: 228 Weights: [-24.79862988   5.00922841] , error: 73.56558542565412\n",
      "Step: 229 Weights: [-24.7412665   5.0026681] , error: 73.23260600059848\n",
      "Step: 230 Weights: [-24.68403393   4.99612274] , error: 72.90114350678702\n",
      "Step: 231 Weights: [-24.62693188   4.98959231] , error: 72.57119103364144\n",
      "Step: 232 Weights: [-24.56996004   4.98307677] , error: 72.24274170206542\n",
      "Step: 233 Weights: [-24.51311812   4.97657609] , error: 71.91578866430132\n",
      "Step: 234 Weights: [-24.45640583   4.97009023] , error: 71.59032510378726\n",
      "Step: 235 Weights: [-24.39982286   4.96361916] , error: 71.26634423501521\n",
      "Step: 236 Weights: [-24.34336892   4.95716285] , error: 70.94383930338938\n",
      "Step: 237 Weights: [-24.28704373   4.95072126] , error: 70.62280358508536\n",
      "Step: 238 Weights: [-24.23084698   4.94429437] , error: 70.3032303869101\n",
      "Step: 239 Weights: [-24.17477838   4.93788213] , error: 69.98511304616213\n",
      "Step: 240 Weights: [-24.11883764   4.93148451] , error: 69.66844493049295\n",
      "Step: 241 Weights: [-24.06302446   4.92510148] , error: 69.35321943776842\n",
      "Step: 242 Weights: [-24.00733857   4.918733  ] , error: 69.03942999593143\n",
      "Step: 243 Weights: [-23.95177966   4.91237905] , error: 68.72707006286464\n",
      "Step: 244 Weights: [-23.89634745   4.90603959] , error: 68.41613312625428\n",
      "Step: 245 Weights: [-23.84104165   4.89971459] , error: 68.10661270345412\n",
      "Step: 246 Weights: [-23.78586197   4.89340401] , error: 67.79850234135058\n",
      "Step: 247 Weights: [-23.73080812   4.88710781] , error: 67.4917956162281\n",
      "Step: 248 Weights: [-23.67587981   4.88082598] , error: 67.18648613363513\n",
      "Step: 249 Weights: [-23.62107677   4.87455848] , error: 66.88256752825095\n",
      "Step: 250 Weights: [-23.5663987    4.86830526] , error: 66.58003346375273\n",
      "Step: 251 Weights: [-23.51184532   4.86206631] , error: 66.2788776326838\n",
      "Step: 252 Weights: [-23.45741634   4.85584158] , error: 65.97909375632182\n",
      "Step: 253 Weights: [-23.40311148   4.84963105] , error: 65.68067558454794\n",
      "Step: 254 Weights: [-23.34893046   4.84343468] , error: 65.38361689571671\n",
      "Step: 255 Weights: [-23.294873     4.83725244] , error: 65.087911496526\n",
      "Step: 256 Weights: [-23.24093881   4.8310843 ] , error: 64.79355322188822\n",
      "Step: 257 Weights: [-23.18712761   4.82493022] , error: 64.50053593480153\n",
      "Step: 258 Weights: [-23.13343912   4.81879018] , error: 64.20885352622219\n",
      "Step: 259 Weights: [-23.07987307   4.81266414] , error: 63.9184999149367\n",
      "Step: 260 Weights: [-23.02642917   4.80655207] , error: 63.62946904743564\n",
      "Step: 261 Weights: [-22.97310714   4.80045394] , error: 63.341754897786956\n",
      "Step: 262 Weights: [-22.91990671   4.79436971] , error: 63.05535146751056\n",
      "Step: 263 Weights: [-22.8668276    4.78829936] , error: 62.770252785453266\n",
      "Step: 264 Weights: [-22.81386953   4.78224285] , error: 62.48645290766417\n",
      "Step: 265 Weights: [-22.76103223   4.77620016] , error: 62.20394591727087\n",
      "Step: 266 Weights: [-22.70831541   4.77017124] , error: 61.92272592435601\n",
      "Step: 267 Weights: [-22.65571882   4.76415607] , error: 61.642787065834625\n",
      "Step: 268 Weights: [-22.60324217   4.75815462] , error: 61.364123505331634\n",
      "Step: 269 Weights: [-22.55088518   4.75216685] , error: 61.08672943306049\n",
      "Step: 270 Weights: [-22.49864759   4.74619274] , error: 60.81059906570175\n",
      "Step: 271 Weights: [-22.44652913   4.74023226] , error: 60.53572664628274\n",
      "Step: 272 Weights: [-22.39452951   4.73428536] , error: 60.262106444057345\n",
      "Step: 273 Weights: [-22.34264848   4.72835203] , error: 59.9897327543867\n",
      "Step: 274 Weights: [-22.29088576   4.72243222] , error: 59.71859989862007\n",
      "Step: 275 Weights: [-22.23924107   4.71652592] , error: 59.44870222397662\n",
      "Step: 276 Weights: [-22.18771416   4.71063308] , error: 59.180034103427495\n",
      "Step: 277 Weights: [-22.13630475   4.70475369] , error: 58.91258993557848\n",
      "Step: 278 Weights: [-22.08501258   4.6988877 ] , error: 58.646364144553246\n",
      "Step: 279 Weights: [-22.03383737   4.69303509] , error: 58.3813511798771\n",
      "Step: 280 Weights: [-21.98277887   4.68719582] , error: 58.11754551636129\n",
      "Step: 281 Weights: [-21.9318368    4.68136987] , error: 57.854941653987744\n",
      "Step: 282 Weights: [-21.8810109    4.67555721] , error: 57.5935341177944\n",
      "Step: 283 Weights: [-21.8303009   4.6697578] , error: 57.33331745776127\n",
      "Step: 284 Weights: [-21.77970654   4.66397161] , error: 57.07428624869642\n",
      "Step: 285 Weights: [-21.72922756   4.65819862] , error: 56.816435090123235\n",
      "Step: 286 Weights: [-21.67886369   4.6524388 ] , error: 56.559758606167605\n",
      "Step: 287 Weights: [-21.62861467   4.64669211] , error: 56.304251445446006\n",
      "Step: 288 Weights: [-21.57848024   4.64095853] , error: 56.0499082809537\n",
      "Step: 289 Weights: [-21.52846014   4.63523802] , error: 55.79672380995402\n",
      "Step: 290 Weights: [-21.47855411   4.62953055] , error: 55.544692753867345\n",
      "Step: 291 Weights: [-21.42876188   4.6238361 ] , error: 55.29380985816151\n",
      "Step: 292 Weights: [-21.3790832    4.61815464] , error: 55.044069892242035\n",
      "Step: 293 Weights: [-21.3295178    4.61248613] , error: 54.79546764934299\n",
      "Step: 294 Weights: [-21.28006544   4.60683055] , error: 54.547997946418604\n",
      "Step: 295 Weights: [-21.23072584   4.60118787] , error: 54.30165562403527\n",
      "Step: 296 Weights: [-21.18149877   4.59555805] , error: 54.05643554626366\n",
      "Step: 297 Weights: [-21.13238395   4.58994107] , error: 53.81233260057192\n",
      "Step: 298 Weights: [-21.08338113   4.5843369 ] , error: 53.569341697719054\n",
      "Step: 299 Weights: [-21.03449006   4.57874551] , error: 53.327457771648675\n",
      "Step: 300 Weights: [-20.98571048   4.57316688] , error: 53.086675779383555\n",
      "Step: 301 Weights: [-20.93704214   4.56760096] , error: 52.84699070092037\n",
      "Step: 302 Weights: [-20.88848478   4.56204774] , error: 52.608397539125086\n",
      "Step: 303 Weights: [-20.84003816   4.55650718] , error: 52.37089131962876\n",
      "Step: 304 Weights: [-20.79170201   4.55097925] , error: 52.134467090723874\n",
      "Step: 305 Weights: [-20.74347609   4.54546393] , error: 51.89911992326099\n",
      "Step: 306 Weights: [-20.69536015   4.53996119] , error: 51.66484491054604\n",
      "Step: 307 Weights: [-20.64735392   4.53447099] , error: 51.43163716823817\n",
      "Step: 308 Weights: [-20.59945718   4.52899332] , error: 51.1994918342477\n",
      "Step: 309 Weights: [-20.55166965   4.52352814] , error: 50.96840406863477\n",
      "Step: 310 Weights: [-20.50399111   4.51807542] , error: 50.73836905350859\n",
      "Step: 311 Weights: [-20.45642129   4.51263513] , error: 50.50938199292693\n",
      "Step: 312 Weights: [-20.40895995   4.50720725] , error: 50.281438112795925\n",
      "Step: 313 Weights: [-20.36160684   4.50179175] , error: 50.054532660770946\n",
      "Step: 314 Weights: [-20.31436171   4.4963886 ] , error: 49.82866090615714\n",
      "Step: 315 Weights: [-20.26722432   4.49099777] , error: 49.60381813981098\n",
      "Step: 316 Weights: [-20.22019443   4.48561923] , error: 49.37999967404208\n",
      "Step: 317 Weights: [-20.17327178   4.48025296] , error: 49.157200842515415\n",
      "Step: 318 Weights: [-20.12645614   4.47489893] , error: 48.935417000154104\n",
      "Step: 319 Weights: [-20.07974726   4.4695571 ] , error: 48.714643523042454\n",
      "Step: 320 Weights: [-20.03314489   4.46422746] , error: 48.49487580832968\n",
      "Step: 321 Weights: [-19.98664879   4.45890997] , error: 48.27610927413386\n",
      "Step: 322 Weights: [-19.94025873   4.45360461] , error: 48.05833935944643\n",
      "Step: 323 Weights: [-19.89397445   4.44831134] , error: 47.8415615240371\n",
      "Step: 324 Weights: [-19.84779572   4.44303015] , error: 47.62577124835922\n",
      "Step: 325 Weights: [-19.8017223   4.437761 ] , error: 47.410964033455485\n",
      "Step: 326 Weights: [-19.75575395   4.43250386] , error: 47.197135400864155\n",
      "Step: 327 Weights: [-19.70989042   4.42725871] , error: 46.98428089252582\n",
      "Step: 328 Weights: [-19.66413148   4.42202553] , error: 46.77239607069016\n",
      "Step: 329 Weights: [-19.61847688   4.41680428] , error: 46.5614765178238\n",
      "Step: 330 Weights: [-19.5729264    4.41159493] , error: 46.351517836517885\n",
      "Step: 331 Weights: [-19.5274798    4.40639747] , error: 46.14251564939657\n",
      "Step: 332 Weights: [-19.48213683   4.40121185] , error: 45.93446559902575\n",
      "Step: 333 Weights: [-19.43689726   4.39603807] , error: 45.72736334782212\n",
      "Step: 334 Weights: [-19.39176086   4.39087608] , error: 45.52120457796283\n",
      "Step: 335 Weights: [-19.34672738   4.38572586] , error: 45.315984991295466\n",
      "Step: 336 Weights: [-19.30179661   4.38058739] , error: 45.11170030924837\n",
      "Step: 337 Weights: [-19.25696829   4.37546063] , error: 44.908346272741454\n",
      "Step: 338 Weights: [-19.2122422    4.37034557] , error: 44.70591864209746\n",
      "Step: 339 Weights: [-19.1676181    4.36524217] , error: 44.50441319695356\n",
      "Step: 340 Weights: [-19.12309577   4.3601504 ] , error: 44.30382573617326\n",
      "Step: 341 Weights: [-19.07867496   4.35507025] , error: 44.104152077759025\n",
      "Step: 342 Weights: [-19.03435545   4.35000169] , error: 43.90538805876479\n",
      "Step: 343 Weights: [-18.99013701   4.34494468] , error: 43.707529535209446\n",
      "Step: 344 Weights: [-18.94601941   4.33989921] , error: 43.51057238199033\n",
      "Step: 345 Weights: [-18.90200241   4.33486524] , error: 43.314512492797135\n",
      "Step: 346 Weights: [-18.85808579   4.32984275] , error: 43.11934578002647\n",
      "Step: 347 Weights: [-18.81426932   4.32483171] , error: 42.92506817469654\n",
      "Step: 348 Weights: [-18.77055277   4.3198321 ] , error: 42.73167562636232\n",
      "Step: 349 Weights: [-18.72693591   4.31484389] , error: 42.539164103031105\n",
      "Step: 350 Weights: [-18.68341851   4.30986706] , error: 42.347529591078484\n",
      "Step: 351 Weights: [-18.64000035   4.30490158] , error: 42.15676809516461\n",
      "Step: 352 Weights: [-18.5966812    4.29994742] , error: 41.96687563815089\n",
      "Step: 353 Weights: [-18.55346084   4.29500455] , error: 41.77784826101723\n",
      "Step: 354 Weights: [-18.51033904   4.29007296] , error: 41.58968202277927\n",
      "Step: 355 Weights: [-18.46731558   4.28515262] , error: 41.402373000406335\n",
      "Step: 356 Weights: [-18.42439022   4.28024349] , error: 41.215917288739604\n",
      "Step: 357 Weights: [-18.38156275   4.27534556] , error: 41.030311000410805\n",
      "Step: 358 Weights: [-18.33883295   4.2704588 ] , error: 40.84555026576099\n",
      "Step: 359 Weights: [-18.29620059   4.26558319] , error: 40.661631232759966\n",
      "Step: 360 Weights: [-18.25366545   4.26071869] , error: 40.47855006692603\n",
      "Step: 361 Weights: [-18.21122731   4.25586528] , error: 40.29630295124586\n",
      "Step: 362 Weights: [-18.16888594   4.25102295] , error: 40.11488608609511\n",
      "Step: 363 Weights: [-18.12664113   4.24619165] , error: 39.9342956891591\n",
      "Step: 364 Weights: [-18.08449266   4.24137137] , error: 39.75452799535398\n",
      "Step: 365 Weights: [-18.0424403    4.23656209] , error: 39.57557925674821\n",
      "Step: 366 Weights: [-18.00048384   4.23176377] , error: 39.397445742484464\n",
      "Step: 367 Weights: [-17.95862305   4.2269764 ] , error: 39.22012373870183\n",
      "Step: 368 Weights: [-17.91685773   4.22219994] , error: 39.04360954845834\n",
      "Step: 369 Weights: [-17.87518765   4.21743437] , error: 38.86789949165395\n",
      "Step: 370 Weights: [-17.83361259   4.21267967] , error: 38.69298990495379\n",
      "Step: 371 Weights: [-17.79213234   4.20793582] , error: 38.518877141711826\n",
      "Step: 372 Weights: [-17.75074669   4.20320278] , error: 38.34555757189476\n",
      "Step: 373 Weights: [-17.70945541   4.19848053] , error: 38.17302758200634\n",
      "Step: 374 Weights: [-17.66825829   4.19376906] , error: 38.00128357501212\n",
      "Step: 375 Weights: [-17.62715512   4.18906833] , error: 37.83032197026445\n",
      "Step: 376 Weights: [-17.58614568   4.18437831] , error: 37.660139203427725\n",
      "Step: 377 Weights: [-17.54522976   4.179699  ] , error: 37.49073172640416\n",
      "Step: 378 Weights: [-17.50440714   4.17503035] , error: 37.322096007259795\n",
      "Step: 379 Weights: [-17.46367762   4.17037235] , error: 37.154228530150824\n",
      "Step: 380 Weights: [-17.42304098   4.16572497] , error: 36.98712579525038\n",
      "Step: 381 Weights: [-17.382497     4.16108819] , error: 36.82078431867551\n",
      "Step: 382 Weights: [-17.34204549   4.15646199] , error: 36.65520063241445\n",
      "Step: 383 Weights: [-17.30168622   4.15184633] , error: 36.490371284254564\n",
      "Step: 384 Weights: [-17.26141898   4.1472412 ] , error: 36.326292837710106\n",
      "Step: 385 Weights: [-17.22124357   4.14264657] , error: 36.162961871950735\n",
      "Step: 386 Weights: [-17.18115978   4.13806242] , error: 36.00037498173017\n",
      "Step: 387 Weights: [-17.14116739   4.13348872] , error: 35.83852877731513\n",
      "Step: 388 Weights: [-17.10126621   4.12892545] , error: 35.67741988441473\n",
      "Step: 389 Weights: [-17.06145602   4.12437259] , error: 35.51704494411007\n",
      "Step: 390 Weights: [-17.0217366    4.11983011] , error: 35.357400612784325\n",
      "Step: 391 Weights: [-16.98210777   4.11529799] , error: 35.19848356205289\n",
      "Step: 392 Weights: [-16.94256931   4.11077621] , error: 35.04029047869405\n",
      "Step: 393 Weights: [-16.90312101   4.10626473] , error: 34.88281806457992\n",
      "Step: 394 Weights: [-16.86376267   4.10176355] , error: 34.726063036607684\n",
      "Step: 395 Weights: [-16.82449408   4.09727263] , error: 34.57002212663111\n",
      "Step: 396 Weights: [-16.78531504   4.09279195] , error: 34.41469208139242\n",
      "Step: 397 Weights: [-16.74622535   4.08832148] , error: 34.260069662454484\n",
      "Step: 398 Weights: [-16.70722479   4.08386122] , error: 34.10615164613332\n",
      "Step: 399 Weights: [-16.66831318   4.07941112] , error: 33.952934823430844\n",
      "Step: 400 Weights: [-16.6294903    4.07497117] , error: 33.80041599996795\n",
      "Step: 401 Weights: [-16.59075595   4.07054135] , error: 33.648591995918004\n",
      "Step: 402 Weights: [-16.55210993   4.06612163] , error: 33.49745964594045\n",
      "Step: 403 Weights: [-16.51355204   4.06171198] , error: 33.34701579911486\n",
      "Step: 404 Weights: [-16.47508208   4.0573124 ] , error: 33.1972573188752\n",
      "Step: 405 Weights: [-16.43669984   4.05292284] , error: 33.04818108294457\n",
      "Step: 406 Weights: [-16.39840514   4.0485433 ] , error: 32.8997839832699\n",
      "Step: 407 Weights: [-16.36019776   4.04417374] , error: 32.75206292595732\n",
      "Step: 408 Weights: [-16.32207751   4.03981415] , error: 32.60501483120758\n",
      "Step: 409 Weights: [-16.28404419   4.0354645 ] , error: 32.4586366332519\n",
      "Step: 410 Weights: [-16.2460976    4.03112477] , error: 32.31292528028794\n",
      "Step: 411 Weights: [-16.20823755   4.02679493] , error: 32.16787773441628\n",
      "Step: 412 Weights: [-16.17046383   4.02247497] , error: 32.02349097157706\n",
      "Step: 413 Weights: [-16.13277625   4.01816486] , error: 31.87976198148689\n",
      "Step: 414 Weights: [-16.09517462   4.01386458] , error: 31.736687767576132\n",
      "Step: 415 Weights: [-16.05765873   4.0095741 ] , error: 31.59426534692643\n",
      "Step: 416 Weights: [-16.02022839   4.00529341] , error: 31.452491750208466\n",
      "Step: 417 Weights: [-15.98288341   4.00102248] , error: 31.31136402162013\n",
      "Step: 418 Weights: [-15.9456236    3.99676129] , error: 31.170879218824815\n",
      "Step: 419 Weights: [-15.90844875   3.99250982] , error: 31.031034412890158\n",
      "Step: 420 Weights: [-15.87135867   3.98826804] , error: 30.891826688226878\n",
      "Step: 421 Weights: [-15.83435318   3.98403594] , error: 30.753253142528074\n",
      "Step: 422 Weights: [-15.79743207   3.97981348] , error: 30.61531088670867\n",
      "Step: 423 Weights: [-15.76059516   3.97560066] , error: 30.477997044845218\n",
      "Step: 424 Weights: [-15.72384226   3.97139744] , error: 30.34130875411587\n",
      "Step: 425 Weights: [-15.68717316   3.96720381] , error: 30.205243164740796\n",
      "Step: 426 Weights: [-15.65058769   3.96301974] , error: 30.069797439922663\n",
      "Step: 427 Weights: [-15.61408564   3.95884521] , error: 29.934968755787526\n",
      "Step: 428 Weights: [-15.57766684   3.95468021] , error: 29.800754301326027\n",
      "Step: 429 Weights: [-15.54133108   3.9505247 ] , error: 29.667151278334696\n",
      "Step: 430 Weights: [-15.50507819   3.94637866] , error: 29.534156901357626\n",
      "Step: 431 Weights: [-15.46890797   3.94224208] , error: 29.40176839762846\n",
      "Step: 432 Weights: [-15.43282023   3.93811494] , error: 29.269983007012467\n",
      "Step: 433 Weights: [-15.39681478   3.9339972 ] , error: 29.138797981949168\n",
      "Step: 434 Weights: [-15.36089145   3.92988886] , error: 29.00821058739488\n",
      "Step: 435 Weights: [-15.32505003   3.92578988] , error: 28.878218100765793\n",
      "Step: 436 Weights: [-15.28929035   3.92170025] , error: 28.748817811881185\n",
      "Step: 437 Weights: [-15.25361221   3.91761995] , error: 28.62000702290692\n",
      "Step: 438 Weights: [-15.21801544   3.91354895] , error: 28.491783048299204\n",
      "Step: 439 Weights: [-15.18249984   3.90948724] , error: 28.36414321474855\n",
      "Step: 440 Weights: [-15.14706523   3.90543479] , error: 28.23708486112413\n",
      "Step: 441 Weights: [-15.11171142   3.90139158] , error: 28.11060533841821\n",
      "Step: 442 Weights: [-15.07643824   3.89735759] , error: 27.984702009690974\n",
      "Step: 443 Weights: [-15.0412455   3.8933328] , error: 27.859372250015518\n",
      "Step: 444 Weights: [-15.006133     3.88931719] , error: 27.73461344642317\n",
      "Step: 445 Weights: [-14.97110058   3.88531073] , error: 27.610422997848897\n",
      "Step: 446 Weights: [-14.93614805   3.88131341] , error: 27.48679831507727\n",
      "Step: 447 Weights: [-14.90127523   3.87732521] , error: 27.363736820688263\n",
      "Step: 448 Weights: [-14.86648193   3.8733461 ] , error: 27.241235949003677\n",
      "Step: 449 Weights: [-14.83176797   3.86937607] , error: 27.119293146033627\n",
      "Step: 450 Weights: [-14.79713317   3.86541508] , error: 26.997905869423178\n",
      "Step: 451 Weights: [-14.76257736   3.86146314] , error: 26.877071588399485\n",
      "Step: 452 Weights: [-14.72810035   3.8575202 ] , error: 26.756787783718966\n",
      "Step: 453 Weights: [-14.69370196   3.85358626] , error: 26.637051947614754\n",
      "Step: 454 Weights: [-14.65938201   3.84966128] , error: 26.517861583744477\n",
      "Step: 455 Weights: [-14.62514033   3.84574526] , error: 26.399214207138144\n",
      "Step: 456 Weights: [-14.59097673   3.84183816] , error: 26.281107344146378\n",
      "Step: 457 Weights: [-14.55689104   3.83793998] , error: 26.163538532388827\n",
      "Step: 458 Weights: [-14.52288308   3.83405069] , error: 26.04650532070288\n",
      "Step: 459 Weights: [-14.48895267   3.83017026] , error: 25.930005269092465\n",
      "Step: 460 Weights: [-14.45509963   3.82629869] , error: 25.814035948677255\n",
      "Step: 461 Weights: [-14.4213238    3.82243594] , error: 25.69859494164198\n",
      "Step: 462 Weights: [-14.38762499   3.818582  ] , error: 25.583679841186083\n",
      "Step: 463 Weights: [-14.35400302   3.81473685] , error: 25.469288251473486\n",
      "Step: 464 Weights: [-14.32045773   3.81090047] , error: 25.35541778758263\n",
      "Step: 465 Weights: [-14.28698893   3.80707284] , error: 25.24206607545679\n",
      "Step: 466 Weights: [-14.25359646   3.80325393] , error: 25.12923075185461\n",
      "Step: 467 Weights: [-14.22028014   3.79944374] , error: 25.01690946430071\n",
      "Step: 468 Weights: [-14.18703979   3.79564223] , error: 24.90509987103678\n",
      "Step: 469 Weights: [-14.15387524   3.7918494 ] , error: 24.793799640972672\n",
      "Step: 470 Weights: [-14.12078632   3.78806521] , error: 24.683006453637837\n",
      "Step: 471 Weights: [-14.08777286   3.78428965] , error: 24.572717999132905\n",
      "Step: 472 Weights: [-14.05483468   3.7805227 ] , error: 24.4629319780816\n",
      "Step: 473 Weights: [-14.02197162   3.77676434] , error: 24.3536461015827\n",
      "Step: 474 Weights: [-13.9891835    3.77301455] , error: 24.244858091162406\n",
      "Step: 475 Weights: [-13.95647014   3.76927332] , error: 24.136565678726793\n",
      "Step: 476 Weights: [-13.92383139   3.76554061] , error: 24.028766606514544\n",
      "Step: 477 Weights: [-13.89126707   3.76181642] , error: 23.92145862704986\n",
      "Step: 478 Weights: [-13.85877701   3.75810072] , error: 23.814639503095613\n",
      "Step: 479 Weights: [-13.82636103   3.75439349] , error: 23.708307007606695\n",
      "Step: 480 Weights: [-13.79401898   3.75069472] , error: 23.602458923683628\n",
      "Step: 481 Weights: [-13.76175069   3.74700438] , error: 23.49709304452624\n",
      "Step: 482 Weights: [-13.72955598   3.74332246] , error: 23.392207173387767\n",
      "Step: 483 Weights: [-13.69743468   3.73964893] , error: 23.287799123529048\n",
      "Step: 484 Weights: [-13.66538664   3.73598378] , error: 23.183866718172823\n",
      "Step: 485 Weights: [-13.63341168   3.73232699] , error: 23.08040779045847\n",
      "Step: 486 Weights: [-13.60150963   3.72867854] , error: 22.977420183396774\n",
      "Step: 487 Weights: [-13.56968034   3.7250384 ] , error: 22.87490174982498\n",
      "Step: 488 Weights: [-13.53792363   3.72140657] , error: 22.772850352361996\n",
      "Step: 489 Weights: [-13.50623933   3.71778302] , error: 22.67126386336384\n",
      "Step: 490 Weights: [-13.47462729   3.71416774] , error: 22.570140164879316\n",
      "Step: 491 Weights: [-13.44308734   3.7105607 ] , error: 22.46947714860581\n",
      "Step: 492 Weights: [-13.41161932   3.70696188] , error: 22.36927271584535\n",
      "Step: 493 Weights: [-13.38022305   3.70337127] , error: 22.269524777460898\n",
      "Step: 494 Weights: [-13.34889838   3.69978885] , error: 22.17023125383272\n",
      "Step: 495 Weights: [-13.31764514   3.6962146 ] , error: 22.071390074815053\n",
      "Step: 496 Weights: [-13.28646318   3.6926485 ] , error: 21.97299917969297\n",
      "Step: 497 Weights: [-13.25535232   3.68909053] , error: 21.875056517139402\n",
      "Step: 498 Weights: [-13.22431241   3.68554067] , error: 21.77756004517235\n",
      "Step: 499 Weights: [-13.19334328   3.68199891] , error: 21.680507731112364\n",
      "Step: 500 Weights: [-13.16244477   3.67846523] , error: 21.58389755154009\n",
      "Step: 501 Weights: [-13.13161673   3.6749396 ] , error: 21.48772749225416\n",
      "Step: 502 Weights: [-13.10085898   3.67142202] , error: 21.391995548229126\n",
      "Step: 503 Weights: [-13.07017138   3.66791245] , error: 21.296699723573745\n",
      "Step: 504 Weights: [-13.03955376   3.66441089] , error: 21.20183803148928\n",
      "Step: 505 Weights: [-13.00900595   3.66091732] , error: 21.107408494228117\n",
      "Step: 506 Weights: [-12.97852781   3.65743171] , error: 21.013409143052527\n",
      "Step: 507 Weights: [-12.94811918   3.65395405] , error: 20.919838018193666\n",
      "Step: 508 Weights: [-12.91777988   3.65048432] , error: 20.826693168810607\n",
      "Step: 509 Weights: [-12.88750977   3.6470225 ] , error: 20.733972652949774\n",
      "Step: 510 Weights: [-12.8573087    3.64356858] , error: 20.64167453750443\n",
      "Step: 511 Weights: [-12.82717649   3.64012253] , error: 20.5497968981743\n",
      "Step: 512 Weights: [-12.79711299   3.63668435] , error: 20.45833781942555\n",
      "Step: 513 Weights: [-12.76711806   3.633254  ] , error: 20.36729539445082\n",
      "Step: 514 Weights: [-12.73719152   3.62983147] , error: 20.276667725129442\n",
      "Step: 515 Weights: [-12.70733323   3.62641675] , error: 20.186452921987897\n",
      "Step: 516 Weights: [-12.67754303   3.62300982] , error: 20.09664910416037\n",
      "Step: 517 Weights: [-12.64782076   3.61961066] , error: 20.00725439934963\n",
      "Step: 518 Weights: [-12.61816627   3.61621924] , error: 19.918266943787916\n",
      "Step: 519 Weights: [-12.58857941   3.61283557] , error: 19.829684882198077\n",
      "Step: 520 Weights: [-12.55906002   3.6094596 ] , error: 19.741506367754972\n",
      "Step: 521 Weights: [-12.52960794   3.60609134] , error: 19.653729562046887\n",
      "Step: 522 Weights: [-12.50022303   3.60273076] , error: 19.566352635037227\n",
      "Step: 523 Weights: [-12.47090512   3.59937784] , error: 19.479373765026367\n",
      "Step: 524 Weights: [-12.44165407   3.59603256] , error: 19.392791138613685\n",
      "Step: 525 Weights: [-12.41246973   3.59269492] , error: 19.30660295065975\n",
      "Step: 526 Weights: [-12.38335194   3.58936489] , error: 19.22080740424863\n",
      "Step: 527 Weights: [-12.35430055   3.58604245] , error: 19.13540271065056\n",
      "Step: 528 Weights: [-12.32531541   3.58272758] , error: 19.050387089284484\n",
      "Step: 529 Weights: [-12.29639637   3.57942028] , error: 18.965758767681063\n",
      "Step: 530 Weights: [-12.26754327   3.57612052] , error: 18.881515981445666\n",
      "Step: 531 Weights: [-12.23875598   3.57282828] , error: 18.797656974221596\n",
      "Step: 532 Weights: [-12.21003433   3.56954355] , error: 18.71417999765346\n",
      "Step: 533 Weights: [-12.18137817   3.56626632] , error: 18.631083311350714\n",
      "Step: 534 Weights: [-12.15278737   3.56299655] , error: 18.548365182851402\n",
      "Step: 535 Weights: [-12.12426176   3.55973424] , error: 18.46602388758606\n",
      "Step: 536 Weights: [-12.0958012    3.55647937] , error: 18.384057708841656\n",
      "Step: 537 Weights: [-12.06740555   3.55323193] , error: 18.302464937725915\n",
      "Step: 538 Weights: [-12.03907465   3.54999188] , error: 18.221243873131623\n",
      "Step: 539 Weights: [-12.01080835   3.54675923] , error: 18.140392821701216\n",
      "Step: 540 Weights: [-11.98260652   3.54353395] , error: 18.059910097791395\n",
      "Step: 541 Weights: [-11.954469     3.54031603] , error: 17.97979402343808\n",
      "Step: 542 Weights: [-11.92639564   3.53710544] , error: 17.900042928321312\n",
      "Step: 543 Weights: [-11.8983863    3.53390217] , error: 17.820655149730555\n",
      "Step: 544 Weights: [-11.87044083   3.53070621] , error: 17.74162903252993\n",
      "Step: 545 Weights: [-11.84255909   3.52751754] , error: 17.662962929123747\n",
      "Step: 546 Weights: [-11.81474094   3.52433613] , error: 17.584655199422173\n",
      "Step: 547 Weights: [-11.78698622   3.52116199] , error: 17.506704210806994\n",
      "Step: 548 Weights: [-11.75929479   3.51799508] , error: 17.429108338097652\n",
      "Step: 549 Weights: [-11.73166651   3.51483539] , error: 17.351865963517234\n",
      "Step: 550 Weights: [-11.70410123   3.51168291] , error: 17.274975476658884\n",
      "Step: 551 Weights: [-11.67659882   3.50853762] , error: 17.198435274452137\n",
      "Step: 552 Weights: [-11.64915912   3.5053995 ] , error: 17.12224376112953\n",
      "Step: 553 Weights: [-11.62178199   3.50226854] , error: 17.046399348193308\n",
      "Step: 554 Weights: [-11.5944673    3.49914471] , error: 16.97090045438238\n",
      "Step: 555 Weights: [-11.56721489   3.49602801] , error: 16.895745505639233\n",
      "Step: 556 Weights: [-11.54002464   3.49291842] , error: 16.820932935077224\n",
      "Step: 557 Weights: [-11.51289638   3.48981592] , error: 16.746461182947833\n",
      "Step: 558 Weights: [-11.48582999   3.48672049] , error: 16.67232869660819\n",
      "Step: 559 Weights: [-11.45882533   3.48363213] , error: 16.598533930488713\n",
      "Step: 560 Weights: [-11.43188224   3.4805508 ] , error: 16.52507534606085\n",
      "Step: 561 Weights: [-11.4050006   3.4774765] , error: 16.451951411804995\n",
      "Step: 562 Weights: [-11.37818026   3.47440922] , error: 16.37916060317859\n",
      "Step: 563 Weights: [-11.35142108   3.47134892] , error: 16.306701402584366\n",
      "Step: 564 Weights: [-11.32472292   3.46829561] , error: 16.23457229933862\n",
      "Step: 565 Weights: [-11.29808564   3.46524926] , error: 16.162771789639798\n",
      "Step: 566 Weights: [-11.27150911   3.46220985] , error: 16.091298376537072\n",
      "Step: 567 Weights: [-11.24499318   3.45917738] , error: 16.020150569899226\n",
      "Step: 568 Weights: [-11.21853773   3.45615182] , error: 15.94932688638346\n",
      "Step: 569 Weights: [-11.1921426    3.45313316] , error: 15.878825849404613\n",
      "Step: 570 Weights: [-11.16580766   3.45012139] , error: 15.808645989104232\n",
      "Step: 571 Weights: [-11.13953278   3.44711648] , error: 15.738785842320038\n",
      "Step: 572 Weights: [-11.11331781   3.44411843] , error: 15.66924395255537\n",
      "Step: 573 Weights: [-11.08716263   3.44112721] , error: 15.600018869948826\n",
      "Step: 574 Weights: [-11.06106709   3.43814282] , error: 15.531109151244026\n",
      "Step: 575 Weights: [-11.03503106   3.43516523] , error: 15.462513359759537\n",
      "Step: 576 Weights: [-11.0090544    3.43219443] , error: 15.394230065358942\n",
      "Step: 577 Weights: [-10.98313698   3.4292304 ] , error: 15.326257844420956\n",
      "Step: 578 Weights: [-10.95727866   3.42627313] , error: 15.258595279809821\n",
      "Step: 579 Weights: [-10.93147931   3.42332261] , error: 15.191240960845692\n",
      "Step: 580 Weights: [-10.90573879   3.42037882] , error: 15.124193483275304\n",
      "Step: 581 Weights: [-10.88005698   3.41744174] , error: 15.05745144924261\n",
      "Step: 582 Weights: [-10.85443372   3.41451135] , error: 14.991013467259705\n",
      "Step: 583 Weights: [-10.8288689    3.41158765] , error: 14.92487815217778\n",
      "Step: 584 Weights: [-10.80336238   3.40867062] , error: 14.85904412515826\n",
      "Step: 585 Weights: [-10.77791402   3.40576024] , error: 14.793510013644001\n",
      "Step: 586 Weights: [-10.7525237    3.40285649] , error: 14.728274451330812\n",
      "Step: 587 Weights: [-10.72719128   3.39995937] , error: 14.663336078138803\n",
      "Step: 588 Weights: [-10.70191662   3.39706885] , error: 14.598693540184133\n",
      "Step: 589 Weights: [-10.6766996    3.39418493] , error: 14.534345489750754\n",
      "Step: 590 Weights: [-10.65154009   3.39130758] , error: 14.470290585262335\n",
      "Step: 591 Weights: [-10.62643795   3.3884368 ] , error: 14.40652749125422\n",
      "Step: 592 Weights: [-10.60139305   3.38557256] , error: 14.34305487834569\n",
      "Step: 593 Weights: [-10.57640527   3.38271485] , error: 14.279871423212162\n",
      "Step: 594 Weights: [-10.55147447   3.37986366] , error: 14.216975808557635\n",
      "Step: 595 Weights: [-10.52660052   3.37701897] , error: 14.154366723087247\n",
      "Step: 596 Weights: [-10.5017833    3.37418076] , error: 14.092042861479868\n",
      "Step: 597 Weights: [-10.47702267   3.37134903] , error: 14.030002924360964\n",
      "Step: 598 Weights: [-10.4523185    3.36852376] , error: 13.968245618275455\n",
      "Step: 599 Weights: [-10.42767067   3.36570493] , error: 13.906769655660773\n",
      "Step: 600 Weights: [-10.40307904   3.36289253] , error: 13.845573754819991\n",
      "Step: 601 Weights: [-10.3785435    3.36008654] , error: 13.784656639895147\n",
      "Step: 602 Weights: [-10.35406391   3.35728695] , error: 13.724017040840604\n",
      "Step: 603 Weights: [-10.32964014   3.35449375] , error: 13.663653693396578\n",
      "Step: 604 Weights: [-10.30527206   3.35170691] , error: 13.603565339062785\n",
      "Step: 605 Weights: [-10.28095956   3.34892643] , error: 13.54375072507222\n",
      "Step: 606 Weights: [-10.2567025    3.34615229] , error: 13.484208604365007\n",
      "Step: 607 Weights: [-10.23250075   3.34338448] , error: 13.424937735562404\n",
      "Step: 608 Weights: [-10.2083542    3.34062298] , error: 13.365936882940968\n",
      "Step: 609 Weights: [-10.1842627    3.33786777] , error: 13.30720481640671\n",
      "Step: 610 Weights: [-10.16022615   3.33511885] , error: 13.248740311469533\n",
      "Step: 611 Weights: [-10.13624441   3.3323762 ] , error: 13.190542149217643\n",
      "Step: 612 Weights: [-10.11231736   3.3296398 ] , error: 13.132609116292164\n",
      "Step: 613 Weights: [-10.08844488   3.32690964] , error: 13.074940004861839\n",
      "Step: 614 Weights: [-10.06462683   3.32418571] , error: 13.017533612597838\n",
      "Step: 615 Weights: [-10.04086309   3.32146799] , error: 12.960388742648696\n",
      "Step: 616 Weights: [-10.01715355   3.31875646] , error: 12.903504203615366\n",
      "Step: 617 Weights: [-9.99349808  3.31605112] , error: 12.846878809526366\n",
      "Step: 618 Weights: [-9.96989655  3.31335195] , error: 12.790511379813083\n",
      "Step: 619 Weights: [-9.94634884  3.31065894] , error: 12.734400739285102\n",
      "Step: 620 Weights: [-9.92285483  3.30797206] , error: 12.678545718105786\n",
      "Step: 621 Weights: [-9.8994144   3.30529132] , error: 12.6229451517678\n",
      "Step: 622 Weights: [-9.87602742  3.30261668] , error: 12.567597881068915\n",
      "Step: 623 Weights: [-9.85269377  3.29994815] , error: 12.512502752087753\n",
      "Step: 624 Weights: [-9.82941333  3.2972857 ] , error: 12.457658616159812\n",
      "Step: 625 Weights: [-9.80618598  3.29462932] , error: 12.403064329853464\n",
      "Step: 626 Weights: [-9.7830116  3.291979 ] , error: 12.348718754946148\n",
      "Step: 627 Weights: [-9.75989007  3.28933473] , error: 12.294620758400601\n",
      "Step: 628 Weights: [-9.73682126  3.28669648] , error: 12.240769212341288\n",
      "Step: 629 Weights: [-9.71380506  3.28406425] , error: 12.187162994030825\n",
      "Step: 630 Weights: [-9.69084135  3.28143802] , error: 12.133800985846637\n",
      "Step: 631 Weights: [-9.66793     3.27881779] , error: 12.080682075257599\n",
      "Step: 632 Weights: [-9.6450709   3.27620352] , error: 12.027805154800886\n",
      "Step: 633 Weights: [-9.62226393  3.27359522] , error: 11.975169122058848\n",
      "Step: 634 Weights: [-9.59950897  3.27099287] , error: 11.92277287963606\n",
      "Step: 635 Weights: [-9.5768059   3.26839645] , error: 11.870615335136414\n",
      "Step: 636 Weights: [-9.5541546   3.26580595] , error: 11.818695401140346\n",
      "Step: 637 Weights: [-9.53155495  3.26322136] , error: 11.767011995182202\n",
      "Step: 638 Weights: [-9.50900685  3.26064266] , error: 11.71556403972762\n",
      "Step: 639 Weights: [-9.48651016  3.25806985] , error: 11.66435046215107\n",
      "Step: 640 Weights: [-9.46406477  3.2555029 ] , error: 11.613370194713559\n",
      "Step: 641 Weights: [-9.44167057  3.2529418 ] , error: 11.562622174540284\n",
      "Step: 642 Weights: [-9.41932743  3.25038655] , error: 11.512105343598481\n",
      "Step: 643 Weights: [-9.39703525  3.24783712] , error: 11.461818648675454\n",
      "Step: 644 Weights: [-9.3747939   3.24529351] , error: 11.411761041356508\n",
      "Step: 645 Weights: [-9.35260328  3.24275569] , error: 11.361931478003157\n",
      "Step: 646 Weights: [-9.33046325  3.24022367] , error: 11.312328919731348\n",
      "Step: 647 Weights: [-9.30837372  3.23769741] , error: 11.262952332389784\n",
      "Step: 648 Weights: [-9.28633456  3.23517692] , error: 11.213800686538397\n",
      "Step: 649 Weights: [-9.26434565  3.23266218] , error: 11.164872957426851\n",
      "Step: 650 Weights: [-9.24240689  3.23015317] , error: 11.116168124973223\n",
      "Step: 651 Weights: [-9.22051816  3.22764988] , error: 11.067685173742671\n",
      "Step: 652 Weights: [-9.19867935  3.2251523 ] , error: 11.019423092926317\n",
      "Step: 653 Weights: [-9.17689034  3.22266042] , error: 10.971380876320165\n",
      "Step: 654 Weights: [-9.15515101  3.22017422] , error: 10.923557522304078\n",
      "Step: 655 Weights: [-9.13346126  3.21769369] , error: 10.875952033820962\n",
      "Step: 656 Weights: [-9.11182097  3.21521881] , error: 10.82856341835595\n",
      "Step: 657 Weights: [-9.09023003  3.21274958] , error: 10.781390687915678\n",
      "Step: 658 Weights: [-9.06868833  3.21028598] , error: 10.734432859007727\n",
      "Step: 659 Weights: [-9.04719575  3.207828  ] , error: 10.687688952620128\n",
      "Step: 660 Weights: [-9.02575218  3.20537562] , error: 10.641157994200888\n",
      "Step: 661 Weights: [-9.00435751  3.20292884] , error: 10.594839013637758\n",
      "Step: 662 Weights: [-8.98301164  3.20048763] , error: 10.548731045237922\n",
      "Step: 663 Weights: [-8.96171443  3.198052  ] , error: 10.502833127707921\n",
      "Step: 664 Weights: [-8.9404658   3.19562191] , error: 10.457144304133601\n",
      "Step: 665 Weights: [-8.91926562  3.19319737] , error: 10.411663621960148\n",
      "Step: 666 Weights: [-8.89811379  3.19077836] , error: 10.366390132972228\n",
      "Step: 667 Weights: [-8.87701019  3.18836486] , error: 10.321322893274246\n",
      "Step: 668 Weights: [-8.85595472  3.18595687] , error: 10.276460963270617\n",
      "Step: 669 Weights: [-8.83494726  3.18355437] , error: 10.231803407646234\n",
      "Step: 670 Weights: [-8.8139877   3.18115734] , error: 10.187349295346927\n",
      "Step: 671 Weights: [-8.79307595  3.17876579] , error: 10.143097699560078\n",
      "Step: 672 Weights: [-8.77221188  3.17637969] , error: 10.099047697695259\n",
      "Step: 673 Weights: [-8.75139539  3.17399902] , error: 10.055198371365046\n",
      "Step: 674 Weights: [-8.73062637  3.17162379] , error: 10.01154880636584\n",
      "Step: 675 Weights: [-8.70990471  3.16925397] , error: 9.968098092658812\n",
      "Step: 676 Weights: [-8.68923031  3.16688956] , error: 9.924845324350951\n",
      "Step: 677 Weights: [-8.66860305  3.16453054] , error: 9.881789599676136\n",
      "Step: 678 Weights: [-8.64802283  3.1621769 ] , error: 9.83893002097637\n",
      "Step: 679 Weights: [-8.62748954  3.15982863] , error: 9.796265694683061\n",
      "Step: 680 Weights: [-8.60700308  3.15748571] , error: 9.753795731298377\n",
      "Step: 681 Weights: [-8.58656334  3.15514813] , error: 9.711519245376724\n",
      "Step: 682 Weights: [-8.5661702   3.15281589] , error: 9.669435355506232\n",
      "Step: 683 Weights: [-8.54582357  3.15048896] , error: 9.627543184290468\n",
      "Step: 684 Weights: [-8.52552334  3.14816734] , error: 9.585841858330067\n",
      "Step: 685 Weights: [-8.5052694   3.14585102] , error: 9.544330508204554\n",
      "Step: 686 Weights: [-8.48506165  3.14353997] , error: 9.503008268454188\n",
      "Step: 687 Weights: [-8.46489998  3.1412342 ] , error: 9.46187427756199\n",
      "Step: 688 Weights: [-8.44478429  3.13893369] , error: 9.42092767793569\n",
      "Step: 689 Weights: [-8.42471447  3.13663842] , error: 9.380167615889938\n",
      "Step: 690 Weights: [-8.40469042  3.13434838] , error: 9.339593241628398\n",
      "Step: 691 Weights: [-8.38471203  3.13206357] , error: 9.299203709226154\n",
      "Step: 692 Weights: [-8.3647792   3.12978397] , error: 9.258998176611968\n",
      "Step: 693 Weights: [-8.34489183  3.12750956] , error: 9.218975805550777\n",
      "Step: 694 Weights: [-8.32504981  3.12524035] , error: 9.179135761626227\n",
      "Step: 695 Weights: [-8.30525303  3.1229763 ] , error: 9.139477214223238\n",
      "Step: 696 Weights: [-8.2855014   3.12071742] , error: 9.099999336510717\n",
      "Step: 697 Weights: [-8.26579482  3.11846369] , error: 9.060701305424288\n",
      "Step: 698 Weights: [-8.24613317  3.11621511] , error: 9.021582301649174\n",
      "Step: 699 Weights: [-8.22651635  3.11397164] , error: 8.982641509603074\n",
      "Step: 700 Weights: [-8.20694428  3.1117333 ] , error: 8.943878117419203\n",
      "Step: 701 Weights: [-8.18741683  3.10950006] , error: 8.905291316929317\n",
      "Step: 702 Weights: [-8.16793392  3.10727191] , error: 8.86688030364691\n",
      "Step: 703 Weights: [-8.14849543  3.10504884] , error: 8.828644276750397\n",
      "Step: 704 Weights: [-8.12910127  3.10283085] , error: 8.79058243906646\n",
      "Step: 705 Weights: [-8.10975134  3.10061791] , error: 8.752693997053395\n",
      "Step: 706 Weights: [-8.09044554  3.09841001] , error: 8.714978160784579\n",
      "Step: 707 Weights: [-8.07118376  3.09620715] , error: 8.677434143932013\n",
      "Step: 708 Weights: [-8.0519659   3.09400932] , error: 8.64006116374992\n",
      "Step: 709 Weights: [-8.03279187  3.0918165 ] , error: 8.602858441058412\n",
      "Step: 710 Weights: [-8.01366157  3.08962867] , error: 8.565825200227264\n",
      "Step: 711 Weights: [-7.99457489  3.08744584] , error: 8.528960669159728\n",
      "Step: 712 Weights: [-7.97553173  3.08526799] , error: 8.492264079276454\n",
      "Step: 713 Weights: [-7.95653201  3.0830951 ] , error: 8.455734665499458\n",
      "Step: 714 Weights: [-7.93757561  3.08092716] , error: 8.419371666236142\n",
      "Step: 715 Weights: [-7.91866243  3.07876417] , error: 8.383174323363479\n",
      "Step: 716 Weights: [-7.89979239  3.07660611] , error: 8.347141882212158\n",
      "Step: 717 Weights: [-7.88096538  3.07445298] , error: 8.311273591550838\n",
      "Step: 718 Weights: [-7.8621813   3.07230475] , error: 8.275568703570551\n",
      "Step: 719 Weights: [-7.84344006  3.07016142] , error: 8.24002647386903\n",
      "Step: 720 Weights: [-7.82474155  3.06802298] , error: 8.204646161435265\n",
      "Step: 721 Weights: [-7.80608569  3.06588942] , error: 8.169427028633997\n",
      "Step: 722 Weights: [-7.78747237  3.06376072] , error: 8.134368341190362\n",
      "Step: 723 Weights: [-7.76890149  3.06163688] , error: 8.099469368174598\n",
      "Step: 724 Weights: [-7.75037297  3.05951788] , error: 8.064729381986773\n",
      "Step: 725 Weights: [-7.7318867   3.05740371] , error: 8.030147658341628\n",
      "Step: 726 Weights: [-7.71344258  3.05529436] , error: 7.995723476253494\n",
      "Step: 727 Weights: [-7.69504052  3.05318983] , error: 7.961456118021237\n",
      "Step: 728 Weights: [-7.67668043  3.05109009] , error: 7.9273448692133055\n",
      "Step: 729 Weights: [-7.65836221  3.04899514] , error: 7.893389018652844\n",
      "Step: 730 Weights: [-7.64008576  3.04690497] , error: 7.859587858402831\n",
      "Step: 731 Weights: [-7.62185099  3.04481956] , error: 7.825940683751373\n",
      "Step: 732 Weights: [-7.6036578   3.04273891] , error: 7.792446793196973\n",
      "Step: 733 Weights: [-7.5855061   3.04066301] , error: 7.75910548843391\n",
      "Step: 734 Weights: [-7.56739579  3.03859184] , error: 7.725916074337691\n",
      "Step: 735 Weights: [-7.54932678  3.03652539] , error: 7.69287785895055\n",
      "Step: 736 Weights: [-7.53129897  3.03446365] , error: 7.659990153467032\n",
      "Step: 737 Weights: [-7.51331228  3.03240662] , error: 7.627252272219616\n",
      "Step: 738 Weights: [-7.49536661  3.03035428] , error: 7.594663532664439\n",
      "Step: 739 Weights: [-7.47746185  3.02830661] , error: 7.562223255367046\n",
      "Step: 740 Weights: [-7.45959793  3.02626362] , error: 7.5299307639882445\n",
      "Step: 741 Weights: [-7.44177475  3.02422529] , error: 7.497785385269979\n",
      "Step: 742 Weights: [-7.42399221  3.0221916 ] , error: 7.465786449021319\n",
      "Step: 743 Weights: [-7.40625022  3.02016255] , error: 7.433933288104486\n",
      "Step: 744 Weights: [-7.38854869  3.01813813] , error: 7.402225238420915\n",
      "Step: 745 Weights: [-7.37088752  3.01611832] , error: 7.370661638897433\n",
      "Step: 746 Weights: [-7.35326663  3.01410312] , error: 7.339241831472485\n",
      "Step: 747 Weights: [-7.33568593  3.01209252] , error: 7.30796516108238\n",
      "Step: 748 Weights: [-7.31814531  3.0100865 ] , error: 7.276830975647687\n",
      "Step: 749 Weights: [-7.3006447   3.00808506] , error: 7.245838626059577\n",
      "Step: 750 Weights: [-7.283184    3.00608818] , error: 7.214987466166333\n",
      "Step: 751 Weights: [-7.26576311  3.00409585] , error: 7.184276852759868\n",
      "Step: 752 Weights: [-7.24838195  3.00210807] , error: 7.1537061455623085\n",
      "Step: 753 Weights: [-7.23104042  3.00012482] , error: 7.12327470721267\n",
      "Step: 754 Weights: [-7.21373844  2.99814609] , error: 7.092981903253509\n",
      "Step: 755 Weights: [-7.19647592  2.99617188] , error: 7.062827102117773\n",
      "Step: 756 Weights: [-7.17925276  2.99420216] , error: 7.032809675115594\n",
      "Step: 757 Weights: [-7.16206888  2.99223694] , error: 7.00292899642115\n",
      "Step: 758 Weights: [-7.14492419  2.9902762 ] , error: 6.973184443059672\n",
      "Step: 759 Weights: [-7.12781859  2.98831994] , error: 6.943575394894449\n",
      "Step: 760 Weights: [-7.110752    2.98636813] , error: 6.914101234613861\n",
      "Step: 761 Weights: [-7.09372433  2.98442077] , error: 6.88476134771854\n",
      "Step: 762 Weights: [-7.07673548  2.98247786] , error: 6.85555512250854\n",
      "Step: 763 Weights: [-7.05978539  2.98053937] , error: 6.826481950070612\n",
      "Step: 764 Weights: [-7.04287394  2.97860531] , error: 6.797541224265472\n",
      "Step: 765 Weights: [-7.02600106  2.97667565] , error: 6.768732341715216\n",
      "Step: 766 Weights: [-7.00916665  2.9747504 ] , error: 6.740054701790656\n",
      "Step: 767 Weights: [-6.99237064  2.97282954] , error: 6.711507706598885\n",
      "Step: 768 Weights: [-6.97561293  2.97091305] , error: 6.683090760970774\n",
      "Step: 769 Weights: [-6.95889343  2.96900094] , error: 6.654803272448539\n",
      "Step: 770 Weights: [-6.94221206  2.96709319] , error: 6.626644651273456\n",
      "Step: 771 Weights: [-6.92556873  2.96518979] , error: 6.598614310373483\n",
      "Step: 772 Weights: [-6.90896335  2.96329073] , error: 6.570711665351078\n",
      "Step: 773 Weights: [-6.89239584  2.961396  ] , error: 6.542936134471009\n",
      "Step: 774 Weights: [-6.87586611  2.95950559] , error: 6.5152871386481985\n",
      "Step: 775 Weights: [-6.85937408  2.95761949] , error: 6.48776410143568\n",
      "Step: 776 Weights: [-6.84291965  2.95573769] , error: 6.460366449012555\n",
      "Step: 777 Weights: [-6.82650275  2.95386019] , error: 6.433093610172035\n",
      "Step: 778 Weights: [-6.81012329  2.95198696] , error: 6.405945016309559\n",
      "Step: 779 Weights: [-6.79378117  2.95011801] , error: 6.378920101410915\n",
      "Step: 780 Weights: [-6.77747633  2.94825332] , error: 6.352018302040422\n",
      "Step: 781 Weights: [-6.76120866  2.94639288] , error: 6.325239057329226\n",
      "Step: 782 Weights: [-6.7449781   2.94453668] , error: 6.2985818089635774\n",
      "Step: 783 Weights: [-6.72878454  2.94268472] , error: 6.272046001173181\n",
      "Step: 784 Weights: [-6.71262791  2.94083698] , error: 6.245631080719665\n",
      "Step: 785 Weights: [-6.69650813  2.93899345] , error: 6.219336496884971\n",
      "Step: 786 Weights: [-6.68042511  2.93715413] , error: 6.193161701459912\n",
      "Step: 787 Weights: [-6.66437876  2.935319  ] , error: 6.167106148732769\n",
      "Step: 788 Weights: [-6.64836901  2.93348806] , error: 6.141169295477848\n",
      "Step: 789 Weights: [-6.63239576  2.93166129] , error: 6.115350600944215\n",
      "Step: 790 Weights: [-6.61645894  2.92983869] , error: 6.089649526844372\n",
      "Step: 791 Weights: [-6.60055846  2.92802024] , error: 6.064065537343098\n",
      "Step: 792 Weights: [-6.58469424  2.92620595] , error: 6.038598099046201\n",
      "Step: 793 Weights: [-6.5688662   2.92439578] , error: 6.013246680989471\n",
      "Step: 794 Weights: [-6.55307426  2.92258975] , error: 5.988010754627534\n",
      "Step: 795 Weights: [-6.53731832  2.92078784] , error: 5.962889793822915\n",
      "Step: 796 Weights: [-6.52159832  2.91899003] , error: 5.937883274834995\n",
      "Step: 797 Weights: [-6.50591416  2.91719632] , error: 5.912990676309146\n",
      "Step: 798 Weights: [-6.49026577  2.91540671] , error: 5.88821147926582\n",
      "Step: 799 Weights: [-6.47465307  2.91362117] , error: 5.8635451670897725\n",
      "Step: 800 Weights: [-6.45907597  2.91183971] , error: 5.838991225519237\n",
      "Step: 801 Weights: [-6.44353439  2.91006231] , error: 5.814549142635258\n",
      "Step: 802 Weights: [-6.42802825  2.90828896] , error: 5.7902184088509845\n",
      "Step: 803 Weights: [-6.41255747  2.90651966] , error: 5.76599851690105\n",
      "Step: 804 Weights: [-6.39712197  2.90475439] , error: 5.741888961831005\n",
      "Step: 805 Weights: [-6.38172167  2.90299315] , error: 5.717889240986803\n",
      "Step: 806 Weights: [-6.36635649  2.90123592] , error: 5.6939988540042705\n",
      "Step: 807 Weights: [-6.35102635  2.8994827 ] , error: 5.670217302798733\n",
      "Step: 808 Weights: [-6.33573117  2.89773348] , error: 5.646544091554603\n",
      "Step: 809 Weights: [-6.32047087  2.89598825] , error: 5.6229787267150355\n",
      "Step: 810 Weights: [-6.30524537  2.89424699] , error: 5.599520716971664\n",
      "Step: 811 Weights: [-6.29005459  2.89250971] , error: 5.576169573254319\n",
      "Step: 812 Weights: [-6.27489845  2.89077639] , error: 5.552924808720876\n",
      "Step: 813 Weights: [-6.25977687  2.88904703] , error: 5.529785938747061\n",
      "Step: 814 Weights: [-6.24468978  2.8873216 ] , error: 5.506752480916404\n",
      "Step: 815 Weights: [-6.22963709  2.88560011] , error: 5.483823955010106\n",
      "Step: 816 Weights: [-6.21461872  2.88388255] , error: 5.460999882997088\n",
      "Step: 817 Weights: [-6.19963461  2.8821689 ] , error: 5.438279789024012\n",
      "Step: 818 Weights: [-6.18468466  2.88045916] , error: 5.415663199405324\n",
      "Step: 819 Weights: [-6.16976881  2.87875332] , error: 5.393149642613445\n",
      "Step: 820 Weights: [-6.15488697  2.87705137] , error: 5.370738649268869\n",
      "Step: 821 Weights: [-6.14003907  2.87535331] , error: 5.348429752130428\n",
      "Step: 822 Weights: [-6.12522503  2.87365911] , error: 5.32622248608551\n",
      "Step: 823 Weights: [-6.11044477  2.87196878] , error: 5.304116388140425\n",
      "Step: 824 Weights: [-6.09569821  2.8702823 ] , error: 5.282110997410663\n",
      "Step: 825 Weights: [-6.08098528  2.86859967] , error: 5.260205855111358\n",
      "Step: 826 Weights: [-6.06630591  2.86692087] , error: 5.238400504547711\n",
      "Step: 827 Weights: [-6.05166001  2.8652459 ] , error: 5.216694491105437\n",
      "Step: 828 Weights: [-6.03704751  2.86357476] , error: 5.195087362241297\n",
      "Step: 829 Weights: [-6.02246833  2.86190742] , error: 5.173578667473708\n",
      "Step: 830 Weights: [-6.00792239  2.86024389] , error: 5.152167958373266\n",
      "Step: 831 Weights: [-5.99340963  2.85858414] , error: 5.130854788553492\n",
      "Step: 832 Weights: [-5.97892997  2.85692819] , error: 5.109638713661452\n",
      "Step: 833 Weights: [-5.96448332  2.85527601] , error: 5.088519291368521\n",
      "Step: 834 Weights: [-5.95006962  2.8536276 ] , error: 5.067496081361171\n",
      "Step: 835 Weights: [-5.93568878  2.85198295] , error: 5.046568645331764\n",
      "Step: 836 Weights: [-5.92134074  2.85034204] , error: 5.025736546969458\n",
      "Step: 837 Weights: [-5.90702542  2.84870488] , error: 5.004999351951046\n",
      "Step: 838 Weights: [-5.89274275  2.84707146] , error: 4.984356627931962\n",
      "Step: 839 Weights: [-5.87849265  2.84544175] , error: 4.963807944537234\n",
      "Step: 840 Weights: [-5.86427504  2.84381577] , error: 4.943352873352517\n",
      "Step: 841 Weights: [-5.85008985  2.84219349] , error: 4.922990987915171\n",
      "Step: 842 Weights: [-5.83593701  2.84057491] , error: 4.902721863705352\n",
      "Step: 843 Weights: [-5.82181645  2.83896003] , error: 4.882545078137186\n",
      "Step: 844 Weights: [-5.80772809  2.83734882] , error: 4.862460210549923\n",
      "Step: 845 Weights: [-5.79367185  2.83574129] , error: 4.84246684219921\n",
      "Step: 846 Weights: [-5.77964767  2.83413743] , error: 4.822564556248329\n",
      "Step: 847 Weights: [-5.76565547  2.83253722] , error: 4.802752937759505\n",
      "Step: 848 Weights: [-5.75169518  2.83094066] , error: 4.783031573685293\n",
      "Step: 849 Weights: [-5.73776672  2.82934774] , error: 4.763400052859914\n",
      "Step: 850 Weights: [-5.72387003  2.82775846] , error: 4.743857965990719\n",
      "Step: 851 Weights: [-5.71000502  2.8261728 ] , error: 4.7244049056496475\n",
      "Step: 852 Weights: [-5.69617164  2.82459075] , error: 4.705040466264721\n",
      "Step: 853 Weights: [-5.6823698   2.82301232] , error: 4.685764244111612\n",
      "Step: 854 Weights: [-5.66859943  2.82143748] , error: 4.666575837305196\n",
      "Step: 855 Weights: [-5.65486046  2.81986623] , error: 4.647474845791195\n",
      "Step: 856 Weights: [-5.64115283  2.81829857] , error: 4.628460871337844\n",
      "Step: 857 Weights: [-5.62747646  2.81673448] , error: 4.609533517527551\n",
      "Step: 858 Weights: [-5.61383127  2.81517396] , error: 4.5906923897486696\n",
      "Step: 859 Weights: [-5.6002172  2.813617 ] , error: 4.571937095187257\n",
      "Step: 860 Weights: [-5.58663417  2.81206359] , error: 4.553267242818882\n",
      "Step: 861 Weights: [-5.57308212  2.81051372] , error: 4.534682443400487\n",
      "Step: 862 Weights: [-5.55956098  2.80896738] , error: 4.516182309462252\n",
      "Step: 863 Weights: [-5.54607067  2.80742458] , error: 4.497766455299518\n",
      "Step: 864 Weights: [-5.53261112  2.80588528] , error: 4.479434496964774\n",
      "Step: 865 Weights: [-5.51918227  2.8043495 ] , error: 4.461186052259622\n",
      "Step: 866 Weights: [-5.50578403  2.80281723] , error: 4.443020740726807\n",
      "Step: 867 Weights: [-5.49241636  2.80128844] , error: 4.42493818364233\n",
      "Step: 868 Weights: [-5.47907916  2.79976314] , error: 4.40693800400748\n",
      "Step: 869 Weights: [-5.46577238  2.79824132] , error: 4.3890198265410385\n",
      "Step: 870 Weights: [-5.45249595  2.79672298] , error: 4.371183277671416\n",
      "Step: 871 Weights: [-5.43924979  2.79520809] , error: 4.353427985528888\n",
      "Step: 872 Weights: [-5.42603384  2.79369666] , error: 4.335753579937821\n",
      "Step: 873 Weights: [-5.41284802  2.79218867] , error: 4.318159692408969\n",
      "Step: 874 Weights: [-5.39969228  2.79068413] , error: 4.300645956131788\n",
      "Step: 875 Weights: [-5.38656654  2.78918301] , error: 4.283212005966789\n",
      "Step: 876 Weights: [-5.37347072  2.78768532] , error: 4.2658574784379235\n",
      "Step: 877 Weights: [-5.36040478  2.78619104] , error: 4.248582011725\n",
      "Step: 878 Weights: [-5.34736862  2.78470017] , error: 4.231385245656142\n",
      "Step: 879 Weights: [-5.3343622  2.7832127] , error: 4.2142668217003\n",
      "Step: 880 Weights: [-5.32138543  2.78172862] , error: 4.1972263829597445\n",
      "Step: 881 Weights: [-5.30843826  2.78024793] , error: 4.180263574162653\n",
      "Step: 882 Weights: [-5.29552061  2.77877061] , error: 4.16337804165568\n",
      "Step: 883 Weights: [-5.28263242  2.77729667] , error: 4.1465694333965954\n",
      "Step: 884 Weights: [-5.26977363  2.77582608] , error: 4.129837398946937\n",
      "Step: 885 Weights: [-5.25694415  2.77435885] , error: 4.113181589464729\n",
      "Step: 886 Weights: [-5.24414393  2.77289496] , error: 4.096601657697182\n",
      "Step: 887 Weights: [-5.2313729   2.77143441] , error: 4.080097257973446\n",
      "Step: 888 Weights: [-5.21863099  2.76997719] , error: 4.06366804619745\n",
      "Step: 889 Weights: [-5.20591814  2.7685233 ] , error: 4.047313679840679\n",
      "Step: 890 Weights: [-5.19323429  2.76707272] , error: 4.031033817935043\n",
      "Step: 891 Weights: [-5.18057935  2.76562545] , error: 4.014828121065795\n",
      "Step: 892 Weights: [-5.16795328  2.76418148] , error: 3.998696251364433\n",
      "Step: 893 Weights: [-5.15535599  2.7627408 ] , error: 3.9826378725016482\n",
      "Step: 894 Weights: [-5.14278744  2.7613034 ] , error: 3.966652649680337\n",
      "Step: 895 Weights: [-5.13024754  2.75986929] , error: 3.950740249628595\n",
      "Step: 896 Weights: [-5.11773624  2.75843844] , error: 3.934900340592783\n",
      "Step: 897 Weights: [-5.10525348  2.75701086] , error: 3.9191325923306293\n",
      "Step: 898 Weights: [-5.09279917  2.75558654] , error: 3.9034366761043002\n",
      "Step: 899 Weights: [-5.08037327  2.75416546] , error: 3.887812264673575\n",
      "Step: 900 Weights: [-5.06797571  2.75274762] , error: 3.872259032289025\n",
      "Step: 901 Weights: [-5.05560642  2.75133302] , error: 3.85677665468521\n",
      "Step: 902 Weights: [-5.04326533  2.74992164] , error: 3.84136480907393\n",
      "Step: 903 Weights: [-5.03095239  2.74851348] , error: 3.8260231741374797\n",
      "Step: 904 Weights: [-5.01866752  2.74710853] , error: 3.8107514300219703\n",
      "Step: 905 Weights: [-5.00641068  2.74570678] , error: 3.795549258330639\n",
      "Step: 906 Weights: [-4.99418178  2.74430823] , error: 3.7804163421172126\n",
      "Step: 907 Weights: [-4.98198076  2.74291288] , error: 3.7653523658793384\n",
      "Step: 908 Weights: [-4.96980758  2.7415207 ] , error: 3.7503570155519457\n",
      "Step: 909 Weights: [-4.95766215  2.7401317 ] , error: 3.7354299785007417\n",
      "Step: 910 Weights: [-4.94554442  2.73874586] , error: 3.720570943515676\n",
      "Step: 911 Weights: [-4.93345432  2.73736319] , error: 3.705779600804463\n",
      "Step: 912 Weights: [-4.92139179  2.73598366] , error: 3.6910556419861065\n",
      "Step: 913 Weights: [-4.90935677  2.73460729] , error: 3.6763987600844956\n",
      "Step: 914 Weights: [-4.89734919  2.73323405] , error: 3.661808649521964\n",
      "Step: 915 Weights: [-4.885369    2.73186395] , error: 3.647285006112963\n",
      "Step: 916 Weights: [-4.87341613  2.73049697] , error: 3.6328275270576995\n",
      "Step: 917 Weights: [-4.86149051  2.7291331 ] , error: 3.6184359109358244\n",
      "Step: 918 Weights: [-4.84959209  2.72777235] , error: 3.6041098577001436\n",
      "Step: 919 Weights: [-4.8377208  2.7264147] , error: 3.589849068670363\n",
      "Step: 920 Weights: [-4.82587659  2.72506014] , error: 3.5756532465268824\n",
      "Step: 921 Weights: [-4.81405938  2.72370868] , error: 3.5615220953045617\n",
      "Step: 922 Weights: [-4.80226912  2.72236029] , error: 3.547455320386576\n",
      "Step: 923 Weights: [-4.79050575  2.72101499] , error: 3.533452628498269\n",
      "Step: 924 Weights: [-4.7787692   2.71967274] , error: 3.519513727701031\n",
      "Step: 925 Weights: [-4.76705942  2.71833356] , error: 3.5056383273862197\n",
      "Step: 926 Weights: [-4.75537634  2.71699744] , error: 3.4918261382690967\n",
      "Step: 927 Weights: [-4.74371991  2.71566436] , error: 3.4780768723827973\n",
      "Step: 928 Weights: [-4.73209005  2.71433432] , error: 3.464390243072331\n",
      "Step: 929 Weights: [-4.72048672  2.71300731] , error: 3.4507659649885944\n",
      "Step: 930 Weights: [-4.70890984  2.71168333] , error: 3.4372037540824354\n",
      "Step: 931 Weights: [-4.69735937  2.71036237] , error: 3.423703327598723\n",
      "Step: 932 Weights: [-4.68583524  2.70904442] , error: 3.410264404070459\n",
      "Step: 933 Weights: [-4.67433738  2.70772948] , error: 3.39688670331289\n",
      "Step: 934 Weights: [-4.66286575  2.70641754] , error: 3.383569946417703\n",
      "Step: 935 Weights: [-4.65142028  2.70510858] , error: 3.3703138557471677\n",
      "Step: 936 Weights: [-4.6400009   2.70380262] , error: 3.357118154928375\n",
      "Step: 937 Weights: [-4.62860757  2.70249963] , error: 3.343982568847478\n",
      "Step: 938 Weights: [-4.61724022  2.70119961] , error: 3.3309068236439354\n",
      "Step: 939 Weights: [-4.60589879  2.69990256] , error: 3.317890646704824\n",
      "Step: 940 Weights: [-4.59458323  2.69860846] , error: 3.3049337666591265\n",
      "Step: 941 Weights: [-4.58329346  2.69731732] , error: 3.2920359133721173\n",
      "Step: 942 Weights: [-4.57202945  2.69602911] , error: 3.2791968179396767\n",
      "Step: 943 Weights: [-4.56079112  2.69474385] , error: 3.2664162126827394\n",
      "Step: 944 Weights: [-4.54957842  2.69346152] , error: 3.2536938311416637\n",
      "Step: 945 Weights: [-4.53839129  2.69218211] , error: 3.241029408070713\n",
      "Step: 946 Weights: [-4.52722967  2.69090562] , error: 3.2284226794325175\n",
      "Step: 947 Weights: [-4.5160935   2.68963204] , error: 3.2158733823925507\n",
      "Step: 948 Weights: [-4.50498273  2.68836137] , error: 3.203381255313668\n",
      "Step: 949 Weights: [-4.49389729  2.68709359] , error: 3.1909460377506473\n",
      "Step: 950 Weights: [-4.48283714  2.68582871] , error: 3.1785674704447597\n",
      "Step: 951 Weights: [-4.4718022  2.6845667] , error: 3.166245295318366\n",
      "Step: 952 Weights: [-4.46079243  2.68330758] , error: 3.1539792554695243\n",
      "Step: 953 Weights: [-4.44980777  2.68205133] , error: 3.141769095166657\n",
      "Step: 954 Weights: [-4.43884816  2.68079794] , error: 3.1296145598431875\n",
      "Step: 955 Weights: [-4.42791354  2.67954741] , error: 3.1175153960922635\n",
      "Step: 956 Weights: [-4.41700385  2.67829973] , error: 3.1054713516614556\n",
      "Step: 957 Weights: [-4.40611905  2.6770549 ] , error: 3.0934821754475097\n",
      "Step: 958 Weights: [-4.39525906  2.67581291] , error: 3.081547617491097\n",
      "Step: 959 Weights: [-4.38442384  2.67457375] , error: 3.0696674289716146\n",
      "Step: 960 Weights: [-4.37361333  2.67333741] , error: 3.057841362201995\n",
      "Step: 961 Weights: [-4.36282747  2.67210389] , error: 3.046069170623536\n",
      "Step: 962 Weights: [-4.35206621  2.67087319] , error: 3.0343506088007715\n",
      "Step: 963 Weights: [-4.34132949  2.66964529] , error: 3.0226854324163543\n",
      "Step: 964 Weights: [-4.33061725  2.6684202 ] , error: 3.011073398265946\n",
      "Step: 965 Weights: [-4.31992944  2.6671979 ] , error: 2.999514264253168\n",
      "Step: 966 Weights: [-4.30926601  2.66597838] , error: 2.988007789384521\n",
      "Step: 967 Weights: [-4.29862689  2.66476165] , error: 2.9765537337644115\n",
      "Step: 968 Weights: [-4.28801203  2.66354769] , error: 2.965151858590105\n",
      "Step: 969 Weights: [-4.27742138  2.66233649] , error: 2.9538019261467685\n",
      "Step: 970 Weights: [-4.26685488  2.66112806] , error: 2.94250369980251\n",
      "Step: 971 Weights: [-4.25631247  2.65992239] , error: 2.9312569440034397\n",
      "Step: 972 Weights: [-4.24579411  2.65871947] , error: 2.9200614242687806\n",
      "Step: 973 Weights: [-4.23529973  2.65751928] , error: 2.908916907185942\n",
      "Step: 974 Weights: [-4.22482929  2.65632184] , error: 2.8978231604056863\n",
      "Step: 975 Weights: [-4.21438272  2.65512713] , error: 2.886779952637272\n",
      "Step: 976 Weights: [-4.20395997  2.65393514] , error: 2.875787053643637\n",
      "Step: 977 Weights: [-4.19356099  2.65274587] , error: 2.864844234236584\n",
      "Step: 978 Weights: [-4.18318573  2.65155931] , error: 2.8539512662720186\n",
      "Step: 979 Weights: [-4.17283413  2.65037545] , error: 2.843107922645186\n",
      "Step: 980 Weights: [-4.16250613  2.6491943 ] , error: 2.832313977285937\n",
      "Step: 981 Weights: [-4.15220168  2.64801584] , error: 2.8215692051540184\n",
      "Step: 982 Weights: [-4.14192074  2.64684007] , error: 2.810873382234368\n",
      "Step: 983 Weights: [-4.13166323  2.64566698] , error: 2.8002262855324584\n",
      "Step: 984 Weights: [-4.12142912  2.64449656] , error: 2.7896276930696478\n",
      "Step: 985 Weights: [-4.11121835  2.64332881] , error: 2.779077383878538\n",
      "Step: 986 Weights: [-4.10103086  2.64216373] , error: 2.7685751379983845\n",
      "Step: 987 Weights: [-4.0908666  2.6410013] , error: 2.758120736470494\n",
      "Step: 988 Weights: [-4.08072552  2.63984153] , error: 2.7477139613336763\n",
      "Step: 989 Weights: [-4.07060757  2.6386844 ] , error: 2.7373545956196947\n",
      "Step: 990 Weights: [-4.06051269  2.6375299 ] , error: 2.7270424233487245\n",
      "Step: 991 Weights: [-4.05044083  2.63637804] , error: 2.7167772295248778\n",
      "Step: 992 Weights: [-4.04039194  2.63522881] , error: 2.7065588001317042\n",
      "Step: 993 Weights: [-4.03036597  2.6340822 ] , error: 2.6963869221277372\n",
      "Step: 994 Weights: [-4.02036286  2.6329382 ] , error: 2.6862613834420435\n",
      "Step: 995 Weights: [-4.01038256  2.63179681] , error: 2.676181972969809\n",
      "Step: 996 Weights: [-4.00042502  2.63065802] , error: 2.6661484805679354\n",
      "Step: 997 Weights: [-3.99049018  2.62952183] , error: 2.6561606970506566\n",
      "Step: 998 Weights: [-3.980578    2.62838823] , error: 2.646218414185185\n",
      "Step: 999 Weights: [-3.97068843  2.62725722] , error: 2.636321424687353\n",
      "Step: 1000 Weights: [-3.96082141  2.62612879] , error: 2.626469522217322\n",
      "Step: 1001 Weights: [-3.95097689  2.62500293] , error: 2.6166625013752385\n",
      "Step: 1002 Weights: [-3.94115482  2.62387963] , error: 2.6069001576969995\n",
      "Step: 1003 Weights: [-3.93135514  2.6227589 ] , error: 2.5971822876499395\n",
      "Step: 1004 Weights: [-3.92157782  2.62164072] , error: 2.587508688628633\n",
      "Step: 1005 Weights: [-3.91182279  2.6205251 ] , error: 2.5778791589506405\n",
      "Step: 1006 Weights: [-3.90209     2.61941202] , error: 2.5682934978523146\n",
      "Step: 1007 Weights: [-3.89237942  2.61830147] , error: 2.5587515054846133\n",
      "Step: 1008 Weights: [-3.88269097  2.61719346] , error: 2.5492529829089303\n",
      "Step: 1009 Weights: [-3.87302462  2.61608798] , error: 2.539797732092956\n",
      "Step: 1010 Weights: [-3.86338031  2.61498501] , error: 2.5303855559065407\n",
      "Step: 1011 Weights: [-3.853758    2.61388456] , error: 2.521016258117583\n",
      "Step: 1012 Weights: [-3.84415762  2.61278662] , error: 2.5116896433879448\n",
      "Step: 1013 Weights: [-3.83457915  2.61169119] , error: 2.5024055172693784\n",
      "Step: 1014 Weights: [-3.82502251  2.61059825] , error: 2.493163686199467\n",
      "Step: 1015 Weights: [-3.81548767  2.60950781] , error: 2.4839639574975956\n",
      "Step: 1016 Weights: [-3.80597457  2.60841985] , error: 2.4748061393609313\n",
      "Step: 1017 Weights: [-3.79648316  2.60733437] , error: 2.465690040860421\n",
      "Step: 1018 Weights: [-3.7870134   2.60625137] , error: 2.456615471936813\n",
      "Step: 1019 Weights: [-3.77756523  2.60517084] , error: 2.447582243396702\n",
      "Step: 1020 Weights: [-3.76813861  2.60409277] , error: 2.438590166908572\n",
      "Step: 1021 Weights: [-3.75873349  2.60301716] , error: 2.429639054998874\n",
      "Step: 1022 Weights: [-3.74934981  2.601944  ] , error: 2.4207287210481274\n",
      "Step: 1023 Weights: [-3.73998753  2.60087329] , error: 2.4118589792870178\n",
      "Step: 1024 Weights: [-3.73064661  2.59980503] , error: 2.40302964479252\n",
      "Step: 1025 Weights: [-3.72132698  2.59873919] , error: 2.394240533484055\n",
      "Step: 1026 Weights: [-3.7120286   2.59767579] , error: 2.3854914621196524\n",
      "Step: 1027 Weights: [-3.70275143  2.59661482] , error: 2.3767822482921193\n",
      "Step: 1028 Weights: [-3.69349542  2.59555626] , error: 2.3681127104252404\n",
      "Step: 1029 Weights: [-3.68426051  2.59450012] , error: 2.3594826677699947\n",
      "Step: 1030 Weights: [-3.67504667  2.59344638] , error: 2.3508919404007953\n",
      "Step: 1031 Weights: [-3.66585383  2.59239505] , error: 2.3423403492117165\n",
      "Step: 1032 Weights: [-3.65668196  2.59134612] , error: 2.3338277159127894\n",
      "Step: 1033 Weights: [-3.647531    2.59029957] , error: 2.3253538630262467\n",
      "Step: 1034 Weights: [-3.63840091  2.58925542] , error: 2.3169186138828657\n",
      "Step: 1035 Weights: [-3.62929164  2.58821364] , error: 2.3085217926182526\n",
      "Step: 1036 Weights: [-3.62020315  2.58717425] , error: 2.3001632241691894\n",
      "Step: 1037 Weights: [-3.61113538  2.58613722] , error: 2.2918427342699768\n",
      "Step: 1038 Weights: [-3.60208829  2.58510255] , error: 2.2835601494488142\n",
      "Step: 1039 Weights: [-3.59306183  2.58407025] , error: 2.2753152970241652\n",
      "Step: 1040 Weights: [-3.58405595  2.5830403 ] , error: 2.2671080051011754\n",
      "Step: 1041 Weights: [-3.57507061  2.5820127 ] , error: 2.258938102568076\n",
      "Step: 1042 Weights: [-3.56610576  2.58098744] , error: 2.2508054190926146\n",
      "Step: 1043 Weights: [-3.55716136  2.57996452] , error: 2.242709785118518\n",
      "Step: 1044 Weights: [-3.54823735  2.57894393] , error: 2.2346510318619437\n",
      "Step: 1045 Weights: [-3.53933369  2.57792567] , error: 2.2266289913079738\n",
      "Step: 1046 Weights: [-3.53045034  2.57690974] , error: 2.218643496207091\n",
      "Step: 1047 Weights: [-3.52158724  2.57589612] , error: 2.210694380071717\n",
      "Step: 1048 Weights: [-3.51274436  2.57488481] , error: 2.2027814771727225\n",
      "Step: 1049 Weights: [-3.50392164  2.5738758 ] , error: 2.194904622535983\n",
      "Step: 1050 Weights: [-3.49511904  2.5728691 ] , error: 2.1870636519389337\n",
      "Step: 1051 Weights: [-3.48633651  2.57186469] , error: 2.179258401907146\n",
      "Step: 1052 Weights: [-3.47757401  2.57086258] , error: 2.1714887097109203\n",
      "Step: 1053 Weights: [-3.4688315   2.56986275] , error: 2.1637544133618967\n",
      "Step: 1054 Weights: [-3.46010892  2.56886519] , error: 2.1560553516096674\n",
      "Step: 1055 Weights: [-3.45140623  2.56786992] , error: 2.148391363938428\n",
      "Step: 1056 Weights: [-3.44272339  2.56687691] , error: 2.1407622905636297\n",
      "Step: 1057 Weights: [-3.43406034  2.56588617] , error: 2.133167972428631\n",
      "Step: 1058 Weights: [-3.42541706  2.56489769] , error: 2.125608251201397\n",
      "Step: 1059 Weights: [-3.41679348  2.56391146] , error: 2.1180829692712053\n",
      "Step: 1060 Weights: [-3.40818957  2.56292748] , error: 2.1105919697453333\n",
      "Step: 1061 Weights: [-3.39960528  2.56194574] , error: 2.1031350964458175\n",
      "Step: 1062 Weights: [-3.39104056  2.56096625] , error: 2.095712193906179\n",
      "Step: 1063 Weights: [-3.38249538  2.55998898] , error: 2.0883231073681814\n",
      "Step: 1064 Weights: [-3.37396968  2.55901395] , error: 2.080967682778617\n",
      "Step: 1065 Weights: [-3.36546343  2.55804114] , error: 2.0736457667860853\n",
      "Step: 1066 Weights: [-3.35697657  2.55707054] , error: 2.0663572067377984\n",
      "Step: 1067 Weights: [-3.34850906  2.55610217] , error: 2.0591018506763916\n",
      "Step: 1068 Weights: [-3.34006087  2.55513599] , error: 2.051879547336776\n",
      "Step: 1069 Weights: [-3.33163194  2.55417203] , error: 2.0446901461429565\n",
      "Step: 1070 Weights: [-3.32322223  2.55321026] , error: 2.0375334972049175\n",
      "Step: 1071 Weights: [-3.3148317   2.55225068] , error: 2.0304094513154745\n",
      "Step: 1072 Weights: [-3.30646031  2.55129329] , error: 2.023317859947189\n",
      "Step: 1073 Weights: [-3.298108    2.55033809] , error: 2.016258575249247\n",
      "Step: 1074 Weights: [-3.28977474  2.54938506] , error: 2.0092314500444\n",
      "Step: 1075 Weights: [-3.28146049  2.54843421] , error: 2.0022363378258756\n",
      "Step: 1076 Weights: [-3.27316519  2.54748552] , error: 1.9952730927543347\n",
      "Step: 1077 Weights: [-3.26488881  2.546539  ] , error: 1.9883415696548277\n",
      "Step: 1078 Weights: [-3.25663131  2.54559464] , error: 1.981441624013772\n",
      "Step: 1079 Weights: [-3.24839263  2.54465243] , error: 1.9745731119759318\n",
      "Step: 1080 Weights: [-3.24017274  2.54371237] , error: 1.9677358903414224\n",
      "Step: 1081 Weights: [-3.2319716   2.54277445] , error: 1.9609298165627291\n",
      "Step: 1082 Weights: [-3.22378916  2.54183867] , error: 1.9541547487417246\n",
      "Step: 1083 Weights: [-3.21562538  2.54090503] , error: 1.9474105456267252\n",
      "Step: 1084 Weights: [-3.20748021  2.53997351] , error: 1.9406970666095287\n",
      "Step: 1085 Weights: [-3.19935362  2.53904412] , error: 1.9340141717224981\n",
      "Step: 1086 Weights: [-3.19124557  2.53811685] , error: 1.9273617216356347\n",
      "Step: 1087 Weights: [-3.183156    2.53719169] , error: 1.920739577653678\n",
      "Step: 1088 Weights: [-3.17508488  2.53626864] , error: 1.914147601713208\n",
      "Step: 1089 Weights: [-3.16703216  2.5353477 ] , error: 1.907585656379775\n",
      "Step: 1090 Weights: [-3.15899781  2.53442886] , error: 1.9010536048450282\n",
      "Step: 1091 Weights: [-3.15098178  2.53351211] , error: 1.8945513109238623\n",
      "Step: 1092 Weights: [-3.14298403  2.53259746] , error: 1.8880786390515856\n",
      "Step: 1093 Weights: [-3.13500452  2.53168489] , error: 1.8816354542810858\n",
      "Step: 1094 Weights: [-3.1270432  2.5307744] , error: 1.8752216222800222\n",
      "Step: 1095 Weights: [-3.11910004  2.52986598] , error: 1.8688370093280176\n",
      "Step: 1096 Weights: [-3.111175    2.52895964] , error: 1.8624814823138858\n",
      "Step: 1097 Weights: [-3.10326802  2.52805537] , error: 1.856154908732837\n",
      "Step: 1098 Weights: [-3.09537908  2.52715315] , error: 1.8498571566837212\n",
      "Step: 1099 Weights: [-3.08750812  2.526253  ] , error: 1.8435880948662957\n",
      "Step: 1100 Weights: [-3.07965512  2.52535489] , error: 1.837347592578456\n",
      "Step: 1101 Weights: [-3.07182003  2.52445884] , error: 1.8311355197135424\n",
      "Step: 1102 Weights: [-3.0640028   2.52356483] , error: 1.8249517467576073\n",
      "Step: 1103 Weights: [-3.05620339  2.52267286] , error: 1.8187961447867105\n",
      "Step: 1104 Weights: [-3.04842178  2.52178292] , error: 1.8126685854642668\n",
      "Step: 1105 Weights: [-3.04065791  2.52089501] , error: 1.8065689410383203\n",
      "Step: 1106 Weights: [-3.03291174  2.52000913] , error: 1.8004970843389183\n",
      "Step: 1107 Weights: [-3.02518324  2.51912526] , error: 1.7944528887754398\n",
      "Step: 1108 Weights: [-3.01747236  2.51824341] , error: 1.788436228333975\n",
      "Step: 1109 Weights: [-3.00977907  2.51736358] , error: 1.7824469775746774\n",
      "Step: 1110 Weights: [-3.00210332  2.51648574] , error: 1.776485011629164\n",
      "Step: 1111 Weights: [-2.99444507  2.51560991] , error: 1.7705502061979\n",
      "Step: 1112 Weights: [-2.98680429  2.51473608] , error: 1.7646424375476197\n",
      "Step: 1113 Weights: [-2.97918094  2.51386424] , error: 1.7587615825087375\n",
      "Step: 1114 Weights: [-2.97157496  2.51299439] , error: 1.752907518472778\n",
      "Step: 1115 Weights: [-2.96398633  2.51212652] , error: 1.7470801233898368\n",
      "Step: 1116 Weights: [-2.95641501  2.51126064] , error: 1.7412792757660094\n",
      "Step: 1117 Weights: [-2.94886095  2.51039672] , error: 1.7355048546608858\n",
      "Step: 1118 Weights: [-2.94132412  2.50953478] , error: 1.7297567396850049\n",
      "Step: 1119 Weights: [-2.93380448  2.5086748 ] , error: 1.724034810997364\n",
      "Step: 1120 Weights: [-2.92630198  2.50781678] , error: 1.7183389493029086\n",
      "Step: 1121 Weights: [-2.9188166   2.50696072] , error: 1.7126690358500403\n",
      "Step: 1122 Weights: [-2.91134828  2.50610662] , error: 1.7070249524281693\n",
      "Step: 1123 Weights: [-2.90389699  2.50525445] , error: 1.7014065813652104\n",
      "Step: 1124 Weights: [-2.8964627   2.50440424] , error: 1.6958138055251508\n",
      "Step: 1125 Weights: [-2.88904536  2.50355596] , error: 1.6902465083056182\n",
      "Step: 1126 Weights: [-2.88164493  2.50270962] , error: 1.6847045736354291\n",
      "Step: 1127 Weights: [-2.87426138  2.5018652 ] , error: 1.6791878859721736\n",
      "Step: 1128 Weights: [-2.86689467  2.50102271] , error: 1.6736963302998267\n",
      "Step: 1129 Weights: [-2.85954476  2.50018215] , error: 1.6682297921263112\n",
      "Step: 1130 Weights: [-2.8522116  2.4993435] , error: 1.6627881574811467\n",
      "Step: 1131 Weights: [-2.84489517  2.49850676] , error: 1.6573713129130634\n",
      "Step: 1132 Weights: [-2.83759543  2.49767193] , error: 1.6519791454876267\n",
      "Step: 1133 Weights: [-2.83031233  2.496839  ] , error: 1.6466115427848902\n",
      "Step: 1134 Weights: [-2.82304584  2.49600798] , error: 1.641268392897054\n",
      "Step: 1135 Weights: [-2.81579592  2.49517884] , error: 1.6359495844261245\n",
      "Step: 1136 Weights: [-2.80856253  2.4943516 ] , error: 1.6306550064816001\n",
      "Step: 1137 Weights: [-2.80134564  2.49352625] , error: 1.6253845486781566\n",
      "Step: 1138 Weights: [-2.7941452   2.49270278] , error: 1.6201381011333393\n",
      "Step: 1139 Weights: [-2.78696119  2.49188118] , error: 1.6149155544652825\n",
      "Step: 1140 Weights: [-2.77979356  2.49106146] , error: 1.609716799790421\n",
      "Step: 1141 Weights: [-2.77264227  2.49024361] , error: 1.6045417287212227\n",
      "Step: 1142 Weights: [-2.76550729  2.48942762] , error: 1.5993902333639278\n",
      "Step: 1143 Weights: [-2.75838858  2.4886135 ] , error: 1.5942622063163105\n",
      "Step: 1144 Weights: [-2.75128611  2.48780123] , error: 1.5891575406654117\n",
      "Step: 1145 Weights: [-2.74419983  2.48699081] , error: 1.5840761299853474\n",
      "Step: 1146 Weights: [-2.73712971  2.48618225] , error: 1.5790178683350569\n",
      "Step: 1147 Weights: [-2.73007572  2.48537552] , error: 1.5739826502561165\n",
      "Step: 1148 Weights: [-2.72303781  2.48457064] , error: 1.568970370770523\n",
      "Step: 1149 Weights: [-2.71601595  2.48376759] , error: 1.5639809253785235\n",
      "Step: 1150 Weights: [-2.7090101   2.48296637] , error: 1.5590142100564237\n",
      "Step: 1151 Weights: [-2.70202023  2.48216698] , error: 1.5540701212544192\n",
      "Step: 1152 Weights: [-2.6950463   2.48136941] , error: 1.549148555894447\n",
      "Step: 1153 Weights: [-2.68808827  2.48057366] , error: 1.544249411368026\n",
      "Step: 1154 Weights: [-2.68114611  2.47977972] , error: 1.5393725855341178\n",
      "Step: 1155 Weights: [-2.67421978  2.4789876 ] , error: 1.53451797671701\n",
      "Step: 1156 Weights: [-2.66730924  2.47819728] , error: 1.5296854837041791\n",
      "Step: 1157 Weights: [-2.66041447  2.47740877] , error: 1.5248750057441953\n",
      "Step: 1158 Weights: [-2.65353542  2.47662205] , error: 1.5200864425446037\n",
      "Step: 1159 Weights: [-2.64667205  2.47583713] , error: 1.5153196942698575\n",
      "Step: 1160 Weights: [-2.63982433  2.47505399] , error: 1.51057466153922\n",
      "Step: 1161 Weights: [-2.63299224  2.47427264] , error: 1.505851245424687\n",
      "Step: 1162 Weights: [-2.62617572  2.47349308] , error: 1.501149347448948\n",
      "Step: 1163 Weights: [-2.61937474  2.47271529] , error: 1.4964688695833113\n",
      "Step: 1164 Weights: [-2.61258928  2.47193928] , error: 1.4918097142456657\n",
      "Step: 1165 Weights: [-2.60581929  2.47116503] , error: 1.4871717842984604\n",
      "Step: 1166 Weights: [-2.59906473  2.47039255] , error: 1.4825549830466467\n",
      "Step: 1167 Weights: [-2.59232558  2.46962183] , error: 1.4779592142356992\n",
      "Step: 1168 Weights: [-2.5856018   2.46885287] , error: 1.4733843820495884\n",
      "Step: 1169 Weights: [-2.57889335  2.46808567] , error: 1.4688303911087868\n",
      "Step: 1170 Weights: [-2.5722002   2.46732021] , error: 1.464297146468278\n",
      "Step: 1171 Weights: [-2.56552231  2.4665565 ] , error: 1.459784553615581\n",
      "Step: 1172 Weights: [-2.55885965  2.46579453] , error: 1.4552925184687848\n",
      "Step: 1173 Weights: [-2.55221219  2.4650343 ] , error: 1.4508209473745735\n",
      "Step: 1174 Weights: [-2.54557988  2.4642758 ] , error: 1.4463697471062837\n",
      "Step: 1175 Weights: [-2.5389627   2.46351903] , error: 1.4419388248619596\n",
      "Step: 1176 Weights: [-2.53236061  2.46276399] , error: 1.437528088262415\n",
      "Step: 1177 Weights: [-2.52577357  2.46201067] , error: 1.4331374453493082\n",
      "Step: 1178 Weights: [-2.51920155  2.46125906] , error: 1.428766804583228\n",
      "Step: 1179 Weights: [-2.51264452  2.46050917] , error: 1.4244160748417842\n",
      "Step: 1180 Weights: [-2.50610245  2.45976099] , error: 1.4200851654177025\n",
      "Step: 1181 Weights: [-2.49957529  2.45901452] , error: 1.4157739860169383\n",
      "Step: 1182 Weights: [-2.49306302  2.45826975] , error: 1.411482446756796\n",
      "Step: 1183 Weights: [-2.4865656   2.45752668] , error: 1.4072104581640559\n",
      "Step: 1184 Weights: [-2.48008299  2.4567853 ] , error: 1.4029579311730902\n",
      "Step: 1185 Weights: [-2.47361517  2.45604561] , error: 1.3987247771240372\n",
      "Step: 1186 Weights: [-2.4671621   2.45530761] , error: 1.3945109077609308\n",
      "Step: 1187 Weights: [-2.46072374  2.45457129] , error: 1.390316235229865\n",
      "Step: 1188 Weights: [-2.45430006  2.45383665] , error: 1.3861406720771636\n",
      "Step: 1189 Weights: [-2.44789104  2.45310369] , error: 1.3819841312475598\n",
      "Step: 1190 Weights: [-2.44149663  2.4523724 ] , error: 1.3778465260823816\n",
      "Step: 1191 Weights: [-2.4351168   2.45164277] , error: 1.3737277703177282\n",
      "Step: 1192 Weights: [-2.42875152  2.45091481] , error: 1.3696277780827029\n",
      "Step: 1193 Weights: [-2.42240075  2.45018851] , error: 1.3655464638975947\n",
      "Step: 1194 Weights: [-2.41606447  2.44946387] , error: 1.361483742672105\n",
      "Step: 1195 Weights: [-2.40974263  2.44874088] , error: 1.3574395297035822\n",
      "Step: 1196 Weights: [-2.40343522  2.44801954] , error: 1.3534137406752451\n",
      "Step: 1197 Weights: [-2.39714218  2.44729984] , error: 1.3494062916544303\n",
      "Step: 1198 Weights: [-2.3908635   2.44658178] , error: 1.345417099090834\n",
      "Step: 1199 Weights: [-2.38459914  2.44586536] , error: 1.341446079814784\n",
      "Step: 1200 Weights: [-2.37834906  2.44515058] , error: 1.3374931510354995\n",
      "Step: 1201 Weights: [-2.37211323  2.44443742] , error: 1.3335582303393578\n",
      "Step: 1202 Weights: [-2.36589162  2.44372589] , error: 1.3296412356881853\n",
      "Step: 1203 Weights: [-2.3596842   2.44301599] , error: 1.3257420854175421\n",
      "Step: 1204 Weights: [-2.35349094  2.4423077 ] , error: 1.3218606982350267\n",
      "Step: 1205 Weights: [-2.3473118   2.44160103] , error: 1.3179969932185664\n",
      "Step: 1206 Weights: [-2.34114675  2.44089596] , error: 1.3141508898147527\n",
      "Step: 1207 Weights: [-2.33499576  2.44019251] , error: 1.310322307837135\n",
      "Step: 1208 Weights: [-2.3288588   2.43949066] , error: 1.3065111674645746\n",
      "Step: 1209 Weights: [-2.32273583  2.43879041] , error: 1.302717389239554\n",
      "Step: 1210 Weights: [-2.31662683  2.43809176] , error: 1.2989408940665483\n",
      "Step: 1211 Weights: [-2.31053175  2.4373947 ] , error: 1.2951816032103594\n",
      "Step: 1212 Weights: [-2.30445058  2.43669924] , error: 1.2914394382944723\n",
      "Step: 1213 Weights: [-2.29838327  2.43600535] , error: 1.2877143212994329\n",
      "Step: 1214 Weights: [-2.2923298   2.43531305] , error: 1.2840061745612104\n",
      "Step: 1215 Weights: [-2.28629013  2.43462233] , error: 1.280314920769583\n",
      "Step: 1216 Weights: [-2.28026424  2.43393318] , error: 1.2766404829665325\n",
      "Step: 1217 Weights: [-2.27425208  2.43324561] , error: 1.2729827845446187\n",
      "Step: 1218 Weights: [-2.26825364  2.4325596 ] , error: 1.2693417492454118\n",
      "Step: 1219 Weights: [-2.26226888  2.43187516] , error: 1.2657173011578795\n",
      "Step: 1220 Weights: [-2.25629776  2.43119228] , error: 1.2621093647168131\n",
      "Step: 1221 Weights: [-2.25034026  2.43051095] , error: 1.258517864701251\n",
      "Step: 1222 Weights: [-2.24439635  2.42983118] , error: 1.2549427262329103\n",
      "Step: 1223 Weights: [-2.23846599  2.42915296] , error: 1.2513838747746298\n",
      "Step: 1224 Weights: [-2.23254916  2.42847629] , error: 1.2478412361288036\n",
      "Step: 1225 Weights: [-2.22664581  2.42780115] , error: 1.244314736435853\n",
      "Step: 1226 Weights: [-2.22075593  2.42712756] , error: 1.2408043021726676\n",
      "Step: 1227 Weights: [-2.21487949  2.42645551] , error: 1.237309860151086\n",
      "Step: 1228 Weights: [-2.20901644  2.42578498] , error: 1.2338313375163628\n",
      "Step: 1229 Weights: [-2.20316676  2.42511599] , error: 1.2303686617456526\n",
      "Step: 1230 Weights: [-2.19733042  2.42444852] , error: 1.2269217606465004\n",
      "Step: 1231 Weights: [-2.19150739  2.42378258] , error: 1.2234905623553276\n",
      "Step: 1232 Weights: [-2.18569764  2.42311815] , error: 1.2200749953359415\n",
      "Step: 1233 Weights: [-2.17990114  2.42245524] , error: 1.2166749883780446\n",
      "Step: 1234 Weights: [-2.17411786  2.42179384] , error: 1.2132904705957446\n",
      "Step: 1235 Weights: [-2.16834776  2.42113394] , error: 1.209921371426081\n",
      "Step: 1236 Weights: [-2.16259083  2.42047556] , error: 1.206567620627549\n",
      "Step: 1237 Weights: [-2.15684702  2.41981867] , error: 1.2032291482786404\n",
      "Step: 1238 Weights: [-2.15111631  2.41916328] , error: 1.1999058847763853\n",
      "Step: 1239 Weights: [-2.14539867  2.41850939] , error: 1.1965977608348957\n",
      "Step: 1240 Weights: [-2.13969406  2.41785699] , error: 1.1933047074839225\n",
      "Step: 1241 Weights: [-2.13400247  2.41720607] , error: 1.1900266560674275\n",
      "Step: 1242 Weights: [-2.12832386  2.41655664] , error: 1.1867635382421404\n",
      "Step: 1243 Weights: [-2.12265819  2.41590869] , error: 1.183515285976133\n",
      "Step: 1244 Weights: [-2.11700544  2.41526222] , error: 1.1802818315474126\n",
      "Step: 1245 Weights: [-2.11136559  2.41461722] , error: 1.177063107542495\n",
      "Step: 1246 Weights: [-2.1057386  2.4139737] , error: 1.1738590468550154\n",
      "Step: 1247 Weights: [-2.10012444  2.41333164] , error: 1.1706695826843156\n",
      "Step: 1248 Weights: [-2.09452308  2.41269104] , error: 1.1674946485340585\n",
      "Step: 1249 Weights: [-2.08893449  2.41205191] , error: 1.1643341782108367\n",
      "Step: 1250 Weights: [-2.08335865  2.41141423] , error: 1.1611881058227989\n",
      "Step: 1251 Weights: [-2.07779552  2.41077801] , error: 1.1580563657782728\n",
      "Step: 1252 Weights: [-2.07224508  2.41014324] , error: 1.1549388927843947\n",
      "Step: 1253 Weights: [-2.0667073   2.40950991] , error: 1.1518356218457515\n",
      "Step: 1254 Weights: [-2.06118215  2.40887803] , error: 1.14874648826303\n",
      "Step: 1255 Weights: [-2.05566959  2.40824759] , error: 1.1456714276316575\n",
      "Step: 1256 Weights: [-2.05016961  2.40761859] , error: 1.1426103758404695\n",
      "Step: 1257 Weights: [-2.04468217  2.40699102] , error: 1.13956326907036\n",
      "Step: 1258 Weights: [-2.03920724  2.40636489] , error: 1.1365300437929693\n",
      "Step: 1259 Weights: [-2.0337448   2.40574018] , error: 1.133510636769341\n",
      "Step: 1260 Weights: [-2.02829481  2.4051169 ] , error: 1.1305049850486215\n",
      "Step: 1261 Weights: [-2.02285726  2.40449504] , error: 1.1275130259667274\n",
      "Step: 1262 Weights: [-2.0174321   2.40387459] , error: 1.1245346971450583\n",
      "Step: 1263 Weights: [-2.01201931  2.40325556] , error: 1.1215699364891847\n",
      "Step: 1264 Weights: [-2.00661887  2.40263795] , error: 1.118618682187552\n",
      "Step: 1265 Weights: [-2.00123074  2.40202174] , error: 1.1156808727102003\n",
      "Step: 1266 Weights: [-1.9958549   2.40140693] , error: 1.1127564468074818\n",
      "Step: 1267 Weights: [-1.99049132  2.40079353] , error: 1.109845343508773\n",
      "Step: 1268 Weights: [-1.98513997  2.40018153] , error: 1.1069475021212094\n",
      "Step: 1269 Weights: [-1.97980082  2.39957092] , error: 1.104062862228424\n",
      "Step: 1270 Weights: [-1.97447385  2.39896171] , error: 1.1011913636892872\n",
      "Step: 1271 Weights: [-1.96915903  2.39835388] , error: 1.0983329466366436\n",
      "Step: 1272 Weights: [-1.96385633  2.39774744] , error: 1.095487551476075\n",
      "Step: 1273 Weights: [-1.95856572  2.39714238] , error: 1.0926551188846516\n",
      "Step: 1274 Weights: [-1.95328717  2.39653871] , error: 1.089835589809695\n",
      "Step: 1275 Weights: [-1.94802066  2.39593641] , error: 1.0870289054675537\n",
      "Step: 1276 Weights: [-1.94276616  2.39533548] , error: 1.0842350073423723\n",
      "Step: 1277 Weights: [-1.93752364  2.39473592] , error: 1.0814538371848645\n",
      "Step: 1278 Weights: [-1.93229308  2.39413774] , error: 1.0786853370111167\n",
      "Step: 1279 Weights: [-1.92707445  2.39354091] , error: 1.0759294491013631\n",
      "Step: 1280 Weights: [-1.92186772  2.39294545] , error: 1.0731861159987872\n",
      "Step: 1281 Weights: [-1.91667286  2.39235134] , error: 1.0704552805083234\n",
      "Step: 1282 Weights: [-1.91148984  2.39175859] , error: 1.0677368856954739\n",
      "Step: 1283 Weights: [-1.90631865  2.39116719] , error: 1.0650308748851012\n",
      "Step: 1284 Weights: [-1.90115925  2.39057714] , error: 1.0623371916602713\n",
      "Step: 1285 Weights: [-1.89601161  2.38998843] , error: 1.0596557798610533\n",
      "Step: 1286 Weights: [-1.89087572  2.38940107] , error: 1.0569865835833692\n",
      "Step: 1287 Weights: [-1.88575153  2.38881505] , error: 1.0543295471778151\n",
      "Step: 1288 Weights: [-1.88063903  2.38823036] , error: 1.0516846152485058\n",
      "Step: 1289 Weights: [-1.87553819  2.38764701] , error: 1.0490517326519182\n",
      "Step: 1290 Weights: [-1.87044898  2.38706498] , error: 1.0464308444957446\n",
      "Step: 1291 Weights: [-1.86537138  2.38648429] , error: 1.0438218961377472\n",
      "Step: 1292 Weights: [-1.86030535  2.38590491] , error: 1.0412248331846152\n",
      "Step: 1293 Weights: [-1.85525088  2.38532686] , error: 1.0386396014908352\n",
      "Step: 1294 Weights: [-1.85020794  2.38475013] , error: 1.0360661471575596\n",
      "Step: 1295 Weights: [-1.84517649  2.38417471] , error: 1.0335044165314873\n",
      "Step: 1296 Weights: [-1.84015652  2.38360061] , error: 1.0309543562037389\n",
      "Step: 1297 Weights: [-1.83514799  2.38302781] , error: 1.028415913008744\n",
      "Step: 1298 Weights: [-1.83015089  2.38245632] , error: 1.0258890340231404\n",
      "Step: 1299 Weights: [-1.82516519  2.38188614] , error: 1.0233736665646618\n",
      "Step: 1300 Weights: [-1.82019085  2.38131725] , error: 1.0208697581910422\n",
      "Step: 1301 Weights: [-1.81522785  2.38074966] , error: 1.0183772566989284\n",
      "Step: 1302 Weights: [-1.81027618  2.38018337] , error: 1.015896110122778\n",
      "Step: 1303 Weights: [-1.80533579  2.37961836] , error: 1.013426266733789\n",
      "Step: 1304 Weights: [-1.80040667  2.37905465] , error: 1.0109676750388197\n",
      "Step: 1305 Weights: [-1.7954888   2.37849222] , error: 1.0085202837793061\n",
      "Step: 1306 Weights: [-1.79058213  2.37793107] , error: 1.0060840419302026\n",
      "Step: 1307 Weights: [-1.78568666  2.37737121] , error: 1.0036588986989183\n",
      "Step: 1308 Weights: [-1.78080235  2.37681262] , error: 1.0012448035242445\n",
      "Step: 1309 Weights: [-1.77592918  2.3762553 ] , error: 0.9988417060753212\n",
      "Step: 1310 Weights: [-1.77106712  2.37569925] , error: 0.9964495562505715\n",
      "Step: 1311 Weights: [-1.76621615  2.37514448] , error: 0.9940683041766638\n",
      "Step: 1312 Weights: [-1.76137624  2.37459096] , error: 0.9916979002074724\n",
      "Step: 1313 Weights: [-1.75654737  2.37403871] , error: 0.9893382949230409\n",
      "Step: 1314 Weights: [-1.7517295   2.37348772] , error: 0.9869894391285472\n",
      "Step: 1315 Weights: [-1.74692263  2.37293799] , error: 0.9846512838532895\n",
      "Step: 1316 Weights: [-1.74212672  2.37238951] , error: 0.982323780349655\n",
      "Step: 1317 Weights: [-1.73734174  2.37184228] , error: 0.9800068800921065\n",
      "Step: 1318 Weights: [-1.73256768  2.3712963 ] , error: 0.977700534776172\n",
      "Step: 1319 Weights: [-1.7278045   2.37075156] , error: 0.9754046963174393\n",
      "Step: 1320 Weights: [-1.72305219  2.37020806] , error: 0.9731193168505454\n",
      "Step: 1321 Weights: [-1.71831071  2.36966581] , error: 0.9708443487281915\n",
      "Step: 1322 Weights: [-1.71358005  2.36912479] , error: 0.9685797445201318\n",
      "Step: 1323 Weights: [-1.70886017  2.36858501] , error: 0.9663254570122077\n",
      "Step: 1324 Weights: [-1.70415105  2.36804645] , error: 0.9640814392053432\n",
      "Step: 1325 Weights: [-1.69945268  2.36750912] , error: 0.961847644314573\n",
      "Step: 1326 Weights: [-1.69476502  2.36697302] , error: 0.9596240257680704\n",
      "Step: 1327 Weights: [-1.69008805  2.36643815] , error: 0.9574105372061676\n",
      "Step: 1328 Weights: [-1.68542174  2.36590449] , error: 0.9552071324803988\n",
      "Step: 1329 Weights: [-1.68076608  2.36537205] , error: 0.9530137656525322\n",
      "Step: 1330 Weights: [-1.67612103  2.36484082] , error: 0.9508303909936118\n",
      "Step: 1331 Weights: [-1.67148658  2.3643108 ] , error: 0.9486569629830096\n",
      "Step: 1332 Weights: [-1.66686269  2.363782  ] , error: 0.9464934363074693\n",
      "Step: 1333 Weights: [-1.66224935  2.36325439] , error: 0.944339765860167\n",
      "Step: 1334 Weights: [-1.65764652  2.362728  ] , error: 0.9421959067397689\n",
      "Step: 1335 Weights: [-1.6530542  2.3622028] , error: 0.9400618142494916\n",
      "Step: 1336 Weights: [-1.64847235  2.3616788 ] , error: 0.9379374438961774\n",
      "Step: 1337 Weights: [-1.64390094  2.36115599] , error: 0.935822751389364\n",
      "Step: 1338 Weights: [-1.63933996  2.36063438] , error: 0.9337176926403551\n",
      "Step: 1339 Weights: [-1.63478938  2.36011396] , error: 0.931622223761311\n",
      "Step: 1340 Weights: [-1.63024918  2.35959472] , error: 0.9295363010643286\n",
      "Step: 1341 Weights: [-1.62571933  2.35907667] , error: 0.9274598810605279\n",
      "Step: 1342 Weights: [-1.62119981  2.3585598 ] , error: 0.9253929204591472\n",
      "Step: 1343 Weights: [-1.6166906  2.3580441] , error: 0.9233353761666472\n",
      "Step: 1344 Weights: [-1.61219167  2.35752959] , error: 0.9212872052858008\n",
      "Step: 1345 Weights: [-1.607703    2.35701625] , error: 0.9192483651148091\n",
      "Step: 1346 Weights: [-1.60322457  2.35650407] , error: 0.917218813146405\n",
      "Step: 1347 Weights: [-1.59875635  2.35599307] , error: 0.9151985070669673\n",
      "Step: 1348 Weights: [-1.59429832  2.35548323] , error: 0.9131874047556425\n",
      "Step: 1349 Weights: [-1.58985045  2.35497455] , error: 0.9111854642834665\n",
      "Step: 1350 Weights: [-1.58541273  2.35446704] , error: 0.9091926439124794\n",
      "Step: 1351 Weights: [-1.58098513  2.35396068] , error: 0.907208902094873\n",
      "Step: 1352 Weights: [-1.57656762  2.35345547] , error: 0.9052341974721123\n",
      "Step: 1353 Weights: [-1.57216019  2.35295142] , error: 0.9032684888740758\n",
      "Step: 1354 Weights: [-1.56776281  2.35244852] , error: 0.9013117353181959\n",
      "Step: 1355 Weights: [-1.56337546  2.35194676] , error: 0.8993638960086122\n",
      "Step: 1356 Weights: [-1.55899811  2.35144615] , error: 0.8974249303353096\n",
      "Step: 1357 Weights: [-1.55463074  2.35094668] , error: 0.8954947978732828\n",
      "Step: 1358 Weights: [-1.55027334  2.35044835] , error: 0.8935734583816821\n",
      "Step: 1359 Weights: [-1.54592587  2.34995115] , error: 0.8916608718029801\n",
      "Step: 1360 Weights: [-1.54158831  2.34945509] , error: 0.8897569982621434\n",
      "Step: 1361 Weights: [-1.53726065  2.34896016] , error: 0.8878617980657882\n",
      "Step: 1362 Weights: [-1.53294285  2.34846636] , error: 0.8859752317013626\n",
      "Step: 1363 Weights: [-1.5286349   2.34797368] , error: 0.8840972598363193\n",
      "Step: 1364 Weights: [-1.52433678  2.34748213] , error: 0.8822278433172918\n",
      "Step: 1365 Weights: [-1.52004845  2.3469917 ] , error: 0.8803669431692859\n",
      "Step: 1366 Weights: [-1.51576991  2.34650239] , error: 0.8785145205948593\n",
      "Step: 1367 Weights: [-1.51150112  2.34601419] , error: 0.8766705369733203\n",
      "Step: 1368 Weights: [-1.50724207  2.34552711] , error: 0.8748349538599198\n",
      "Step: 1369 Weights: [-1.50299272  2.34504114] , error: 0.8730077329850404\n",
      "Step: 1370 Weights: [-1.49875307  2.34455627] , error: 0.8711888362534186\n",
      "Step: 1371 Weights: [-1.49452309  2.34407251] , error: 0.8693782257433285\n",
      "Step: 1372 Weights: [-1.49030276  2.34358986] , error: 0.8675758637058102\n",
      "Step: 1373 Weights: [-1.48609204  2.3431083 ] , error: 0.8657817125638658\n",
      "Step: 1374 Weights: [-1.48189093  2.34262785] , error: 0.8639957349116911\n",
      "Step: 1375 Weights: [-1.4776994   2.34214849] , error: 0.8622178935138856\n",
      "Step: 1376 Weights: [-1.47351743  2.34167022] , error: 0.8604481513046807\n",
      "Step: 1377 Weights: [-1.469345    2.34119304] , error: 0.8586864713871658\n",
      "Step: 1378 Weights: [-1.46518208  2.34071695] , error: 0.8569328170325159\n",
      "Step: 1379 Weights: [-1.46102865  2.34024195] , error: 0.8551871516792346\n",
      "Step: 1380 Weights: [-1.4568847   2.33976803] , error: 0.8534494389323808\n",
      "Step: 1381 Weights: [-1.45275019  2.33929519] , error: 0.8517196425628186\n",
      "Step: 1382 Weights: [-1.44862511  2.33882343] , error: 0.8499977265064598\n",
      "Step: 1383 Weights: [-1.44450944  2.33835274] , error: 0.848283654863506\n",
      "Step: 1384 Weights: [-1.44040316  2.33788313] , error: 0.8465773918977078\n",
      "Step: 1385 Weights: [-1.43630624  2.33741459] , error: 0.8448789020356176\n",
      "Step: 1386 Weights: [-1.43221866  2.33694712] , error: 0.843188149865847\n",
      "Step: 1387 Weights: [-1.42814041  2.33648071] , error: 0.8415051001383278\n",
      "Step: 1388 Weights: [-1.42407145  2.33601537] , error: 0.8398297177635798\n",
      "Step: 1389 Weights: [-1.42001177  2.33555108] , error: 0.8381619678119757\n",
      "Step: 1390 Weights: [-1.41596135  2.33508786] , error: 0.8365018155130157\n",
      "Step: 1391 Weights: [-1.41192017  2.3346257 ] , error: 0.8348492262546\n",
      "Step: 1392 Weights: [-1.4078882   2.33416458] , error: 0.8332041655823108\n",
      "Step: 1393 Weights: [-1.40386543  2.33370452] , error: 0.8315665991986896\n",
      "Step: 1394 Weights: [-1.39985183  2.33324551] , error: 0.829936492962531\n",
      "Step: 1395 Weights: [-1.39584738  2.33278754] , error: 0.8283138128881529\n",
      "Step: 1396 Weights: [-1.39185207  2.33233062] , error: 0.8266985251447097\n",
      "Step: 1397 Weights: [-1.38786587  2.33187474] , error: 0.8250905960554713\n",
      "Step: 1398 Weights: [-1.38388875  2.3314199 ] , error: 0.8234899920971286\n",
      "Step: 1399 Weights: [-1.37992071  2.3309661 ] , error: 0.8218966798990895\n",
      "Step: 1400 Weights: [-1.37596171  2.33051333] , error: 0.82031062624279\n",
      "Step: 1401 Weights: [-1.37201175  2.3300616 ] , error: 0.818731798060994\n",
      "Step: 1402 Weights: [-1.36807079  2.32961089] , error: 0.8171601624371105\n",
      "Step: 1403 Weights: [-1.36413881  2.32916122] , error: 0.8155956866045033\n",
      "Step: 1404 Weights: [-1.36021581  2.32871257] , error: 0.8140383379458055\n",
      "Step: 1405 Weights: [-1.35630175  2.32826494] , error: 0.8124880839922504\n",
      "Step: 1406 Weights: [-1.35239661  2.32781833] , error: 0.8109448924229772\n",
      "Step: 1407 Weights: [-1.34850039  2.32737274] , error: 0.809408731064375\n",
      "Step: 1408 Weights: [-1.34461304  2.32692817] , error: 0.8078795678894027\n",
      "Step: 1409 Weights: [-1.34073456  2.32648461] , error: 0.8063573710169193\n",
      "Step: 1410 Weights: [-1.33686493  2.32604206] , error: 0.8048421087110221\n",
      "Step: 1411 Weights: [-1.33300412  2.32560052] , error: 0.8033337493803918\n",
      "Step: 1412 Weights: [-1.32915211  2.32515999] , error: 0.8018322615776221\n",
      "Step: 1413 Weights: [-1.32530889  2.32472046] , error: 0.8003376139985696\n",
      "Step: 1414 Weights: [-1.32147443  2.32428194] , error: 0.7988497754817032\n",
      "Step: 1415 Weights: [-1.31764872  2.32384441] , error: 0.7973687150074489\n",
      "Step: 1416 Weights: [-1.31383173  2.32340789] , error: 0.7958944016975515\n",
      "Step: 1417 Weights: [-1.31002345  2.32297236] , error: 0.7944268048144214\n",
      "Step: 1418 Weights: [-1.30622385  2.32253782] , error: 0.7929658937605001\n",
      "Step: 1419 Weights: [-1.30243291  2.32210427] , error: 0.79151163807762\n",
      "Step: 1420 Weights: [-1.29865062  2.32167171] , error: 0.7900640074463668\n",
      "Step: 1421 Weights: [-1.29487695  2.32124014] , error: 0.7886229716854571\n",
      "Step: 1422 Weights: [-1.29111189  2.32080955] , error: 0.7871885007510955\n",
      "Step: 1423 Weights: [-1.28735542  2.32037994] , error: 0.7857605647363586\n",
      "Step: 1424 Weights: [-1.28360751  2.31995132] , error: 0.7843391338705648\n",
      "Step: 1425 Weights: [-1.27986815  2.31952367] , error: 0.7829241785186616\n",
      "Step: 1426 Weights: [-1.27613732  2.319097  ] , error: 0.7815156691805965\n",
      "Step: 1427 Weights: [-1.27241499  2.31867129] , error: 0.7801135764907159\n",
      "Step: 1428 Weights: [-1.26870115  2.31824656] , error: 0.7787178712171368\n",
      "Step: 1429 Weights: [-1.26499578  2.3178228 ] , error: 0.7773285242611574\n",
      "Step: 1430 Weights: [-1.26129886  2.31740001] , error: 0.7759455066566248\n",
      "Step: 1431 Weights: [-1.25761038  2.31697818] , error: 0.7745687895693545\n",
      "Step: 1432 Weights: [-1.2539303   2.31655731] , error: 0.7731983442965185\n",
      "Step: 1433 Weights: [-1.25025862  2.3161374 ] , error: 0.771834142266044\n",
      "Step: 1434 Weights: [-1.2465953   2.31571845] , error: 0.7704761550360302\n",
      "Step: 1435 Weights: [-1.24294035  2.31530045] , error: 0.7691243542941394\n",
      "Step: 1436 Weights: [-1.23929372  2.31488341] , error: 0.767778711857017\n",
      "Step: 1437 Weights: [-1.23565542  2.31446731] , error: 0.7664391996697013\n",
      "Step: 1438 Weights: [-1.2320254   2.31405217] , error: 0.7651057898050415\n",
      "Step: 1439 Weights: [-1.22840367  2.31363797] , error: 0.7637784544631062\n",
      "Step: 1440 Weights: [-1.2247902   2.31322472] , error: 0.762457165970619\n",
      "Step: 1441 Weights: [-1.22118497  2.31281241] , error: 0.7611418967803605\n",
      "Step: 1442 Weights: [-1.21758795  2.31240104] , error: 0.7598326194706225\n",
      "Step: 1443 Weights: [-1.21399914  2.31199061] , error: 0.7585293067446061\n",
      "Step: 1444 Weights: [-1.21041852  2.31158112] , error: 0.757231931429871\n",
      "Step: 1445 Weights: [-1.20684606  2.31117256] , error: 0.7559404664777647\n",
      "Step: 1446 Weights: [-1.20328175  2.31076493] , error: 0.7546548849628605\n",
      "Step: 1447 Weights: [-1.19972556  2.31035822] , error: 0.7533751600823912\n",
      "Step: 1448 Weights: [-1.19617749  2.30995245] , error: 0.7521012651556948\n",
      "Step: 1449 Weights: [-1.1926375  2.3095476] , error: 0.7508331736236526\n",
      "Step: 1450 Weights: [-1.18910559  2.30914368] , error: 0.7495708590481465\n",
      "Step: 1451 Weights: [-1.18558173  2.30874068] , error: 0.748314295111496\n",
      "Step: 1452 Weights: [-1.18206591  2.30833859] , error: 0.7470634556159126\n",
      "Step: 1453 Weights: [-1.17855811  2.30793743] , error: 0.745818314482961\n",
      "Step: 1454 Weights: [-1.1750583   2.30753717] , error: 0.7445788457530027\n",
      "Step: 1455 Weights: [-1.17156648  2.30713783] , error: 0.7433450235846679\n",
      "Step: 1456 Weights: [-1.16808262  2.3067394 ] , error: 0.7421168222543082\n",
      "Step: 1457 Weights: [-1.1646067   2.30634188] , error: 0.7408942161554595\n",
      "Step: 1458 Weights: [-1.16113871  2.30594527] , error: 0.7396771797983173\n",
      "Step: 1459 Weights: [-1.15767863  2.30554956] , error: 0.7384656878091949\n",
      "Step: 1460 Weights: [-1.15422644  2.30515475] , error: 0.7372597149299982\n",
      "Step: 1461 Weights: [-1.15078212  2.30476085] , error: 0.7360592360177035\n",
      "Step: 1462 Weights: [-1.14734566  2.30436784] , error: 0.7348642260438265\n",
      "Step: 1463 Weights: [-1.14391703  2.30397573] , error: 0.7336746600939046\n",
      "Step: 1464 Weights: [-1.14049622  2.30358451] , error: 0.7324905133669766\n",
      "Step: 1465 Weights: [-1.13708321  2.30319418] , error: 0.7313117611750627\n",
      "Step: 1466 Weights: [-1.13367799  2.30280475] , error: 0.7301383789426554\n",
      "Step: 1467 Weights: [-1.13028053  2.3024162 ] , error: 0.7289703422062024\n",
      "Step: 1468 Weights: [-1.12689082  2.30202854] , error: 0.7278076266136007\n",
      "Step: 1469 Weights: [-1.12350883  2.30164176] , error: 0.7266502079236831\n",
      "Step: 1470 Weights: [-1.12013456  2.30125586] , error: 0.7254980620057188\n",
      "Step: 1471 Weights: [-1.11676799  2.30087085] , error: 0.7243511648389067\n",
      "Step: 1472 Weights: [-1.11340909  2.30048671] , error: 0.7232094925118742\n",
      "Step: 1473 Weights: [-1.11005785  2.30010345] , error: 0.7220730212221826\n",
      "Step: 1474 Weights: [-1.10671426  2.29972106] , error: 0.7209417272758298\n",
      "Step: 1475 Weights: [-1.10337829  2.29933954] , error: 0.7198155870867466\n",
      "Step: 1476 Weights: [-1.10004992  2.2989589 ] , error: 0.7186945771763237\n",
      "Step: 1477 Weights: [-1.09672915  2.29857912] , error: 0.7175786741729068\n",
      "Step: 1478 Weights: [-1.09341595  2.29820021] , error: 0.7164678548113113\n",
      "Step: 1479 Weights: [-1.0901103   2.29782216] , error: 0.7153620959323437\n",
      "Step: 1480 Weights: [-1.0868122   2.29744498] , error: 0.7142613744823156\n",
      "Step: 1481 Weights: [-1.08352161  2.29706865] , error: 0.7131656675125635\n",
      "Step: 1482 Weights: [-1.08023853  2.29669318] , error: 0.7120749521789662\n",
      "Step: 1483 Weights: [-1.07696293  2.29631857] , error: 0.7109892057414725\n",
      "Step: 1484 Weights: [-1.07369481  2.29594482] , error: 0.7099084055636277\n",
      "Step: 1485 Weights: [-1.07043413  2.29557191] , error: 0.7088325291121024\n",
      "Step: 1486 Weights: [-1.0671809   2.29519986] , error: 0.7077615539562156\n",
      "Step: 1487 Weights: [-1.06393508  2.29482865] , error: 0.7066954577674764\n",
      "Step: 1488 Weights: [-1.06069666  2.29445829] , error: 0.7056342183191144\n",
      "Step: 1489 Weights: [-1.05746563  2.29408878] , error: 0.7045778134856131\n",
      "Step: 1490 Weights: [-1.05424197  2.29372011] , error: 0.7035262212422535\n",
      "Step: 1491 Weights: [-1.05102565  2.29335228] , error: 0.7024794196646529\n",
      "Step: 1492 Weights: [-1.04781668  2.29298528] , error: 0.7014373869283081\n",
      "Step: 1493 Weights: [-1.04461502  2.29261913] , error: 0.7004001013081399\n",
      "Step: 1494 Weights: [-1.04142066  2.29225381] , error: 0.6993675411780411\n",
      "Step: 1495 Weights: [-1.03823358  2.29188932] , error: 0.698339685010424\n",
      "Step: 1496 Weights: [-1.03505378  2.29152567] , error: 0.6973165113757753\n",
      "Step: 1497 Weights: [-1.03188122  2.29116284] , error: 0.6962979989422033\n",
      "Step: 1498 Weights: [-1.0287159   2.29080084] , error: 0.6952841264749978\n",
      "Step: 1499 Weights: [-1.0255578   2.29043967] , error: 0.6942748728361854\n",
      "Step: 1500 Weights: [-1.0224069   2.29007931] , error: 0.6932702169840923\n",
      "Step: 1501 Weights: [-1.01926318  2.28971979] , error: 0.692270137972899\n",
      "Step: 1502 Weights: [-1.01612664  2.28936108] , error: 0.6912746149522118\n",
      "Step: 1503 Weights: [-1.01299724  2.28900319] , error: 0.6902836271666186\n",
      "Step: 1504 Weights: [-1.00987498  2.28864611] , error: 0.6892971539552651\n",
      "Step: 1505 Weights: [-1.00675985  2.28828985] , error: 0.6883151747514187\n",
      "Step: 1506 Weights: [-1.00365181  2.2879344 ] , error: 0.68733766908204\n",
      "Step: 1507 Weights: [-1.00055087  2.28757977] , error: 0.6863646165673609\n",
      "Step: 1508 Weights: [-0.99745699  2.28722594] , error: 0.6853959969204526\n",
      "Step: 1509 Weights: [-0.99437017  2.28687292] , error: 0.6844317899468079\n",
      "Step: 1510 Weights: [-0.99129039  2.2865207 ] , error: 0.6834719755439167\n",
      "Step: 1511 Weights: [-0.98821764  2.28616929] , error: 0.6825165337008493\n",
      "Step: 1512 Weights: [-0.98515189  2.28581868] , error: 0.6815654444978403\n",
      "Step: 1513 Weights: [-0.98209313  2.28546886] , error: 0.6806186881058682\n",
      "Step: 1514 Weights: [-0.97904135  2.28511985] , error: 0.6796762447862468\n",
      "Step: 1515 Weights: [-0.97599652  2.28477163] , error: 0.6787380948902126\n",
      "Step: 1516 Weights: [-0.97295864  2.2844242 ] , error: 0.6778042188585138\n",
      "Step: 1517 Weights: [-0.96992769  2.28407757] , error: 0.676874597221003\n",
      "Step: 1518 Weights: [-0.96690365  2.28373173] , error: 0.6759492105962297\n",
      "Step: 1519 Weights: [-0.9638865   2.28338668] , error: 0.6750280396910446\n",
      "Step: 1520 Weights: [-0.96087624  2.28304241] , error: 0.6741110653001863\n",
      "Step: 1521 Weights: [-0.95787284  2.28269893] , error: 0.6731982683058819\n",
      "Step: 1522 Weights: [-0.95487629  2.28235623] , error: 0.6722896296774596\n",
      "Step: 1523 Weights: [-0.95188657  2.28201431] , error: 0.6713851304709405\n",
      "Step: 1524 Weights: [-0.94890367  2.28167318] , error: 0.6704847518286445\n",
      "Step: 1525 Weights: [-0.94592758  2.28133282] , error: 0.669588474978809\n",
      "Step: 1526 Weights: [-0.94295826  2.28099323] , error: 0.6686962812351792\n",
      "Step: 1527 Weights: [-0.93999573  2.28065443] , error: 0.6678081519966288\n",
      "Step: 1528 Weights: [-0.93703994  2.28031639] , error: 0.6669240687467797\n",
      "Step: 1529 Weights: [-0.9340909   2.27997913] , error: 0.6660440130535998\n",
      "Step: 1530 Weights: [-0.93114858  2.27964263] , error: 0.6651679665690287\n",
      "Step: 1531 Weights: [-0.92821297  2.2793069 ] , error: 0.6642959110285948\n",
      "Step: 1532 Weights: [-0.92528406  2.27897194] , error: 0.663427828251028\n",
      "Step: 1533 Weights: [-0.92236182  2.27863774] , error: 0.6625637001378926\n",
      "Step: 1534 Weights: [-0.91944625  2.2783043 ] , error: 0.6617035086731944\n",
      "Step: 1535 Weights: [-0.91653733  2.27797162] , error: 0.6608472359230178\n",
      "Step: 1536 Weights: [-0.91363504  2.27763971] , error: 0.6599948640351512\n",
      "Step: 1537 Weights: [-0.91073937  2.27730855] , error: 0.6591463752387029\n",
      "Step: 1538 Weights: [-0.9078503   2.27697814] , error: 0.6583017518437437\n",
      "Step: 1539 Weights: [-0.90496783  2.27664849] , error: 0.6574609762409338\n",
      "Step: 1540 Weights: [-0.90209192  2.27631959] , error: 0.6566240309011524\n",
      "Step: 1541 Weights: [-0.89922257  2.27599144] , error: 0.6557908983751387\n",
      "Step: 1542 Weights: [-0.89635977  2.27566403] , error: 0.6549615612931173\n",
      "Step: 1543 Weights: [-0.89350349  2.27533738] , error: 0.6541360023644516\n",
      "Step: 1544 Weights: [-0.89065373  2.27501147] , error: 0.6533142043772708\n",
      "Step: 1545 Weights: [-0.88781047  2.2746863 ] , error: 0.6524961501981096\n",
      "Step: 1546 Weights: [-0.88497369  2.27436187] , error: 0.65168182277157\n",
      "Step: 1547 Weights: [-0.88214338  2.27403819] , error: 0.6508712051199375\n",
      "Step: 1548 Weights: [-0.87931952  2.27371524] , error: 0.6500642803428489\n",
      "Step: 1549 Weights: [-0.87650211  2.27339303] , error: 0.6492610316169356\n",
      "Step: 1550 Weights: [-0.87369112  2.27307155] , error: 0.6484614421954626\n",
      "Step: 1551 Weights: [-0.87088653  2.27275081] , error: 0.6476654954079938\n",
      "Step: 1552 Weights: [-0.86808835  2.2724308 ] , error: 0.6468731746600315\n",
      "Step: 1553 Weights: [-0.86529654  2.27211151] , error: 0.6460844634326817\n",
      "Step: 1554 Weights: [-0.8625111   2.27179296] , error: 0.645299345282301\n",
      "Step: 1555 Weights: [-0.85973202  2.27147513] , error: 0.6445178038401578\n",
      "Step: 1556 Weights: [-0.85695927  2.27115803] , error: 0.6437398228120926\n",
      "Step: 1557 Weights: [-0.85419284  2.27084165] , error: 0.6429653859781721\n",
      "Step: 1558 Weights: [-0.85143273  2.27052599] , error: 0.6421944771923576\n",
      "Step: 1559 Weights: [-0.8486789   2.27021105] , error: 0.6414270803821676\n",
      "Step: 1560 Weights: [-0.84593136  2.26989683] , error: 0.6406631795483348\n",
      "Step: 1561 Weights: [-0.84319008  2.26958332] , error: 0.6399027587644844\n",
      "Step: 1562 Weights: [-0.84045506  2.26927054] , error: 0.6391458021767957\n",
      "Step: 1563 Weights: [-0.83772627  2.26895846] , error: 0.638392294003668\n",
      "Step: 1564 Weights: [-0.8350037  2.2686471] , error: 0.6376422185354006\n",
      "Step: 1565 Weights: [-0.83228734  2.26833644] , error: 0.6368955601338582\n",
      "Step: 1566 Weights: [-0.82957718  2.2680265 ] , error: 0.6361523032321463\n",
      "Step: 1567 Weights: [-0.82687319  2.26771726] , error: 0.6354124323342888\n",
      "Step: 1568 Weights: [-0.82417538  2.26740872] , error: 0.6346759320149029\n",
      "Step: 1569 Weights: [-0.82148371  2.26710089] , error: 0.633942786918878\n",
      "Step: 1570 Weights: [-0.81879819  2.26679376] , error: 0.6332129817610549\n",
      "Step: 1571 Weights: [-0.81611878  2.26648734] , error: 0.6324865013259156\n",
      "Step: 1572 Weights: [-0.81344549  2.26618161] , error: 0.6317633304672433\n",
      "Step: 1573 Weights: [-0.81077829  2.26587658] , error: 0.6310434541078345\n",
      "Step: 1574 Weights: [-0.80811718  2.26557224] , error: 0.6303268572391664\n",
      "Step: 1575 Weights: [-0.80546213  2.2652686 ] , error: 0.629613524921093\n",
      "Step: 1576 Weights: [-0.80281314  2.26496565] , error: 0.6289034422815248\n",
      "Step: 1577 Weights: [-0.80017019  2.26466339] , error: 0.6281965945161292\n",
      "Step: 1578 Weights: [-0.79753327  2.26436182] , error: 0.6274929668880147\n",
      "Step: 1579 Weights: [-0.79490236  2.26406094] , error: 0.6267925447274241\n",
      "Step: 1580 Weights: [-0.79227745  2.26376074] , error: 0.6260953134314331\n",
      "Step: 1581 Weights: [-0.78965853  2.26346123] , error: 0.6254012584636384\n",
      "Step: 1582 Weights: [-0.78704557  2.2631624 ] , error: 0.6247103653538669\n",
      "Step: 1583 Weights: [-0.78443858  2.26286425] , error: 0.6240226196978573\n",
      "Step: 1584 Weights: [-0.78183753  2.26256679] , error: 0.6233380071569752\n",
      "Step: 1585 Weights: [-0.77924241  2.26227   ] , error: 0.6226565134579061\n",
      "Step: 1586 Weights: [-0.77665321  2.26197389] , error: 0.6219781243923559\n",
      "Step: 1587 Weights: [-0.77406992  2.26167845] , error: 0.6213028258167645\n",
      "Step: 1588 Weights: [-0.77149252  2.26138369] , error: 0.6206306036520018\n",
      "Step: 1589 Weights: [-0.76892099  2.2610896 ] , error: 0.6199614438830734\n",
      "Step: 1590 Weights: [-0.76635533  2.26079618] , error: 0.6192953325588372\n",
      "Step: 1591 Weights: [-0.76379552  2.26050343] , error: 0.6186322557917052\n",
      "Step: 1592 Weights: [-0.76124154  2.26021134] , error: 0.6179721997573557\n",
      "Step: 1593 Weights: [-0.75869339  2.25991993] , error: 0.6173151506944473\n",
      "Step: 1594 Weights: [-0.75615105  2.25962917] , error: 0.6166610949043285\n",
      "Step: 1595 Weights: [-0.75361451  2.25933908] , error: 0.616010018750755\n",
      "Step: 1596 Weights: [-0.75108376  2.25904966] , error: 0.6153619086596017\n",
      "Step: 1597 Weights: [-0.74855877  2.25876089] , error: 0.6147167511185846\n",
      "Step: 1598 Weights: [-0.74603954  2.25847278] , error: 0.6140745326769779\n",
      "Step: 1599 Weights: [-0.74352606  2.25818533] , error: 0.6134352399453283\n",
      "Step: 1600 Weights: [-0.74101831  2.25789853] , error: 0.612798859595183\n",
      "Step: 1601 Weights: [-0.73851628  2.25761239] , error: 0.6121653783588077\n",
      "Step: 1602 Weights: [-0.73601995  2.2573269 ] , error: 0.6115347830289107\n",
      "Step: 1603 Weights: [-0.73352932  2.25704206] , error: 0.6109070604583693\n",
      "Step: 1604 Weights: [-0.73104436  2.25675787] , error: 0.6102821975599532\n",
      "Step: 1605 Weights: [-0.72856507  2.25647433] , error: 0.6096601813060508\n",
      "Step: 1606 Weights: [-0.72609144  2.25619143] , error: 0.6090409987284047\n",
      "Step: 1607 Weights: [-0.72362345  2.25590918] , error: 0.6084246369178279\n",
      "Step: 1608 Weights: [-0.72116108  2.25562757] , error: 0.6078110830239518\n",
      "Step: 1609 Weights: [-0.71870433  2.25534661] , error: 0.6072003242549442\n",
      "Step: 1610 Weights: [-0.71625319  2.25506629] , error: 0.6065923478772496\n",
      "Step: 1611 Weights: [-0.71380763  2.2547866 ] , error: 0.6059871412153196\n",
      "Step: 1612 Weights: [-0.71136765  2.25450755] , error: 0.605384691651352\n",
      "Step: 1613 Weights: [-0.70893323  2.25422914] , error: 0.6047849866250288\n",
      "Step: 1614 Weights: [-0.70650437  2.25395137] , error: 0.6041880136332488\n",
      "Step: 1615 Weights: [-0.70408104  2.25367423] , error: 0.6035937602298742\n",
      "Step: 1616 Weights: [-0.70166324  2.25339772] , error: 0.6030022140254633\n",
      "Step: 1617 Weights: [-0.69925095  2.25312184] , error: 0.602413362687017\n",
      "Step: 1618 Weights: [-0.69684417  2.25284659] , error: 0.6018271939377247\n",
      "Step: 1619 Weights: [-0.69444287  2.25257197] , error: 0.6012436955566965\n",
      "Step: 1620 Weights: [-0.69204705  2.25229797] , error: 0.6006628553787265\n",
      "Step: 1621 Weights: [-0.68965669  2.2520246 ] , error: 0.6000846612940192\n",
      "Step: 1622 Weights: [-0.68727179  2.25175185] , error: 0.5995091012479532\n",
      "Step: 1623 Weights: [-0.68489232  2.25147972] , error: 0.5989361632408212\n",
      "Step: 1624 Weights: [-0.68251828  2.25120822] , error: 0.5983658353275846\n",
      "Step: 1625 Weights: [-0.68014965  2.25093733] , error: 0.597798105617616\n",
      "Step: 1626 Weights: [-0.67778642  2.25066706] , error: 0.5972329622744644\n",
      "Step: 1627 Weights: [-0.67542858  2.25039741] , error: 0.5966703935155953\n",
      "Step: 1628 Weights: [-0.67307612  2.25012837] , error: 0.5961103876121575\n",
      "Step: 1629 Weights: [-0.67072903  2.24985995] , error: 0.5955529328887239\n",
      "Step: 1630 Weights: [-0.66838728  2.24959214] , error: 0.5949980177230669\n",
      "Step: 1631 Weights: [-0.66605088  2.24932494] , error: 0.5944456305458935\n",
      "Step: 1632 Weights: [-0.6637198   2.24905835] , error: 0.5938957598406245\n",
      "Step: 1633 Weights: [-0.66139405  2.24879236] , error: 0.593348394143145\n",
      "Step: 1634 Weights: [-0.65907359  2.24852699] , error: 0.5928035220415618\n",
      "Step: 1635 Weights: [-0.65675843  2.24826221] , error: 0.5922611321759765\n",
      "Step: 1636 Weights: [-0.65444854  2.24799805] , error: 0.5917212132382387\n",
      "Step: 1637 Weights: [-0.65214392  2.24773448] , error: 0.5911837539717103\n",
      "Step: 1638 Weights: [-0.64984456  2.24747152] , error: 0.590648743171042\n",
      "Step: 1639 Weights: [-0.64755044  2.24720915] , error: 0.5901161696819262\n",
      "Step: 1640 Weights: [-0.64526156  2.24694738] , error: 0.5895860224008723\n",
      "Step: 1641 Weights: [-0.64297789  2.24668621] , error: 0.5890582902749739\n",
      "Step: 1642 Weights: [-0.64069943  2.24642564] , error: 0.588532962301673\n",
      "Step: 1643 Weights: [-0.63842617  2.24616566] , error: 0.5880100275285425\n",
      "Step: 1644 Weights: [-0.63615809  2.24590627] , error: 0.5874894750530427\n",
      "Step: 1645 Weights: [-0.63389518  2.24564748] , error: 0.5869712940223082\n",
      "Step: 1646 Weights: [-0.63163743  2.24538927] , error: 0.5864554736329118\n",
      "Step: 1647 Weights: [-0.62938483  2.24513165] , error: 0.5859420031306446\n",
      "Step: 1648 Weights: [-0.62713737  2.24487463] , error: 0.5854308718102889\n",
      "Step: 1649 Weights: [-0.62489503  2.24461818] , error: 0.5849220690153946\n",
      "Step: 1650 Weights: [-0.62265781  2.24436232] , error: 0.5844155841380623\n",
      "Step: 1651 Weights: [-0.62042569  2.24410705] , error: 0.583911406618715\n",
      "Step: 1652 Weights: [-0.61819866  2.24385236] , error: 0.5834095259458804\n",
      "Step: 1653 Weights: [-0.61597671  2.24359824] , error: 0.5829099316559765\n",
      "Step: 1654 Weights: [-0.61375982  2.24334471] , error: 0.5824126133330862\n",
      "Step: 1655 Weights: [-0.61154799  2.24309176] , error: 0.581917560608746\n",
      "Step: 1656 Weights: [-0.60934121  2.24283938] , error: 0.5814247631617238\n",
      "Step: 1657 Weights: [-0.60713945  2.24258758] , error: 0.5809342107178102\n",
      "Step: 1658 Weights: [-0.60494272  2.24233635] , error: 0.5804458930496023\n",
      "Step: 1659 Weights: [-0.602751   2.2420857] , error: 0.5799597999762842\n",
      "Step: 1660 Weights: [-0.60056427  2.24183561] , error: 0.5794759213634276\n",
      "Step: 1661 Weights: [-0.59838253  2.2415861 ] , error: 0.5789942471227645\n",
      "Step: 1662 Weights: [-0.59620577  2.24133716] , error: 0.5785147672119921\n",
      "Step: 1663 Weights: [-0.59403397  2.24108878] , error: 0.5780374716345541\n",
      "Step: 1664 Weights: [-0.59186712  2.24084097] , error: 0.5775623504394329\n",
      "Step: 1665 Weights: [-0.58970522  2.24059373] , error: 0.577089393720948\n",
      "Step: 1666 Weights: [-0.58754824  2.24034705] , error: 0.5766185916185427\n",
      "Step: 1667 Weights: [-0.58539618  2.24010093] , error: 0.5761499343165818\n",
      "Step: 1668 Weights: [-0.58324903  2.23985537] , error: 0.5756834120441475\n",
      "Step: 1669 Weights: [-0.58110678  2.23961037] , error: 0.5752190150748333\n",
      "Step: 1670 Weights: [-0.57896941  2.23936593] , error: 0.5747567337265431\n",
      "Step: 1671 Weights: [-0.57683692  2.23912205] , error: 0.5742965583612933\n",
      "Step: 1672 Weights: [-0.57470929  2.23887873] , error: 0.5738384793849975\n",
      "Step: 1673 Weights: [-0.57258651  2.23863596] , error: 0.573382487247285\n",
      "Step: 1674 Weights: [-0.57046857  2.23839374] , error: 0.572928572441288\n",
      "Step: 1675 Weights: [-0.56835546  2.23815208] , error: 0.572476725503454\n",
      "Step: 1676 Weights: [-0.56624717  2.23791097] , error: 0.572026937013337\n",
      "Step: 1677 Weights: [-0.56414369  2.2376704 ] , error: 0.5715791975934108\n",
      "Step: 1678 Weights: [-0.56204501  2.23743039] , error: 0.571133497908868\n",
      "Step: 1679 Weights: [-0.55995111  2.23719092] , error: 0.5706898286674285\n",
      "Step: 1680 Weights: [-0.55786199  2.236952  ] , error: 0.5702481806191432\n",
      "Step: 1681 Weights: [-0.55577763  2.23671362] , error: 0.5698085445562023\n",
      "Step: 1682 Weights: [-0.55369802  2.23647579] , error: 0.5693709113127456\n",
      "Step: 1683 Weights: [-0.55162316  2.2362385 ] , error: 0.5689352717646645\n",
      "Step: 1684 Weights: [-0.54955302  2.23600175] , error: 0.5685016168294224\n",
      "Step: 1685 Weights: [-0.54748761  2.23576554] , error: 0.5680699374658549\n",
      "Step: 1686 Weights: [-0.54542691  2.23552987] , error: 0.5676402246739884\n",
      "Step: 1687 Weights: [-0.54337091  2.23529474] , error: 0.5672124694948465\n",
      "Step: 1688 Weights: [-0.54131959  2.23506014] , error: 0.5667866630102711\n",
      "Step: 1689 Weights: [-0.53927296  2.23482608] , error: 0.5663627963427295\n",
      "Step: 1690 Weights: [-0.53723099  2.23459255] , error: 0.5659408606551306\n",
      "Step: 1691 Weights: [-0.53519367  2.23435956] , error: 0.5655208471506429\n",
      "Step: 1692 Weights: [-0.53316101  2.23412709] , error: 0.5651027470725128\n",
      "Step: 1693 Weights: [-0.53113298  2.23389516] , error: 0.5646865517038755\n",
      "Step: 1694 Weights: [-0.52910957  2.23366375] , error: 0.5642722523675765\n",
      "Step: 1695 Weights: [-0.52709078  2.23343288] , error: 0.5638598404259954\n",
      "Step: 1696 Weights: [-0.52507659  2.23320252] , error: 0.5634493072808577\n",
      "Step: 1697 Weights: [-0.52306699  2.2329727 ] , error: 0.5630406443730613\n",
      "Step: 1698 Weights: [-0.52106198  2.2327434 ] , error: 0.5626338431824942\n",
      "Step: 1699 Weights: [-0.51906154  2.23251462] , error: 0.5622288952278652\n",
      "Step: 1700 Weights: [-0.51706566  2.23228636] , error: 0.5618257920665123\n",
      "Step: 1701 Weights: [-0.51507433  2.23205862] , error: 0.5614245252942396\n",
      "Step: 1702 Weights: [-0.51308755  2.23183141] , error: 0.5610250865451356\n",
      "Step: 1703 Weights: [-0.51110529  2.23160471] , error: 0.5606274674914032\n",
      "Step: 1704 Weights: [-0.50912756  2.23137853] , error: 0.5602316598431842\n",
      "Step: 1705 Weights: [-0.50715433  2.23115286] , error: 0.5598376553483815\n",
      "Step: 1706 Weights: [-0.50518561  2.23092771] , error: 0.559445445792496\n",
      "Step: 1707 Weights: [-0.50322137  2.23070307] , error: 0.5590550229984512\n",
      "Step: 1708 Weights: [-0.50126161  2.23047894] , error: 0.558666378826414\n",
      "Step: 1709 Weights: [-0.49930633  2.23025533] , error: 0.5582795051736447\n",
      "Step: 1710 Weights: [-0.4973555   2.23003222] , error: 0.5578943939743097\n",
      "Step: 1711 Weights: [-0.49540912  2.22980963] , error: 0.5575110371993234\n",
      "Step: 1712 Weights: [-0.49346718  2.22958754] , error: 0.5571294268561757\n",
      "Step: 1713 Weights: [-0.49152966  2.22936596] , error: 0.5567495549887697\n",
      "Step: 1714 Weights: [-0.48959657  2.22914488] , error: 0.5563714136772504\n",
      "Step: 1715 Weights: [-0.48766788  2.22892431] , error: 0.555994995037846\n",
      "Step: 1716 Weights: [-0.48574359  2.22870424] , error: 0.555620291222698\n",
      "Step: 1717 Weights: [-0.48382369  2.22848467] , error: 0.5552472944197\n",
      "Step: 1718 Weights: [-0.48190817  2.2282656 ] , error: 0.5548759968523367\n",
      "Step: 1719 Weights: [-0.47999702  2.22804703] , error: 0.554506390779518\n",
      "Step: 1720 Weights: [-0.47809022  2.22782897] , error: 0.5541384684954176\n",
      "Step: 1721 Weights: [-0.47618778  2.22761139] , error: 0.5537722223293191\n",
      "Step: 1722 Weights: [-0.47428967  2.22739432] , error: 0.5534076446454474\n",
      "Step: 1723 Weights: [-0.47239589  2.22717774] , error: 0.5530447278428126\n",
      "Step: 1724 Weights: [-0.47050643  2.22696165] , error: 0.5526834643550538\n",
      "Step: 1725 Weights: [-0.46862127  2.22674606] , error: 0.55232384665028\n",
      "Step: 1726 Weights: [-0.46674042  2.22653095] , error: 0.5519658672309112\n",
      "Step: 1727 Weights: [-0.46486385  2.22631634] , error: 0.5516095186335264\n",
      "Step: 1728 Weights: [-0.46299157  2.22610222] , error: 0.5512547934286989\n",
      "Step: 1729 Weights: [-0.46112355  2.22588859] , error: 0.550901684220856\n",
      "Step: 1730 Weights: [-0.4592598   2.22567544] , error: 0.5505501836481104\n",
      "Step: 1731 Weights: [-0.45740029  2.22546278] , error: 0.5502002843821152\n",
      "Step: 1732 Weights: [-0.45554503  2.2252506 ] , error: 0.5498519791279084\n",
      "Step: 1733 Weights: [-0.45369399  2.22503891] , error: 0.5495052606237616\n",
      "Step: 1734 Weights: [-0.45184718  2.2248277 ] , error: 0.5491601216410281\n",
      "Step: 1735 Weights: [-0.45000458  2.22461697] , error: 0.5488165549839913\n",
      "Step: 1736 Weights: [-0.44816618  2.22440673] , error: 0.5484745534897153\n",
      "Step: 1737 Weights: [-0.44633197  2.22419696] , error: 0.5481341100278986\n",
      "Step: 1738 Weights: [-0.44450194  2.22398767] , error: 0.5477952175007199\n",
      "Step: 1739 Weights: [-0.44267609  2.22377886] , error: 0.5474578688426947\n",
      "Step: 1740 Weights: [-0.4408544   2.22357052] , error: 0.5471220570205241\n",
      "Step: 1741 Weights: [-0.43903687  2.22336266] , error: 0.546787775032952\n",
      "Step: 1742 Weights: [-0.43722348  2.22315527] , error: 0.5464550159106176\n",
      "Step: 1743 Weights: [-0.43541423  2.22294836] , error: 0.546123772715911\n",
      "Step: 1744 Weights: [-0.4336091   2.22274192] , error: 0.5457940385428238\n",
      "Step: 1745 Weights: [-0.43180809  2.22253594] , error: 0.5454658065168116\n",
      "Step: 1746 Weights: [-0.43001118  2.22233044] , error: 0.5451390697946471\n",
      "Step: 1747 Weights: [-0.42821837  2.22212541] , error: 0.5448138215642792\n",
      "Step: 1748 Weights: [-0.42642966  2.22192085] , error: 0.5444900550446894\n",
      "Step: 1749 Weights: [-0.42464502  2.22171675] , error: 0.5441677634857502\n",
      "Step: 1750 Weights: [-0.42286445  2.22151311] , error: 0.5438469401680843\n",
      "Step: 1751 Weights: [-0.42108794  2.22130994] , error: 0.543527578402929\n",
      "Step: 1752 Weights: [-0.41931548  2.22110724] , error: 0.5432096715319901\n",
      "Step: 1753 Weights: [-0.41754706  2.22090499] , error: 0.5428932129273075\n",
      "Step: 1754 Weights: [-0.41578268  2.22070321] , error: 0.5425781959911156\n",
      "Step: 1755 Weights: [-0.41402232  2.22050189] , error: 0.5422646141557037\n",
      "Step: 1756 Weights: [-0.41226597  2.22030103] , error: 0.5419524608832837\n",
      "Step: 1757 Weights: [-0.41051363  2.22010062] , error: 0.5416417296658513\n",
      "Step: 1758 Weights: [-0.40876529  2.21990067] , error: 0.541332414025048\n",
      "Step: 1759 Weights: [-0.40702093  2.21970118] , error: 0.5410245075120306\n",
      "Step: 1760 Weights: [-0.40528055  2.21950214] , error: 0.5407180037073326\n",
      "Step: 1761 Weights: [-0.40354414  2.21930356] , error: 0.5404128962207343\n",
      "Step: 1762 Weights: [-0.40181169  2.21910543] , error: 0.5401091786911241\n",
      "Step: 1763 Weights: [-0.40008319  2.21890775] , error: 0.5398068447863743\n",
      "Step: 1764 Weights: [-0.39835863  2.21871052] , error: 0.539505888203201\n",
      "Step: 1765 Weights: [-0.39663801  2.21851375] , error: 0.5392063026670328\n",
      "Step: 1766 Weights: [-0.3949213   2.21831742] , error: 0.5389080819318883\n",
      "Step: 1767 Weights: [-0.39320852  2.21812154] , error: 0.5386112197802391\n",
      "Step: 1768 Weights: [-0.39149963  2.2179261 ] , error: 0.5383157100228797\n",
      "Step: 1769 Weights: [-0.38979465  2.21773111] , error: 0.5380215464988003\n",
      "Step: 1770 Weights: [-0.38809355  2.21753657] , error: 0.5377287230750605\n",
      "Step: 1771 Weights: [-0.38639634  2.21734247] , error: 0.5374372336466587\n",
      "Step: 1772 Weights: [-0.38470299  2.21714881] , error: 0.5371470721364049\n",
      "Step: 1773 Weights: [-0.3830135   2.21695559] , error: 0.5368582324947933\n",
      "Step: 1774 Weights: [-0.38132787  2.21676281] , error: 0.5365707086998801\n",
      "Step: 1775 Weights: [-0.37964608  2.21657048] , error: 0.5362844947571533\n",
      "Step: 1776 Weights: [-0.37796813  2.21637858] , error: 0.5359995846994099\n",
      "Step: 1777 Weights: [-0.376294    2.21618712] , error: 0.5357159725866316\n",
      "Step: 1778 Weights: [-0.37462369  2.2159961 ] , error: 0.5354336525058626\n",
      "Step: 1779 Weights: [-0.37295719  2.21580551] , error: 0.5351526185710797\n",
      "Step: 1780 Weights: [-0.37129449  2.21561536] , error: 0.5348728649230778\n",
      "Step: 1781 Weights: [-0.36963558  2.21542564] , error: 0.5345943857293449\n",
      "Step: 1782 Weights: [-0.36798046  2.21523635] , error: 0.5343171751839368\n",
      "Step: 1783 Weights: [-0.36632911  2.21504749] , error: 0.5340412275073595\n",
      "Step: 1784 Weights: [-0.36468152  2.21485907] , error: 0.5337665369464514\n",
      "Step: 1785 Weights: [-0.36303769  2.21467107] , error: 0.5334930977742555\n",
      "Step: 1786 Weights: [-0.36139761  2.21448351] , error: 0.533220904289909\n",
      "Step: 1787 Weights: [-0.35976127  2.21429637] , error: 0.5329499508185177\n",
      "Step: 1788 Weights: [-0.35812867  2.21410966] , error: 0.5326802317110404\n",
      "Step: 1789 Weights: [-0.35649978  2.21392337] , error: 0.5324117413441709\n",
      "Step: 1790 Weights: [-0.35487461  2.21373751] , error: 0.5321444741202227\n",
      "Step: 1791 Weights: [-0.35325315  2.21355207] , error: 0.5318784244670063\n",
      "Step: 1792 Weights: [-0.35163538  2.21336706] , error: 0.531613586837721\n",
      "Step: 1793 Weights: [-0.3500213   2.21318246] , error: 0.5313499557108329\n",
      "Step: 1794 Weights: [-0.34841091  2.21299829] , error: 0.5310875255899608\n",
      "Step: 1795 Weights: [-0.34680418  2.21281454] , error: 0.5308262910037687\n",
      "Step: 1796 Weights: [-0.34520112  2.21263121] , error: 0.5305662465058392\n",
      "Step: 1797 Weights: [-0.34360172  2.21244829] , error: 0.5303073866745721\n",
      "Step: 1798 Weights: [-0.34200596  2.2122658 ] , error: 0.5300497061130622\n",
      "Step: 1799 Weights: [-0.34041384  2.21208371] , error: 0.5297931994489928\n",
      "Step: 1800 Weights: [-0.33882535  2.21190205] , error: 0.5295378613345197\n",
      "Step: 1801 Weights: [-0.33724049  2.2117208 ] , error: 0.5292836864461666\n",
      "Step: 1802 Weights: [-0.33565924  2.21153996] , error: 0.5290306694846996\n",
      "Step: 1803 Weights: [-0.33408159  2.21135953] , error: 0.5287788051750348\n",
      "Step: 1804 Weights: [-0.33250754  2.21117952] , error: 0.5285280882661161\n",
      "Step: 1805 Weights: [-0.33093709  2.21099991] , error: 0.5282785135308091\n",
      "Step: 1806 Weights: [-0.32937021  2.21082072] , error: 0.5280300757657921\n",
      "Step: 1807 Weights: [-0.3278069   2.21064193] , error: 0.5277827697914499\n",
      "Step: 1808 Weights: [-0.32624717  2.21046355] , error: 0.527536590451762\n",
      "Step: 1809 Weights: [-0.32469098  2.21028558] , error: 0.5272915326141969\n",
      "Step: 1810 Weights: [-0.32313835  2.21010802] , error: 0.5270475911696043\n",
      "Step: 1811 Weights: [-0.32158926  2.20993086] , error: 0.5268047610321125\n",
      "Step: 1812 Weights: [-0.3200437  2.2097541] , error: 0.5265630371390152\n",
      "Step: 1813 Weights: [-0.31850166  2.20957774] , error: 0.5263224144506711\n",
      "Step: 1814 Weights: [-0.31696314  2.20940179] , error: 0.5260828879503999\n",
      "Step: 1815 Weights: [-0.31542813  2.20922624] , error: 0.5258444526443736\n",
      "Step: 1816 Weights: [-0.31389662  2.20905109] , error: 0.5256071035615124\n",
      "Step: 1817 Weights: [-0.31236861  2.20887634] , error: 0.5253708357533868\n",
      "Step: 1818 Weights: [-0.31084407  2.20870199] , error: 0.525135644294108\n",
      "Step: 1819 Weights: [-0.30932302  2.20852804] , error: 0.5249015242802284\n",
      "Step: 1820 Weights: [-0.30780543  2.20835448] , error: 0.524668470830638\n",
      "Step: 1821 Weights: [-0.3062913   2.20818132] , error: 0.5244364790864646\n",
      "Step: 1822 Weights: [-0.30478063  2.20800855] , error: 0.5242055442109701\n",
      "Step: 1823 Weights: [-0.3032734   2.20783618] , error: 0.5239756613894522\n",
      "Step: 1824 Weights: [-0.30176961  2.2076642 ] , error: 0.52374682582914\n",
      "Step: 1825 Weights: [-0.30026924  2.20749261] , error: 0.523519032759099\n",
      "Step: 1826 Weights: [-0.2987723   2.20732141] , error: 0.52329227743013\n",
      "Step: 1827 Weights: [-0.29727878  2.20715061] , error: 0.5230665551146667\n",
      "Step: 1828 Weights: [-0.29578865  2.20698019] , error: 0.5228418611066811\n",
      "Step: 1829 Weights: [-0.29430193  2.20681016] , error: 0.5226181907215847\n",
      "Step: 1830 Weights: [-0.2928186   2.20664052] , error: 0.5223955392961301\n",
      "Step: 1831 Weights: [-0.29133865  2.20647127] , error: 0.5221739021883124\n",
      "Step: 1832 Weights: [-0.28986207  2.2063024 ] , error: 0.5219532747772768\n",
      "Step: 1833 Weights: [-0.28838886  2.20613392] , error: 0.5217336524632166\n",
      "Step: 1834 Weights: [-0.28691901  2.20596582] , error: 0.5215150306672826\n",
      "Step: 1835 Weights: [-0.28545251  2.2057981 ] , error: 0.5212974048314822\n",
      "Step: 1836 Weights: [-0.28398936  2.20563077] , error: 0.5210807704185892\n",
      "Step: 1837 Weights: [-0.28252955  2.20546382] , error: 0.5208651229120473\n",
      "Step: 1838 Weights: [-0.28107306  2.20529725] , error: 0.5206504578158772\n",
      "Step: 1839 Weights: [-0.27961989  2.20513106] , error: 0.5204367706545795\n",
      "Step: 1840 Weights: [-0.27817004  2.20496525] , error: 0.520224056973043\n",
      "Step: 1841 Weights: [-0.27672349  2.20479982] , error: 0.520012312336455\n",
      "Step: 1842 Weights: [-0.27528025  2.20463476] , error: 0.5198015323302031\n",
      "Step: 1843 Weights: [-0.27384029  2.20447008] , error: 0.5195917125597893\n",
      "Step: 1844 Weights: [-0.27240362  2.20430578] , error: 0.519382848650733\n",
      "Step: 1845 Weights: [-0.27097022  2.20414185] , error: 0.5191749362484839\n",
      "Step: 1846 Weights: [-0.26954009  2.20397829] , error: 0.5189679710183278\n",
      "Step: 1847 Weights: [-0.26811323  2.20381511] , error: 0.5187619486452987\n",
      "Step: 1848 Weights: [-0.26668962  2.2036523 ] , error: 0.5185568648340884\n",
      "Step: 1849 Weights: [-0.26526925  2.20348986] , error: 0.5183527153089553\n",
      "Step: 1850 Weights: [-0.26385212  2.20332779] , error: 0.5181494958136367\n",
      "Step: 1851 Weights: [-0.26243823  2.20316609] , error: 0.517947202111263\n",
      "Step: 1852 Weights: [-0.26102756  2.20300476] , error: 0.5177458299842604\n",
      "Step: 1853 Weights: [-0.2596201  2.2028438] , error: 0.5175453752342721\n",
      "Step: 1854 Weights: [-0.25821586  2.20268321] , error: 0.5173458336820695\n",
      "Step: 1855 Weights: [-0.25681482  2.20252298] , error: 0.5171472011674603\n",
      "Step: 1856 Weights: [-0.25541697  2.20236311] , error: 0.5169494735492046\n",
      "Step: 1857 Weights: [-0.25402231  2.20220361] , error: 0.5167526467049279\n",
      "Step: 1858 Weights: [-0.25263083  2.20204448] , error: 0.5165567165310396\n",
      "Step: 1859 Weights: [-0.25124252  2.20188571] , error: 0.5163616789426374\n",
      "Step: 1860 Weights: [-0.24985738  2.2017273 ] , error: 0.5161675298734334\n",
      "Step: 1861 Weights: [-0.2484754   2.20156925] , error: 0.515974265275662\n",
      "Step: 1862 Weights: [-0.24709657  2.20141156] , error: 0.5157818811199982\n",
      "Step: 1863 Weights: [-0.24572089  2.20125423] , error: 0.5155903733954721\n",
      "Step: 1864 Weights: [-0.24434834  2.20109726] , error: 0.5153997381093885\n",
      "Step: 1865 Weights: [-0.24297892  2.20094065] , error: 0.5152099712872397\n",
      "Step: 1866 Weights: [-0.24161262  2.20078439] , error: 0.5150210689726256\n",
      "Step: 1867 Weights: [-0.24024944  2.20062849] , error: 0.5148330272271684\n",
      "Step: 1868 Weights: [-0.23888937  2.20047295] , error: 0.5146458421304326\n",
      "Step: 1869 Weights: [-0.2375324   2.20031776] , error: 0.5144595097798439\n",
      "Step: 1870 Weights: [-0.23617853  2.20016292] , error: 0.5142740262906054\n",
      "Step: 1871 Weights: [-0.23482774  2.20000844] , error: 0.5140893877956185\n",
      "Step: 1872 Weights: [-0.23348003  2.19985431] , error: 0.5139055904454014\n",
      "Step: 1873 Weights: [-0.2321354   2.19970053] , error: 0.5137226304080106\n",
      "Step: 1874 Weights: [-0.23079383  2.19954711] , error: 0.5135405038689562\n",
      "Step: 1875 Weights: [-0.22945532  2.19939403] , error: 0.5133592070311299\n",
      "Step: 1876 Weights: [-0.22811987  2.1992413 ] , error: 0.5131787361147162\n",
      "Step: 1877 Weights: [-0.22678746  2.19908892] , error: 0.5129990873571266\n",
      "Step: 1878 Weights: [-0.22545808  2.19893689] , error: 0.5128202570129048\n",
      "Step: 1879 Weights: [-0.22413174  2.1987852 ] , error: 0.5126422413536658\n",
      "Step: 1880 Weights: [-0.22280843  2.19863386] , error: 0.5124650366680028\n",
      "Step: 1881 Weights: [-0.22148813  2.19848287] , error: 0.5122886392614203\n",
      "Step: 1882 Weights: [-0.22017084  2.19833222] , error: 0.5121130454562546\n",
      "Step: 1883 Weights: [-0.21885656  2.19818191] , error: 0.511938251591594\n",
      "Step: 1884 Weights: [-0.21754527  2.19803195] , error: 0.5117642540232041\n",
      "Step: 1885 Weights: [-0.21623697  2.19788232] , error: 0.5115910491234541\n",
      "Step: 1886 Weights: [-0.21493166  2.19773304] , error: 0.5114186332812377\n",
      "Step: 1887 Weights: [-0.21362932  2.1975841 ] , error: 0.5112470029019023\n",
      "Step: 1888 Weights: [-0.21232996  2.1974355 ] , error: 0.5110761544071664\n",
      "Step: 1889 Weights: [-0.21103355  2.19728724] , error: 0.5109060842350548\n",
      "Step: 1890 Weights: [-0.20974011  2.19713931] , error: 0.5107367888398158\n",
      "Step: 1891 Weights: [-0.20844961  2.19699173] , error: 0.5105682646918539\n",
      "Step: 1892 Weights: [-0.20716206  2.19684448] , error: 0.510400508277649\n",
      "Step: 1893 Weights: [-0.20587744  2.19669756] , error: 0.5102335160996915\n",
      "Step: 1894 Weights: [-0.20459575  2.19655098] , error: 0.5100672846764034\n",
      "Step: 1895 Weights: [-0.20331698  2.19640474] , error: 0.509901810542067\n",
      "Step: 1896 Weights: [-0.20204113  2.19625883] , error: 0.5097370902467531\n",
      "Step: 1897 Weights: [-0.20076819  2.19611325] , error: 0.5095731203562506\n",
      "Step: 1898 Weights: [-0.19949815  2.195968  ] , error: 0.5094098974519923\n",
      "Step: 1899 Weights: [-0.19823101  2.19582309] , error: 0.5092474181309836\n",
      "Step: 1900 Weights: [-0.19696676  2.1956785 ] , error: 0.5090856790057354\n",
      "Step: 1901 Weights: [-0.19570539  2.19553425] , error: 0.5089246767041878\n",
      "Step: 1902 Weights: [-0.1944469   2.19539032] , error: 0.5087644078696466\n",
      "Step: 1903 Weights: [-0.19319128  2.19524672] , error: 0.5086048691607056\n",
      "Step: 1904 Weights: [-0.19193852  2.19510345] , error: 0.5084460572511814\n",
      "Step: 1905 Weights: [-0.19068862  2.19496051] , error: 0.5082879688300451\n",
      "Step: 1906 Weights: [-0.18944156  2.19481789] , error: 0.5081306006013523\n",
      "Step: 1907 Weights: [-0.18819736  2.19467559] , error: 0.5079739492841697\n",
      "Step: 1908 Weights: [-0.18695598  2.19453363] , error: 0.5078180116125156\n",
      "Step: 1909 Weights: [-0.18571744  2.19439198] , error: 0.5076627843352828\n",
      "Step: 1910 Weights: [-0.18448173  2.19425066] , error: 0.5075082642161786\n",
      "Step: 1911 Weights: [-0.18324883  2.19410966] , error: 0.5073544480336518\n",
      "Step: 1912 Weights: [-0.18201874  2.19396898] , error: 0.5072013325808251\n",
      "Step: 1913 Weights: [-0.18079146  2.19382863] , error: 0.5070489146654348\n",
      "Step: 1914 Weights: [-0.17956698  2.19368859] , error: 0.5068971911097572\n",
      "Step: 1915 Weights: [-0.17834529  2.19354887] , error: 0.5067461587505466\n",
      "Step: 1916 Weights: [-0.17712639  2.19340947] , error: 0.5065958144389673\n",
      "Step: 1917 Weights: [-0.17591026  2.19327039] , error: 0.5064461550405275\n",
      "Step: 1918 Weights: [-0.17469691  2.19313163] , error: 0.5062971774350165\n",
      "Step: 1919 Weights: [-0.17348633  2.19299318] , error: 0.5061488785164376\n",
      "Step: 1920 Weights: [-0.1722785   2.19285505] , error: 0.506001255192945\n",
      "Step: 1921 Weights: [-0.17107343  2.19271723] , error: 0.5058543043867759\n",
      "Step: 1922 Weights: [-0.16987111  2.19257973] , error: 0.5057080230341898\n",
      "Step: 1923 Weights: [-0.16867153  2.19244254] , error: 0.5055624080854039\n",
      "Step: 1924 Weights: [-0.16747469  2.19230566] , error: 0.5054174565045276\n",
      "Step: 1925 Weights: [-0.16628058  2.1921691 ] , error: 0.5052731652695032\n",
      "Step: 1926 Weights: [-0.16508918  2.19203285] , error: 0.505129531372039\n",
      "Step: 1927 Weights: [-0.16390051  2.1918969 ] , error: 0.5049865518175454\n",
      "Step: 1928 Weights: [-0.16271454  2.19176127] , error: 0.5048442236250816\n",
      "Step: 1929 Weights: [-0.16153129  2.19162595] , error: 0.5047025438272796\n",
      "Step: 1930 Weights: [-0.16035072  2.19149094] , error: 0.5045615094702943\n",
      "Step: 1931 Weights: [-0.15917286  2.19135623] , error: 0.5044211176137355\n",
      "Step: 1932 Weights: [-0.15799767  2.19122183] , error: 0.5042813653306099\n",
      "Step: 1933 Weights: [-0.15682517  2.19108774] , error: 0.5041422497072543\n",
      "Step: 1934 Weights: [-0.15565534  2.19095395] , error: 0.5040037678432845\n",
      "Step: 1935 Weights: [-0.15448818  2.19082047] , error: 0.5038659168515252\n",
      "Step: 1936 Weights: [-0.15332368  2.19068729] , error: 0.5037286938579575\n",
      "Step: 1937 Weights: [-0.15216183  2.19055442] , error: 0.5035920960016523\n",
      "Step: 1938 Weights: [-0.15100264  2.19042185] , error: 0.5034561204347145\n",
      "Step: 1939 Weights: [-0.14984609  2.19028958] , error: 0.5033207643222258\n",
      "Step: 1940 Weights: [-0.14869217  2.19015762] , error: 0.5031860248421801\n",
      "Step: 1941 Weights: [-0.14754089  2.19002595] , error: 0.5030518991854263\n",
      "Step: 1942 Weights: [-0.14639223  2.18989458] , error: 0.5029183845556129\n",
      "Step: 1943 Weights: [-0.1452462   2.18976352] , error: 0.5027854781691262\n",
      "Step: 1944 Weights: [-0.14410277  2.18963275] , error: 0.5026531772550376\n",
      "Step: 1945 Weights: [-0.14296195  2.18950228] , error: 0.5025214790550343\n",
      "Step: 1946 Weights: [-0.14182374  2.18937211] , error: 0.5023903808233765\n",
      "Step: 1947 Weights: [-0.14068812  2.18924224] , error: 0.5022598798268278\n",
      "Step: 1948 Weights: [-0.13955509  2.18911266] , error: 0.502129973344608\n",
      "Step: 1949 Weights: [-0.13842464  2.18898338] , error: 0.5020006586683283\n",
      "Step: 1950 Weights: [-0.13729677  2.18885439] , error: 0.5018719331019391\n",
      "Step: 1951 Weights: [-0.13617148  2.1887257 ] , error: 0.5017437939616736\n",
      "Step: 1952 Weights: [-0.13504875  2.1885973 ] , error: 0.5016162385759919\n",
      "Step: 1953 Weights: [-0.13392858  2.18846919] , error: 0.5014892642855227\n",
      "Step: 1954 Weights: [-0.13281096  2.18834137] , error: 0.5013628684430111\n",
      "Step: 1955 Weights: [-0.13169589  2.18821385] , error: 0.5012370484132629\n",
      "Step: 1956 Weights: [-0.13058337  2.18808662] , error: 0.5011118015730861\n",
      "Step: 1957 Weights: [-0.12947338  2.18795967] , error: 0.5009871253112423\n",
      "Step: 1958 Weights: [-0.12836593  2.18783302] , error: 0.5008630170283878\n",
      "Step: 1959 Weights: [-0.127261    2.18770666] , error: 0.5007394741370177\n",
      "Step: 1960 Weights: [-0.12615859  2.18758058] , error: 0.5006164940614197\n",
      "Step: 1961 Weights: [-0.12505869  2.18745479] , error: 0.5004940742376127\n",
      "Step: 1962 Weights: [-0.1239613   2.18732929] , error: 0.5003722121132952\n",
      "Step: 1963 Weights: [-0.12286642  2.18720407] , error: 0.5002509051477952\n",
      "Step: 1964 Weights: [-0.12177403  2.18707914] , error: 0.5001301508120155\n",
      "Step: 1965 Weights: [-0.12068413  2.1869545 ] , error: 0.5000099465883763\n",
      "Step: 1966 Weights: [-0.11959672  2.18683014] , error: 0.49989028997077223\n",
      "Step: 1967 Weights: [-0.11851178  2.18670606] , error: 0.4997711784645115\n",
      "Step: 1968 Weights: [-0.11742932  2.18658226] , error: 0.4996526095862685\n",
      "Step: 1969 Weights: [-0.11634933  2.18645875] , error: 0.49953458086403146\n",
      "Step: 1970 Weights: [-0.11527181  2.18633552] , error: 0.49941708983704747\n",
      "Step: 1971 Weights: [-0.11419674  2.18621257] , error: 0.4993001340557765\n",
      "Step: 1972 Weights: [-0.11312412  2.1860899 ] , error: 0.49918371108183646\n",
      "Step: 1973 Weights: [-0.11205394  2.18596751] , error: 0.4990678184879557\n",
      "Step: 1974 Weights: [-0.11098621  2.1858454 ] , error: 0.4989524538579153\n",
      "Step: 1975 Weights: [-0.10992091  2.18572357] , error: 0.49883761478650923\n",
      "Step: 1976 Weights: [-0.10885805  2.18560202] , error: 0.4987232988794868\n",
      "Step: 1977 Weights: [-0.1077976   2.18548074] , error: 0.49860950375350355\n",
      "Step: 1978 Weights: [-0.10673958  2.18535974] , error: 0.49849622703607416\n",
      "Step: 1979 Weights: [-0.10568396  2.18523902] , error: 0.49838346636551945\n",
      "Step: 1980 Weights: [-0.10463076  2.18511857] , error: 0.4982712193909214\n",
      "Step: 1981 Weights: [-0.10357995  2.18499839] , error: 0.49815948377207087\n",
      "Step: 1982 Weights: [-0.10253154  2.18487849] , error: 0.4980482571794206\n",
      "Step: 1983 Weights: [-0.10148553  2.18475886] , error: 0.49793753729403434\n",
      "Step: 1984 Weights: [-0.10044189  2.18463951] , error: 0.4978273218075425\n",
      "Step: 1985 Weights: [-0.09940064  2.18452043] , error: 0.4977176084220875\n",
      "Step: 1986 Weights: [-0.09836176  2.18440162] , error: 0.4976083948502844\n",
      "Step: 1987 Weights: [-0.09732526  2.18428308] , error: 0.49749967881516566\n",
      "Step: 1988 Weights: [-0.09629111  2.18416481] , error: 0.497391458050141\n",
      "Step: 1989 Weights: [-0.09525933  2.18404681] , error: 0.49728373029893835\n",
      "Step: 1990 Weights: [-0.09422989  2.18392908] , error: 0.49717649331557245\n",
      "Step: 1991 Weights: [-0.09320281  2.18381162] , error: 0.49706974486428457\n",
      "Step: 1992 Weights: [-0.09217806  2.18369442] , error: 0.4969634827195028\n",
      "Step: 1993 Weights: [-0.09115565  2.1835775 ] , error: 0.4968577046657956\n",
      "Step: 1994 Weights: [-0.09013558  2.18346084] , error: 0.4967524084978219\n",
      "Step: 1995 Weights: [-0.08911783  2.18334444] , error: 0.49664759202028896\n",
      "Step: 1996 Weights: [-0.0881024   2.18322831] , error: 0.4965432530479045\n",
      "Step: 1997 Weights: [-0.08708929  2.18311245] , error: 0.4964393894053315\n",
      "Step: 1998 Weights: [-0.08607849  2.18299685] , error: 0.4963359989271412\n",
      "Step: 1999 Weights: [-0.08506999  2.18288151] , error: 0.4962330794577733\n",
      "Step: 2000 Weights: [-0.08406379  2.18276644] , error: 0.49613062885148557\n",
      "Step: 2001 Weights: [-0.08305989  2.18265163] , error: 0.4960286449723097\n",
      "Step: 2002 Weights: [-0.08205827  2.18253708] , error: 0.4959271256940109\n",
      "Step: 2003 Weights: [-0.08105894  2.18242279] , error: 0.49582606890003844\n",
      "Step: 2004 Weights: [-0.08006189  2.18230877] , error: 0.49572547248348553\n",
      "Step: 2005 Weights: [-0.07906712  2.182195  ] , error: 0.495625334347042\n",
      "Step: 2006 Weights: [-0.07807461  2.18208149] , error: 0.4955256524029525\n",
      "Step: 2007 Weights: [-0.07708436  2.18196824] , error: 0.4954264245729731\n",
      "Step: 2008 Weights: [-0.07609638  2.18185525] , error: 0.49532764878832825\n",
      "Step: 2009 Weights: [-0.07511064  2.18174252] , error: 0.49522932298966604\n",
      "Step: 2010 Weights: [-0.07412715  2.18163005] , error: 0.4951314451270176\n",
      "Step: 2011 Weights: [-0.07314591  2.18151783] , error: 0.4950340131597515\n",
      "Step: 2012 Weights: [-0.07216691  2.18140586] , error: 0.4949370250565333\n",
      "Step: 2013 Weights: [-0.07119013  2.18129416] , error: 0.4948404787952809\n",
      "Step: 2014 Weights: [-0.07021559  2.1811827 ] , error: 0.4947443723631272\n",
      "Step: 2015 Weights: [-0.06924326  2.1810715 ] , error: 0.49464870375637243\n",
      "Step: 2016 Weights: [-0.06827316  2.18096056] , error: 0.4945534709804459\n",
      "Step: 2017 Weights: [-0.06730526  2.18084987] , error: 0.49445867204986393\n",
      "Step: 2018 Weights: [-0.06633958  2.18073943] , error: 0.4943643049881874\n",
      "Step: 2019 Weights: [-0.06537609  2.18062924] , error: 0.4942703678279793\n",
      "Step: 2020 Weights: [-0.0644148  2.1805193] , error: 0.49417685861077043\n",
      "Step: 2021 Weights: [-0.06345571  2.18040961] , error: 0.49408377538700804\n",
      "Step: 2022 Weights: [-0.0624988   2.18030018] , error: 0.4939911162160243\n",
      "Step: 2023 Weights: [-0.06154407  2.18019099] , error: 0.4938988791659923\n",
      "Step: 2024 Weights: [-0.06059153  2.18008205] , error: 0.4938070623138838\n",
      "Step: 2025 Weights: [-0.05964115  2.17997337] , error: 0.4937156637454317\n",
      "Step: 2026 Weights: [-0.05869294  2.17986492] , error: 0.4936246815550922\n",
      "Step: 2027 Weights: [-0.05774689  2.17975673] , error: 0.49353411384599866\n",
      "Step: 2028 Weights: [-0.056803    2.17964878] , error: 0.4934439587299282\n",
      "Step: 2029 Weights: [-0.05586127  2.17954108] , error: 0.4933542143272598\n",
      "Step: 2030 Weights: [-0.05492168  2.17943363] , error: 0.4932648787669357\n",
      "Step: 2031 Weights: [-0.05398423  2.17932642] , error: 0.4931759501864178\n",
      "Step: 2032 Weights: [-0.05304892  2.17921945] , error: 0.4930874267316615\n",
      "Step: 2033 Weights: [-0.05211574  2.17911273] , error: 0.4929993065570587\n",
      "Step: 2034 Weights: [-0.0511847   2.17900625] , error: 0.4929115878254169\n",
      "Step: 2035 Weights: [-0.05025577  2.17890001] , error: 0.49282426870790996\n",
      "Step: 2036 Weights: [-0.04932896  2.17879402] , error: 0.49273734738404223\n",
      "Step: 2037 Weights: [-0.04840427  2.17868827] , error: 0.4926508220416138\n",
      "Step: 2038 Weights: [-0.04748169  2.17858276] , error: 0.4925646908766804\n",
      "Step: 2039 Weights: [-0.04656121  2.17847749] , error: 0.4924789520935138\n",
      "Step: 2040 Weights: [-0.04564282  2.17837246] , error: 0.49239360390456705\n",
      "Step: 2041 Weights: [-0.04472654  2.17826767] , error: 0.49230864453043854\n",
      "Step: 2042 Weights: [-0.04381234  2.17816312] , error: 0.4922240721998313\n",
      "Step: 2043 Weights: [-0.04290023  2.1780588 ] , error: 0.49213988514951734\n",
      "Step: 2044 Weights: [-0.04199019  2.17795473] , error: 0.49205608162430237\n",
      "Step: 2045 Weights: [-0.04108223  2.17785089] , error: 0.4919726598769879\n",
      "Step: 2046 Weights: [-0.04017635  2.17774729] , error: 0.49188961816833426\n",
      "Step: 2047 Weights: [-0.03927253  2.17764392] , error: 0.49180695476702807\n",
      "Step: 2048 Weights: [-0.03837077  2.17754079] , error: 0.491724667949637\n",
      "Step: 2049 Weights: [-0.03747106  2.1774379 ] , error: 0.49164275600058716\n",
      "Step: 2050 Weights: [-0.03657341  2.17733524] , error: 0.491561217212114\n",
      "Step: 2051 Weights: [-0.0356778   2.17723282] , error: 0.4914800498842379\n",
      "Step: 2052 Weights: [-0.03478424  2.17713062] , error: 0.4913992523247217\n",
      "Step: 2053 Weights: [-0.03389272  2.17702867] , error: 0.49131882284903616\n",
      "Step: 2054 Weights: [-0.03300322  2.17692694] , error: 0.49123875978032766\n",
      "Step: 2055 Weights: [-0.03211576  2.17682545] , error: 0.49115906144938204\n",
      "Step: 2056 Weights: [-0.03123032  2.17672418] , error: 0.4910797261945887\n",
      "Step: 2057 Weights: [-0.0303469   2.17662315] , error: 0.491000752361906\n",
      "Step: 2058 Weights: [-0.02946549  2.17652235] , error: 0.49092213830482834\n",
      "Step: 2059 Weights: [-0.0285861   2.17642178] , error: 0.4908438823843529\n",
      "Step: 2060 Weights: [-0.0277087   2.17632144] , error: 0.490765982968939\n",
      "Step: 2061 Weights: [-0.02683331  2.17622132] , error: 0.49068843843448223\n",
      "Step: 2062 Weights: [-0.02595992  2.17612144] , error: 0.4906112471642762\n",
      "Step: 2063 Weights: [-0.02508852  2.17602178] , error: 0.4905344075489801\n",
      "Step: 2064 Weights: [-0.0242191   2.17592235] , error: 0.49045791798658445\n",
      "Step: 2065 Weights: [-0.02335167  2.17582315] , error: 0.4903817768823758\n",
      "Step: 2066 Weights: [-0.02248622  2.17572417] , error: 0.4903059826489077\n",
      "Step: 2067 Weights: [-0.02162274  2.17562542] , error: 0.49023053370596636\n",
      "Step: 2068 Weights: [-0.02076122  2.17552689] , error: 0.49015542848053484\n",
      "Step: 2069 Weights: [-0.01990168  2.17542859] , error: 0.4900806654067642\n",
      "Step: 2070 Weights: [-0.01904409  2.17533051] , error: 0.49000624292593586\n",
      "Step: 2071 Weights: [-0.01818846  2.17523266] , error: 0.4899321594864366\n",
      "Step: 2072 Weights: [-0.01733478  2.17513503] , error: 0.48985841354371795\n",
      "Step: 2073 Weights: [-0.01648305  2.17503762] , error: 0.4897850035602685\n",
      "Step: 2074 Weights: [-0.01563326  2.17494044] , error: 0.4897119280055839\n",
      "Step: 2075 Weights: [-0.0147854   2.17484347] , error: 0.4896391853561294\n",
      "Step: 2076 Weights: [-0.01393948  2.17474673] , error: 0.48956677409531046\n",
      "Step: 2077 Weights: [-0.01309549  2.17465021] , error: 0.48949469271344564\n",
      "Step: 2078 Weights: [-0.01225343  2.17455391] , error: 0.4894229397077259\n",
      "Step: 2079 Weights: [-0.01141328  2.17445782] , error: 0.4893515135821922\n",
      "Step: 2080 Weights: [-0.01057505  2.17436196] , error: 0.48928041284769863\n",
      "Step: 2081 Weights: [-0.00973873  2.17426631] , error: 0.4892096360218833\n",
      "Step: 2082 Weights: [-0.00890432  2.17417089] , error: 0.4891391816291388\n",
      "Step: 2083 Weights: [-0.00807181  2.17407568] , error: 0.4890690482005785\n",
      "Step: 2084 Weights: [-0.0072412   2.17398069] , error: 0.4889992342740092\n",
      "Step: 2085 Weights: [-0.00641249  2.17388591] , error: 0.48892973839389636\n",
      "Step: 2086 Weights: [-0.00558566  2.17379135] , error: 0.4888605591113393\n",
      "Step: 2087 Weights: [-0.00476072  2.17369701] , error: 0.488791694984037\n",
      "Step: 2088 Weights: [-0.00393766  2.17360288] , error: 0.48872314457625554\n",
      "Step: 2089 Weights: [-0.00311648  2.17350897] , error: 0.4886549064588074\n",
      "Step: 2090 Weights: [-0.00229717  2.17341527] , error: 0.4885869792090124\n",
      "Step: 2091 Weights: [-1.47972911e-03  2.17332178e+00] , error: 0.48851936141067276\n",
      "Step: 2092 Weights: [-6.64151957e-04  2.17322851e+00] , error: 0.4884520516540398\n",
      "Step: 2093 Weights: [1.49565340e-04 2.17313545e+00] , error: 0.48838504853579223\n",
      "Step: 2094 Weights: [9.61427024e-04 2.17304260e+00] , error: 0.48831835065899865\n",
      "Step: 2095 Weights: [1.77143733e-03 2.17294996e+00] , error: 0.48825195663309007\n",
      "Step: 2096 Weights: [0.0025796  2.17285754] , error: 0.4881858650738341\n",
      "Step: 2097 Weights: [0.00338592 2.17276532] , error: 0.48812007460330487\n",
      "Step: 2098 Weights: [0.0041904  2.17267332] , error: 0.4880545838498543\n",
      "Step: 2099 Weights: [0.00499305 2.17258153] , error: 0.4879893914480822\n",
      "Step: 2100 Weights: [0.00579387 2.17248994] , error: 0.48792449603880694\n",
      "Step: 2101 Weights: [0.00659286 2.17239856] , error: 0.48785989626904186\n",
      "Step: 2102 Weights: [0.00739002 2.1723074 ] , error: 0.48779559079196144\n",
      "Step: 2103 Weights: [0.00818537 2.17221644] , error: 0.4877315782668781\n",
      "Step: 2104 Weights: [0.00897891 2.17212569] , error: 0.4876678573592098\n",
      "Step: 2105 Weights: [0.00977064 2.17203514] , error: 0.4876044267404547\n",
      "Step: 2106 Weights: [0.01056056 2.1719448 ] , error: 0.48754128508816685\n",
      "Step: 2107 Weights: [0.01134868 2.17185467] , error: 0.48747843108591793\n",
      "Step: 2108 Weights: [0.012135   2.17176474] , error: 0.48741586342328275\n",
      "Step: 2109 Weights: [0.01291953 2.17167502] , error: 0.48735358079580426\n",
      "Step: 2110 Weights: [0.01370227 2.1715855 ] , error: 0.48729158190496585\n",
      "Step: 2111 Weights: [0.01448323 2.17149619] , error: 0.4872298654581695\n",
      "Step: 2112 Weights: [0.0152624  2.17140708] , error: 0.4871684301687046\n",
      "Step: 2113 Weights: [0.0160398  2.17131817] , error: 0.48710727475572085\n",
      "Step: 2114 Weights: [0.01681543 2.17122947] , error: 0.4870463979442061\n",
      "Step: 2115 Weights: [0.01758929 2.17114097] , error: 0.4869857984649546\n",
      "Step: 2116 Weights: [0.01836138 2.17105267] , error: 0.4869254750545415\n",
      "Step: 2117 Weights: [0.01913171 2.17096457] , error: 0.4868654264553004\n",
      "Step: 2118 Weights: [0.01990028 2.17087667] , error: 0.48680565141529375\n",
      "Step: 2119 Weights: [0.0206671  2.17078897] , error: 0.4867461486882859\n",
      "Step: 2120 Weights: [0.02143218 2.17070148] , error: 0.48668691703371814\n",
      "Step: 2121 Weights: [0.02219551 2.17061418] , error: 0.48662795521668833\n",
      "Step: 2122 Weights: [0.02295709 2.17052708] , error: 0.4865692620079116\n",
      "Step: 2123 Weights: [0.02371694 2.17044018] , error: 0.4865108361837118\n",
      "Step: 2124 Weights: [0.02447506 2.17035348] , error: 0.4864526765259819\n",
      "Step: 2125 Weights: [0.02523145 2.17026698] , error: 0.4863947818221659\n",
      "Step: 2126 Weights: [0.02598612 2.17018067] , error: 0.4863371508652312\n",
      "Step: 2127 Weights: [0.02673906 2.17009456] , error: 0.4862797824536461\n",
      "Step: 2128 Weights: [0.02749029 2.17000865] , error: 0.486222675391349\n",
      "Step: 2129 Weights: [0.0282398  2.16992293] , error: 0.4861658284877308\n",
      "Step: 2130 Weights: [0.02898761 2.16983741] , error: 0.48610924055760335\n",
      "Step: 2131 Weights: [0.0297337  2.16975208] , error: 0.48605291042118015\n",
      "Step: 2132 Weights: [0.0304781  2.16966695] , error: 0.4859968369040476\n",
      "Step: 2133 Weights: [0.0312208  2.16958201] , error: 0.4859410188371428\n",
      "Step: 2134 Weights: [0.03196181 2.16949726] , error: 0.48588545505673086\n",
      "Step: 2135 Weights: [0.03270112 2.16941271] , error: 0.4858301444043731\n",
      "Step: 2136 Weights: [0.03343876 2.16932835] , error: 0.48577508572691364\n",
      "Step: 2137 Weights: [0.0341747  2.16924419] , error: 0.4857202778764483\n",
      "Step: 2138 Weights: [0.03490897 2.16916021] , error: 0.4856657197103018\n",
      "Step: 2139 Weights: [0.03564157 2.16907643] , error: 0.48561141009100306\n",
      "Step: 2140 Weights: [0.03637249 2.16899284] , error: 0.48555734788626653\n",
      "Step: 2141 Weights: [0.03710175 2.16890944] , error: 0.48550353196896134\n",
      "Step: 2142 Weights: [0.03782935 2.16882623] , error: 0.48544996121709433\n",
      "Step: 2143 Weights: [0.03855528 2.16874321] , error: 0.48539663451378046\n",
      "Step: 2144 Weights: [0.03927957 2.16866038] , error: 0.4853435507472278\n",
      "Step: 2145 Weights: [0.04000219 2.16857773] , error: 0.4852907088107023\n",
      "Step: 2146 Weights: [0.04072318 2.16849528] , error: 0.48523810760251773\n",
      "Step: 2147 Weights: [0.04144251 2.16841301] , error: 0.48518574602600534\n",
      "Step: 2148 Weights: [0.04216021 2.16833093] , error: 0.48513362298949014\n",
      "Step: 2149 Weights: [0.04287627 2.16824904] , error: 0.4850817374062739\n",
      "Step: 2150 Weights: [0.0435907  2.16816734] , error: 0.48503008819460636\n",
      "Step: 2151 Weights: [0.04430349 2.16808582] , error: 0.48497867427766506\n",
      "Step: 2152 Weights: [0.04501467 2.16800448] , error: 0.48492749458353474\n",
      "Step: 2153 Weights: [0.04572422 2.16792334] , error: 0.48487654804518326\n",
      "Step: 2154 Weights: [0.04643215 2.16784238] , error: 0.4848258336004392\n",
      "Step: 2155 Weights: [0.04713847 2.1677616 ] , error: 0.48477535019196805\n",
      "Step: 2156 Weights: [0.04784318 2.167681  ] , error: 0.4847250967672561\n",
      "Step: 2157 Weights: [0.04854628 2.1676006 ] , error: 0.4846750722785821\n",
      "Step: 2158 Weights: [0.04924777 2.16752037] , error: 0.4846252756829968\n",
      "Step: 2159 Weights: [0.04994767 2.16744033] , error: 0.48457570594230365\n",
      "Step: 2160 Weights: [0.05064597 2.16736046] , error: 0.48452636202303645\n",
      "Step: 2161 Weights: [0.05134268 2.16728079] , error: 0.48447724289643535\n",
      "Step: 2162 Weights: [0.0520378  2.16720129] , error: 0.4844283475384292\n",
      "Step: 2163 Weights: [0.05273134 2.16712197] , error: 0.48437967492960965\n",
      "Step: 2164 Weights: [0.05342329 2.16704284] , error: 0.4843312240552138\n",
      "Step: 2165 Weights: [0.05411366 2.16696388] , error: 0.48428299390510227\n",
      "Step: 2166 Weights: [0.05480247 2.16688511] , error: 0.4842349834737367\n",
      "Step: 2167 Weights: [0.0554897  2.16680652] , error: 0.4841871917601592\n",
      "Step: 2168 Weights: [0.05617536 2.1667281 ] , error: 0.484139617767973\n",
      "Step: 2169 Weights: [0.05685946 2.16664986] , error: 0.4840922605053197\n",
      "Step: 2170 Weights: [0.057542   2.16657181] , error: 0.48404511898485775\n",
      "Step: 2171 Weights: [0.05822298 2.16649393] , error: 0.4839981922237486\n",
      "Step: 2172 Weights: [0.05890241 2.16641622] , error: 0.4839514792436249\n",
      "Step: 2173 Weights: [0.05958029 2.1663387 ] , error: 0.48390497907058183\n",
      "Step: 2174 Weights: [0.06025663 2.16626135] , error: 0.4838586907351481\n",
      "Step: 2175 Weights: [0.06093142 2.16618418] , error: 0.48381261327226943\n",
      "Step: 2176 Weights: [0.06160467 2.16610718] , error: 0.4837667457212886\n",
      "Step: 2177 Weights: [0.06227639 2.16603036] , error: 0.483721087125925\n",
      "Step: 2178 Weights: [0.06294658 2.16595372] , error: 0.4836756365342538\n",
      "Step: 2179 Weights: [0.06361524 2.16587725] , error: 0.483630392998686\n",
      "Step: 2180 Weights: [0.06428237 2.16580095] , error: 0.48358535557595317\n",
      "Step: 2181 Weights: [0.06494798 2.16572483] , error: 0.48354052332707825\n",
      "Step: 2182 Weights: [0.06561208 2.16564888] , error: 0.4834958953173663\n",
      "Step: 2183 Weights: [0.06627466 2.1655731 ] , error: 0.4834514706163804\n",
      "Step: 2184 Weights: [0.06693573 2.1654975 ] , error: 0.48340724829791915\n",
      "Step: 2185 Weights: [0.06759529 2.16542207] , error: 0.48336322744000226\n",
      "Step: 2186 Weights: [0.06825335 2.16534681] , error: 0.48331940712485205\n",
      "Step: 2187 Weights: [0.0689099  2.16527172] , error: 0.48327578643886904\n",
      "Step: 2188 Weights: [0.06956496 2.16519681] , error: 0.4832323644726148\n",
      "Step: 2189 Weights: [0.07021853 2.16512206] , error: 0.4831891403207974\n",
      "Step: 2190 Weights: [0.0708706  2.16504749] , error: 0.4831461130822476\n",
      "Step: 2191 Weights: [0.07152119 2.16497309] , error: 0.4831032818598996\n",
      "Step: 2192 Weights: [0.0721703  2.16489885] , error: 0.4830606457607776\n",
      "Step: 2193 Weights: [0.07281792 2.16482479] , error: 0.4830182038959714\n",
      "Step: 2194 Weights: [0.07346407 2.16475089] , error: 0.4829759553806208\n",
      "Step: 2195 Weights: [0.07410874 2.16467716] , error: 0.48293389933389896\n",
      "Step: 2196 Weights: [0.07475195 2.1646036 ] , error: 0.48289203487898846\n",
      "Step: 2197 Weights: [0.07539368 2.16453021] , error: 0.482850361143068\n",
      "Step: 2198 Weights: [0.07603396 2.16445699] , error: 0.4828088772572925\n",
      "Step: 2199 Weights: [0.07667277 2.16438393] , error: 0.48276758235677436\n",
      "Step: 2200 Weights: [0.07731013 2.16431104] , error: 0.48272647558056647\n",
      "Step: 2201 Weights: [0.07794603 2.16423832] , error: 0.48268555607164576\n",
      "Step: 2202 Weights: [0.07858048 2.16416576] , error: 0.48264482297688915\n",
      "Step: 2203 Weights: [0.07921349 2.16409336] , error: 0.48260427544706486\n",
      "Step: 2204 Weights: [0.07984505 2.16402113] , error: 0.4825639126368054\n",
      "Step: 2205 Weights: [0.08047518 2.16394907] , error: 0.48252373370459856\n",
      "Step: 2206 Weights: [0.08110386 2.16387717] , error: 0.4824837378127629\n",
      "Step: 2207 Weights: [0.08173112 2.16380544] , error: 0.48244392412743403\n",
      "Step: 2208 Weights: [0.08235694 2.16373387] , error: 0.4824042918185477\n",
      "Step: 2209 Weights: [0.08298133 2.16366246] , error: 0.482364840059818\n",
      "Step: 2210 Weights: [0.0836043  2.16359121] , error: 0.4823255680287257\n",
      "Step: 2211 Weights: [0.08422585 2.16352013] , error: 0.48228647490649923\n",
      "Step: 2212 Weights: [0.08484599 2.16344921] , error: 0.4822475598780945\n",
      "Step: 2213 Weights: [0.0854647  2.16337845] , error: 0.48220882213218125\n",
      "Step: 2214 Weights: [0.08608201 2.16330785] , error: 0.48217026086112946\n",
      "Step: 2215 Weights: [0.08669791 2.16323741] , error: 0.4821318752609804\n",
      "Step: 2216 Weights: [0.08731241 2.16316714] , error: 0.482093664531445\n",
      "Step: 2217 Weights: [0.0879255  2.16309702] , error: 0.4820556278758773\n",
      "Step: 2218 Weights: [0.0885372  2.16302706] , error: 0.48201776450125977\n",
      "Step: 2219 Weights: [0.0891475  2.16295727] , error: 0.48198007361818795\n",
      "Step: 2220 Weights: [0.08975641 2.16288763] , error: 0.4819425544408559\n",
      "Step: 2221 Weights: [0.09036393 2.16281815] , error: 0.4819052061870344\n",
      "Step: 2222 Weights: [0.09097007 2.16274883] , error: 0.48186802807805873\n",
      "Step: 2223 Weights: [0.09157482 2.16267967] , error: 0.48183101933881267\n",
      "Step: 2224 Weights: [0.09217819 2.16261067] , error: 0.48179417919771017\n",
      "Step: 2225 Weights: [0.09278019 2.16254182] , error: 0.48175750688668073\n",
      "Step: 2226 Weights: [0.09338082 2.16247313] , error: 0.4817210016411513\n",
      "Step: 2227 Weights: [0.09398007 2.16240459] , error: 0.4816846627000344\n",
      "Step: 2228 Weights: [0.09457796 2.16233622] , error: 0.481648489305708\n",
      "Step: 2229 Weights: [0.09517449 2.162268  ] , error: 0.4816124807040013\n",
      "Step: 2230 Weights: [0.09576965 2.16219993] , error: 0.48157663614418206\n",
      "Step: 2231 Weights: [0.09636346 2.16213202] , error: 0.48154095487893583\n",
      "Step: 2232 Weights: [0.09695591 2.16206426] , error: 0.48150543616435004\n",
      "Step: 2233 Weights: [0.09754702 2.16199666] , error: 0.4814700792599066\n",
      "Step: 2234 Weights: [0.09813677 2.16192922] , error: 0.4814348834284579\n",
      "Step: 2235 Weights: [0.09872518 2.16186192] , error: 0.48139984793621327\n",
      "Step: 2236 Weights: [0.09931225 2.16179478] , error: 0.4813649720527292\n",
      "Step: 2237 Weights: [0.09989798 2.1617278 ] , error: 0.4813302550508843\n",
      "Step: 2238 Weights: [0.10048237 2.16166096] , error: 0.48129569620687507\n",
      "Step: 2239 Weights: [0.10106544 2.16159428] , error: 0.48126129480019053\n",
      "Step: 2240 Weights: [0.10164717 2.16152775] , error: 0.4812270501136071\n",
      "Step: 2241 Weights: [0.10222757 2.16146138] , error: 0.4811929614331627\n",
      "Step: 2242 Weights: [0.10280665 2.16139515] , error: 0.481159028048153\n",
      "Step: 2243 Weights: [0.10338441 2.16132907] , error: 0.4811252492511099\n",
      "Step: 2244 Weights: [0.10396086 2.16126315] , error: 0.4810916243377863\n",
      "Step: 2245 Weights: [0.10453599 2.16119738] , error: 0.4810581526071448\n",
      "Step: 2246 Weights: [0.1051098  2.16113175] , error: 0.48102483336134316\n",
      "Step: 2247 Weights: [0.10568231 2.16106628] , error: 0.48099166590571574\n",
      "Step: 2248 Weights: [0.10625352 2.16100095] , error: 0.48095864954876266\n",
      "Step: 2249 Weights: [0.10682342 2.16093578] , error: 0.48092578360213445\n",
      "Step: 2250 Weights: [0.10739202 2.16087075] , error: 0.4808930673806163\n",
      "Step: 2251 Weights: [0.10795932 2.16080587] , error: 0.48086050020211735\n",
      "Step: 2252 Weights: [0.10852533 2.16074114] , error: 0.480828081387651\n",
      "Step: 2253 Weights: [0.10909005 2.16067655] , error: 0.480795810261328\n",
      "Step: 2254 Weights: [0.10965348 2.16061212] , error: 0.48076368615033344\n",
      "Step: 2255 Weights: [0.11021563 2.16054783] , error: 0.4807317083849214\n",
      "Step: 2256 Weights: [0.1107765  2.16048368] , error: 0.4806998762983928\n",
      "Step: 2257 Weights: [0.11133608 2.16041969] , error: 0.480668189227092\n",
      "Step: 2258 Weights: [0.11189439 2.16035584] , error: 0.48063664651038157\n",
      "Step: 2259 Weights: [0.11245143 2.16029213] , error: 0.48060524749063327\n",
      "Step: 2260 Weights: [0.1130072  2.16022857] , error: 0.48057399151322044\n",
      "Step: 2261 Weights: [0.1135617  2.16016516] , error: 0.480542877926494\n",
      "Step: 2262 Weights: [0.11411493 2.16010189] , error: 0.48051190608177263\n",
      "Step: 2263 Weights: [0.1146669  2.16003876] , error: 0.4804810753333344\n",
      "Step: 2264 Weights: [0.11521762 2.15997578] , error: 0.48045038503839577\n",
      "Step: 2265 Weights: [0.11576708 2.15991294] , error: 0.48041983455710285\n",
      "Step: 2266 Weights: [0.11631528 2.15985025] , error: 0.48038942325251627\n",
      "Step: 2267 Weights: [0.11686224 2.15978769] , error: 0.4803591504905973\n",
      "Step: 2268 Weights: [0.11740795 2.15972528] , error: 0.4803290156401985\n",
      "Step: 2269 Weights: [0.11795241 2.15966302] , error: 0.48029901807304465\n",
      "Step: 2270 Weights: [0.11849563 2.15960089] , error: 0.48026915716372376\n",
      "Step: 2271 Weights: [0.11903762 2.15953891] , error: 0.48023943228967547\n",
      "Step: 2272 Weights: [0.11957836 2.15947707] , error: 0.4802098428311708\n",
      "Step: 2273 Weights: [0.12011788 2.15941536] , error: 0.4801803881713065\n",
      "Step: 2274 Weights: [0.12065616 2.1593538 ] , error: 0.48015106769599164\n",
      "Step: 2275 Weights: [0.12119322 2.15929238] , error: 0.4801218807939307\n",
      "Step: 2276 Weights: [0.12172905 2.1592311 ] , error: 0.48009282685661236\n",
      "Step: 2277 Weights: [0.12226366 2.15916996] , error: 0.4800639052782987\n",
      "Step: 2278 Weights: [0.12279705 2.15910896] , error: 0.480035115456011\n",
      "Step: 2279 Weights: [0.12332923 2.1590481 ] , error: 0.48000645678951764\n",
      "Step: 2280 Weights: [0.12386019 2.15898738] , error: 0.4799779286813196\n",
      "Step: 2281 Weights: [0.12438994 2.15892679] , error: 0.47994953053664535\n",
      "Step: 2282 Weights: [0.12491848 2.15886635] , error: 0.47992126176342575\n",
      "Step: 2283 Weights: [0.12544582 2.15880604] , error: 0.4798931217722923\n",
      "Step: 2284 Weights: [0.12597195 2.15874587] , error: 0.47986510997656406\n",
      "Step: 2285 Weights: [0.12649689 2.15868583] , error: 0.47983722579222765\n",
      "Step: 2286 Weights: [0.12702062 2.15862594] , error: 0.4798094686379344\n",
      "Step: 2287 Weights: [0.12754317 2.15856618] , error: 0.47978183793498075\n",
      "Step: 2288 Weights: [0.12806452 2.15850655] , error: 0.47975433310730087\n",
      "Step: 2289 Weights: [0.12858468 2.15844707] , error: 0.47972695358145634\n",
      "Step: 2290 Weights: [0.12910366 2.15838771] , error: 0.479699698786615\n",
      "Step: 2291 Weights: [0.12962145 2.1583285 ] , error: 0.47967256815455017\n",
      "Step: 2292 Weights: [0.13013806 2.15826941] , error: 0.4796455611196222\n",
      "Step: 2293 Weights: [0.13065349 2.15821047] , error: 0.4796186771187678\n",
      "Step: 2294 Weights: [0.13116775 2.15815165] , error: 0.47959191559148956\n",
      "Step: 2295 Weights: [0.13168084 2.15809298] , error: 0.479565275979842\n",
      "Step: 2296 Weights: [0.13219275 2.15803443] , error: 0.4795387577284239\n",
      "Step: 2297 Weights: [0.1327035  2.15797602] , error: 0.47951236028436184\n",
      "Step: 2298 Weights: [0.13321309 2.15791774] , error: 0.479486083097303\n",
      "Step: 2299 Weights: [0.13372151 2.1578596 ] , error: 0.4794599256194003\n",
      "Step: 2300 Weights: [0.13422877 2.15780158] , error: 0.47943388730530345\n",
      "Step: 2301 Weights: [0.13473488 2.1577437 ] , error: 0.4794079676121452\n",
      "Step: 2302 Weights: [0.13523983 2.15768596] , error: 0.4793821659995343\n",
      "Step: 2303 Weights: [0.13574363 2.15762834] , error: 0.47935648192953795\n",
      "Step: 2304 Weights: [0.13624628 2.15757085] , error: 0.47933091486667656\n",
      "Step: 2305 Weights: [0.13674778 2.1575135 ] , error: 0.4793054642779063\n",
      "Step: 2306 Weights: [0.13724814 2.15745628] , error: 0.479280129632617\n",
      "Step: 2307 Weights: [0.13774736 2.15739918] , error: 0.47925491040261237\n",
      "Step: 2308 Weights: [0.13824544 2.15734222] , error: 0.4792298060621015\n",
      "Step: 2309 Weights: [0.13874239 2.15728539] , error: 0.4792048160876925\n",
      "Step: 2310 Weights: [0.1392382  2.15722868] , error: 0.4791799399583734\n",
      "Step: 2311 Weights: [0.13973288 2.15717211] , error: 0.47915517715551026\n",
      "Step: 2312 Weights: [0.14022644 2.15711567] , error: 0.4791305271628285\n",
      "Step: 2313 Weights: [0.14071887 2.15705935] , error: 0.4791059894664058\n",
      "Step: 2314 Weights: [0.14121017 2.15700316] , error: 0.4790815635546639\n",
      "Step: 2315 Weights: [0.14170036 2.1569471 ] , error: 0.4790572489183509\n",
      "Step: 2316 Weights: [0.14218942 2.15689117] , error: 0.4790330450505381\n",
      "Step: 2317 Weights: [0.14267738 2.15683537] , error: 0.4790089514466057\n",
      "Step: 2318 Weights: [0.14316421 2.15677969] , error: 0.4789849676042309\n",
      "Step: 2319 Weights: [0.14364994 2.15672414] , error: 0.4789610930233834\n",
      "Step: 2320 Weights: [0.14413456 2.15666872] , error: 0.4789373272063038\n",
      "Step: 2321 Weights: [0.14461808 2.15661342] , error: 0.4789136696575078\n",
      "Step: 2322 Weights: [0.14510049 2.15655825] , error: 0.4788901198837636\n",
      "Step: 2323 Weights: [0.14558181 2.1565032 ] , error: 0.4788666773940877\n",
      "Step: 2324 Weights: [0.14606202 2.15644828] , error: 0.47884334169973525\n",
      "Step: 2325 Weights: [0.14654114 2.15639349] , error: 0.478820112314185\n",
      "Step: 2326 Weights: [0.14701917 2.15633882] , error: 0.4787969887531338\n",
      "Step: 2327 Weights: [0.14749611 2.15628427] , error: 0.47877397053448234\n",
      "Step: 2328 Weights: [0.14797196 2.15622985] , error: 0.47875105717833194\n",
      "Step: 2329 Weights: [0.14844673 2.15617556] , error: 0.47872824820696797\n",
      "Step: 2330 Weights: [0.14892041 2.15612139] , error: 0.4787055431448499\n",
      "Step: 2331 Weights: [0.14939301 2.15606734] , error: 0.4786829415186077\n",
      "Step: 2332 Weights: [0.14986454 2.15601341] , error: 0.478660442857025\n",
      "Step: 2333 Weights: [0.15033498 2.15595961] , error: 0.4786380466910303\n",
      "Step: 2334 Weights: [0.15080436 2.15590593] , error: 0.47861575255369426\n",
      "Step: 2335 Weights: [0.15127267 2.15585237] , error: 0.478593559980212\n",
      "Step: 2336 Weights: [0.15173991 2.15579894] , error: 0.4785714685078968\n",
      "Step: 2337 Weights: [0.15220608 2.15574562] , error: 0.47854947767616685\n",
      "Step: 2338 Weights: [0.15267119 2.15569243] , error: 0.4785275870265424\n",
      "Step: 2339 Weights: [0.15313524 2.15563936] , error: 0.47850579610263044\n",
      "Step: 2340 Weights: [0.15359823 2.15558641] , error: 0.4784841044501168\n",
      "Step: 2341 Weights: [0.15406016 2.15553358] , error: 0.478462511616758\n",
      "Step: 2342 Weights: [0.15452104 2.15548087] , error: 0.47844101715237075\n",
      "Step: 2343 Weights: [0.15498087 2.15542829] , error: 0.4784196206088239\n",
      "Step: 2344 Weights: [0.15543966 2.15537582] , error: 0.4783983215400231\n",
      "Step: 2345 Weights: [0.15589739 2.15532347] , error: 0.47837711950191186\n",
      "Step: 2346 Weights: [0.15635408 2.15527124] , error: 0.47835601405245254\n",
      "Step: 2347 Weights: [0.15680973 2.15521913] , error: 0.47833500475162355\n",
      "Step: 2348 Weights: [0.15726435 2.15516714] , error: 0.4783140911614081\n",
      "Step: 2349 Weights: [0.15771792 2.15511527] , error: 0.47829327284578294\n",
      "Step: 2350 Weights: [0.15817046 2.15506351] , error: 0.47827254937071295\n",
      "Step: 2351 Weights: [0.15862197 2.15501187] , error: 0.47825192030413993\n",
      "Step: 2352 Weights: [0.15907245 2.15496036] , error: 0.47823138521597164\n",
      "Step: 2353 Weights: [0.1595219  2.15490895] , error: 0.4782109436780787\n",
      "Step: 2354 Weights: [0.15997033 2.15485767] , error: 0.4781905952642819\n",
      "Step: 2355 Weights: [0.16041773 2.1548065 ] , error: 0.47817033955033916\n",
      "Step: 2356 Weights: [0.16086411 2.15475545] , error: 0.4781501761139465\n",
      "Step: 2357 Weights: [0.16130948 2.15470452] , error: 0.4781301045347212\n",
      "Step: 2358 Weights: [0.16175383 2.1546537 ] , error: 0.4781101243941956\n",
      "Step: 2359 Weights: [0.16219717 2.154603  ] , error: 0.47809023527580763\n",
      "Step: 2360 Weights: [0.16263949 2.15455241] , error: 0.47807043676489613\n",
      "Step: 2361 Weights: [0.16308081 2.15450194] , error: 0.47805072844868546\n",
      "Step: 2362 Weights: [0.16352112 2.15445159] , error: 0.47803110991628217\n",
      "Step: 2363 Weights: [0.16396043 2.15440135] , error: 0.4780115807586658\n",
      "Step: 2364 Weights: [0.16439873 2.15435122] , error: 0.47799214056867645\n",
      "Step: 2365 Weights: [0.16483604 2.15430121] , error: 0.47797278894100936\n",
      "Step: 2366 Weights: [0.16527235 2.15425131] , error: 0.4779535254722092\n",
      "Step: 2367 Weights: [0.16570766 2.15420153] , error: 0.47793434976065663\n",
      "Step: 2368 Weights: [0.16614198 2.15415185] , error: 0.4779152614065616\n",
      "Step: 2369 Weights: [0.16657531 2.1541023 ] , error: 0.47789626001195545\n",
      "Step: 2370 Weights: [0.16700765 2.15405285] , error: 0.4778773451806836\n",
      "Step: 2371 Weights: [0.16743901 2.15400352] , error: 0.477858516518394\n",
      "Step: 2372 Weights: [0.16786938 2.1539543 ] , error: 0.4778397736325358\n",
      "Step: 2373 Weights: [0.16829877 2.15390519] , error: 0.47782111613233924\n",
      "Step: 2374 Weights: [0.16872718 2.1538562 ] , error: 0.4778025436288209\n",
      "Step: 2375 Weights: [0.16915462 2.15380732] , error: 0.47778405573476834\n",
      "Step: 2376 Weights: [0.16958108 2.15375854] , error: 0.4777656520647305\n",
      "Step: 2377 Weights: [0.17000656 2.15370988] , error: 0.4777473322350142\n",
      "Step: 2378 Weights: [0.17043108 2.15366133] , error: 0.47772909586367246\n",
      "Step: 2379 Weights: [0.17085463 2.1536129 ] , error: 0.47771094257050295\n",
      "Step: 2380 Weights: [0.17127721 2.15356457] , error: 0.47769287197703064\n",
      "Step: 2381 Weights: [0.17169883 2.15351635] , error: 0.4776748837065057\n",
      "Step: 2382 Weights: [0.17211949 2.15346824] , error: 0.47765697738389545\n",
      "Step: 2383 Weights: [0.17253919 2.15342024] , error: 0.4776391526358752\n",
      "Step: 2384 Weights: [0.17295793 2.15337235] , error: 0.4776214090908232\n",
      "Step: 2385 Weights: [0.17337572 2.15332457] , error: 0.47760374637880576\n",
      "Step: 2386 Weights: [0.17379255 2.1532769 ] , error: 0.4775861641315805\n",
      "Step: 2387 Weights: [0.17420844 2.15322934] , error: 0.4775686619825765\n",
      "Step: 2388 Weights: [0.17462337 2.15318189] , error: 0.4775512395668986\n",
      "Step: 2389 Weights: [0.17503736 2.15313454] , error: 0.4775338965213096\n",
      "Step: 2390 Weights: [0.1754504 2.1530873] , error: 0.47751663248422843\n",
      "Step: 2391 Weights: [0.17586251 2.15304017] , error: 0.47749944709572234\n",
      "Step: 2392 Weights: [0.17627367 2.15299315] , error: 0.47748233999749795\n",
      "Step: 2393 Weights: [0.1766839  2.15294624] , error: 0.4774653108328919\n",
      "Step: 2394 Weights: [0.17709319 2.15289943] , error: 0.4774483592468699\n",
      "Step: 2395 Weights: [0.17750154 2.15285273] , error: 0.4774314848860096\n",
      "Step: 2396 Weights: [0.17790897 2.15280613] , error: 0.4774146873985046\n",
      "Step: 2397 Weights: [0.17831547 2.15275964] , error: 0.47739796643414645\n",
      "Step: 2398 Weights: [0.17872103 2.15271326] , error: 0.4773813216443251\n",
      "Step: 2399 Weights: [0.17912568 2.15266698] , error: 0.4773647526820163\n",
      "Step: 2400 Weights: [0.1795294  2.15262081] , error: 0.4773482592017778\n",
      "Step: 2401 Weights: [0.1799322  2.15257475] , error: 0.47733184085974256\n",
      "Step: 2402 Weights: [0.18033408 2.15252879] , error: 0.47731549731360867\n",
      "Step: 2403 Weights: [0.18073505 2.15248293] , error: 0.47729922822263227\n",
      "Step: 2404 Weights: [0.1811351  2.15243718] , error: 0.4772830332476241\n",
      "Step: 2405 Weights: [0.18153424 2.15239153] , error: 0.47726691205093896\n",
      "Step: 2406 Weights: [0.18193247 2.15234599] , error: 0.4772508642964699\n",
      "Step: 2407 Weights: [0.18232979 2.15230055] , error: 0.4772348896496419\n",
      "Step: 2408 Weights: [0.18272621 2.15225521] , error: 0.4772189877774031\n",
      "Step: 2409 Weights: [0.18312172 2.15220998] , error: 0.4772031583482194\n",
      "Step: 2410 Weights: [0.18351633 2.15216485] , error: 0.477187401032066\n",
      "Step: 2411 Weights: [0.18391004 2.15211982] , error: 0.47717171550042436\n",
      "Step: 2412 Weights: [0.18430285 2.1520749 ] , error: 0.47715610142627046\n",
      "Step: 2413 Weights: [0.18469476 2.15203008] , error: 0.47714055848406983\n",
      "Step: 2414 Weights: [0.18508579 2.15198536] , error: 0.47712508634977113\n",
      "Step: 2415 Weights: [0.18547592 2.15194074] , error: 0.47710968470080095\n",
      "Step: 2416 Weights: [0.18586516 2.15189623] , error: 0.477094353216053\n",
      "Step: 2417 Weights: [0.18625351 2.15185182] , error: 0.47707909157588546\n",
      "Step: 2418 Weights: [0.18664098 2.1518075 ] , error: 0.4770638994621124\n",
      "Step: 2419 Weights: [0.18702756 2.15176329] , error: 0.47704877655799627\n",
      "Step: 2420 Weights: [0.18741326 2.15171918] , error: 0.4770337225482454\n",
      "Step: 2421 Weights: [0.18779809 2.15167517] , error: 0.4770187371190008\n",
      "Step: 2422 Weights: [0.18818203 2.15163126] , error: 0.47700381995783603\n",
      "Step: 2423 Weights: [0.1885651  2.15158745] , error: 0.4769889707537458\n",
      "Step: 2424 Weights: [0.1889473  2.15154374] , error: 0.47697418919714424\n",
      "Step: 2425 Weights: [0.18932862 2.15150013] , error: 0.47695947497985314\n",
      "Step: 2426 Weights: [0.18970908 2.15145662] , error: 0.476944827795101\n",
      "Step: 2427 Weights: [0.19008866 2.15141321] , error: 0.4769302473375096\n",
      "Step: 2428 Weights: [0.19046739 2.1513699 ] , error: 0.4769157333030973\n",
      "Step: 2429 Weights: [0.19084524 2.15132669] , error: 0.4769012853892639\n",
      "Step: 2430 Weights: [0.19122224 2.15128357] , error: 0.4768869032947878\n",
      "Step: 2431 Weights: [0.19159838 2.15124055] , error: 0.4768725867198207\n",
      "Step: 2432 Weights: [0.19197365 2.15119764] , error: 0.4768583353658814\n",
      "Step: 2433 Weights: [0.19234808 2.15115481] , error: 0.47684414893584376\n",
      "Step: 2434 Weights: [0.19272165 2.15111209] , error: 0.4768300271339412\n",
      "Step: 2435 Weights: [0.19309436 2.15106947] , error: 0.47681596966575\n",
      "Step: 2436 Weights: [0.19346623 2.15102694] , error: 0.47680197623819176\n",
      "Step: 2437 Weights: [0.19383725 2.15098451] , error: 0.476788046559519\n",
      "Step: 2438 Weights: [0.19420742 2.15094217] , error: 0.47677418033931623\n",
      "Step: 2439 Weights: [0.19457675 2.15089993] , error: 0.47676037728849086\n",
      "Step: 2440 Weights: [0.19494524 2.15085779] , error: 0.47674663711926385\n",
      "Step: 2441 Weights: [0.19531289 2.15081575] , error: 0.4767329595451739\n",
      "Step: 2442 Weights: [0.1956797 2.1507738] , error: 0.476719344281056\n",
      "Step: 2443 Weights: [0.19604567 2.15073194] , error: 0.4767057910430533\n",
      "Step: 2444 Weights: [0.1964108  2.15069018] , error: 0.47669229954859516\n",
      "Step: 2445 Weights: [0.19677511 2.15064852] , error: 0.4766788695164016\n",
      "Step: 2446 Weights: [0.19713858 2.15060695] , error: 0.47666550066647206\n",
      "Step: 2447 Weights: [0.19750123 2.15056548] , error: 0.47665219272008524\n",
      "Step: 2448 Weights: [0.19786305 2.1505241 ] , error: 0.476638945399784\n",
      "Step: 2449 Weights: [0.19822404 2.15048282] , error: 0.4766257584293815\n",
      "Step: 2450 Weights: [0.19858421 2.15044162] , error: 0.4766126315339432\n",
      "Step: 2451 Weights: [0.19894356 2.15040053] , error: 0.4765995644397923\n",
      "Step: 2452 Weights: [0.19930208 2.15035953] , error: 0.4765865568744938\n",
      "Step: 2453 Weights: [0.1996598  2.15031862] , error: 0.4765736085668577\n",
      "Step: 2454 Weights: [0.20001669 2.1502778 ] , error: 0.476560719246927\n",
      "Step: 2455 Weights: [0.20037277 2.15023708] , error: 0.4765478886459761\n",
      "Step: 2456 Weights: [0.20072804 2.15019645] , error: 0.4765351164965032\n",
      "Step: 2457 Weights: [0.2010825  2.15015591] , error: 0.4765224025322249\n",
      "Step: 2458 Weights: [0.20143615 2.15011546] , error: 0.47650974648807065\n",
      "Step: 2459 Weights: [0.201789   2.15007511] , error: 0.4764971481001784\n",
      "Step: 2460 Weights: [0.20214104 2.15003485] , error: 0.4764846071058869\n",
      "Step: 2461 Weights: [0.20249228 2.14999468] , error: 0.47647212324373134\n",
      "Step: 2462 Weights: [0.20284271 2.1499546 ] , error: 0.4764596962534402\n",
      "Step: 2463 Weights: [0.20319235 2.14991462] , error: 0.47644732587592586\n",
      "Step: 2464 Weights: [0.20354119 2.14987472] , error: 0.47643501185328113\n",
      "Step: 2465 Weights: [0.20388923 2.14983492] , error: 0.4764227539287747\n",
      "Step: 2466 Weights: [0.20423648 2.14979521] , error: 0.4764105518468432\n",
      "Step: 2467 Weights: [0.20458294 2.14975558] , error: 0.47639840535308986\n",
      "Step: 2468 Weights: [0.20492861 2.14971605] , error: 0.47638631419427335\n",
      "Step: 2469 Weights: [0.20527349 2.14967661] , error: 0.47637427811831007\n",
      "Step: 2470 Weights: [0.20561758 2.14963726] , error: 0.47636229687426335\n",
      "Step: 2471 Weights: [0.20596089 2.149598  ] , error: 0.4763503702123366\n",
      "Step: 2472 Weights: [0.20630342 2.14955882] , error: 0.4763384978838761\n",
      "Step: 2473 Weights: [0.20664517 2.14951974] , error: 0.47632667964135844\n",
      "Step: 2474 Weights: [0.20698613 2.14948075] , error: 0.47631491523838554\n",
      "Step: 2475 Weights: [0.20732632 2.14944184] , error: 0.4763032044296882\n",
      "Step: 2476 Weights: [0.20766573 2.14940302] , error: 0.47629154697110904\n",
      "Step: 2477 Weights: [0.20800437 2.14936429] , error: 0.47627994261960294\n",
      "Step: 2478 Weights: [0.20834224 2.14932566] , error: 0.4762683911332354\n",
      "Step: 2479 Weights: [0.20867933 2.1492871 ] , error: 0.4762568922711732\n",
      "Step: 2480 Weights: [0.20901566 2.14924864] , error: 0.4762454457936782\n",
      "Step: 2481 Weights: [0.20935122 2.14921026] , error: 0.47623405146210546\n",
      "Step: 2482 Weights: [0.20968602 2.14917197] , error: 0.47622270903889763\n",
      "Step: 2483 Weights: [0.21002005 2.14913377] , error: 0.4762114182875797\n",
      "Step: 2484 Weights: [0.21035332 2.14909566] , error: 0.47620017897275435\n",
      "Step: 2485 Weights: [0.21068583 2.14905763] , error: 0.4761889908600942\n",
      "Step: 2486 Weights: [0.21101758 2.14901969] , error: 0.4761778537163413\n",
      "Step: 2487 Weights: [0.21134857 2.14898184] , error: 0.4761667673093026\n",
      "Step: 2488 Weights: [0.21167881 2.14894407] , error: 0.47615573140783773\n",
      "Step: 2489 Weights: [0.2120083  2.14890639] , error: 0.4761447457818625\n",
      "Step: 2490 Weights: [0.21233704 2.14886879] , error: 0.47613381020234\n",
      "Step: 2491 Weights: [0.21266502 2.14883128] , error: 0.4761229244412791\n",
      "Step: 2492 Weights: [0.21299226 2.14879386] , error: 0.4761120882717239\n",
      "Step: 2493 Weights: [0.21331875 2.14875652] , error: 0.47610130146775337\n",
      "Step: 2494 Weights: [0.2136445  2.14871927] , error: 0.4760905638044765\n",
      "Step: 2495 Weights: [0.2139695 2.1486821] , error: 0.4760798750580268\n",
      "Step: 2496 Weights: [0.21429377 2.14864501] , error: 0.47606923500555753\n",
      "Step: 2497 Weights: [0.21461729 2.14860801] , error: 0.47605864342523607\n",
      "Step: 2498 Weights: [0.21494008 2.1485711 ] , error: 0.47604810009624127\n",
      "Step: 2499 Weights: [0.21526213 2.14853427] , error: 0.4760376047987579\n",
      "Step: 2500 Weights: [0.21558344 2.14849752] , error: 0.4760271573139728\n",
      "Step: 2501 Weights: [0.21590403 2.14846086] , error: 0.4760167574240696\n",
      "Step: 2502 Weights: [0.21622388 2.14842428] , error: 0.47600640491222135\n",
      "Step: 2503 Weights: [0.216543   2.14838778] , error: 0.47599609956259414\n",
      "Step: 2504 Weights: [0.2168614  2.14835137] , error: 0.4759858411603311\n",
      "Step: 2505 Weights: [0.21717906 2.14831504] , error: 0.47597562949155936\n",
      "Step: 2506 Weights: [0.21749601 2.14827879] , error: 0.47596546434337794\n",
      "Step: 2507 Weights: [0.21781223 2.14824263] , error: 0.4759553455038552\n",
      "Step: 2508 Weights: [0.21812773 2.14820654] , error: 0.47594527276202786\n",
      "Step: 2509 Weights: [0.21844251 2.14817055] , error: 0.4759352459078922\n",
      "Step: 2510 Weights: [0.21875658 2.14813463] , error: 0.47592526473239755\n",
      "Step: 2511 Weights: [0.21906992 2.14809879] , error: 0.4759153290274527\n",
      "Step: 2512 Weights: [0.21938255 2.14806304] , error: 0.4759054385859084\n",
      "Step: 2513 Weights: [0.21969447 2.14802737] , error: 0.47589559320156166\n",
      "Step: 2514 Weights: [0.22000568 2.14799177] , error: 0.47588579266914793\n",
      "Step: 2515 Weights: [0.22031618 2.14795626] , error: 0.47587603678433976\n",
      "Step: 2516 Weights: [0.22062597 2.14792084] , error: 0.47586632534373907\n",
      "Step: 2517 Weights: [0.22093505 2.14788549] , error: 0.4758566581448733\n",
      "Step: 2518 Weights: [0.22124343 2.14785022] , error: 0.47584703498619424\n",
      "Step: 2519 Weights: [0.22155111 2.14781503] , error: 0.4758374556670713\n",
      "Step: 2520 Weights: [0.22185808 2.14777993] , error: 0.47582791998778695\n",
      "Step: 2521 Weights: [0.22216436 2.1477449 ] , error: 0.47581842774953453\n",
      "Step: 2522 Weights: [0.22246993 2.14770995] , error: 0.4758089787544135\n",
      "Step: 2523 Weights: [0.22277481 2.14767509] , error: 0.475799572805422\n",
      "Step: 2524 Weights: [0.223079  2.1476403] , error: 0.47579020970646035\n",
      "Step: 2525 Weights: [0.22338249 2.14760559] , error: 0.47578088926231743\n",
      "Step: 2526 Weights: [0.22368528 2.14757096] , error: 0.4757716112786755\n",
      "Step: 2527 Weights: [0.22398739 2.14753641] , error: 0.4757623755620991\n",
      "Step: 2528 Weights: [0.22428881 2.14750194] , error: 0.47575318192003546\n",
      "Step: 2529 Weights: [0.22458954 2.14746755] , error: 0.47574403016080863\n",
      "Step: 2530 Weights: [0.22488959 2.14743323] , error: 0.47573492009361545\n",
      "Step: 2531 Weights: [0.22518895 2.14739899] , error: 0.4757258515285231\n",
      "Step: 2532 Weights: [0.22548763 2.14736484] , error: 0.4757168242764628\n",
      "Step: 2533 Weights: [0.22578562 2.14733076] , error: 0.4757078381492281\n",
      "Step: 2534 Weights: [0.22608294 2.14729675] , error: 0.475698892959469\n",
      "Step: 2535 Weights: [0.22637958 2.14726283] , error: 0.47568998852069\n",
      "Step: 2536 Weights: [0.22667554 2.14722898] , error: 0.4756811246472444\n",
      "Step: 2537 Weights: [0.22697083 2.14719521] , error: 0.4756723011543308\n",
      "Step: 2538 Weights: [0.22726545 2.14716152] , error: 0.4756635178579919\n",
      "Step: 2539 Weights: [0.22755939 2.1471279 ] , error: 0.47565477457510563\n",
      "Step: 2540 Weights: [0.22785266 2.14709436] , error: 0.4756460711233864\n",
      "Step: 2541 Weights: [0.22814527 2.1470609 ] , error: 0.47563740732137794\n",
      "Step: 2542 Weights: [0.2284372  2.14702751] , error: 0.4756287829884503\n",
      "Step: 2543 Weights: [0.22872847 2.1469942 ] , error: 0.47562019794479815\n",
      "Step: 2544 Weights: [0.22901908 2.14696096] , error: 0.47561165201143263\n",
      "Step: 2545 Weights: [0.22930903 2.1469278 ] , error: 0.47560314501018164\n",
      "Step: 2546 Weights: [0.22959831 2.14689472] , error: 0.4755946767636864\n",
      "Step: 2547 Weights: [0.22988693 2.14686171] , error: 0.4755862470953937\n",
      "Step: 2548 Weights: [0.2301749  2.14682878] , error: 0.4755778558295553\n",
      "Step: 2549 Weights: [0.2304622  2.14679592] , error: 0.4755695027912235\n",
      "Step: 2550 Weights: [0.23074886 2.14676314] , error: 0.475561187806248\n",
      "Step: 2551 Weights: [0.23103486 2.14673043] , error: 0.4755529107012732\n",
      "Step: 2552 Weights: [0.2313202 2.1466978] , error: 0.47554467130372896\n",
      "Step: 2553 Weights: [0.2316049  2.14666524] , error: 0.47553646944183875\n",
      "Step: 2554 Weights: [0.23188895 2.14663275] , error: 0.47552830494460047\n",
      "Step: 2555 Weights: [0.23217235 2.14660034] , error: 0.47552017764179455\n",
      "Step: 2556 Weights: [0.2324551  2.14656801] , error: 0.4755120873639778\n",
      "Step: 2557 Weights: [0.23273721 2.14653574] , error: 0.4755040339424784\n",
      "Step: 2558 Weights: [0.23301868 2.14650355] , error: 0.47549601720939044\n",
      "Step: 2559 Weights: [0.2332995  2.14647144] , error: 0.47548803699757836\n",
      "Step: 2560 Weights: [0.23357968 2.14643939] , error: 0.47548009314066253\n",
      "Step: 2561 Weights: [0.23385923 2.14640742] , error: 0.47547218547302394\n",
      "Step: 2562 Weights: [0.23413813 2.14637553] , error: 0.4754643138297977\n",
      "Step: 2563 Weights: [0.2344164 2.1463437] , error: 0.4754564780468707\n",
      "Step: 2564 Weights: [0.23469404 2.14631195] , error: 0.4754486779608749\n",
      "Step: 2565 Weights: [0.23497104 2.14628027] , error: 0.47544091340918954\n",
      "Step: 2566 Weights: [0.23524741 2.14624867] , error: 0.47543318422993364\n",
      "Step: 2567 Weights: [0.23552315 2.14621713] , error: 0.47542549026196124\n",
      "Step: 2568 Weights: [0.23579827 2.14618567] , error: 0.47541783134486615\n",
      "Step: 2569 Weights: [0.23607275 2.14615428] , error: 0.475410207318967\n",
      "Step: 2570 Weights: [0.23634661 2.14612296] , error: 0.475402618025314\n",
      "Step: 2571 Weights: [0.23661984 2.14609171] , error: 0.47539506330567854\n",
      "Step: 2572 Weights: [0.23689246 2.14606053] , error: 0.4753875430025542\n",
      "Step: 2573 Weights: [0.23716444 2.14602943] , error: 0.47538005695915403\n",
      "Step: 2574 Weights: [0.23743581 2.14599839] , error: 0.4753726050194008\n",
      "Step: 2575 Weights: [0.23770656 2.14596743] , error: 0.47536518702793223\n",
      "Step: 2576 Weights: [0.2379767  2.14593653] , error: 0.47535780283009194\n",
      "Step: 2577 Weights: [0.23824621 2.14590571] , error: 0.4753504522719292\n",
      "Step: 2578 Weights: [0.23851512 2.14587496] , error: 0.4753431352001941\n",
      "Step: 2579 Weights: [0.23878341 2.14584427] , error: 0.47533585146233437\n",
      "Step: 2580 Weights: [0.23905108 2.14581366] , error: 0.4753286009064941\n",
      "Step: 2581 Weights: [0.23931815 2.14578312] , error: 0.4753213833815065\n",
      "Step: 2582 Weights: [0.23958461 2.14575265] , error: 0.47531419873689634\n",
      "Step: 2583 Weights: [0.23985046 2.14572224] , error: 0.47530704682287395\n",
      "Step: 2584 Weights: [0.2401157  2.14569191] , error: 0.4752999274903283\n",
      "Step: 2585 Weights: [0.24038034 2.14566164] , error: 0.4752928405908329\n",
      "Step: 2586 Weights: [0.24064438 2.14563145] , error: 0.47528578597663307\n",
      "Step: 2587 Weights: [0.24090781 2.14560132] , error: 0.4752787635006481\n",
      "Step: 2588 Weights: [0.24117064 2.14557126] , error: 0.47527177301647033\n",
      "Step: 2589 Weights: [0.24143288 2.14554127] , error: 0.4752648143783552\n",
      "Step: 2590 Weights: [0.24169451 2.14551135] , error: 0.47525788744122466\n",
      "Step: 2591 Weights: [0.24195555 2.14548149] , error: 0.47525099206066207\n",
      "Step: 2592 Weights: [0.242216   2.14545171] , error: 0.4752441280929045\n",
      "Step: 2593 Weights: [0.24247585 2.14542199] , error: 0.4752372953948479\n",
      "Step: 2594 Weights: [0.2427351  2.14539234] , error: 0.4752304938240397\n",
      "Step: 2595 Weights: [0.24299377 2.14536276] , error: 0.4752237232386759\n",
      "Step: 2596 Weights: [0.24325184 2.14533325] , error: 0.4752169834975966\n",
      "Step: 2597 Weights: [0.24350933 2.1453038 ] , error: 0.47521027446028874\n",
      "Step: 2598 Weights: [0.24376623 2.14527442] , error: 0.47520359598687556\n",
      "Step: 2599 Weights: [0.24402255 2.1452451 ] , error: 0.47519694793812034\n",
      "Step: 2600 Weights: [0.24427828 2.14521586] , error: 0.47519033017541884\n",
      "Step: 2601 Weights: [0.24453342 2.14518668] , error: 0.47518374256080087\n",
      "Step: 2602 Weights: [0.24478799 2.14515757] , error: 0.47517718495691985\n",
      "Step: 2603 Weights: [0.24504197 2.14512852] , error: 0.47517065722705965\n",
      "Step: 2604 Weights: [0.24529538 2.14509954] , error: 0.47516415923512484\n",
      "Step: 2605 Weights: [0.24554821 2.14507062] , error: 0.47515769084564136\n",
      "Step: 2606 Weights: [0.24580046 2.14504178] , error: 0.47515125192374946\n",
      "Step: 2607 Weights: [0.24605213 2.14501299] , error: 0.4751448423352083\n",
      "Step: 2608 Weights: [0.24630323 2.14498428] , error: 0.47513846194638454\n",
      "Step: 2609 Weights: [0.24655376 2.14495562] , error: 0.4751321106242543\n",
      "Step: 2610 Weights: [0.24680372 2.14492704] , error: 0.4751257882364014\n",
      "Step: 2611 Weights: [0.24705311 2.14489852] , error: 0.47511949465101155\n",
      "Step: 2612 Weights: [0.24730193 2.14487006] , error: 0.475113229736872\n",
      "Step: 2613 Weights: [0.24755018 2.14484167] , error: 0.4751069933633665\n",
      "Step: 2614 Weights: [0.24779786 2.14481334] , error: 0.47510078540047507\n",
      "Step: 2615 Weights: [0.24804499 2.14478508] , error: 0.4750946057187686\n",
      "Step: 2616 Weights: [0.24829154 2.14475688] , error: 0.4750884541894099\n",
      "Step: 2617 Weights: [0.24853754 2.14472875] , error: 0.4750823306841455\n",
      "Step: 2618 Weights: [0.24878297 2.14470068] , error: 0.4750762350753088\n",
      "Step: 2619 Weights: [0.24902785 2.14467268] , error: 0.4750701672358142\n",
      "Step: 2620 Weights: [0.24927216 2.14464474] , error: 0.47506412703915557\n",
      "Step: 2621 Weights: [0.24951592 2.14461686] , error: 0.4750581143593994\n",
      "Step: 2622 Weights: [0.24975912 2.14458905] , error: 0.4750521290711929\n",
      "Step: 2623 Weights: [0.25000177 2.1445613 ] , error: 0.4750461710497472\n",
      "Step: 2624 Weights: [0.25024387 2.14453361] , error: 0.4750402401708458\n",
      "Step: 2625 Weights: [0.25048541 2.14450598] , error: 0.475034336310838\n",
      "Step: 2626 Weights: [0.2507264  2.14447842] , error: 0.4750284593466359\n",
      "Step: 2627 Weights: [0.25096684 2.14445093] , error: 0.4750226091557106\n",
      "Step: 2628 Weights: [0.25120674 2.14442349] , error: 0.47501678561609406\n",
      "Step: 2629 Weights: [0.25144608 2.14439612] , error: 0.4750109886063731\n",
      "Step: 2630 Weights: [0.25168489 2.14436881] , error: 0.47500521800568574\n",
      "Step: 2631 Weights: [0.25192314 2.14434156] , error: 0.4749994736937236\n",
      "Step: 2632 Weights: [0.25216086 2.14431437] , error: 0.4749937555507242\n",
      "Step: 2633 Weights: [0.25239803 2.14428725] , error: 0.4749880634574725\n",
      "Step: 2634 Weights: [0.25263466 2.14426019] , error: 0.474982397295295\n",
      "Step: 2635 Weights: [0.25287075 2.14423319] , error: 0.4749767569460588\n",
      "Step: 2636 Weights: [0.2531063  2.14420625] , error: 0.47497114229216925\n",
      "Step: 2637 Weights: [0.25334132 2.14417937] , error: 0.47496555321656925\n",
      "Step: 2638 Weights: [0.25357579 2.14415255] , error: 0.47495998960273283\n",
      "Step: 2639 Weights: [0.25380974 2.1441258 ] , error: 0.4749544513346652\n",
      "Step: 2640 Weights: [0.25404315 2.14409911] , error: 0.47494893829690105\n",
      "Step: 2641 Weights: [0.25427603 2.14407247] , error: 0.4749434503745002\n",
      "Step: 2642 Weights: [0.25450838 2.1440459 ] , error: 0.4749379874530468\n",
      "Step: 2643 Weights: [0.25474019 2.14401939] , error: 0.4749325494186446\n",
      "Step: 2644 Weights: [0.25497148 2.14399294] , error: 0.47492713615791793\n",
      "Step: 2645 Weights: [0.25520225 2.14396655] , error: 0.4749217475580084\n",
      "Step: 2646 Weights: [0.25543248 2.14394022] , error: 0.4749163835065686\n",
      "Step: 2647 Weights: [0.25566219 2.14391395] , error: 0.4749110438917653\n",
      "Step: 2648 Weights: [0.25589138 2.14388773] , error: 0.47490572860227453\n",
      "Step: 2649 Weights: [0.25612004 2.14386158] , error: 0.4749004375272782\n",
      "Step: 2650 Weights: [0.25634819 2.14383549] , error: 0.474895170556466\n",
      "Step: 2651 Weights: [0.25657581 2.14380946] , error: 0.4748899275800263\n",
      "Step: 2652 Weights: [0.25680291 2.14378349] , error: 0.47488470848865166\n",
      "Step: 2653 Weights: [0.2570295  2.14375757] , error: 0.47487951317352683\n",
      "Step: 2654 Weights: [0.25725557 2.14373172] , error: 0.4748743415263397\n",
      "Step: 2655 Weights: [0.25748112 2.14370593] , error: 0.47486919343926715\n",
      "Step: 2656 Weights: [0.25770616 2.14368019] , error: 0.47486406880497667\n",
      "Step: 2657 Weights: [0.25793068 2.14365451] , error: 0.4748589675166259\n",
      "Step: 2658 Weights: [0.2581547  2.14362889] , error: 0.47485388946786206\n",
      "Step: 2659 Weights: [0.2583782  2.14360333] , error: 0.47484883455281124\n",
      "Step: 2660 Weights: [0.25860119 2.14357783] , error: 0.4748438026660856\n",
      "Step: 2661 Weights: [0.25882368 2.14355238] , error: 0.4748387937027773\n",
      "Step: 2662 Weights: [0.25904565 2.143527  ] , error: 0.47483380755845583\n",
      "Step: 2663 Weights: [0.25926713 2.14350167] , error: 0.47482884412916443\n",
      "Step: 2664 Weights: [0.25948809 2.1434764 ] , error: 0.47482390331142443\n",
      "Step: 2665 Weights: [0.25970855 2.14345119] , error: 0.4748189850022251\n",
      "Step: 2666 Weights: [0.25992851 2.14342603] , error: 0.47481408909902395\n",
      "Step: 2667 Weights: [0.26014797 2.14340093] , error: 0.47480921549974875\n",
      "Step: 2668 Weights: [0.26036693 2.14337589] , error: 0.47480436410279286\n",
      "Step: 2669 Weights: [0.26058539 2.14335091] , error: 0.4747995348070098\n",
      "Step: 2670 Weights: [0.26080335 2.14332598] , error: 0.4747947275117125\n",
      "Step: 2671 Weights: [0.26102081 2.14330111] , error: 0.47478994211667674\n",
      "Step: 2672 Weights: [0.26123778 2.1432763 ] , error: 0.4747851785221343\n",
      "Step: 2673 Weights: [0.26145425 2.14325154] , error: 0.47478043662876745\n",
      "Step: 2674 Weights: [0.26167023 2.14322684] , error: 0.4747757163377146\n",
      "Step: 2675 Weights: [0.26188571 2.1432022 ] , error: 0.4747710175505645\n",
      "Step: 2676 Weights: [0.26210071 2.14317761] , error: 0.4747663401693531\n",
      "Step: 2677 Weights: [0.26231521 2.14315308] , error: 0.4747616840965624\n",
      "Step: 2678 Weights: [0.26252923 2.1431286 ] , error: 0.4747570492351185\n",
      "Step: 2679 Weights: [0.26274275 2.14310418] , error: 0.4747524354883911\n",
      "Step: 2680 Weights: [0.26295579 2.14307982] , error: 0.47474784276018983\n",
      "Step: 2681 Weights: [0.26316835 2.14305551] , error: 0.47474327095476143\n",
      "Step: 2682 Weights: [0.26338042 2.14303126] , error: 0.4747387199767894\n",
      "Step: 2683 Weights: [0.263592   2.14300706] , error: 0.4747341897313913\n",
      "Step: 2684 Weights: [0.26380311 2.14298292] , error: 0.47472968012411826\n",
      "Step: 2685 Weights: [0.26401373 2.14295883] , error: 0.47472519106094896\n",
      "Step: 2686 Weights: [0.26422387 2.1429348 ] , error: 0.4747207224482941\n",
      "Step: 2687 Weights: [0.26443353 2.14291082] , error: 0.47471627419298745\n",
      "Step: 2688 Weights: [0.26464272 2.14288689] , error: 0.4747118462022882\n",
      "Step: 2689 Weights: [0.26485142 2.14286303] , error: 0.4747074383838788\n",
      "Step: 2690 Weights: [0.26505966 2.14283921] , error: 0.47470305064586116\n",
      "Step: 2691 Weights: [0.26526741 2.14281545] , error: 0.47469868289675765\n",
      "Step: 2692 Weights: [0.2654747  2.14279175] , error: 0.47469433504550507\n",
      "Step: 2693 Weights: [0.26568151 2.14276809] , error: 0.47469000700145697\n",
      "Step: 2694 Weights: [0.26588784 2.1427445 ] , error: 0.47468569867437793\n",
      "Step: 2695 Weights: [0.26609371 2.14272095] , error: 0.47468140997444574\n",
      "Step: 2696 Weights: [0.26629911 2.14269746] , error: 0.47467714081224566\n",
      "Step: 2697 Weights: [0.26650404 2.14267403] , error: 0.47467289109877286\n",
      "Step: 2698 Weights: [0.2667085  2.14265064] , error: 0.4746686607454222\n",
      "Step: 2699 Weights: [0.2669125  2.14262731] , error: 0.4746644496639999\n",
      "Step: 2700 Weights: [0.26711603 2.14260404] , error: 0.4746602577667093\n",
      "Step: 2701 Weights: [0.2673191  2.14258081] , error: 0.47465608496615364\n",
      "Step: 2702 Weights: [0.2675217  2.14255764] , error: 0.47465193117533516\n",
      "Step: 2703 Weights: [0.26772385 2.14253452] , error: 0.4746477963076534\n",
      "Step: 2704 Weights: [0.26792553 2.14251146] , error: 0.4746436802769018\n",
      "Step: 2705 Weights: [0.26812675 2.14248845] , error: 0.474639582997265\n",
      "Step: 2706 Weights: [0.26832751 2.14246549] , error: 0.47463550438332014\n",
      "Step: 2707 Weights: [0.26852781 2.14244258] , error: 0.4746314443500338\n",
      "Step: 2708 Weights: [0.26872766 2.14241972] , error: 0.47462740281275967\n",
      "Step: 2709 Weights: [0.26892705 2.14239692] , error: 0.4746233796872368\n",
      "Step: 2710 Weights: [0.26912599 2.14237417] , error: 0.47461937488958633\n",
      "Step: 2711 Weights: [0.26932448 2.14235147] , error: 0.474615388336315\n",
      "Step: 2712 Weights: [0.26952251 2.14232882] , error: 0.47461141994430833\n",
      "Step: 2713 Weights: [0.26972009 2.14230623] , error: 0.47460746963082745\n",
      "Step: 2714 Weights: [0.26991722 2.14228368] , error: 0.47460353731351757\n",
      "Step: 2715 Weights: [0.27011389 2.14226119] , error: 0.4745996229103906\n",
      "Step: 2716 Weights: [0.27031013 2.14223875] , error: 0.47459572633983993\n",
      "Step: 2717 Weights: [0.27050591 2.14221636] , error: 0.47459184752062533\n",
      "Step: 2718 Weights: [0.27070125 2.14219402] , error: 0.474587986371876\n",
      "Step: 2719 Weights: [0.27089614 2.14217173] , error: 0.47458414281309513\n",
      "Step: 2720 Weights: [0.27109058 2.14214949] , error: 0.4745803167641479\n",
      "Step: 2721 Weights: [0.27128459 2.1421273 ] , error: 0.4745765081452661\n",
      "Step: 2722 Weights: [0.27147815 2.14210517] , error: 0.4745727168770453\n",
      "Step: 2723 Weights: [0.27167127 2.14208308] , error: 0.474568942880441\n",
      "Step: 2724 Weights: [0.27186395 2.14206104] , error: 0.47456518607677234\n",
      "Step: 2725 Weights: [0.27205619 2.14203906] , error: 0.47456144638771214\n",
      "Step: 2726 Weights: [0.27224799 2.14201712] , error: 0.474557723735294\n",
      "Step: 2727 Weights: [0.27243935 2.14199524] , error: 0.4745540180419053\n",
      "Step: 2728 Weights: [0.27263028 2.1419734 ] , error: 0.4745503292302863\n",
      "Step: 2729 Weights: [0.27282077 2.14195162] , error: 0.47454665722353023\n",
      "Step: 2730 Weights: [0.27301083 2.14192988] , error: 0.4745430019450797\n",
      "Step: 2731 Weights: [0.27320046 2.1419082 ] , error: 0.4745393633187285\n",
      "Step: 2732 Weights: [0.27338965 2.14188656] , error: 0.47453574126861475\n",
      "Step: 2733 Weights: [0.27357841 2.14186497] , error: 0.47453213571922276\n",
      "Step: 2734 Weights: [0.27376674 2.14184343] , error: 0.4745285465953816\n",
      "Step: 2735 Weights: [0.27395464 2.14182194] , error: 0.47452497382226216\n",
      "Step: 2736 Weights: [0.27414211 2.1418005 ] , error: 0.47452141732537767\n",
      "Step: 2737 Weights: [0.27432916 2.14177911] , error: 0.4745178770305792\n",
      "Step: 2738 Weights: [0.27451578 2.14175777] , error: 0.47451435286405574\n",
      "Step: 2739 Weights: [0.27470197 2.14173648] , error: 0.4745108447523335\n",
      "Step: 2740 Weights: [0.27488774 2.14171523] , error: 0.4745073526222723\n",
      "Step: 2741 Weights: [0.27507308 2.14169403] , error: 0.4745038764010655\n",
      "Step: 2742 Weights: [0.275258   2.14167289] , error: 0.47450041601623694\n",
      "Step: 2743 Weights: [0.2754425  2.14165179] , error: 0.4744969713956448\n",
      "Step: 2744 Weights: [0.27562658 2.14163073] , error: 0.4744935424674708\n",
      "Step: 2745 Weights: [0.27581024 2.14160973] , error: 0.4744901291602265\n",
      "Step: 2746 Weights: [0.27599348 2.14158877] , error: 0.4744867314027495\n",
      "Step: 2747 Weights: [0.27617631 2.14156786] , error: 0.47448334912419965\n",
      "Step: 2748 Weights: [0.27635871 2.141547  ] , error: 0.4744799822540616\n",
      "Step: 2749 Weights: [0.2765407  2.14152619] , error: 0.4744766307221413\n",
      "Step: 2750 Weights: [0.27672228 2.14150543] , error: 0.47447329445856\n",
      "Step: 2751 Weights: [0.27690344 2.14148471] , error: 0.4744699733937652\n",
      "Step: 2752 Weights: [0.27708419 2.14146404] , error: 0.47446666745851324\n",
      "Step: 2753 Weights: [0.27726452 2.14144341] , error: 0.4744633765838806\n",
      "Step: 2754 Weights: [0.27744445 2.14142284] , error: 0.4744601007012575\n",
      "Step: 2755 Weights: [0.27762396 2.14140231] , error: 0.4744568397423466\n",
      "Step: 2756 Weights: [0.27780307 2.14138182] , error: 0.4744535936391578\n",
      "Step: 2757 Weights: [0.27798176 2.14136139] , error: 0.4744503623240178\n",
      "Step: 2758 Weights: [0.27816005 2.141341  ] , error: 0.4744471457295548\n",
      "Step: 2759 Weights: [0.27833793 2.14132065] , error: 0.4744439437887075\n",
      "Step: 2760 Weights: [0.27851541 2.14130036] , error: 0.4744407564347214\n",
      "Step: 2761 Weights: [0.27869248 2.1412801 ] , error: 0.47443758360114024\n",
      "Step: 2762 Weights: [0.27886915 2.1412599 ] , error: 0.47443442522181795\n",
      "Step: 2763 Weights: [0.27904542 2.14123974] , error: 0.47443128123090467\n",
      "Step: 2764 Weights: [0.27922128 2.14121963] , error: 0.47442815156285234\n",
      "Step: 2765 Weights: [0.27939674 2.14119956] , error: 0.4744250361524112\n",
      "Step: 2766 Weights: [0.2795718  2.14117954] , error: 0.47442193493463\n",
      "Step: 2767 Weights: [0.27974647 2.14115957] , error: 0.474418847844851\n",
      "Step: 2768 Weights: [0.27992073 2.14113964] , error: 0.47441577481871194\n",
      "Step: 2769 Weights: [0.2800946  2.14111975] , error: 0.4744127157921452\n",
      "Step: 2770 Weights: [0.28026807 2.14109991] , error: 0.4744096707013733\n",
      "Step: 2771 Weights: [0.28044114 2.14108012] , error: 0.47440663948290984\n",
      "Step: 2772 Weights: [0.28061382 2.14106037] , error: 0.4744036220735585\n",
      "Step: 2773 Weights: [0.28078611 2.14104067] , error: 0.47440061841040876\n",
      "Step: 2774 Weights: [0.280958   2.14102101] , error: 0.47439762843083866\n",
      "Step: 2775 Weights: [0.28112951 2.1410014 ] , error: 0.4743946520725113\n",
      "Step: 2776 Weights: [0.28130062 2.14098183] , error: 0.47439168927337166\n",
      "Step: 2777 Weights: [0.28147134 2.1409623 ] , error: 0.47438873997165176\n",
      "Step: 2778 Weights: [0.28164167 2.14094282] , error: 0.4743858041058605\n",
      "Step: 2779 Weights: [0.28181161 2.14092339] , error: 0.47438288161478853\n",
      "Step: 2780 Weights: [0.28198117 2.140904  ] , error: 0.47437997243750674\n",
      "Step: 2781 Weights: [0.28215034 2.14088465] , error: 0.47437707651336236\n",
      "Step: 2782 Weights: [0.28231912 2.14086535] , error: 0.47437419378197754\n",
      "Step: 2783 Weights: [0.28248752 2.14084609] , error: 0.47437132418325223\n",
      "Step: 2784 Weights: [0.28265553 2.14082687] , error: 0.47436846765735874\n",
      "Step: 2785 Weights: [0.28282316 2.1408077 ] , error: 0.4743656241447413\n",
      "Step: 2786 Weights: [0.28299041 2.14078858] , error: 0.47436279358611744\n",
      "Step: 2787 Weights: [0.28315728 2.14076949] , error: 0.47435997592247336\n",
      "Step: 2788 Weights: [0.28332376 2.14075045] , error: 0.4743571710950638\n",
      "Step: 2789 Weights: [0.28348987 2.14073146] , error: 0.4743543790454107\n",
      "Step: 2790 Weights: [0.2836556 2.1407125] , error: 0.4743515997153056\n",
      "Step: 2791 Weights: [0.28382095 2.14069359] , error: 0.47434883304680037\n",
      "Step: 2792 Weights: [0.28398592 2.14067472] , error: 0.4743460789822156\n",
      "Step: 2793 Weights: [0.28415052 2.1406559 ] , error: 0.4743433374641313\n",
      "Step: 2794 Weights: [0.28431474 2.14063712] , error: 0.47434060843539044\n",
      "Step: 2795 Weights: [0.28447859 2.14061838] , error: 0.47433789183909664\n",
      "Step: 2796 Weights: [0.28464206 2.14059969] , error: 0.4743351876186119\n",
      "Step: 2797 Weights: [0.28480516 2.14058103] , error: 0.4743324957175557\n",
      "Step: 2798 Weights: [0.28496789 2.14056242] , error: 0.4743298160798076\n",
      "Step: 2799 Weights: [0.28513025 2.14054385] , error: 0.47432714864949876\n",
      "Step: 2800 Weights: [0.28529223 2.14052533] , error: 0.4743244933710159\n",
      "Step: 2801 Weights: [0.28545385 2.14050685] , error: 0.4743218501890022\n",
      "Step: 2802 Weights: [0.2856151 2.1404884] , error: 0.4743192190483481\n",
      "Step: 2803 Weights: [0.28577598 2.14047001] , error: 0.4743165998941995\n",
      "Step: 2804 Weights: [0.2859365  2.14045165] , error: 0.4743139926719493\n",
      "Step: 2805 Weights: [0.28609665 2.14043333] , error: 0.47431139732724137\n",
      "Step: 2806 Weights: [0.28625643 2.14041506] , error: 0.4743088138059636\n",
      "Step: 2807 Weights: [0.28641585 2.14039683] , error: 0.4743062420542555\n",
      "Step: 2808 Weights: [0.2865749  2.14037864] , error: 0.4743036820184967\n",
      "Step: 2809 Weights: [0.2867336  2.14036049] , error: 0.47430113364531656\n",
      "Step: 2810 Weights: [0.28689193 2.14034238] , error: 0.47429859688158277\n",
      "Step: 2811 Weights: [0.2870499  2.14032432] , error: 0.47429607167440657\n",
      "Step: 2812 Weights: [0.28720751 2.14030629] , error: 0.47429355797114214\n",
      "Step: 2813 Weights: [0.28736476 2.14028831] , error: 0.47429105571938074\n",
      "Step: 2814 Weights: [0.28752165 2.14027036] , error: 0.4742885648669547\n",
      "Step: 2815 Weights: [0.28767818 2.14025246] , error: 0.4742860853619321\n",
      "Step: 2816 Weights: [0.28783436 2.1402346 ] , error: 0.474283617152616\n",
      "Step: 2817 Weights: [0.28799018 2.14021678] , error: 0.4742811601875522\n",
      "Step: 2818 Weights: [0.28814565 2.140199  ] , error: 0.47427871441551195\n",
      "Step: 2819 Weights: [0.28830076 2.14018126] , error: 0.47427627978550696\n",
      "Step: 2820 Weights: [0.28845552 2.14016356] , error: 0.4742738562467761\n",
      "Step: 2821 Weights: [0.28860992 2.1401459 ] , error: 0.4742714437487923\n",
      "Step: 2822 Weights: [0.28876397 2.14012829] , error: 0.47426904224125843\n",
      "Step: 2823 Weights: [0.28891767 2.14011071] , error: 0.47426665167410553\n",
      "Step: 2824 Weights: [0.28907102 2.14009317] , error: 0.47426427199749327\n",
      "Step: 2825 Weights: [0.28922402 2.14007567] , error: 0.4742619031618084\n",
      "Step: 2826 Weights: [0.28937668 2.14005822] , error: 0.47425954511766366\n",
      "Step: 2827 Weights: [0.28952898 2.1400408 ] , error: 0.47425719781589676\n",
      "Step: 2828 Weights: [0.28968094 2.14002342] , error: 0.47425486120756993\n",
      "Step: 2829 Weights: [0.28983255 2.14000608] , error: 0.47425253524396704\n",
      "Step: 2830 Weights: [0.28998381 2.13998878] , error: 0.4742502198765956\n",
      "Step: 2831 Weights: [0.29013473 2.13997152] , error: 0.474247915057183\n",
      "Step: 2832 Weights: [0.2902853 2.1399543] , error: 0.47424562073767423\n",
      "Step: 2833 Weights: [0.29043554 2.13993712] , error: 0.4742433368702399\n",
      "Step: 2834 Weights: [0.29058543 2.13991998] , error: 0.4742410634072594\n",
      "Step: 2835 Weights: [0.29073497 2.13990287] , error: 0.4742388003013375\n",
      "Step: 2836 Weights: [0.29088418 2.13988581] , error: 0.47423654750529076\n",
      "Step: 2837 Weights: [0.29103305 2.13986879] , error: 0.4742343049721493\n",
      "Step: 2838 Weights: [0.29118157 2.1398518 ] , error: 0.47423207265516154\n",
      "Step: 2839 Weights: [0.29132976 2.13983485] , error: 0.4742298505077841\n",
      "Step: 2840 Weights: [0.29147761 2.13981794] , error: 0.4742276384836909\n",
      "Step: 2841 Weights: [0.29162512 2.13980107] , error: 0.47422543653676\n",
      "Step: 2842 Weights: [0.2917723  2.13978424] , error: 0.4742232446210873\n",
      "Step: 2843 Weights: [0.29191914 2.13976745] , error: 0.47422106269097253\n",
      "Step: 2844 Weights: [0.29206565 2.13975069] , error: 0.47421889070092427\n",
      "Step: 2845 Weights: [0.29221182 2.13973398] , error: 0.47421672860566166\n",
      "Step: 2846 Weights: [0.29235766 2.1397173 ] , error: 0.47421457636010567\n",
      "Step: 2847 Weights: [0.29250316 2.13970066] , error: 0.4742124339193846\n",
      "Step: 2848 Weights: [0.29264834 2.13968405] , error: 0.4742103012388327\n",
      "Step: 2849 Weights: [0.29279318 2.13966749] , error: 0.4742081782739849\n",
      "Step: 2850 Weights: [0.29293769 2.13965096] , error: 0.47420606498058177\n",
      "Step: 2851 Weights: [0.29308187 2.13963447] , error: 0.4742039613145613\n",
      "Step: 2852 Weights: [0.29322573 2.13961802] , error: 0.47420186723206714\n",
      "Step: 2853 Weights: [0.29336925 2.13960161] , error: 0.4741997826894389\n",
      "Step: 2854 Weights: [0.29351245 2.13958523] , error: 0.4741977076432169\n",
      "Step: 2855 Weights: [0.29365533 2.13956889] , error: 0.47419564205013887\n",
      "Step: 2856 Weights: [0.29379787 2.13955259] , error: 0.4741935858671391\n",
      "Step: 2857 Weights: [0.29394009 2.13953632] , error: 0.47419153905134936\n",
      "Step: 2858 Weights: [0.29408199 2.1395201 ] , error: 0.47418950156009687\n",
      "Step: 2859 Weights: [0.29422356 2.1395039 ] , error: 0.4741874733509017\n",
      "Step: 2860 Weights: [0.29436482 2.13948775] , error: 0.47418545438147797\n",
      "Step: 2861 Weights: [0.29450574 2.13947163] , error: 0.4741834446097335\n",
      "Step: 2862 Weights: [0.29464635 2.13945555] , error: 0.47418144399376627\n",
      "Step: 2863 Weights: [0.29478664 2.13943951] , error: 0.4741794524918661\n",
      "Step: 2864 Weights: [0.29492661 2.1394235 ] , error: 0.4741774700625137\n",
      "Step: 2865 Weights: [0.29506625 2.13940753] , error: 0.47417549666437664\n",
      "Step: 2866 Weights: [0.29520558 2.1393916 ] , error: 0.47417353225631215\n",
      "Step: 2867 Weights: [0.29534459 2.1393757 ] , error: 0.4741715767973656\n",
      "Step: 2868 Weights: [0.29548329 2.13935984] , error: 0.47416963024676617\n",
      "Step: 2869 Weights: [0.29562167 2.13934401] , error: 0.47416769256393376\n",
      "Step: 2870 Weights: [0.29575973 2.13932822] , error: 0.4741657637084678\n",
      "Step: 2871 Weights: [0.29589748 2.13931247] , error: 0.4741638436401544\n",
      "Step: 2872 Weights: [0.29603491 2.13929675] , error: 0.4741619323189634\n",
      "Step: 2873 Weights: [0.29617203 2.13928107] , error: 0.47416002970504584\n",
      "Step: 2874 Weights: [0.29630884 2.13926542] , error: 0.4741581357587333\n",
      "Step: 2875 Weights: [0.29644533 2.13924981] , error: 0.47415625044054194\n",
      "Step: 2876 Weights: [0.29658152 2.13923424] , error: 0.4741543737111613\n",
      "Step: 2877 Weights: [0.29671739 2.1392187 ] , error: 0.47415250553146937\n",
      "Step: 2878 Weights: [0.29685295 2.1392032 ] , error: 0.4741506458625136\n",
      "Step: 2879 Weights: [0.29698821 2.13918773] , error: 0.4741487946655206\n",
      "Step: 2880 Weights: [0.29712316 2.1391723 ] , error: 0.47414695190189793\n",
      "Step: 2881 Weights: [0.29725779 2.1391569 ] , error: 0.47414511753322697\n",
      "Step: 2882 Weights: [0.29739213 2.13914153] , error: 0.47414329152125984\n",
      "Step: 2883 Weights: [0.29752615 2.13912621] , error: 0.4741414738279297\n",
      "Step: 2884 Weights: [0.29765987 2.13911091] , error: 0.4741396644153392\n",
      "Step: 2885 Weights: [0.29779328 2.13909566] , error: 0.47413786324576324\n",
      "Step: 2886 Weights: [0.2979264  2.13908043] , error: 0.4741360702816503\n",
      "Step: 2887 Weights: [0.2980592  2.13906524] , error: 0.47413428548562075\n",
      "Step: 2888 Weights: [0.29819171 2.13905009] , error: 0.47413250882046126\n",
      "Step: 2889 Weights: [0.29832391 2.13903497] , error: 0.47413074024913227\n",
      "Step: 2890 Weights: [0.29845581 2.13901989] , error: 0.4741289797347612\n",
      "Step: 2891 Weights: [0.29858741 2.13900484] , error: 0.47412722724064266\n",
      "Step: 2892 Weights: [0.29871871 2.13898982] , error: 0.47412548273024047\n",
      "Step: 2893 Weights: [0.29884971 2.13897484] , error: 0.47412374616718234\n",
      "Step: 2894 Weights: [0.29898041 2.13895989] , error: 0.474122017515264\n",
      "Step: 2895 Weights: [0.29911081 2.13894498] , error: 0.4741202967384461\n",
      "Step: 2896 Weights: [0.29924092 2.1389301 ] , error: 0.4741185838008508\n",
      "Step: 2897 Weights: [0.29937073 2.13891525] , error: 0.47411687866676694\n",
      "Step: 2898 Weights: [0.29950024 2.13890044] , error: 0.4741151813006438\n",
      "Step: 2899 Weights: [0.29962946 2.13888566] , error: 0.47411349166709366\n",
      "Step: 2900 Weights: [0.29975838 2.13887092] , error: 0.4741118097308896\n",
      "Step: 2901 Weights: [0.29988701 2.13885621] , error: 0.47411013545696556\n",
      "Step: 2902 Weights: [0.30001535 2.13884153] , error: 0.474108468810415\n",
      "Step: 2903 Weights: [0.30014339 2.13882689] , error: 0.4741068097564911\n",
      "Step: 2904 Weights: [0.30027114 2.13881228] , error: 0.4741051582606033\n",
      "Step: 2905 Weights: [0.3003986 2.1387977] , error: 0.4741035142883201\n",
      "Step: 2906 Weights: [0.30052577 2.13878316] , error: 0.4741018778053681\n",
      "Step: 2907 Weights: [0.30065265 2.13876865] , error: 0.4741002487776268\n",
      "Step: 2908 Weights: [0.30077924 2.13875417] , error: 0.47409862717113527\n",
      "Step: 2909 Weights: [0.30090554 2.13873973] , error: 0.4740970129520826\n",
      "Step: 2910 Weights: [0.30103155 2.13872531] , error: 0.4740954060868175\n",
      "Step: 2911 Weights: [0.30115728 2.13871094] , error: 0.47409380654183475\n",
      "Step: 2912 Weights: [0.30128272 2.13869659] , error: 0.47409221428378895\n",
      "Step: 2913 Weights: [0.30140787 2.13868228] , error: 0.4740906292794834\n",
      "Step: 2914 Weights: [0.30153274 2.138668  ] , error: 0.4740890514958707\n",
      "Step: 2915 Weights: [0.30165732 2.13865375] , error: 0.47408748090005765\n",
      "Step: 2916 Weights: [0.30178162 2.13863953] , error: 0.47408591745929896\n",
      "Step: 2917 Weights: [0.30190563 2.13862535] , error: 0.47408436114099894\n",
      "Step: 2918 Weights: [0.30202937 2.1386112 ] , error: 0.47408281191270946\n",
      "Step: 2919 Weights: [0.30215282 2.13859708] , error: 0.4740812697421324\n",
      "Step: 2920 Weights: [0.30227599 2.138583  ] , error: 0.474079734597114\n",
      "Step: 2921 Weights: [0.30239887 2.13856894] , error: 0.47407820644564963\n",
      "Step: 2922 Weights: [0.30252148 2.13855492] , error: 0.47407668525587865\n",
      "Step: 2923 Weights: [0.30264381 2.13854093] , error: 0.4740751709960873\n",
      "Step: 2924 Weights: [0.30276586 2.13852697] , error: 0.4740736636347042\n",
      "Step: 2925 Weights: [0.30288763 2.13851305] , error: 0.47407216314030004\n",
      "Step: 2926 Weights: [0.30300912 2.13849915] , error: 0.4740706694815958\n",
      "Step: 2927 Weights: [0.30313034 2.13848529] , error: 0.47406918262744935\n",
      "Step: 2928 Weights: [0.30325128 2.13847146] , error: 0.47406770254685926\n",
      "Step: 2929 Weights: [0.30337194 2.13845766] , error: 0.4740662292089711\n",
      "Step: 2930 Weights: [0.30349233 2.13844389] , error: 0.47406476258306623\n",
      "Step: 2931 Weights: [0.30361245 2.13843015] , error: 0.4740633026385659\n",
      "Step: 2932 Weights: [0.30373229 2.13841645] , error: 0.4740618493450337\n",
      "Step: 2933 Weights: [0.30385185 2.13840277] , error: 0.47406040267217064\n",
      "Step: 2934 Weights: [0.30397115 2.13838913] , error: 0.47405896258981417\n",
      "Step: 2935 Weights: [0.30409017 2.13837552] , error: 0.4740575290679414\n",
      "Step: 2936 Weights: [0.30420892 2.13836194] , error: 0.47405610207666427\n",
      "Step: 2937 Weights: [0.3043274  2.13834839] , error: 0.47405468158623165\n",
      "Step: 2938 Weights: [0.30444561 2.13833487] , error: 0.47405326756703015\n",
      "Step: 2939 Weights: [0.30456355 2.13832138] , error: 0.4740518599895767\n",
      "Step: 2940 Weights: [0.30468122 2.13830792] , error: 0.47405045882452584\n",
      "Step: 2941 Weights: [0.30479862 2.1382945 ] , error: 0.4740490640426654\n",
      "Step: 2942 Weights: [0.30491576 2.1382811 ] , error: 0.4740476756149162\n",
      "Step: 2943 Weights: [0.30503263 2.13826773] , error: 0.4740462935123306\n",
      "Step: 2944 Weights: [0.30514923 2.1382544 ] , error: 0.474044917706095\n",
      "Step: 2945 Weights: [0.30526557 2.13824109] , error: 0.4740435481675228\n",
      "Step: 2946 Weights: [0.30538164 2.13822782] , error: 0.47404218486806293\n",
      "Step: 2947 Weights: [0.30549744 2.13821458] , error: 0.47404082777929124\n",
      "Step: 2948 Weights: [0.30561298 2.13820136] , error: 0.4740394768729137\n",
      "Step: 2949 Weights: [0.30572826 2.13818818] , error: 0.4740381321207701\n",
      "Step: 2950 Weights: [0.30584328 2.13817503] , error: 0.4740367934948177\n",
      "Step: 2951 Weights: [0.30595803 2.1381619 ] , error: 0.47403546096715127\n",
      "Step: 2952 Weights: [0.30607252 2.13814881] , error: 0.47403413450998855\n",
      "Step: 2953 Weights: [0.30618675 2.13813574] , error: 0.4740328140956742\n",
      "Step: 2954 Weights: [0.30630072 2.13812271] , error: 0.47403149969668074\n",
      "Step: 2955 Weights: [0.30641443 2.13810971] , error: 0.47403019128560175\n",
      "Step: 2956 Weights: [0.30652788 2.13809673] , error: 0.47402888883516214\n",
      "Step: 2957 Weights: [0.30664107 2.13808379] , error: 0.47402759231820496\n",
      "Step: 2958 Weights: [0.30675401 2.13807087] , error: 0.47402630170769877\n",
      "Step: 2959 Weights: [0.30686668 2.13805798] , error: 0.4740250169767384\n",
      "Step: 2960 Weights: [0.3069791  2.13804513] , error: 0.47402373809853804\n",
      "Step: 2961 Weights: [0.30709127 2.1380323 ] , error: 0.4740224650464335\n",
      "Step: 2962 Weights: [0.30720317 2.1380195 ] , error: 0.47402119779388413\n",
      "Step: 2963 Weights: [0.30731482 2.13800673] , error: 0.4740199363144688\n",
      "Step: 2964 Weights: [0.30742622 2.13799399] , error: 0.47401868058188945\n",
      "Step: 2965 Weights: [0.30753736 2.13798128] , error: 0.4740174305699612\n",
      "Step: 2966 Weights: [0.30764825 2.1379686 ] , error: 0.47401618625262737\n",
      "Step: 2967 Weights: [0.30775889 2.13795595] , error: 0.4740149476039432\n",
      "Step: 2968 Weights: [0.30786928 2.13794332] , error: 0.47401371459808483\n",
      "Step: 2969 Weights: [0.30797941 2.13793073] , error: 0.47401248720934563\n",
      "Step: 2970 Weights: [0.30808929 2.13791816] , error: 0.47401126541213495\n",
      "Step: 2971 Weights: [0.30819892 2.13790562] , error: 0.4740100491809828\n",
      "Step: 2972 Weights: [0.3083083  2.13789311] , error: 0.47400883849052944\n",
      "Step: 2973 Weights: [0.30841743 2.13788063] , error: 0.4740076333155354\n",
      "Step: 2974 Weights: [0.30852632 2.13786818] , error: 0.4740064336308727\n",
      "Step: 2975 Weights: [0.30863495 2.13785576] , error: 0.4740052394115301\n",
      "Step: 2976 Weights: [0.30874334 2.13784336] , error: 0.4740040506326095\n",
      "Step: 2977 Weights: [0.30885148 2.13783099] , error: 0.47400286726932594\n",
      "Step: 2978 Weights: [0.30895937 2.13781866] , error: 0.474001689297009\n",
      "Step: 2979 Weights: [0.30906702 2.13780634] , error: 0.47400051669109877\n",
      "Step: 2980 Weights: [0.30917442 2.13779406] , error: 0.473999349427148\n",
      "Step: 2981 Weights: [0.30928158 2.13778181] , error: 0.47399818748082034\n",
      "Step: 2982 Weights: [0.30938849 2.13776958] , error: 0.4739970308278908\n",
      "Step: 2983 Weights: [0.30949516 2.13775738] , error: 0.4739958794442451\n",
      "Step: 2984 Weights: [0.30960158 2.13774521] , error: 0.47399473330587777\n",
      "Step: 2985 Weights: [0.30970777 2.13773307] , error: 0.4739935923888927\n",
      "Step: 2986 Weights: [0.30981371 2.13772095] , error: 0.47399245666950507\n",
      "Step: 2987 Weights: [0.3099194  2.13770886] , error: 0.4739913261240349\n",
      "Step: 2988 Weights: [0.31002486 2.1376968 ] , error: 0.4739902007289114\n",
      "Step: 2989 Weights: [0.31013008 2.13768477] , error: 0.4739890804606736\n",
      "Step: 2990 Weights: [0.31023506 2.13767276] , error: 0.4739879652959629\n",
      "Step: 2991 Weights: [0.3103398  2.13766078] , error: 0.4739868552115317\n",
      "Step: 2992 Weights: [0.31044429 2.13764883] , error: 0.4739857501842337\n",
      "Step: 2993 Weights: [0.31054855 2.13763691] , error: 0.47398465019103325\n",
      "Step: 2994 Weights: [0.31065258 2.13762501] , error: 0.47398355520899516\n",
      "Step: 2995 Weights: [0.31075636 2.13761314] , error: 0.47398246521529014\n",
      "Step: 2996 Weights: [0.31085991 2.1376013 ] , error: 0.47398138018719405\n",
      "Step: 2997 Weights: [0.31096323 2.13758949] , error: 0.4739803001020845\n",
      "Step: 2998 Weights: [0.3110663 2.1375777] , error: 0.4739792249374452\n",
      "Step: 2999 Weights: [0.31116915 2.13756594] , error: 0.47397815467085797\n",
      "Step: 3000 Weights: [0.31127175 2.1375542 ] , error: 0.4739770892800094\n",
      "Step: 3001 Weights: [0.31137413 2.13754249] , error: 0.4739760287426884\n",
      "Step: 3002 Weights: [0.31147627 2.13753081] , error: 0.47397497303678304\n",
      "Step: 3003 Weights: [0.31157818 2.13751916] , error: 0.47397392214028455\n",
      "Step: 3004 Weights: [0.31167985 2.13750753] , error: 0.47397287603128185\n",
      "Step: 3005 Weights: [0.31178129 2.13749593] , error: 0.4739718346879658\n",
      "Step: 3006 Weights: [0.31188251 2.13748435] , error: 0.47397079808862475\n",
      "Step: 3007 Weights: [0.31198349 2.1374728 ] , error: 0.4739697662116469\n",
      "Step: 3008 Weights: [0.31208424 2.13746128] , error: 0.4739687390355197\n",
      "Step: 3009 Weights: [0.31218476 2.13744979] , error: 0.47396771653882747\n",
      "Step: 3010 Weights: [0.31228505 2.13743832] , error: 0.4739666987002531\n",
      "Step: 3011 Weights: [0.31238511 2.13742687] , error: 0.4739656854985747\n",
      "Step: 3012 Weights: [0.31248495 2.13741546] , error: 0.47396467691266864\n",
      "Step: 3013 Weights: [0.31258456 2.13740406] , error: 0.4739636729215082\n",
      "Step: 3014 Weights: [0.31268394 2.1373927 ] , error: 0.47396267350415966\n",
      "Step: 3015 Weights: [0.31278309 2.13738136] , error: 0.4739616786397877\n",
      "Step: 3016 Weights: [0.31288202 2.13737005] , error: 0.4739606883076497\n",
      "Step: 3017 Weights: [0.31298072 2.13735876] , error: 0.47395970248709923\n",
      "Step: 3018 Weights: [0.31307919 2.1373475 ] , error: 0.4739587211575832\n",
      "Step: 3019 Weights: [0.31317745 2.13733626] , error: 0.47395774429864257\n",
      "Step: 3020 Weights: [0.31327548 2.13732505] , error: 0.4739567718899089\n",
      "Step: 3021 Weights: [0.31337328 2.13731386] , error: 0.47395580391111214\n",
      "Step: 3022 Weights: [0.31347086 2.1373027 ] , error: 0.4739548403420669\n",
      "Step: 3023 Weights: [0.31356822 2.13729157] , error: 0.4739538811626886\n",
      "Step: 3024 Weights: [0.31366536 2.13728046] , error: 0.4739529263529757\n",
      "Step: 3025 Weights: [0.31376227 2.13726938] , error: 0.47395197589302296\n",
      "Step: 3026 Weights: [0.31385897 2.13725832] , error: 0.4739510297630147\n",
      "Step: 3027 Weights: [0.31395544 2.13724728] , error: 0.47395008794322613\n",
      "Step: 3028 Weights: [0.31405169 2.13723628] , error: 0.47394915041402\n",
      "Step: 3029 Weights: [0.31414773 2.13722529] , error: 0.47394821715585017\n",
      "Step: 3030 Weights: [0.31424354 2.13721434] , error: 0.4739472881492606\n",
      "Step: 3031 Weights: [0.31433914 2.1372034 ] , error: 0.47394636337488116\n",
      "Step: 3032 Weights: [0.31443452 2.13719249] , error: 0.47394544281343287\n",
      "Step: 3033 Weights: [0.31452968 2.13718161] , error: 0.473944526445722\n",
      "Step: 3034 Weights: [0.31462463 2.13717075] , error: 0.47394361425264425\n",
      "Step: 3035 Weights: [0.31471935 2.13715992] , error: 0.47394270621518025\n",
      "Step: 3036 Weights: [0.31481387 2.13714911] , error: 0.4739418023144004\n",
      "Step: 3037 Weights: [0.31490816 2.13713833] , error: 0.47394090253145826\n",
      "Step: 3038 Weights: [0.31500224 2.13712757] , error: 0.4739400068475946\n",
      "Step: 3039 Weights: [0.31509611 2.13711683] , error: 0.4739391152441357\n",
      "Step: 3040 Weights: [0.31518976 2.13710612] , error: 0.47393822770249294\n",
      "Step: 3041 Weights: [0.3152832  2.13709544] , error: 0.4739373442041611\n",
      "Step: 3042 Weights: [0.31537643 2.13708477] , error: 0.4739364647307226\n",
      "Step: 3043 Weights: [0.31546944 2.13707414] , error: 0.47393558926383994\n",
      "Step: 3044 Weights: [0.31556224 2.13706352] , error: 0.47393471778526025\n",
      "Step: 3045 Weights: [0.31565483 2.13705293] , error: 0.47393385027681634\n",
      "Step: 3046 Weights: [0.31574721 2.13704237] , error: 0.4739329867204191\n",
      "Step: 3047 Weights: [0.31583938 2.13703183] , error: 0.4739321270980663\n",
      "Step: 3048 Weights: [0.31593134 2.13702131] , error: 0.4739312713918347\n",
      "Step: 3049 Weights: [0.31602309 2.13701082] , error: 0.47393041958388554\n",
      "Step: 3050 Weights: [0.31611462 2.13700035] , error: 0.47392957165645816\n",
      "Step: 3051 Weights: [0.31620595 2.13698991] , error: 0.4739287275918749\n",
      "Step: 3052 Weights: [0.31629708 2.13697948] , error: 0.47392788737253844\n",
      "Step: 3053 Weights: [0.31638799 2.13696909] , error: 0.4739270509809306\n",
      "Step: 3054 Weights: [0.3164787  2.13695871] , error: 0.47392621839961346\n",
      "Step: 3055 Weights: [0.3165692  2.13694836] , error: 0.47392538961122965\n",
      "Step: 3056 Weights: [0.31665949 2.13693804] , error: 0.4739245645985001\n",
      "Step: 3057 Weights: [0.31674958 2.13692773] , error: 0.47392374334422305\n",
      "Step: 3058 Weights: [0.31683946 2.13691746] , error: 0.4739229258312774\n",
      "Step: 3059 Weights: [0.31692914 2.1369072 ] , error: 0.4739221120426176\n",
      "Step: 3060 Weights: [0.31701861 2.13689697] , error: 0.47392130196127924\n",
      "Step: 3061 Weights: [0.31710788 2.13688676] , error: 0.47392049557037214\n",
      "Step: 3062 Weights: [0.31719694 2.13687657] , error: 0.4739196928530851\n",
      "Step: 3063 Weights: [0.31728581 2.13686641] , error: 0.47391889379268015\n",
      "Step: 3064 Weights: [0.31737446 2.13685627] , error: 0.4739180983724989\n",
      "Step: 3065 Weights: [0.31746292 2.13684615] , error: 0.4739173065759593\n",
      "Step: 3066 Weights: [0.31755118 2.13683606] , error: 0.4739165183865509\n",
      "Step: 3067 Weights: [0.31763923 2.13682599] , error: 0.47391573378784435\n",
      "Step: 3068 Weights: [0.31772708 2.13681594] , error: 0.47391495276347767\n",
      "Step: 3069 Weights: [0.31781474 2.13680592] , error: 0.47391417529717084\n",
      "Step: 3070 Weights: [0.31790219 2.13679592] , error: 0.47391340137271193\n",
      "Step: 3071 Weights: [0.31798944 2.13678594] , error: 0.4739126309739681\n",
      "Step: 3072 Weights: [0.3180765  2.13677598] , error: 0.47391186408487507\n",
      "Step: 3073 Weights: [0.31816336 2.13676605] , error: 0.473911100689446\n",
      "Step: 3074 Weights: [0.31825001 2.13675614] , error: 0.4739103407717647\n",
      "Step: 3075 Weights: [0.31833647 2.13674625] , error: 0.4739095843159875\n",
      "Step: 3076 Weights: [0.31842274 2.13673639] , error: 0.47390883130634376\n",
      "Step: 3077 Weights: [0.3185088  2.13672654] , error: 0.47390808172713317\n",
      "Step: 3078 Weights: [0.31859467 2.13671672] , error: 0.47390733556272846\n",
      "Step: 3079 Weights: [0.31868035 2.13670692] , error: 0.4739065927975741\n",
      "Step: 3080 Weights: [0.31876583 2.13669715] , error: 0.47390585341618197\n",
      "Step: 3081 Weights: [0.31885111 2.13668739] , error: 0.4739051174031399\n",
      "Step: 3082 Weights: [0.3189362  2.13667766] , error: 0.47390438474309987\n",
      "Step: 3083 Weights: [0.3190211  2.13666795] , error: 0.4739036554207884\n",
      "Step: 3084 Weights: [0.3191058  2.13665827] , error: 0.47390292942100065\n",
      "Step: 3085 Weights: [0.31919031 2.1366486 ] , error: 0.47390220672859973\n",
      "Step: 3086 Weights: [0.31927463 2.13663896] , error: 0.4739014873285182\n",
      "Step: 3087 Weights: [0.31935875 2.13662934] , error: 0.47390077120575747\n",
      "Step: 3088 Weights: [0.31944268 2.13661974] , error: 0.4739000583453876\n",
      "Step: 3089 Weights: [0.31952642 2.13661016] , error: 0.47389934873254624\n",
      "Step: 3090 Weights: [0.31960997 2.13660061] , error: 0.4738986423524387\n",
      "Step: 3091 Weights: [0.31969333 2.13659107] , error: 0.47389793919033785\n",
      "Step: 3092 Weights: [0.3197765  2.13658156] , error: 0.47389723923158467\n",
      "Step: 3093 Weights: [0.31985948 2.13657207] , error: 0.4738965424615845\n",
      "Step: 3094 Weights: [0.31994227 2.1365626 ] , error: 0.4738958488658104\n",
      "Step: 3095 Weights: [0.32002487 2.13655316] , error: 0.47389515842980284\n",
      "Step: 3096 Weights: [0.32010728 2.13654373] , error: 0.47389447113916705\n",
      "Step: 3097 Weights: [0.32018951 2.13653433] , error: 0.47389378697957285\n",
      "Step: 3098 Weights: [0.32027155 2.13652495] , error: 0.473893105936757\n",
      "Step: 3099 Weights: [0.3203534  2.13651559] , error: 0.473892427996521\n",
      "Step: 3100 Weights: [0.32043506 2.13650625] , error: 0.4738917531447295\n",
      "Step: 3101 Weights: [0.32051654 2.13649693] , error: 0.47389108136731506\n",
      "Step: 3102 Weights: [0.32059783 2.13648763] , error: 0.4738904126502689\n",
      "Step: 3103 Weights: [0.32067894 2.13647836] , error: 0.47388974697965136\n",
      "Step: 3104 Weights: [0.32075986 2.1364691 ] , error: 0.4738890843415827\n",
      "Step: 3105 Weights: [0.3208406  2.13645987] , error: 0.47388842472224824\n",
      "Step: 3106 Weights: [0.32092115 2.13645066] , error: 0.4738877681078955\n",
      "Step: 3107 Weights: [0.32100152 2.13644146] , error: 0.4738871144848358\n",
      "Step: 3108 Weights: [0.3210817  2.13643229] , error: 0.47388646383944166\n",
      "Step: 3109 Weights: [0.32116171 2.13642314] , error: 0.47388581615814673\n",
      "Step: 3110 Weights: [0.32124153 2.13641402] , error: 0.4738851714274497\n",
      "Step: 3111 Weights: [0.32132117 2.13640491] , error: 0.47388452963390615\n",
      "Step: 3112 Weights: [0.32140062 2.13639582] , error: 0.4738838907641376\n",
      "Step: 3113 Weights: [0.3214799  2.13638676] , error: 0.47388325480482335\n",
      "Step: 3114 Weights: [0.32155899 2.13637771] , error: 0.4738826217427048\n",
      "Step: 3115 Weights: [0.32163791 2.13636868] , error: 0.4738819915645839\n",
      "Step: 3116 Weights: [0.32171664 2.13635968] , error: 0.47388136425732036\n",
      "Step: 3117 Weights: [0.3217952 2.1363507] , error: 0.47388073980783807\n",
      "Step: 3118 Weights: [0.32187358 2.13634173] , error: 0.47388011820311665\n",
      "Step: 3119 Weights: [0.32195177 2.13633279] , error: 0.47387949943019747\n",
      "Step: 3120 Weights: [0.32202979 2.13632387] , error: 0.4738788834761779\n",
      "Step: 3121 Weights: [0.32210763 2.13631496] , error: 0.4738782703282175\n",
      "Step: 3122 Weights: [0.3221853  2.13630608] , error: 0.4738776599735335\n",
      "Step: 3123 Weights: [0.32226278 2.13629722] , error: 0.4738770523993987\n",
      "Step: 3124 Weights: [0.32234009 2.13628838] , error: 0.47387644759314795\n",
      "Step: 3125 Weights: [0.32241723 2.13627956] , error: 0.47387584554217105\n",
      "Step: 3126 Weights: [0.32249418 2.13627076] , error: 0.47387524623391664\n",
      "Step: 3127 Weights: [0.32257097 2.13626198] , error: 0.4738746496558881\n",
      "Step: 3128 Weights: [0.32264757 2.13625322] , error: 0.47387405579564906\n",
      "Step: 3129 Weights: [0.322724   2.13624447] , error: 0.4738734646408175\n",
      "Step: 3130 Weights: [0.32280026 2.13623575] , error: 0.4738728761790696\n",
      "Step: 3131 Weights: [0.32287635 2.13622705] , error: 0.4738722903981355\n",
      "Step: 3132 Weights: [0.32295226 2.13621837] , error: 0.47387170728580297\n",
      "Step: 3133 Weights: [0.32302799 2.13620971] , error: 0.47387112682991556\n",
      "Step: 3134 Weights: [0.32310356 2.13620107] , error: 0.4738705490183702\n",
      "Step: 3135 Weights: [0.32317895 2.13619244] , error: 0.47386997383912105\n",
      "Step: 3136 Weights: [0.32325417 2.13618384] , error: 0.4738694012801758\n",
      "Step: 3137 Weights: [0.32332922 2.13617526] , error: 0.47386883132959756\n",
      "Step: 3138 Weights: [0.3234041 2.1361667] , error: 0.4738682639755034\n",
      "Step: 3139 Weights: [0.32347881 2.13615815] , error: 0.4738676992060648\n",
      "Step: 3140 Weights: [0.32355334 2.13614963] , error: 0.4738671370095083\n",
      "Step: 3141 Weights: [0.32362771 2.13614112] , error: 0.4738665773741107\n",
      "Step: 3142 Weights: [0.32370191 2.13613264] , error: 0.4738660202882048\n",
      "Step: 3143 Weights: [0.32377593 2.13612417] , error: 0.4738654657401772\n",
      "Step: 3144 Weights: [0.32384979 2.13611572] , error: 0.4738649137184645\n",
      "Step: 3145 Weights: [0.32392348 2.1361073 ] , error: 0.47386436421155964\n",
      "Step: 3146 Weights: [0.32399701 2.13609889] , error: 0.47386381720800574\n",
      "Step: 3147 Weights: [0.32407036 2.1360905 ] , error: 0.4738632726963969\n",
      "Step: 3148 Weights: [0.32414355 2.13608213] , error: 0.4738627306653823\n",
      "Step: 3149 Weights: [0.32421657 2.13607378] , error: 0.4738621911036608\n",
      "Step: 3150 Weights: [0.32428942 2.13606545] , error: 0.47386165399998337\n",
      "Step: 3151 Weights: [0.32436211 2.13605713] , error: 0.4738611193431505\n",
      "Step: 3152 Weights: [0.32443464 2.13604884] , error: 0.473860587122017\n",
      "Step: 3153 Weights: [0.32450699 2.13604056] , error: 0.47386005732548814\n",
      "Step: 3154 Weights: [0.32457918 2.13603231] , error: 0.4738595299425148\n",
      "Step: 3155 Weights: [0.32465121 2.13602407] , error: 0.4738590049621048\n",
      "Step: 3156 Weights: [0.32472307 2.13601585] , error: 0.47385848237331046\n",
      "Step: 3157 Weights: [0.32479477 2.13600765] , error: 0.47385796216523796\n",
      "Step: 3158 Weights: [0.32486631 2.13599947] , error: 0.47385744432704113\n",
      "Step: 3159 Weights: [0.32493768 2.13599131] , error: 0.47385692884792396\n",
      "Step: 3160 Weights: [0.32500889 2.13598316] , error: 0.473856415717139\n",
      "Step: 3161 Weights: [0.32507994 2.13597504] , error: 0.47385590492398866\n",
      "Step: 3162 Weights: [0.32515083 2.13596693] , error: 0.4738553964578234\n",
      "Step: 3163 Weights: [0.32522155 2.13595884] , error: 0.47385489030804157\n",
      "Step: 3164 Weights: [0.32529211 2.13595077] , error: 0.47385438646409256\n",
      "Step: 3165 Weights: [0.32536251 2.13594272] , error: 0.4738538849154686\n",
      "Step: 3166 Weights: [0.32543275 2.13593469] , error: 0.47385338565171586\n",
      "Step: 3167 Weights: [0.32550284 2.13592668] , error: 0.4738528886624239\n",
      "Step: 3168 Weights: [0.32557276 2.13591868] , error: 0.47385239393723194\n",
      "Step: 3169 Weights: [0.32564252 2.1359107 ] , error: 0.4738519014658244\n",
      "Step: 3170 Weights: [0.32571212 2.13590274] , error: 0.4738514112379354\n",
      "Step: 3171 Weights: [0.32578156 2.1358948 ] , error: 0.473850923243344\n",
      "Step: 3172 Weights: [0.32585085 2.13588687] , error: 0.47385043747187405\n",
      "Step: 3173 Weights: [0.32591998 2.13587897] , error: 0.47384995391340107\n",
      "Step: 3174 Weights: [0.32598895 2.13587108] , error: 0.47384947255784154\n",
      "Step: 3175 Weights: [0.32605776 2.13586321] , error: 0.4738489933951593\n",
      "Step: 3176 Weights: [0.32612642 2.13585536] , error: 0.4738485164153654\n",
      "Step: 3177 Weights: [0.32619491 2.13584753] , error: 0.47384804160851546\n",
      "Step: 3178 Weights: [0.32626326 2.13583971] , error: 0.4738475689647098\n",
      "Step: 3179 Weights: [0.32633144 2.13583191] , error: 0.4738470984740958\n",
      "Step: 3180 Weights: [0.32639948 2.13582413] , error: 0.47384663012686173\n",
      "Step: 3181 Weights: [0.32646735 2.13581637] , error: 0.47384616391324597\n",
      "Step: 3182 Weights: [0.32653507 2.13580862] , error: 0.47384569982352676\n",
      "Step: 3183 Weights: [0.32660264 2.1358009 ] , error: 0.47384523784802834\n",
      "Step: 3184 Weights: [0.32667005 2.13579319] , error: 0.4738447779771205\n",
      "Step: 3185 Weights: [0.32673731 2.1357855 ] , error: 0.4738443202012141\n",
      "Step: 3186 Weights: [0.32680442 2.13577782] , error: 0.47384386451076566\n",
      "Step: 3187 Weights: [0.32687137 2.13577016] , error: 0.47384341089627424\n",
      "Step: 3188 Weights: [0.32693817 2.13576252] , error: 0.4738429593482838\n",
      "Step: 3189 Weights: [0.32700482 2.1357549 ] , error: 0.47384250985737814\n",
      "Step: 3190 Weights: [0.32707132 2.1357473 ] , error: 0.4738420624141871\n",
      "Step: 3191 Weights: [0.32713766 2.13573971] , error: 0.4738416170093819\n",
      "Step: 3192 Weights: [0.32720385 2.13573214] , error: 0.4738411736336759\n",
      "Step: 3193 Weights: [0.3272699  2.13572459] , error: 0.47384073227782747\n",
      "Step: 3194 Weights: [0.32733579 2.13571705] , error: 0.4738402929326326\n",
      "Step: 3195 Weights: [0.32740153 2.13570953] , error: 0.47383985558893205\n",
      "Step: 3196 Weights: [0.32746712 2.13570203] , error: 0.47383942023760783\n",
      "Step: 3197 Weights: [0.32753256 2.13569455] , error: 0.4738389868695829\n",
      "Step: 3198 Weights: [0.32759785 2.13568708] , error: 0.473838555475823\n",
      "Step: 3199 Weights: [0.327663   2.13567963] , error: 0.4738381260473346\n",
      "Step: 3200 Weights: [0.32772799 2.1356722 ] , error: 0.47383769857516256\n",
      "Step: 3201 Weights: [0.32779284 2.13566478] , error: 0.4738372730503958\n",
      "Step: 3202 Weights: [0.32785754 2.13565738] , error: 0.4738368494641627\n",
      "Step: 3203 Weights: [0.32792209 2.13565   ] , error: 0.4738364278076321\n",
      "Step: 3204 Weights: [0.32798649 2.13564263] , error: 0.4738360080720128\n",
      "Step: 3205 Weights: [0.32805075 2.13563528] , error: 0.4738355902485547\n",
      "Step: 3206 Weights: [0.32811486 2.13562795] , error: 0.4738351743285449\n",
      "Step: 3207 Weights: [0.32817883 2.13562064] , error: 0.47383476030331373\n",
      "Step: 3208 Weights: [0.32824264 2.13561334] , error: 0.47383434816422854\n",
      "Step: 3209 Weights: [0.32830632 2.13560606] , error: 0.47383393790269623\n",
      "Step: 3210 Weights: [0.32836985 2.13559879] , error: 0.4738335295101636\n",
      "Step: 3211 Weights: [0.32843323 2.13559154] , error: 0.4738331229781174\n",
      "Step: 3212 Weights: [0.32849647 2.13558431] , error: 0.4738327182980805\n",
      "Step: 3213 Weights: [0.32855956 2.1355771 ] , error: 0.47383231546161736\n",
      "Step: 3214 Weights: [0.32862251 2.1355699 ] , error: 0.473831914460327\n",
      "Step: 3215 Weights: [0.32868532 2.13556271] , error: 0.4738315152858512\n",
      "Step: 3216 Weights: [0.32874798 2.13555555] , error: 0.47383111792986593\n",
      "Step: 3217 Weights: [0.3288105 2.1355484] , error: 0.47383072238408824\n",
      "Step: 3218 Weights: [0.32887288 2.13554126] , error: 0.4738303286402703\n",
      "Step: 3219 Weights: [0.32893512 2.13553415] , error: 0.47382993669020496\n",
      "Step: 3220 Weights: [0.32899721 2.13552704] , error: 0.47382954652571885\n",
      "Step: 3221 Weights: [0.32905916 2.13551996] , error: 0.4738291581386783\n",
      "Step: 3222 Weights: [0.32912097 2.13551289] , error: 0.47382877152098485\n",
      "Step: 3223 Weights: [0.32918265 2.13550584] , error: 0.47382838666457944\n",
      "Step: 3224 Weights: [0.32924417 2.1354988 ] , error: 0.47382800356143695\n",
      "Step: 3225 Weights: [0.32930556 2.13549178] , error: 0.4738276222035712\n",
      "Step: 3226 Weights: [0.32936681 2.13548477] , error: 0.47382724258303105\n",
      "Step: 3227 Weights: [0.32942792 2.13547779] , error: 0.47382686469190205\n",
      "Step: 3228 Weights: [0.32948889 2.13547081] , error: 0.4738264885223058\n",
      "Step: 3229 Weights: [0.32954972 2.13546386] , error: 0.4738261140663983\n",
      "Step: 3230 Weights: [0.32961042 2.13545691] , error: 0.4738257413163738\n",
      "Step: 3231 Weights: [0.32967097 2.13544999] , error: 0.4738253702644603\n",
      "Step: 3232 Weights: [0.32973139 2.13544308] , error: 0.47382500090292334\n",
      "Step: 3233 Weights: [0.32979167 2.13543619] , error: 0.47382463322406043\n",
      "Step: 3234 Weights: [0.32985181 2.13542931] , error: 0.47382426722020654\n",
      "Step: 3235 Weights: [0.32991181 2.13542245] , error: 0.4738239028837311\n",
      "Step: 3236 Weights: [0.32997168 2.1354156 ] , error: 0.47382354020703893\n",
      "Step: 3237 Weights: [0.33003141 2.13540877] , error: 0.4738231791825661\n",
      "Step: 3238 Weights: [0.330091   2.13540195] , error: 0.4738228198027882\n",
      "Step: 3239 Weights: [0.33015046 2.13539515] , error: 0.47382246206021195\n",
      "Step: 3240 Weights: [0.33020978 2.13538837] , error: 0.47382210594737845\n",
      "Step: 3241 Weights: [0.33026897 2.1353816 ] , error: 0.473821751456864\n",
      "Step: 3242 Weights: [0.33032802 2.13537485] , error: 0.4738213985812771\n",
      "Step: 3243 Weights: [0.33038694 2.13536811] , error: 0.4738210473132606\n",
      "Step: 3244 Weights: [0.33044572 2.13536139] , error: 0.4738206976454914\n",
      "Step: 3245 Weights: [0.33050437 2.13535468] , error: 0.4738203495706799\n",
      "Step: 3246 Weights: [0.33056289 2.13534799] , error: 0.473820003081568\n",
      "Step: 3247 Weights: [0.33062127 2.13534131] , error: 0.4738196581709333\n",
      "Step: 3248 Weights: [0.33067952 2.13533465] , error: 0.47381931483158374\n",
      "Step: 3249 Weights: [0.33073763 2.135328  ] , error: 0.4738189730563611\n",
      "Step: 3250 Weights: [0.33079562 2.13532137] , error: 0.47381863283814046\n",
      "Step: 3251 Weights: [0.33085347 2.13531475] , error: 0.4738182941698278\n",
      "Step: 3252 Weights: [0.33091119 2.13530815] , error: 0.4738179570443632\n",
      "Step: 3253 Weights: [0.33096878 2.13530157] , error: 0.4738176214547181\n",
      "Step: 3254 Weights: [0.33102623 2.135295  ] , error: 0.47381728739389534\n",
      "Step: 3255 Weights: [0.33108356 2.13528844] , error: 0.47381695485493\n",
      "Step: 3256 Weights: [0.33114075 2.1352819 ] , error: 0.47381662383088885\n",
      "Step: 3257 Weights: [0.33119782 2.13527537] , error: 0.4738162943148714\n",
      "Step: 3258 Weights: [0.33125475 2.13526886] , error: 0.47381596630000716\n",
      "Step: 3259 Weights: [0.33131155 2.13526237] , error: 0.47381563977945695\n",
      "Step: 3260 Weights: [0.33136823 2.13525588] , error: 0.4738153147464148\n",
      "Step: 3261 Weights: [0.33142478 2.13524942] , error: 0.4738149911941026\n",
      "Step: 3262 Weights: [0.33148119 2.13524297] , error: 0.47381466911577513\n",
      "Step: 3263 Weights: [0.33153748 2.13523653] , error: 0.4738143485047182\n",
      "Step: 3264 Weights: [0.33159364 2.13523011] , error: 0.4738140293542456\n",
      "Step: 3265 Weights: [0.33164967 2.1352237 ] , error: 0.4738137116577051\n",
      "Step: 3266 Weights: [0.33170557 2.1352173 ] , error: 0.4738133954084726\n",
      "Step: 3267 Weights: [0.33176135 2.13521093] , error: 0.4738130805999551\n",
      "Step: 3268 Weights: [0.331817   2.13520456] , error: 0.4738127672255895\n",
      "Step: 3269 Weights: [0.33187252 2.13519821] , error: 0.47381245527884\n",
      "Step: 3270 Weights: [0.33192792 2.13519188] , error: 0.4738121447532059\n",
      "Step: 3271 Weights: [0.33198319 2.13518555] , error: 0.47381183564221196\n",
      "Step: 3272 Weights: [0.33203833 2.13517925] , error: 0.4738115279394124\n",
      "Step: 3273 Weights: [0.33209335 2.13517296] , error: 0.4738112216383944\n",
      "Step: 3274 Weights: [0.33214824 2.13516668] , error: 0.47381091673277065\n",
      "Step: 3275 Weights: [0.33220301 2.13516042] , error: 0.47381061321618345\n",
      "Step: 3276 Weights: [0.33225765 2.13515417] , error: 0.47381031108230603\n",
      "Step: 3277 Weights: [0.33231217 2.13514793] , error: 0.4738100103248388\n",
      "Step: 3278 Weights: [0.33236656 2.13514171] , error: 0.473809710937512\n",
      "Step: 3279 Weights: [0.33242083 2.1351355 ] , error: 0.4738094129140824\n",
      "Step: 3280 Weights: [0.33247497 2.13512931] , error: 0.473809116248338\n",
      "Step: 3281 Weights: [0.33252899 2.13512313] , error: 0.47380882093409354\n",
      "Step: 3282 Weights: [0.33258289 2.13511697] , error: 0.4738085269651905\n",
      "Step: 3283 Weights: [0.33263667 2.13511082] , error: 0.47380823433550207\n",
      "Step: 3284 Weights: [0.33269032 2.13510468] , error: 0.47380794303892576\n",
      "Step: 3285 Weights: [0.33274385 2.13509856] , error: 0.4738076530693893\n",
      "Step: 3286 Weights: [0.33279726 2.13509245] , error: 0.47380736442084714\n",
      "Step: 3287 Weights: [0.33285055 2.13508636] , error: 0.47380707708728126\n",
      "Step: 3288 Weights: [0.33290371 2.13508028] , error: 0.47380679106270096\n",
      "Step: 3289 Weights: [0.33295676 2.13507421] , error: 0.47380650634114246\n",
      "Step: 3290 Weights: [0.33300968 2.13506816] , error: 0.4738062229166706\n",
      "Step: 3291 Weights: [0.33306248 2.13506212] , error: 0.4738059407833754\n",
      "Step: 3292 Weights: [0.33311516 2.1350561 ] , error: 0.4738056599353766\n",
      "Step: 3293 Weights: [0.33316773 2.13505009] , error: 0.47380538036681574\n",
      "Step: 3294 Weights: [0.33322017 2.13504409] , error: 0.47380510207186755\n",
      "Step: 3295 Weights: [0.33327249 2.1350381 ] , error: 0.47380482504472743\n",
      "Step: 3296 Weights: [0.33332469 2.13503213] , error: 0.47380454927962035\n",
      "Step: 3297 Weights: [0.33337678 2.13502618] , error: 0.4738042747707975\n",
      "Step: 3298 Weights: [0.33342874 2.13502024] , error: 0.47380400151253566\n",
      "Step: 3299 Weights: [0.33348059 2.13501431] , error: 0.4738037294991373\n",
      "Step: 3300 Weights: [0.33353232 2.13500839] , error: 0.4738034587249321\n",
      "Step: 3301 Weights: [0.33358393 2.13500249] , error: 0.4738031891842731\n",
      "Step: 3302 Weights: [0.33363542 2.1349966 ] , error: 0.47380292087154235\n",
      "Step: 3303 Weights: [0.3336868  2.13499072] , error: 0.4738026537811455\n",
      "Step: 3304 Weights: [0.33373805 2.13498486] , error: 0.4738023879075141\n",
      "Step: 3305 Weights: [0.3337892  2.13497901] , error: 0.4738021232451035\n",
      "Step: 3306 Weights: [0.33384022 2.13497318] , error: 0.4738018597883982\n",
      "Step: 3307 Weights: [0.33389113 2.13496735] , error: 0.47380159753190343\n",
      "Step: 3308 Weights: [0.33394192 2.13496155] , error: 0.47380133647015266\n",
      "Step: 3309 Weights: [0.3339926  2.13495575] , error: 0.47380107659770365\n",
      "Step: 3310 Weights: [0.33404316 2.13494997] , error: 0.47380081790913653\n",
      "Step: 3311 Weights: [0.3340936 2.1349442] , error: 0.4738005603990592\n",
      "Step: 3312 Weights: [0.33414393 2.13493844] , error: 0.4738003040621023\n",
      "Step: 3313 Weights: [0.33419415 2.1349327 ] , error: 0.4738000488929227\n",
      "Step: 3314 Weights: [0.33424425 2.13492697] , error: 0.4737997948861995\n",
      "Step: 3315 Weights: [0.33429424 2.13492125] , error: 0.4737995420366359\n",
      "Step: 3316 Weights: [0.33434411 2.13491555] , error: 0.47379929033896273\n",
      "Step: 3317 Weights: [0.33439387 2.13490986] , error: 0.4737990397879304\n",
      "Step: 3318 Weights: [0.33444352 2.13490418] , error: 0.47379879037831624\n",
      "Step: 3319 Weights: [0.33449305 2.13489852] , error: 0.47379854210492045\n",
      "Step: 3320 Weights: [0.33454247 2.13489286] , error: 0.4737982949625672\n",
      "Step: 3321 Weights: [0.33459178 2.13488723] , error: 0.4737980489461011\n",
      "Step: 3322 Weights: [0.33464097 2.1348816 ] , error: 0.4737978040503964\n",
      "Step: 3323 Weights: [0.33469005 2.13487599] , error: 0.4737975602703465\n",
      "Step: 3324 Weights: [0.33473902 2.13487039] , error: 0.47379731760086796\n",
      "Step: 3325 Weights: [0.33478788 2.1348648 ] , error: 0.47379707603690235\n",
      "Step: 3326 Weights: [0.33483663 2.13485922] , error: 0.47379683557341173\n",
      "Step: 3327 Weights: [0.33488526 2.13485366] , error: 0.4737965962053854\n",
      "Step: 3328 Weights: [0.33493379 2.13484811] , error: 0.4737963579278308\n",
      "Step: 3329 Weights: [0.3349822  2.13484257] , error: 0.4737961207357807\n",
      "Step: 3330 Weights: [0.33503051 2.13483705] , error: 0.4737958846242897\n",
      "Step: 3331 Weights: [0.3350787  2.13483154] , error: 0.47379564958843545\n",
      "Step: 3332 Weights: [0.33512679 2.13482604] , error: 0.47379541562331795\n",
      "Step: 3333 Weights: [0.33517476 2.13482055] , error: 0.47379518272405907\n",
      "Step: 3334 Weights: [0.33522263 2.13481508] , error: 0.47379495088580337\n",
      "Step: 3335 Weights: [0.33527038 2.13480962] , error: 0.47379472010371654\n",
      "Step: 3336 Weights: [0.33531803 2.13480417] , error: 0.4737944903729877\n",
      "Step: 3337 Weights: [0.33536557 2.13479873] , error: 0.47379426168882766\n",
      "Step: 3338 Weights: [0.335413   2.13479331] , error: 0.4737940340464685\n",
      "Step: 3339 Weights: [0.33546032 2.1347879 ] , error: 0.4737938074411624\n",
      "Step: 3340 Weights: [0.33550753 2.1347825 ] , error: 0.4737935818681881\n",
      "Step: 3341 Weights: [0.33555464 2.13477711] , error: 0.4737933573228399\n",
      "Step: 3342 Weights: [0.33560164 2.13477173] , error: 0.47379313380043697\n",
      "Step: 3343 Weights: [0.33564853 2.13476637] , error: 0.4737929112963195\n",
      "Step: 3344 Weights: [0.33569531 2.13476102] , error: 0.4737926898058492\n",
      "Step: 3345 Weights: [0.33574199 2.13475568] , error: 0.4737924693244082\n",
      "Step: 3346 Weights: [0.33578856 2.13475036] , error: 0.4737922498473985\n",
      "Step: 3347 Weights: [0.33583503 2.13474504] , error: 0.473792031370245\n",
      "Step: 3348 Weights: [0.33588139 2.13473974] , error: 0.47379181388839264\n",
      "Step: 3349 Weights: [0.33592764 2.13473445] , error: 0.47379159739730714\n",
      "Step: 3350 Weights: [0.33597379 2.13472917] , error: 0.47379138189247566\n",
      "Step: 3351 Weights: [0.33601983 2.13472391] , error: 0.47379116736940435\n",
      "Step: 3352 Weights: [0.33606577 2.13471865] , error: 0.47379095382362096\n",
      "Step: 3353 Weights: [0.3361116  2.13471341] , error: 0.4737907412506733\n",
      "Step: 3354 Weights: [0.33615733 2.13470818] , error: 0.4737905296461289\n",
      "Step: 3355 Weights: [0.33620296 2.13470296] , error: 0.4737903190055766\n",
      "Step: 3356 Weights: [0.33624848 2.13469776] , error: 0.47379010932462473\n",
      "Step: 3357 Weights: [0.33629389 2.13469256] , error: 0.47378990059890347\n",
      "Step: 3358 Weights: [0.33633921 2.13468738] , error: 0.4737896928240577\n",
      "Step: 3359 Weights: [0.33638442 2.13468221] , error: 0.47378948599575754\n",
      "Step: 3360 Weights: [0.33642952 2.13467705] , error: 0.47378928010969135\n",
      "Step: 3361 Weights: [0.33647453 2.13467191] , error: 0.4737890751615658\n",
      "Step: 3362 Weights: [0.33651943 2.13466677] , error: 0.47378887114710866\n",
      "Step: 3363 Weights: [0.33656423 2.13466165] , error: 0.47378866806206493\n",
      "Step: 3364 Weights: [0.33660892 2.13465654] , error: 0.47378846590220225\n",
      "Step: 3365 Weights: [0.33665352 2.13465144] , error: 0.4737882646633055\n",
      "Step: 3366 Weights: [0.33669801 2.13464635] , error: 0.4737880643411788\n",
      "Step: 3367 Weights: [0.3367424  2.13464127] , error: 0.4737878649316447\n",
      "Step: 3368 Weights: [0.33678669 2.13463621] , error: 0.4737876664305474\n",
      "Step: 3369 Weights: [0.33683088 2.13463115] , error: 0.47378746883374784\n",
      "Step: 3370 Weights: [0.33687497 2.13462611] , error: 0.4737872721371269\n",
      "Step: 3371 Weights: [0.33691896 2.13462108] , error: 0.4737870763365816\n",
      "Step: 3372 Weights: [0.33696285 2.13461606] , error: 0.473786881428033\n",
      "Step: 3373 Weights: [0.33700663 2.13461105] , error: 0.4737866874074146\n",
      "Step: 3374 Weights: [0.33705032 2.13460606] , error: 0.47378649427068265\n",
      "Step: 3375 Weights: [0.33709391 2.13460107] , error: 0.4737863020138108\n",
      "Step: 3376 Weights: [0.3371374 2.1345961] , error: 0.47378611063278925\n",
      "Step: 3377 Weights: [0.33718079 2.13459114] , error: 0.47378592012363047\n",
      "Step: 3378 Weights: [0.33722408 2.13458618] , error: 0.47378573048236045\n",
      "Step: 3379 Weights: [0.33726727 2.13458124] , error: 0.47378554170502424\n",
      "Step: 3380 Weights: [0.33731036 2.13457632] , error: 0.47378535378768943\n",
      "Step: 3381 Weights: [0.33735336 2.1345714 ] , error: 0.47378516672643606\n",
      "Step: 3382 Weights: [0.33739625 2.13456649] , error: 0.47378498051736495\n",
      "Step: 3383 Weights: [0.33743905 2.1345616 ] , error: 0.47378479515659444\n",
      "Step: 3384 Weights: [0.33748176 2.13455672] , error: 0.4737846106402569\n",
      "Step: 3385 Weights: [0.33752436 2.13455184] , error: 0.4737844269645097\n",
      "Step: 3386 Weights: [0.33756687 2.13454698] , error: 0.47378424412552017\n",
      "Step: 3387 Weights: [0.33760928 2.13454213] , error: 0.47378406211947827\n",
      "Step: 3388 Weights: [0.33765159 2.13453729] , error: 0.4737838809425882\n",
      "Step: 3389 Weights: [0.33769381 2.13453246] , error: 0.4737837005910741\n",
      "Step: 3390 Weights: [0.33773593 2.13452765] , error: 0.4737835210611728\n",
      "Step: 3391 Weights: [0.33777795 2.13452284] , error: 0.473783342349146\n",
      "Step: 3392 Weights: [0.33781988 2.13451805] , error: 0.4737831644512626\n",
      "Step: 3393 Weights: [0.33786171 2.13451326] , error: 0.4737829873638186\n",
      "Step: 3394 Weights: [0.33790345 2.13450849] , error: 0.4737828110831175\n",
      "Step: 3395 Weights: [0.33794509 2.13450373] , error: 0.47378263560548717\n",
      "Step: 3396 Weights: [0.33798664 2.13449897] , error: 0.4737824609272676\n",
      "Step: 3397 Weights: [0.33802809 2.13449423] , error: 0.47378228704481856\n",
      "Step: 3398 Weights: [0.33806945 2.1344895 ] , error: 0.4737821139545124\n",
      "Step: 3399 Weights: [0.33811072 2.13448478] , error: 0.47378194165274257\n",
      "Step: 3400 Weights: [0.33815189 2.13448008] , error: 0.4737817701359152\n",
      "Step: 3401 Weights: [0.33819296 2.13447538] , error: 0.47378159940045683\n",
      "Step: 3402 Weights: [0.33823394 2.13447069] , error: 0.4737814294428042\n",
      "Step: 3403 Weights: [0.33827483 2.13446602] , error: 0.47378126025941747\n",
      "Step: 3404 Weights: [0.33831563 2.13446135] , error: 0.4737810918467666\n",
      "Step: 3405 Weights: [0.33835633 2.1344567 ] , error: 0.4737809242013422\n",
      "Step: 3406 Weights: [0.33839694 2.13445205] , error: 0.4737807573196472\n",
      "Step: 3407 Weights: [0.33843746 2.13444742] , error: 0.47378059119820454\n",
      "Step: 3408 Weights: [0.33847788 2.13444279] , error: 0.4737804258335496\n",
      "Step: 3409 Weights: [0.33851822 2.13443818] , error: 0.473780261222235\n",
      "Step: 3410 Weights: [0.33855846 2.13443358] , error: 0.4737800973608286\n",
      "Step: 3411 Weights: [0.33859861 2.13442899] , error: 0.4737799342459149\n",
      "Step: 3412 Weights: [0.33863866 2.13442441] , error: 0.47377977187409154\n",
      "Step: 3413 Weights: [0.33867863 2.13441984] , error: 0.47377961024197457\n",
      "Step: 3414 Weights: [0.3387185  2.13441528] , error: 0.4737794493461933\n",
      "Step: 3415 Weights: [0.33875829 2.13441073] , error: 0.4737792891833947\n",
      "Step: 3416 Weights: [0.33879798 2.13440619] , error: 0.47377912975023845\n",
      "Step: 3417 Weights: [0.33883758 2.13440166] , error: 0.4737789710434006\n",
      "Step: 3418 Weights: [0.33887709 2.13439714] , error: 0.47377881305957226\n",
      "Step: 3419 Weights: [0.33891652 2.13439263] , error: 0.47377865579546036\n",
      "Step: 3420 Weights: [0.33895585 2.13438813] , error: 0.47377849924778487\n",
      "Step: 3421 Weights: [0.33899509 2.13438364] , error: 0.4737783434132838\n",
      "Step: 3422 Weights: [0.33903425 2.13437917] , error: 0.47377818828870594\n",
      "Step: 3423 Weights: [0.33907331 2.1343747 ] , error: 0.4737780338708191\n",
      "Step: 3424 Weights: [0.33911228 2.13437024] , error: 0.4737778801564033\n",
      "Step: 3425 Weights: [0.33915117 2.13436579] , error: 0.4737777271422535\n",
      "Step: 3426 Weights: [0.33918997 2.13436136] , error: 0.47377757482517924\n",
      "Step: 3427 Weights: [0.33922868 2.13435693] , error: 0.47377742320200494\n",
      "Step: 3428 Weights: [0.3392673  2.13435251] , error: 0.47377727226957045\n",
      "Step: 3429 Weights: [0.33930583 2.13434811] , error: 0.47377712202472977\n",
      "Step: 3430 Weights: [0.33934427 2.13434371] , error: 0.47377697246434647\n",
      "Step: 3431 Weights: [0.33938263 2.13433932] , error: 0.4737768235853068\n",
      "Step: 3432 Weights: [0.3394209  2.13433495] , error: 0.47377667538450413\n",
      "Step: 3433 Weights: [0.33945908 2.13433058] , error: 0.4737765278588492\n",
      "Step: 3434 Weights: [0.33949718 2.13432622] , error: 0.4737763810052667\n",
      "Step: 3435 Weights: [0.33953518 2.13432188] , error: 0.4737762348206968\n",
      "Step: 3436 Weights: [0.33957311 2.13431754] , error: 0.47377608930208787\n",
      "Step: 3437 Weights: [0.33961094 2.13431321] , error: 0.4737759444464082\n",
      "Step: 3438 Weights: [0.33964869 2.1343089 ] , error: 0.47377580025063776\n",
      "Step: 3439 Weights: [0.33968635 2.13430459] , error: 0.47377565671177035\n",
      "Step: 3440 Weights: [0.33972393 2.13430029] , error: 0.4737755138268123\n",
      "Step: 3441 Weights: [0.33976142 2.134296  ] , error: 0.4737753715927859\n",
      "Step: 3442 Weights: [0.33979883 2.13429173] , error: 0.4737752300067255\n",
      "Step: 3443 Weights: [0.33983615 2.13428746] , error: 0.4737750890656777\n",
      "Step: 3444 Weights: [0.33987338 2.1342832 ] , error: 0.47377494876670584\n",
      "Step: 3445 Weights: [0.33991053 2.13427895] , error: 0.4737748091068844\n",
      "Step: 3446 Weights: [0.3399476  2.13427471] , error: 0.4737746700833011\n",
      "Step: 3447 Weights: [0.33998458 2.13427048] , error: 0.47377453169305894\n",
      "Step: 3448 Weights: [0.34002147 2.13426626] , error: 0.47377439393327087\n",
      "Step: 3449 Weights: [0.34005829 2.13426205] , error: 0.4737742568010649\n",
      "Step: 3450 Weights: [0.34009502 2.13425785] , error: 0.47377412029358335\n",
      "Step: 3451 Weights: [0.34013166 2.13425366] , error: 0.4737739844079792\n",
      "Step: 3452 Weights: [0.34016822 2.13424948] , error: 0.47377384914141973\n",
      "Step: 3453 Weights: [0.3402047  2.13424531] , error: 0.47377371449108474\n",
      "Step: 3454 Weights: [0.34024109 2.13424115] , error: 0.47377358045416723\n",
      "Step: 3455 Weights: [0.34027741 2.13423699] , error: 0.4737734470278721\n",
      "Step: 3456 Weights: [0.34031363 2.13423285] , error: 0.4737733142094183\n",
      "Step: 3457 Weights: [0.34034978 2.13422872] , error: 0.47377318199603535\n",
      "Step: 3458 Weights: [0.34038585 2.13422459] , error: 0.47377305038496836\n",
      "Step: 3459 Weights: [0.34042183 2.13422048] , error: 0.47377291937347277\n",
      "Step: 3460 Weights: [0.34045773 2.13421637] , error: 0.4737727889588169\n",
      "Step: 3461 Weights: [0.34049354 2.13421227] , error: 0.4737726591382825\n",
      "Step: 3462 Weights: [0.34052928 2.13420819] , error: 0.4737725299091613\n",
      "Step: 3463 Weights: [0.34056493 2.13420411] , error: 0.4737724012687617\n",
      "Step: 3464 Weights: [0.34060051 2.13420004] , error: 0.4737722732144\n",
      "Step: 3465 Weights: [0.340636   2.13419598] , error: 0.47377214574340654\n",
      "Step: 3466 Weights: [0.34067141 2.13419193] , error: 0.4737720188531234\n",
      "Step: 3467 Weights: [0.34070674 2.13418789] , error: 0.47377189254090574\n",
      "Step: 3468 Weights: [0.34074199 2.13418386] , error: 0.4737717668041197\n",
      "Step: 3469 Weights: [0.34077716 2.13417984] , error: 0.4737716416401442\n",
      "Step: 3470 Weights: [0.34081225 2.13417583] , error: 0.47377151704636944\n",
      "Step: 3471 Weights: [0.34084726 2.13417182] , error: 0.4737713930201979\n",
      "Step: 3472 Weights: [0.34088219 2.13416783] , error: 0.4737712695590438\n",
      "Step: 3473 Weights: [0.34091704 2.13416384] , error: 0.47377114666033315\n",
      "Step: 3474 Weights: [0.34095181 2.13415987] , error: 0.4737710243215038\n",
      "Step: 3475 Weights: [0.3409865 2.1341559] , error: 0.47377090254000437\n",
      "Step: 3476 Weights: [0.34102111 2.13415194] , error: 0.4737707813132974\n",
      "Step: 3477 Weights: [0.34105564 2.13414799] , error: 0.4737706606388538\n",
      "Step: 3478 Weights: [0.3410901  2.13414405] , error: 0.4737705405141583\n",
      "Step: 3479 Weights: [0.34112447 2.13414012] , error: 0.47377042093670646\n",
      "Step: 3480 Weights: [0.34115877 2.1341362 ] , error: 0.47377030190400526\n",
      "Step: 3481 Weights: [0.34119299 2.13413228] , error: 0.4737701834135746\n",
      "Step: 3482 Weights: [0.34122713 2.13412838] , error: 0.4737700654629409\n",
      "Step: 3483 Weights: [0.34126119 2.13412448] , error: 0.47376994804964784\n",
      "Step: 3484 Weights: [0.34129518 2.1341206 ] , error: 0.4737698311712452\n",
      "Step: 3485 Weights: [0.34132909 2.13411672] , error: 0.4737697148252976\n",
      "Step: 3486 Weights: [0.34136292 2.13411285] , error: 0.47376959900937976\n",
      "Step: 3487 Weights: [0.34139667 2.13410899] , error: 0.47376948372107563\n",
      "Step: 3488 Weights: [0.34143035 2.13410514] , error: 0.47376936895798377\n",
      "Step: 3489 Weights: [0.34146395 2.1341013 ] , error: 0.4737692547177085\n",
      "Step: 3490 Weights: [0.34149747 2.13409746] , error: 0.4737691409978708\n",
      "Step: 3491 Weights: [0.34153092 2.13409364] , error: 0.47376902779609875\n",
      "Step: 3492 Weights: [0.34156429 2.13408982] , error: 0.4737689151100324\n",
      "Step: 3493 Weights: [0.34159758 2.13408601] , error: 0.4737688029373212\n",
      "Step: 3494 Weights: [0.3416308  2.13408221] , error: 0.4737686912756274\n",
      "Step: 3495 Weights: [0.34166394 2.13407842] , error: 0.4737685801226238\n",
      "Step: 3496 Weights: [0.34169701 2.13407464] , error: 0.4737684694759921\n",
      "Step: 3497 Weights: [0.34173    2.13407087] , error: 0.47376835933342454\n",
      "Step: 3498 Weights: [0.34176292 2.1340671 ] , error: 0.47376824969262676\n",
      "Step: 3499 Weights: [0.34179576 2.13406335] , error: 0.47376814055131217\n",
      "Step: 3500 Weights: [0.34182853 2.1340596 ] , error: 0.47376803190720507\n",
      "Step: 3501 Weights: [0.34186122 2.13405586] , error: 0.47376792375803956\n",
      "Step: 3502 Weights: [0.34189384 2.13405213] , error: 0.47376781610156266\n",
      "Step: 3503 Weights: [0.34192638 2.13404841] , error: 0.4737677089355281\n",
      "Step: 3504 Weights: [0.34195885 2.1340447 ] , error: 0.4737676022577029\n",
      "Step: 3505 Weights: [0.34199124 2.13404099] , error: 0.4737674960658618\n",
      "Step: 3506 Weights: [0.34202356 2.1340373 ] , error: 0.4737673903577928\n",
      "Step: 3507 Weights: [0.34205581 2.13403361] , error: 0.47376728513128963\n",
      "Step: 3508 Weights: [0.34208798 2.13402993] , error: 0.4737671803841592\n",
      "Step: 3509 Weights: [0.34212008 2.13402626] , error: 0.4737670761142195\n",
      "Step: 3510 Weights: [0.34215211 2.13402259] , error: 0.4737669723192935\n",
      "Step: 3511 Weights: [0.34218406 2.13401894] , error: 0.4737668689972194\n",
      "Step: 3512 Weights: [0.34221594 2.13401529] , error: 0.4737667661458435\n",
      "Step: 3513 Weights: [0.34224775 2.13401166] , error: 0.4737666637630189\n",
      "Step: 3514 Weights: [0.34227949 2.13400803] , error: 0.4737665618466138\n",
      "Step: 3515 Weights: [0.34231115 2.13400441] , error: 0.4737664603945017\n",
      "Step: 3516 Weights: [0.34234274 2.13400079] , error: 0.4737663594045677\n",
      "Step: 3517 Weights: [0.34237426 2.13399719] , error: 0.4737662588747071\n",
      "Step: 3518 Weights: [0.34240571 2.13399359] , error: 0.4737661588028229\n",
      "Step: 3519 Weights: [0.34243708 2.13399   ] , error: 0.4737660591868294\n",
      "Step: 3520 Weights: [0.34246839 2.13398642] , error: 0.47376596002465\n",
      "Step: 3521 Weights: [0.34249962 2.13398285] , error: 0.47376586131421616\n",
      "Step: 3522 Weights: [0.34253078 2.13397929] , error: 0.47376576305347073\n",
      "Step: 3523 Weights: [0.34256187 2.13397573] , error: 0.473765665240365\n",
      "Step: 3524 Weights: [0.34259289 2.13397218] , error: 0.4737655678728597\n",
      "Step: 3525 Weights: [0.34262384 2.13396864] , error: 0.4737654709489255\n",
      "Step: 3526 Weights: [0.34265472 2.13396511] , error: 0.47376537446653955\n",
      "Step: 3527 Weights: [0.34268553 2.13396159] , error: 0.47376527842369254\n",
      "Step: 3528 Weights: [0.34271626 2.13395808] , error: 0.4737651828183816\n",
      "Step: 3529 Weights: [0.34274693 2.13395457] , error: 0.4737650876486127\n",
      "Step: 3530 Weights: [0.34277753 2.13395107] , error: 0.4737649929124015\n",
      "Step: 3531 Weights: [0.34280806 2.13394758] , error: 0.47376489860777465\n",
      "Step: 3532 Weights: [0.34283851 2.13394409] , error: 0.47376480473276383\n",
      "Step: 3533 Weights: [0.3428689  2.13394062] , error: 0.47376471128541364\n",
      "Step: 3534 Weights: [0.34289922 2.13393715] , error: 0.47376461826377425\n",
      "Step: 3535 Weights: [0.34292947 2.13393369] , error: 0.473764525665908\n",
      "Step: 3536 Weights: [0.34295965 2.13393024] , error: 0.47376443348988295\n",
      "Step: 3537 Weights: [0.34298976 2.1339268 ] , error: 0.47376434173377774\n",
      "Step: 3538 Weights: [0.34301981 2.13392336] , error: 0.47376425039567915\n",
      "Step: 3539 Weights: [0.34304978 2.13391993] , error: 0.4737641594736837\n",
      "Step: 3540 Weights: [0.34307969 2.13391651] , error: 0.47376406896589496\n",
      "Step: 3541 Weights: [0.34310953 2.1339131 ] , error: 0.473763978870427\n",
      "Step: 3542 Weights: [0.3431393  2.13390969] , error: 0.47376388918540074\n",
      "Step: 3543 Weights: [0.343169  2.1339063] , error: 0.4737637999089446\n",
      "Step: 3544 Weights: [0.34319864 2.13390291] , error: 0.47376371103920073\n",
      "Step: 3545 Weights: [0.3432282  2.13389953] , error: 0.4737636225743146\n",
      "Step: 3546 Weights: [0.3432577  2.13389615] , error: 0.4737635345124407\n",
      "Step: 3547 Weights: [0.34328714 2.13389279] , error: 0.47376344685174426\n",
      "Step: 3548 Weights: [0.3433165  2.13388943] , error: 0.4737633595903989\n",
      "Step: 3549 Weights: [0.3433458  2.13388608] , error: 0.4737632727265827\n",
      "Step: 3550 Weights: [0.34337503 2.13388274] , error: 0.4737631862584858\n",
      "Step: 3551 Weights: [0.3434042 2.1338794] , error: 0.4737631001843066\n",
      "Step: 3552 Weights: [0.3434333  2.13387607] , error: 0.47376301450224945\n",
      "Step: 3553 Weights: [0.34346233 2.13387275] , error: 0.4737629292105268\n",
      "Step: 3554 Weights: [0.34349129 2.13386944] , error: 0.47376284430736393\n",
      "Step: 3555 Weights: [0.34352019 2.13386613] , error: 0.47376275979098637\n",
      "Step: 3556 Weights: [0.34354903 2.13386284] , error: 0.4737626756596353\n",
      "Step: 3557 Weights: [0.3435778  2.13385955] , error: 0.4737625919115557\n",
      "Step: 3558 Weights: [0.3436065  2.13385626] , error: 0.473762508545001\n",
      "Step: 3559 Weights: [0.34363514 2.13385299] , error: 0.4737624255582333\n",
      "Step: 3560 Weights: [0.34366371 2.13384972] , error: 0.4737623429495234\n",
      "Step: 3561 Weights: [0.34369221 2.13384646] , error: 0.4737622607171473\n",
      "Step: 3562 Weights: [0.34372066 2.13384321] , error: 0.4737621788593924\n",
      "Step: 3563 Weights: [0.34374903 2.13383996] , error: 0.47376209737455066\n",
      "Step: 3564 Weights: [0.34377735 2.13383673] , error: 0.47376201626092423\n",
      "Step: 3565 Weights: [0.34380559 2.13383349] , error: 0.4737619355168208\n",
      "Step: 3566 Weights: [0.34383378 2.13383027] , error: 0.473761855140558\n",
      "Step: 3567 Weights: [0.3438619  2.13382706] , error: 0.47376177513046003\n",
      "Step: 3568 Weights: [0.34388995 2.13382385] , error: 0.4737616954848584\n",
      "Step: 3569 Weights: [0.34391794 2.13382065] , error: 0.4737616162020933\n",
      "Step: 3570 Weights: [0.34394587 2.13381745] , error: 0.47376153728051007\n",
      "Step: 3571 Weights: [0.34397373 2.13381427] , error: 0.4737614587184651\n",
      "Step: 3572 Weights: [0.34400153 2.13381109] , error: 0.4737613805143194\n",
      "Step: 3573 Weights: [0.34402927 2.13380791] , error: 0.473761302666443\n",
      "Step: 3574 Weights: [0.34405694 2.13380475] , error: 0.47376122517321295\n",
      "Step: 3575 Weights: [0.34408455 2.13380159] , error: 0.47376114803301317\n",
      "Step: 3576 Weights: [0.3441121  2.13379844] , error: 0.4737610712442362\n",
      "Step: 3577 Weights: [0.34413958 2.1337953 ] , error: 0.4737609948052804\n",
      "Step: 3578 Weights: [0.344167   2.13379216] , error: 0.4737609187145513\n",
      "Step: 3579 Weights: [0.34419436 2.13378903] , error: 0.47376084297046384\n",
      "Step: 3580 Weights: [0.34422166 2.13378591] , error: 0.47376076757143926\n",
      "Step: 3581 Weights: [0.34424889 2.1337828 ] , error: 0.4737606925159037\n",
      "Step: 3582 Weights: [0.34427607 2.13377969] , error: 0.47376061780229395\n",
      "Step: 3583 Weights: [0.34430318 2.13377659] , error: 0.4737605434290525\n",
      "Step: 3584 Weights: [0.34433022 2.1337735 ] , error: 0.47376046939462696\n",
      "Step: 3585 Weights: [0.34435721 2.13377041] , error: 0.4737603956974758\n",
      "Step: 3586 Weights: [0.34438414 2.13376733] , error: 0.47376032233606047\n",
      "Step: 3587 Weights: [0.344411   2.13376426] , error: 0.47376024930885374\n",
      "Step: 3588 Weights: [0.3444378  2.13376119] , error: 0.4737601766143321\n",
      "Step: 3589 Weights: [0.34446454 2.13375813] , error: 0.4737601042509789\n",
      "Step: 3590 Weights: [0.34449122 2.13375508] , error: 0.47376003221728663\n",
      "Step: 3591 Weights: [0.34451784 2.13375204] , error: 0.4737599605117535\n",
      "Step: 3592 Weights: [0.3445444 2.133749 ] , error: 0.47375988913288436\n",
      "Step: 3593 Weights: [0.3445709  2.13374597] , error: 0.47375981807919104\n",
      "Step: 3594 Weights: [0.34459734 2.13374295] , error: 0.4737597473491916\n",
      "Step: 3595 Weights: [0.34462372 2.13373993] , error: 0.4737596769414121\n",
      "Step: 3596 Weights: [0.34465003 2.13373692] , error: 0.473759606854385\n",
      "Step: 3597 Weights: [0.34467629 2.13373392] , error: 0.4737595370866482\n",
      "Step: 3598 Weights: [0.34470249 2.13373092] , error: 0.47375946763674714\n",
      "Step: 3599 Weights: [0.34472863 2.13372793] , error: 0.47375939850323395\n",
      "Step: 3600 Weights: [0.34475471 2.13372495] , error: 0.4737593296846683\n",
      "Step: 3601 Weights: [0.34478072 2.13372197] , error: 0.4737592611796133\n",
      "Step: 3602 Weights: [0.34480668 2.13371901] , error: 0.4737591929866434\n",
      "Step: 3603 Weights: [0.34483258 2.13371604] , error: 0.47375912510433493\n",
      "Step: 3604 Weights: [0.34485843 2.13371309] , error: 0.47375905753127345\n",
      "Step: 3605 Weights: [0.34488421 2.13371014] , error: 0.4737589902660497\n",
      "Step: 3606 Weights: [0.34490993 2.1337072 ] , error: 0.4737589233072621\n",
      "Step: 3607 Weights: [0.3449356  2.13370426] , error: 0.4737588566535126\n",
      "Step: 3608 Weights: [0.3449612  2.13370133] , error: 0.4737587903034134\n",
      "Step: 3609 Weights: [0.34498675 2.13369841] , error: 0.4737587242555813\n",
      "Step: 3610 Weights: [0.34501224 2.1336955 ] , error: 0.47375865850863913\n",
      "Step: 3611 Weights: [0.34503767 2.13369259] , error: 0.47375859306121454\n",
      "Step: 3612 Weights: [0.34506305 2.13368969] , error: 0.47375852791194517\n",
      "Step: 3613 Weights: [0.34508836 2.13368679] , error: 0.47375846305947067\n",
      "Step: 3614 Weights: [0.34511362 2.1336839 ] , error: 0.47375839850244167\n",
      "Step: 3615 Weights: [0.34513882 2.13368102] , error: 0.47375833423950897\n",
      "Step: 3616 Weights: [0.34516396 2.13367815] , error: 0.47375827026933576\n",
      "Step: 3617 Weights: [0.34518905 2.13367528] , error: 0.47375820659058687\n",
      "Step: 3618 Weights: [0.34521408 2.13367241] , error: 0.47375814320193443\n",
      "Step: 3619 Weights: [0.34523905 2.13366956] , error: 0.473758080102057\n",
      "Step: 3620 Weights: [0.34526396 2.13366671] , error: 0.47375801728963973\n",
      "Step: 3621 Weights: [0.34528882 2.13366387] , error: 0.47375795476337257\n",
      "Step: 3622 Weights: [0.34531362 2.13366103] , error: 0.4737578925219518\n",
      "Step: 3623 Weights: [0.34533836 2.1336582 ] , error: 0.4737578305640802\n",
      "Step: 3624 Weights: [0.34536305 2.13365538] , error: 0.4737577688884641\n",
      "Step: 3625 Weights: [0.34538768 2.13365256] , error: 0.47375770749382146\n",
      "Step: 3626 Weights: [0.34541226 2.13364975] , error: 0.47375764637887025\n",
      "Step: 3627 Weights: [0.34543678 2.13364695] , error: 0.4737575855423348\n",
      "Step: 3628 Weights: [0.34546124 2.13364415] , error: 0.4737575249829495\n",
      "Step: 3629 Weights: [0.34548565 2.13364136] , error: 0.4737574646994498\n",
      "Step: 3630 Weights: [0.34551    2.13363857] , error: 0.4737574046905798\n",
      "Step: 3631 Weights: [0.3455343  2.13363579] , error: 0.47375734495508637\n",
      "Step: 3632 Weights: [0.34555854 2.13363302] , error: 0.47375728549172696\n",
      "Step: 3633 Weights: [0.34558272 2.13363025] , error: 0.4737572262992614\n",
      "Step: 3634 Weights: [0.34560685 2.13362749] , error: 0.47375716737645457\n",
      "Step: 3635 Weights: [0.34563093 2.13362474] , error: 0.47375710872207755\n",
      "Step: 3636 Weights: [0.34565495 2.13362199] , error: 0.47375705033490767\n",
      "Step: 3637 Weights: [0.34567892 2.13361925] , error: 0.4737569922137297\n",
      "Step: 3638 Weights: [0.34570283 2.13361652] , error: 0.4737569343573296\n",
      "Step: 3639 Weights: [0.34572668 2.13361379] , error: 0.4737568767645017\n",
      "Step: 3640 Weights: [0.34575049 2.13361107] , error: 0.4737568194340459\n",
      "Step: 3641 Weights: [0.34577423 2.13360835] , error: 0.47375676236476555\n",
      "Step: 3642 Weights: [0.34579793 2.13360564] , error: 0.473756705555473\n",
      "Step: 3643 Weights: [0.34582157 2.13360294] , error: 0.47375664900498177\n",
      "Step: 3644 Weights: [0.34584515 2.13360024] , error: 0.47375659271211396\n",
      "Step: 3645 Weights: [0.34586869 2.13359755] , error: 0.4737565366756956\n",
      "Step: 3646 Weights: [0.34589217 2.13359487] , error: 0.47375648089455935\n",
      "Step: 3647 Weights: [0.34591559 2.13359219] , error: 0.4737564253675404\n",
      "Step: 3648 Weights: [0.34593896 2.13358951] , error: 0.47375637009348237\n",
      "Step: 3649 Weights: [0.34596228 2.13358685] , error: 0.4737563150712316\n",
      "Step: 3650 Weights: [0.34598554 2.13358419] , error: 0.47375626029964213\n",
      "Step: 3651 Weights: [0.34600876 2.13358153] , error: 0.4737562057775732\n",
      "Step: 3652 Weights: [0.34603192 2.13357888] , error: 0.4737561515038854\n",
      "Step: 3653 Weights: [0.34605502 2.13357624] , error: 0.4737560974774482\n",
      "Step: 3654 Weights: [0.34607808 2.1335736 ] , error: 0.4737560436971359\n",
      "Step: 3655 Weights: [0.34610108 2.13357097] , error: 0.47375599016182746\n",
      "Step: 3656 Weights: [0.34612403 2.13356835] , error: 0.4737559368704058\n",
      "Step: 3657 Weights: [0.34614692 2.13356573] , error: 0.4737558838217604\n",
      "Step: 3658 Weights: [0.34616977 2.13356312] , error: 0.4737558310147842\n",
      "Step: 3659 Weights: [0.34619256 2.13356051] , error: 0.47375577844837835\n",
      "Step: 3660 Weights: [0.3462153  2.13355791] , error: 0.473755726121444\n",
      "Step: 3661 Weights: [0.34623799 2.13355532] , error: 0.4737556740328931\n",
      "Step: 3662 Weights: [0.34626062 2.13355273] , error: 0.47375562218163814\n",
      "Step: 3663 Weights: [0.34628321 2.13355014] , error: 0.47375557056659773\n",
      "Step: 3664 Weights: [0.34630574 2.13354757] , error: 0.47375551918669623\n",
      "Step: 3665 Weights: [0.34632822 2.133545  ] , error: 0.47375546804086394\n",
      "Step: 3666 Weights: [0.34635065 2.13354243] , error: 0.47375541712803165\n",
      "Step: 3667 Weights: [0.34637303 2.13353987] , error: 0.4737553664471412\n",
      "Step: 3668 Weights: [0.34639536 2.13353732] , error: 0.4737553159971326\n",
      "Step: 3669 Weights: [0.34641764 2.13353477] , error: 0.47375526577695626\n",
      "Step: 3670 Weights: [0.34643986 2.13353223] , error: 0.4737552157855638\n",
      "Step: 3671 Weights: [0.34646204 2.13352969] , error: 0.4737551660219139\n",
      "Step: 3672 Weights: [0.34648416 2.13352716] , error: 0.473755116484969\n",
      "Step: 3673 Weights: [0.34650624 2.13352464] , error: 0.4737550671736964\n",
      "Step: 3674 Weights: [0.34652826 2.13352212] , error: 0.47375501808706805\n",
      "Step: 3675 Weights: [0.34655024 2.13351961] , error: 0.47375496922405896\n",
      "Step: 3676 Weights: [0.34657216 2.1335171 ] , error: 0.47375492058365287\n",
      "Step: 3677 Weights: [0.34659404 2.1335146 ] , error: 0.47375487216483364\n",
      "Step: 3678 Weights: [0.34661586 2.1335121 ] , error: 0.47375482396659363\n",
      "Step: 3679 Weights: [0.34663764 2.13350961] , error: 0.47375477598792665\n",
      "Step: 3680 Weights: [0.34665936 2.13350713] , error: 0.4737547282278322\n",
      "Step: 3681 Weights: [0.34668104 2.13350465] , error: 0.4737546806853156\n",
      "Step: 3682 Weights: [0.34670266 2.13350217] , error: 0.4737546333593854\n",
      "Step: 3683 Weights: [0.34672424 2.13349971] , error: 0.4737545862490539\n",
      "Step: 3684 Weights: [0.34674577 2.13349724] , error: 0.4737545393533402\n",
      "Step: 3685 Weights: [0.34676724 2.13349479] , error: 0.47375449267126557\n",
      "Step: 3686 Weights: [0.34678867 2.13349234] , error: 0.47375444620185736\n",
      "Step: 3687 Weights: [0.34681005 2.13348989] , error: 0.4737543999441465\n",
      "Step: 3688 Weights: [0.34683139 2.13348745] , error: 0.4737543538971695\n",
      "Step: 3689 Weights: [0.34685267 2.13348502] , error: 0.4737543080599649\n",
      "Step: 3690 Weights: [0.3468739  2.13348259] , error: 0.4737542624315775\n",
      "Step: 3691 Weights: [0.34689509 2.13348017] , error: 0.47375421701105697\n",
      "Step: 3692 Weights: [0.34691623 2.13347775] , error: 0.47375417179745516\n",
      "Step: 3693 Weights: [0.34693732 2.13347534] , error: 0.4737541267898292\n",
      "Step: 3694 Weights: [0.34695836 2.13347293] , error: 0.4737540819872415\n",
      "Step: 3695 Weights: [0.34697935 2.13347053] , error: 0.47375403738875843\n",
      "Step: 3696 Weights: [0.3470003  2.13346813] , error: 0.47375399299345\n",
      "Step: 3697 Weights: [0.3470212  2.13346574] , error: 0.4737539488003887\n",
      "Step: 3698 Weights: [0.34704205 2.13346336] , error: 0.4737539048086564\n",
      "Step: 3699 Weights: [0.34706285 2.13346098] , error: 0.47375386101733225\n",
      "Step: 3700 Weights: [0.3470836  2.13345861] , error: 0.47375381742550604\n",
      "Step: 3701 Weights: [0.34710431 2.13345624] , error: 0.47375377403226865\n",
      "Step: 3702 Weights: [0.34712497 2.13345388] , error: 0.47375373083671485\n",
      "Step: 3703 Weights: [0.34714559 2.13345152] , error: 0.4737536878379438\n",
      "Step: 3704 Weights: [0.34716615 2.13344917] , error: 0.4737536450350586\n",
      "Step: 3705 Weights: [0.34718667 2.13344682] , error: 0.4737536024271673\n",
      "Step: 3706 Weights: [0.34720715 2.13344448] , error: 0.47375356001338276\n",
      "Step: 3707 Weights: [0.34722757 2.13344214] , error: 0.4737535177928205\n",
      "Step: 3708 Weights: [0.34724795 2.13343981] , error: 0.47375347576459814\n",
      "Step: 3709 Weights: [0.34726829 2.13343749] , error: 0.4737534339278407\n",
      "Step: 3710 Weights: [0.34728857 2.13343517] , error: 0.4737533922816773\n",
      "Step: 3711 Weights: [0.34730881 2.13343285] , error: 0.4737533508252373\n",
      "Step: 3712 Weights: [0.34732901 2.13343054] , error: 0.473753309557658\n",
      "Step: 3713 Weights: [0.34734916 2.13342824] , error: 0.47375326847807836\n",
      "Step: 3714 Weights: [0.34736926 2.13342594] , error: 0.4737532275856419\n",
      "Step: 3715 Weights: [0.34738931 2.13342365] , error: 0.4737531868794965\n",
      "Step: 3716 Weights: [0.34740933 2.13342136] , error: 0.47375314635879434\n",
      "Step: 3717 Weights: [0.34742929 2.13341907] , error: 0.47375310602268794\n",
      "Step: 3718 Weights: [0.34744921 2.1334168 ] , error: 0.4737530658703383\n",
      "Step: 3719 Weights: [0.34746908 2.13341452] , error: 0.47375302590090834\n",
      "Step: 3720 Weights: [0.34748891 2.13341225] , error: 0.4737529861135634\n",
      "Step: 3721 Weights: [0.3475087  2.13340999] , error: 0.4737529465074765\n",
      "Step: 3722 Weights: [0.34752844 2.13340773] , error: 0.4737529070818194\n",
      "Step: 3723 Weights: [0.34754813 2.13340548] , error: 0.4737528678357705\n",
      "Step: 3724 Weights: [0.34756778 2.13340324] , error: 0.47375282876851366\n",
      "Step: 3725 Weights: [0.34758738 2.13340099] , error: 0.47375278987923175\n",
      "Step: 3726 Weights: [0.34760694 2.13339876] , error: 0.4737527511671143\n",
      "Step: 3727 Weights: [0.34762645 2.13339652] , error: 0.4737527126313563\n",
      "Step: 3728 Weights: [0.34764592 2.1333943 ] , error: 0.4737526742711529\n",
      "Step: 3729 Weights: [0.34766535 2.13339208] , error: 0.47375263608570356\n",
      "Step: 3730 Weights: [0.34768473 2.13338986] , error: 0.47375259807421277\n",
      "Step: 3731 Weights: [0.34770407 2.13338765] , error: 0.47375256023588924\n",
      "Step: 3732 Weights: [0.34772336 2.13338544] , error: 0.4737525225699436\n",
      "Step: 3733 Weights: [0.34774261 2.13338324] , error: 0.47375248507558904\n",
      "Step: 3734 Weights: [0.34776182 2.13338104] , error: 0.47375244775204484\n",
      "Step: 3735 Weights: [0.34778098 2.13337885] , error: 0.4737524105985335\n",
      "Step: 3736 Weights: [0.3478001  2.13337667] , error: 0.47375237361428046\n",
      "Step: 3737 Weights: [0.34781917 2.13337449] , error: 0.47375233679851303\n",
      "Step: 3738 Weights: [0.3478382  2.13337231] , error: 0.4737523001504641\n",
      "Step: 3739 Weights: [0.34785719 2.13337014] , error: 0.47375226366937073\n",
      "Step: 3740 Weights: [0.34787613 2.13336797] , error: 0.47375222735447187\n",
      "Step: 3741 Weights: [0.34789503 2.13336581] , error: 0.47375219120501055\n",
      "Step: 3742 Weights: [0.34791389 2.13336365] , error: 0.4737521552202325\n",
      "Step: 3743 Weights: [0.3479327 2.1333615] , error: 0.47375211939938766\n",
      "Step: 3744 Weights: [0.34795148 2.13335935] , error: 0.4737520837417302\n",
      "Step: 3745 Weights: [0.3479702  2.13335721] , error: 0.4737520482465152\n",
      "Step: 3746 Weights: [0.34798889 2.13335508] , error: 0.47375201291300256\n",
      "Step: 3747 Weights: [0.34800753 2.13335294] , error: 0.4737519777404573\n",
      "Step: 3748 Weights: [0.34802613 2.13335082] , error: 0.4737519427281447\n",
      "Step: 3749 Weights: [0.34804469 2.13334869] , error: 0.4737519078753354\n",
      "Step: 3750 Weights: [0.34806321 2.13334658] , error: 0.473751873181303\n",
      "Step: 3751 Weights: [0.34808168 2.13334446] , error: 0.4737518386453236\n",
      "Step: 3752 Weights: [0.34810012 2.13334236] , error: 0.47375180426667696\n",
      "Step: 3753 Weights: [0.34811851 2.13334025] , error: 0.4737517700446473\n",
      "Step: 3754 Weights: [0.34813685 2.13333815] , error: 0.47375173597852044\n",
      "Step: 3755 Weights: [0.34815516 2.13333606] , error: 0.4737517020675856\n",
      "Step: 3756 Weights: [0.34817342 2.13333397] , error: 0.4737516683111366\n",
      "Step: 3757 Weights: [0.34819165 2.13333189] , error: 0.47375163470847037\n",
      "Step: 3758 Weights: [0.34820983 2.13332981] , error: 0.47375160125888566\n",
      "Step: 3759 Weights: [0.34822797 2.13332773] , error: 0.47375156796168355\n",
      "Step: 3760 Weights: [0.34824607 2.13332566] , error: 0.47375153481617205\n",
      "Step: 3761 Weights: [0.34826412 2.1333236 ] , error: 0.4737515018216591\n",
      "Step: 3762 Weights: [0.34828214 2.13332154] , error: 0.4737514689774562\n",
      "Step: 3763 Weights: [0.34830011 2.13331948] , error: 0.4737514362828812\n",
      "Step: 3764 Weights: [0.34831805 2.13331743] , error: 0.4737514037372489\n",
      "Step: 3765 Weights: [0.34833594 2.13331539] , error: 0.4737513713398833\n",
      "Step: 3766 Weights: [0.34835379 2.13331334] , error: 0.47375133909010775\n",
      "Step: 3767 Weights: [0.3483716  2.13331131] , error: 0.4737513069872508\n",
      "Step: 3768 Weights: [0.34838937 2.13330927] , error: 0.47375127503064096\n",
      "Step: 3769 Weights: [0.3484071  2.13330725] , error: 0.47375124321961676\n",
      "Step: 3770 Weights: [0.34842479 2.13330522] , error: 0.47375121155350897\n",
      "Step: 3771 Weights: [0.34844244 2.1333032 ] , error: 0.4737511800316618\n",
      "Step: 3772 Weights: [0.34846005 2.13330119] , error: 0.4737511486534154\n",
      "Step: 3773 Weights: [0.34847762 2.13329918] , error: 0.47375111741811726\n",
      "Step: 3774 Weights: [0.34849515 2.13329718] , error: 0.47375108632511587\n",
      "Step: 3775 Weights: [0.34851264 2.13329518] , error: 0.4737510553737623\n",
      "Step: 3776 Weights: [0.34853009 2.13329318] , error: 0.4737510245634131\n",
      "Step: 3777 Weights: [0.3485475  2.13329119] , error: 0.4737509938934214\n",
      "Step: 3778 Weights: [0.34856487 2.1332892 ] , error: 0.4737509633631529\n",
      "Step: 3779 Weights: [0.3485822  2.13328722] , error: 0.473750932971969\n",
      "Step: 3780 Weights: [0.34859949 2.13328524] , error: 0.47375090271923537\n",
      "Step: 3781 Weights: [0.34861674 2.13328327] , error: 0.4737508726043229\n",
      "Step: 3782 Weights: [0.34863395 2.1332813 ] , error: 0.4737508426266022\n",
      "Step: 3783 Weights: [0.34865112 2.13327934] , error: 0.4737508127854499\n",
      "Step: 3784 Weights: [0.34866826 2.13327738] , error: 0.47375078308024127\n",
      "Step: 3785 Weights: [0.34868535 2.13327542] , error: 0.47375075351035967\n",
      "Step: 3786 Weights: [0.34870241 2.13327347] , error: 0.47375072407518737\n",
      "Step: 3787 Weights: [0.34871942 2.13327153] , error: 0.473750694774111\n",
      "Step: 3788 Weights: [0.3487364  2.13326959] , error: 0.47375066560651913\n",
      "Step: 3789 Weights: [0.34875334 2.13326765] , error: 0.4737506365718045\n",
      "Step: 3790 Weights: [0.34877024 2.13326572] , error: 0.4737506076693607\n",
      "Step: 3791 Weights: [0.3487871  2.13326379] , error: 0.47375057889858635\n",
      "Step: 3792 Weights: [0.34880393 2.13326186] , error: 0.4737505502588807\n",
      "Step: 3793 Weights: [0.34882071 2.13325994] , error: 0.4737505217496466\n",
      "Step: 3794 Weights: [0.34883746 2.13325803] , error: 0.47375049337029057\n",
      "Step: 3795 Weights: [0.34885417 2.13325612] , error: 0.47375046512022023\n",
      "Step: 3796 Weights: [0.34887084 2.13325421] , error: 0.4737504369988466\n",
      "Step: 3797 Weights: [0.34888747 2.13325231] , error: 0.47375040900558374\n",
      "Step: 3798 Weights: [0.34890406 2.13325041] , error: 0.4737503811398489\n",
      "Step: 3799 Weights: [0.34892062 2.13324852] , error: 0.4737503534010576\n",
      "Step: 3800 Weights: [0.34893714 2.13324663] , error: 0.47375032578863685\n",
      "Step: 3801 Weights: [0.34895362 2.13324474] , error: 0.4737502983020055\n",
      "Step: 3802 Weights: [0.34897006 2.13324286] , error: 0.47375027094059396\n",
      "Step: 3803 Weights: [0.34898647 2.13324099] , error: 0.4737502437038326\n",
      "Step: 3804 Weights: [0.34900284 2.13323912] , error: 0.47375021659114935\n",
      "Step: 3805 Weights: [0.34901917 2.13323725] , error: 0.47375018960198306\n",
      "Step: 3806 Weights: [0.34903546 2.13323538] , error: 0.4737501627357694\n",
      "Step: 3807 Weights: [0.34905172 2.13323353] , error: 0.4737501359919467\n",
      "Step: 3808 Weights: [0.34906794 2.13323167] , error: 0.47375010936996\n",
      "Step: 3809 Weights: [0.34908412 2.13322982] , error: 0.47375008286925374\n",
      "Step: 3810 Weights: [0.34910027 2.13322797] , error: 0.4737500564892744\n",
      "Step: 3811 Weights: [0.34911638 2.13322613] , error: 0.4737500302294733\n",
      "Step: 3812 Weights: [0.34913245 2.13322429] , error: 0.4737500040893012\n",
      "Step: 3813 Weights: [0.34914849 2.13322246] , error: 0.47374997806821456\n",
      "Step: 3814 Weights: [0.34916448 2.13322063] , error: 0.4737499521656692\n",
      "Step: 3815 Weights: [0.34918045 2.1332188 ] , error: 0.4737499263811278\n",
      "Step: 3816 Weights: [0.34919637 2.13321698] , error: 0.4737499007140503\n",
      "Step: 3817 Weights: [0.34921226 2.13321517] , error: 0.47374987516390343\n",
      "Step: 3818 Weights: [0.34922812 2.13321335] , error: 0.4737498497301534\n",
      "Step: 3819 Weights: [0.34924393 2.13321154] , error: 0.4737498244122692\n",
      "Step: 3820 Weights: [0.34925972 2.13320974] , error: 0.4737497992097249\n",
      "Step: 3821 Weights: [0.34927546 2.13320794] , error: 0.47374977412199315\n",
      "Step: 3822 Weights: [0.34929117 2.13320614] , error: 0.4737497491485528\n",
      "Step: 3823 Weights: [0.34930685 2.13320435] , error: 0.4737497242888814\n",
      "Step: 3824 Weights: [0.34932248 2.13320256] , error: 0.4737496995424618\n",
      "Step: 3825 Weights: [0.34933809 2.13320078] , error: 0.47374967490877795\n",
      "Step: 3826 Weights: [0.34935365 2.133199  ] , error: 0.47374965038731665\n",
      "Step: 3827 Weights: [0.34936918 2.13319722] , error: 0.4737496259775649\n",
      "Step: 3828 Weights: [0.34938468 2.13319545] , error: 0.47374960167901586\n",
      "Step: 3829 Weights: [0.34940014 2.13319368] , error: 0.47374957749116076\n",
      "Step: 3830 Weights: [0.34941557 2.13319191] , error: 0.47374955341349745\n",
      "Step: 3831 Weights: [0.34943096 2.13319015] , error: 0.473749529445523\n",
      "Step: 3832 Weights: [0.34944631 2.1331884 ] , error: 0.47374950558673845\n",
      "Step: 3833 Weights: [0.34946163 2.13318665] , error: 0.4737494818366449\n",
      "Step: 3834 Weights: [0.34947692 2.1331849 ] , error: 0.473749458194748\n",
      "Step: 3835 Weights: [0.34949217 2.13318315] , error: 0.47374943466055525\n",
      "Step: 3836 Weights: [0.34950738 2.13318141] , error: 0.4737494112335749\n",
      "Step: 3837 Weights: [0.34952256 2.13317968] , error: 0.47374938791331966\n",
      "Step: 3838 Weights: [0.34953771 2.13317795] , error: 0.47374936469930284\n",
      "Step: 3839 Weights: [0.34955282 2.13317622] , error: 0.4737493415910408\n",
      "Step: 3840 Weights: [0.3495679  2.13317449] , error: 0.4737493185880508\n",
      "Step: 3841 Weights: [0.34958294 2.13317277] , error: 0.47374929568985513\n",
      "Step: 3842 Weights: [0.34959795 2.13317106] , error: 0.4737492728959741\n",
      "Step: 3843 Weights: [0.34961292 2.13316934] , error: 0.47374925020593395\n",
      "Step: 3844 Weights: [0.34962786 2.13316764] , error: 0.47374922761926186\n",
      "Step: 3845 Weights: [0.34964277 2.13316593] , error: 0.47374920513548496\n",
      "Step: 3846 Weights: [0.34965764 2.13316423] , error: 0.47374918275413674\n",
      "Step: 3847 Weights: [0.34967248 2.13316253] , error: 0.47374916047474963\n",
      "Step: 3848 Weights: [0.34968728 2.13316084] , error: 0.47374913829685894\n",
      "Step: 3849 Weights: [0.34970205 2.13315915] , error: 0.47374911622000204\n",
      "Step: 3850 Weights: [0.34971679 2.13315747] , error: 0.47374909424371997\n",
      "Step: 3851 Weights: [0.34973149 2.13315578] , error: 0.47374907236755354\n",
      "Step: 3852 Weights: [0.34974616 2.13315411] , error: 0.47374905059104633\n",
      "Step: 3853 Weights: [0.3497608  2.13315243] , error: 0.47374902891374554\n",
      "Step: 3854 Weights: [0.3497754  2.13315076] , error: 0.47374900733519876\n",
      "Step: 3855 Weights: [0.34978997 2.1331491 ] , error: 0.47374898585495495\n",
      "Step: 3856 Weights: [0.34980451 2.13314743] , error: 0.473748964472568\n",
      "Step: 3857 Weights: [0.34981901 2.13314577] , error: 0.4737489431875903\n",
      "Step: 3858 Weights: [0.34983348 2.13314412] , error: 0.47374892199958024\n",
      "Step: 3859 Weights: [0.34984792 2.13314247] , error: 0.47374890090809385\n",
      "Step: 3860 Weights: [0.34986232 2.13314082] , error: 0.473748879912693\n",
      "Step: 3861 Weights: [0.34987669 2.13313918] , error: 0.47374885901293906\n",
      "Step: 3862 Weights: [0.34989103 2.13313754] , error: 0.47374883820839725\n",
      "Step: 3863 Weights: [0.34990534 2.1331359 ] , error: 0.4737488174986329\n",
      "Step: 3864 Weights: [0.34991961 2.13313427] , error: 0.4737487968832154\n",
      "Step: 3865 Weights: [0.34993385 2.13313264] , error: 0.47374877636171253\n",
      "Step: 3866 Weights: [0.34994806 2.13313102] , error: 0.4737487559336995\n",
      "Step: 3867 Weights: [0.34996224 2.1331294 ] , error: 0.47374873559874864\n",
      "Step: 3868 Weights: [0.34997638 2.13312778] , error: 0.4737487153564361\n",
      "Step: 3869 Weights: [0.34999049 2.13312616] , error: 0.47374869520633933\n",
      "Step: 3870 Weights: [0.35000457 2.13312455] , error: 0.4737486751480404\n",
      "Step: 3871 Weights: [0.35001862 2.13312295] , error: 0.47374865518111875\n",
      "Step: 3872 Weights: [0.35003263 2.13312134] , error: 0.47374863530516\n",
      "Step: 3873 Weights: [0.35004661 2.13311975] , error: 0.4737486155197471\n",
      "Step: 3874 Weights: [0.35006057 2.13311815] , error: 0.4737485958244704\n",
      "Step: 3875 Weights: [0.35007448 2.13311656] , error: 0.4737485762189179\n",
      "Step: 3876 Weights: [0.35008837 2.13311497] , error: 0.4737485567026805\n",
      "Step: 3877 Weights: [0.35010223 2.13311339] , error: 0.4737485372753523\n",
      "Step: 3878 Weights: [0.35011605 2.1331118 ] , error: 0.4737485179365278\n",
      "Step: 3879 Weights: [0.35012984 2.13311023] , error: 0.4737484986858043\n",
      "Step: 3880 Weights: [0.35014361 2.13310865] , error: 0.47374847952277993\n",
      "Step: 3881 Weights: [0.35015734 2.13310708] , error: 0.4737484604470551\n",
      "Step: 3882 Weights: [0.35017103 2.13310552] , error: 0.4737484414582316\n",
      "Step: 3883 Weights: [0.3501847  2.13310395] , error: 0.4737484225559139\n",
      "Step: 3884 Weights: [0.35019834 2.13310239] , error: 0.47374840373970994\n",
      "Step: 3885 Weights: [0.35021194 2.13310084] , error: 0.4737483850092243\n",
      "Step: 3886 Weights: [0.35022552 2.13309929] , error: 0.4737483663640674\n",
      "Step: 3887 Weights: [0.35023906 2.13309774] , error: 0.4737483478038524\n",
      "Step: 3888 Weights: [0.35025257 2.13309619] , error: 0.47374832932818994\n",
      "Step: 3889 Weights: [0.35026605 2.13309465] , error: 0.4737483109366959\n",
      "Step: 3890 Weights: [0.3502795  2.13309311] , error: 0.47374829262898666\n",
      "Step: 3891 Weights: [0.35029292 2.13309158] , error: 0.47374827440468065\n",
      "Step: 3892 Weights: [0.35030631 2.13309004] , error: 0.4737482562633978\n",
      "Step: 3893 Weights: [0.35031967 2.13308852] , error: 0.4737482382047604\n",
      "Step: 3894 Weights: [0.350333   2.13308699] , error: 0.4737482202283917\n",
      "Step: 3895 Weights: [0.3503463  2.13308547] , error: 0.47374820233391607\n",
      "Step: 3896 Weights: [0.35035957 2.13308395] , error: 0.47374818452096107\n",
      "Step: 3897 Weights: [0.3503728  2.13308244] , error: 0.4737481667891543\n",
      "Step: 3898 Weights: [0.35038601 2.13308093] , error: 0.47374814913812857\n",
      "Step: 3899 Weights: [0.35039919 2.13307942] , error: 0.4737481315675137\n",
      "Step: 3900 Weights: [0.35041234 2.13307792] , error: 0.47374811407694495\n",
      "Step: 3901 Weights: [0.35042545 2.13307642] , error: 0.473748096666055\n",
      "Step: 3902 Weights: [0.35043854 2.13307492] , error: 0.4737480793344845\n",
      "Step: 3903 Weights: [0.3504516  2.13307343] , error: 0.47374806208186937\n",
      "Step: 3904 Weights: [0.35046462 2.13307194] , error: 0.4737480449078513\n",
      "Step: 3905 Weights: [0.35047762 2.13307045] , error: 0.47374802781207065\n",
      "Step: 3906 Weights: [0.35049059 2.13306897] , error: 0.47374801079417284\n",
      "Step: 3907 Weights: [0.35050353 2.13306749] , error: 0.4737479938538023\n",
      "Step: 3908 Weights: [0.35051644 2.13306601] , error: 0.47374797699060583\n",
      "Step: 3909 Weights: [0.35052932 2.13306454] , error: 0.47374796020423215\n",
      "Step: 3910 Weights: [0.35054217 2.13306307] , error: 0.47374794349433014\n",
      "Step: 3911 Weights: [0.35055499 2.13306161] , error: 0.4737479268605531\n",
      "Step: 3912 Weights: [0.35056778 2.13306014] , error: 0.47374791030255214\n",
      "Step: 3913 Weights: [0.35058054 2.13305868] , error: 0.4737478938199846\n",
      "Step: 3914 Weights: [0.35059328 2.13305723] , error: 0.473747877412505\n",
      "Step: 3915 Weights: [0.35060598 2.13305577] , error: 0.4737478610797716\n",
      "Step: 3916 Weights: [0.35061866 2.13305432] , error: 0.47374784482144494\n",
      "Step: 3917 Weights: [0.3506313  2.13305288] , error: 0.4737478286371846\n",
      "Step: 3918 Weights: [0.35064392 2.13305143] , error: 0.4737478125266531\n",
      "Step: 3919 Weights: [0.35065651 2.13305   ] , error: 0.4737477964895169\n",
      "Step: 3920 Weights: [0.35066907 2.13304856] , error: 0.473747780525439\n",
      "Step: 3921 Weights: [0.3506816  2.13304713] , error: 0.47374776463408785\n",
      "Step: 3922 Weights: [0.3506941 2.1330457] , error: 0.4737477488151312\n",
      "Step: 3923 Weights: [0.35070658 2.13304427] , error: 0.47374773306824014\n",
      "Step: 3924 Weights: [0.35071903 2.13304285] , error: 0.47374771739308646\n",
      "Step: 3925 Weights: [0.35073144 2.13304143] , error: 0.4737477017893423\n",
      "Step: 3926 Weights: [0.35074383 2.13304001] , error: 0.4737476862566834\n",
      "Step: 3927 Weights: [0.35075619 2.13303859] , error: 0.4737476707947854\n",
      "Step: 3928 Weights: [0.35076853 2.13303718] , error: 0.47374765540332636\n",
      "Step: 3929 Weights: [0.35078083 2.13303578] , error: 0.47374764008198617\n",
      "Step: 3930 Weights: [0.35079311 2.13303437] , error: 0.47374762483044247\n",
      "Step: 3931 Weights: [0.35080536 2.13303297] , error: 0.47374760964838036\n",
      "Step: 3932 Weights: [0.35081758 2.13303157] , error: 0.4737475945354823\n",
      "Step: 3933 Weights: [0.35082977 2.13303018] , error: 0.47374757949143154\n",
      "Step: 3934 Weights: [0.35084194 2.13302879] , error: 0.47374756451591715\n",
      "Step: 3935 Weights: [0.35085407 2.1330274 ] , error: 0.47374754960862503\n",
      "Step: 3936 Weights: [0.35086618 2.13302602] , error: 0.4737475347692459\n",
      "Step: 3937 Weights: [0.35087826 2.13302463] , error: 0.4737475199974684\n",
      "Step: 3938 Weights: [0.35089032 2.13302326] , error: 0.47374750529298626\n",
      "Step: 3939 Weights: [0.35090235 2.13302188] , error: 0.47374749065549226\n",
      "Step: 3940 Weights: [0.35091435 2.13302051] , error: 0.4737474760846819\n",
      "Step: 3941 Weights: [0.35092632 2.13301914] , error: 0.4737474615802493\n",
      "Step: 3942 Weights: [0.35093826 2.13301777] , error: 0.4737474471418949\n",
      "Step: 3943 Weights: [0.35095018 2.13301641] , error: 0.4737474327693157\n",
      "Step: 3944 Weights: [0.35096207 2.13301505] , error: 0.47374741846221247\n",
      "Step: 3945 Weights: [0.35097393 2.13301369] , error: 0.4737474042202875\n",
      "Step: 3946 Weights: [0.35098577 2.13301234] , error: 0.4737473900432437\n",
      "Step: 3947 Weights: [0.35099758 2.13301099] , error: 0.4737473759307843\n",
      "Step: 3948 Weights: [0.35100936 2.13300964] , error: 0.4737473618826168\n",
      "Step: 3949 Weights: [0.35102112 2.1330083 ] , error: 0.4737473478984469\n",
      "Step: 3950 Weights: [0.35103285 2.13300696] , error: 0.4737473339779847\n",
      "Step: 3951 Weights: [0.35104455 2.13300562] , error: 0.4737473201209394\n",
      "Step: 3952 Weights: [0.35105622 2.13300428] , error: 0.4737473063270212\n",
      "Step: 3953 Weights: [0.35106787 2.13300295] , error: 0.47374729259594106\n",
      "Step: 3954 Weights: [0.3510795  2.13300162] , error: 0.47374727892741697\n",
      "Step: 3955 Weights: [0.35109109 2.13300029] , error: 0.4737472653211599\n",
      "Step: 3956 Weights: [0.35110266 2.13299897] , error: 0.4737472517768898\n",
      "Step: 3957 Weights: [0.3511142  2.13299765] , error: 0.47374723829432075\n",
      "Step: 3958 Weights: [0.35112572 2.13299633] , error: 0.4737472248731743\n",
      "Step: 3959 Weights: [0.35113721 2.13299502] , error: 0.47374721151317\n",
      "Step: 3960 Weights: [0.35114867 2.13299371] , error: 0.47374719821402766\n",
      "Step: 3961 Weights: [0.35116011 2.1329924 ] , error: 0.47374718497547197\n",
      "Step: 3962 Weights: [0.35117152 2.1329911 ] , error: 0.47374717179722614\n",
      "Step: 3963 Weights: [0.35118291 2.13298979] , error: 0.4737471586790164\n",
      "Step: 3964 Weights: [0.35119427 2.13298849] , error: 0.47374714562056686\n",
      "Step: 3965 Weights: [0.3512056 2.1329872] , error: 0.47374713262160784\n",
      "Step: 3966 Weights: [0.35121691 2.13298591] , error: 0.4737471196818672\n",
      "Step: 3967 Weights: [0.35122819 2.13298461] , error: 0.47374710680107396\n",
      "Step: 3968 Weights: [0.35123945 2.13298333] , error: 0.47374709397896286\n",
      "Step: 3969 Weights: [0.35125068 2.13298204] , error: 0.47374708121526354\n",
      "Step: 3970 Weights: [0.35126189 2.13298076] , error: 0.47374706850971104\n",
      "Step: 3971 Weights: [0.35127307 2.13297948] , error: 0.47374705586204013\n",
      "Step: 3972 Weights: [0.35128422 2.13297821] , error: 0.4737470432719873\n",
      "Step: 3973 Weights: [0.35129535 2.13297693] , error: 0.4737470307392899\n",
      "Step: 3974 Weights: [0.35130645 2.13297566] , error: 0.473747018263687\n",
      "Step: 3975 Weights: [0.35131753 2.1329744 ] , error: 0.4737470058449181\n",
      "Step: 3976 Weights: [0.35132858 2.13297313] , error: 0.4737469934827258\n",
      "Step: 3977 Weights: [0.35133961 2.13297187] , error: 0.47374698117685\n",
      "Step: 3978 Weights: [0.35135061 2.13297061] , error: 0.4737469689270356\n",
      "Step: 3979 Weights: [0.35136159 2.13296936] , error: 0.4737469567330266\n",
      "Step: 3980 Weights: [0.35137254 2.13296811] , error: 0.4737469445945703\n",
      "Step: 3981 Weights: [0.35138347 2.13296686] , error: 0.47374693251141053\n",
      "Step: 3982 Weights: [0.35139437 2.13296561] , error: 0.4737469204832972\n",
      "Step: 3983 Weights: [0.35140525 2.13296437] , error: 0.4737469085099807\n",
      "Step: 3984 Weights: [0.3514161  2.13296312] , error: 0.4737468965912084\n",
      "Step: 3985 Weights: [0.35142693 2.13296189] , error: 0.4737468847267352\n",
      "Step: 3986 Weights: [0.35143774 2.13296065] , error: 0.47374687291631223\n",
      "Step: 3987 Weights: [0.35144851 2.13295942] , error: 0.47374686115969256\n",
      "Step: 3988 Weights: [0.35145927 2.13295819] , error: 0.47374684945663137\n",
      "Step: 3989 Weights: [0.35147    2.13295696] , error: 0.47374683780688553\n",
      "Step: 3990 Weights: [0.3514807  2.13295574] , error: 0.47374682621021175\n",
      "Step: 3991 Weights: [0.35149138 2.13295452] , error: 0.47374681466636814\n",
      "Step: 3992 Weights: [0.35150204 2.1329533 ] , error: 0.47374680317511436\n",
      "Step: 3993 Weights: [0.35151267 2.13295208] , error: 0.47374679173620926\n",
      "Step: 3994 Weights: [0.35152328 2.13295087] , error: 0.4737467803494167\n",
      "Step: 3995 Weights: [0.35153386 2.13294966] , error: 0.47374676901449775\n",
      "Step: 3996 Weights: [0.35154442 2.13294845] , error: 0.473746757731217\n",
      "Step: 3997 Weights: [0.35155496 2.13294724] , error: 0.4737467464993378\n",
      "Step: 3998 Weights: [0.35156547 2.13294604] , error: 0.47374673531862654\n",
      "Step: 3999 Weights: [0.35157596 2.13294484] , error: 0.4737467241888518\n",
      "Step: 4000 Weights: [0.35158642 2.13294365] , error: 0.47374671310977984\n",
      "Step: 4001 Weights: [0.35159686 2.13294245] , error: 0.47374670208117914\n",
      "Step: 4002 Weights: [0.35160728 2.13294126] , error: 0.47374669110282197\n",
      "Step: 4003 Weights: [0.35161767 2.13294007] , error: 0.47374668017447724\n",
      "Step: 4004 Weights: [0.35162804 2.13293889] , error: 0.47374666929591824\n",
      "Step: 4005 Weights: [0.35163838 2.1329377 ] , error: 0.47374665846691805\n",
      "Step: 4006 Weights: [0.3516487  2.13293652] , error: 0.4737466476872516\n",
      "Step: 4007 Weights: [0.351659   2.13293535] , error: 0.4737466369566917\n",
      "Step: 4008 Weights: [0.35166927 2.13293417] , error: 0.47374662627501773\n",
      "Step: 4009 Weights: [0.35167953 2.132933  ] , error: 0.47374661564200465\n",
      "Step: 4010 Weights: [0.35168975 2.13293183] , error: 0.47374660505743194\n",
      "Step: 4011 Weights: [0.35169996 2.13293066] , error: 0.47374659452107826\n",
      "Step: 4012 Weights: [0.35171014 2.1329295 ] , error: 0.4737465840327249\n",
      "Step: 4013 Weights: [0.35172029 2.13292834] , error: 0.47374657359215244\n",
      "Step: 4014 Weights: [0.35173043 2.13292718] , error: 0.47374656319914304\n",
      "Step: 4015 Weights: [0.35174054 2.13292602] , error: 0.4737465528534798\n",
      "Step: 4016 Weights: [0.35175063 2.13292487] , error: 0.4737465425549484\n",
      "Step: 4017 Weights: [0.35176069 2.13292372] , error: 0.47374653230333313\n",
      "Step: 4018 Weights: [0.35177074 2.13292257] , error: 0.4737465220984208\n",
      "Step: 4019 Weights: [0.35178076 2.13292142] , error: 0.4737465119399971\n",
      "Step: 4020 Weights: [0.35179075 2.13292028] , error: 0.4737465018278536\n",
      "Step: 4021 Weights: [0.35180073 2.13291914] , error: 0.473746491761775\n",
      "Step: 4022 Weights: [0.35181068 2.132918  ] , error: 0.47374648174155576\n",
      "Step: 4023 Weights: [0.3518206  2.13291686] , error: 0.4737464717669829\n",
      "Step: 4024 Weights: [0.35183051 2.13291573] , error: 0.47374646183785185\n",
      "Step: 4025 Weights: [0.35184039 2.1329146 ] , error: 0.47374645195395376\n",
      "Step: 4026 Weights: [0.35185025 2.13291347] , error: 0.47374644211508404\n",
      "Step: 4027 Weights: [0.35186009 2.13291235] , error: 0.47374643232103536\n",
      "Step: 4028 Weights: [0.35186991 2.13291123] , error: 0.4737464225716044\n",
      "Step: 4029 Weights: [0.3518797  2.13291011] , error: 0.47374641286658986\n",
      "Step: 4030 Weights: [0.35188947 2.13290899] , error: 0.4737464032057865\n",
      "Step: 4031 Weights: [0.35189922 2.13290787] , error: 0.4737463935889949\n",
      "Step: 4032 Weights: [0.35190895 2.13290676] , error: 0.47374638401601354\n",
      "Step: 4033 Weights: [0.35191865 2.13290565] , error: 0.47374637448664303\n",
      "Step: 4034 Weights: [0.35192833 2.13290454] , error: 0.4737463650006847\n",
      "Step: 4035 Weights: [0.35193799 2.13290344] , error: 0.47374635555794126\n",
      "Step: 4036 Weights: [0.35194763 2.13290234] , error: 0.4737463461582149\n",
      "Step: 4037 Weights: [0.35195725 2.13290124] , error: 0.47374633680131173\n",
      "Step: 4038 Weights: [0.35196684 2.13290014] , error: 0.47374632748703344\n",
      "Step: 4039 Weights: [0.35197641 2.13289905] , error: 0.4737463182151882\n",
      "Step: 4040 Weights: [0.35198596 2.13289795] , error: 0.473746308985582\n",
      "Step: 4041 Weights: [0.35199549 2.13289686] , error: 0.4737462997980229\n",
      "Step: 4042 Weights: [0.352005   2.13289578] , error: 0.4737462906523186\n",
      "Step: 4043 Weights: [0.35201448 2.13289469] , error: 0.473746281548279\n",
      "Step: 4044 Weights: [0.35202395 2.13289361] , error: 0.4737462724857133\n",
      "Step: 4045 Weights: [0.35203339 2.13289253] , error: 0.4737462634644342\n",
      "Step: 4046 Weights: [0.35204281 2.13289145] , error: 0.4737462544842518\n",
      "Step: 4047 Weights: [0.35205221 2.13289038] , error: 0.4737462455449809\n",
      "Step: 4048 Weights: [0.35206159 2.1328893 ] , error: 0.47374623664643284\n",
      "Step: 4049 Weights: [0.35207094 2.13288823] , error: 0.4737462277884233\n",
      "Step: 4050 Weights: [0.35208028 2.13288717] , error: 0.47374621897076885\n",
      "Step: 4051 Weights: [0.35208959 2.1328861 ] , error: 0.473746210193284\n",
      "Step: 4052 Weights: [0.35209888 2.13288504] , error: 0.4737462014557848\n",
      "Step: 4053 Weights: [0.35210815 2.13288398] , error: 0.4737461927580913\n",
      "Step: 4054 Weights: [0.3521174  2.13288292] , error: 0.47374618410002195\n",
      "Step: 4055 Weights: [0.35212663 2.13288187] , error: 0.4737461754813947\n",
      "Step: 4056 Weights: [0.35213584 2.13288081] , error: 0.4737461669020304\n",
      "Step: 4057 Weights: [0.35214503 2.13287976] , error: 0.4737461583617519\n",
      "Step: 4058 Weights: [0.35215419 2.13287871] , error: 0.47374614986037833\n",
      "Step: 4059 Weights: [0.35216334 2.13287767] , error: 0.4737461413977344\n",
      "Step: 4060 Weights: [0.35217246 2.13287662] , error: 0.47374613297364465\n",
      "Step: 4061 Weights: [0.35218156 2.13287558] , error: 0.4737461245879302\n",
      "Step: 4062 Weights: [0.35219065 2.13287454] , error: 0.4737461162404175\n",
      "Step: 4063 Weights: [0.35219971 2.13287351] , error: 0.4737461079309336\n",
      "Step: 4064 Weights: [0.35220875 2.13287247] , error: 0.47374609965930603\n",
      "Step: 4065 Weights: [0.35221777 2.13287144] , error: 0.47374609142535956\n",
      "Step: 4066 Weights: [0.35222677 2.13287041] , error: 0.473746083228924\n",
      "Step: 4067 Weights: [0.35223575 2.13286939] , error: 0.4737460750698286\n",
      "Step: 4068 Weights: [0.35224471 2.13286836] , error: 0.47374606694790306\n",
      "Step: 4069 Weights: [0.35225365 2.13286734] , error: 0.47374605886297727\n",
      "Step: 4070 Weights: [0.35226257 2.13286632] , error: 0.47374605081488463\n",
      "Step: 4071 Weights: [0.35227146 2.1328653 ] , error: 0.47374604280345445\n",
      "Step: 4072 Weights: [0.35228034 2.13286429] , error: 0.4737460348285231\n",
      "Step: 4073 Weights: [0.3522892  2.13286327] , error: 0.47374602688992185\n",
      "Step: 4074 Weights: [0.35229803 2.13286226] , error: 0.4737460189874856\n",
      "Step: 4075 Weights: [0.35230685 2.13286125] , error: 0.47374601112105075\n",
      "Step: 4076 Weights: [0.35231565 2.13286025] , error: 0.4737460032904518\n",
      "Step: 4077 Weights: [0.35232442 2.13285925] , error: 0.47374599549552693\n",
      "Step: 4078 Weights: [0.35233318 2.13285824] , error: 0.47374598773611254\n",
      "Step: 4079 Weights: [0.35234192 2.13285724] , error: 0.4737459800120461\n",
      "Step: 4080 Weights: [0.35235064 2.13285625] , error: 0.4737459723231683\n",
      "Step: 4081 Weights: [0.35235933 2.13285525] , error: 0.47374596466931956\n",
      "Step: 4082 Weights: [0.35236801 2.13285426] , error: 0.47374595705033684\n",
      "Step: 4083 Weights: [0.35237667 2.13285327] , error: 0.47374594946606413\n",
      "Step: 4084 Weights: [0.3523853  2.13285228] , error: 0.47374594191634356\n",
      "Step: 4085 Weights: [0.35239392 2.1328513 ] , error: 0.4737459344010163\n",
      "Step: 4086 Weights: [0.35240252 2.13285031] , error: 0.4737459269199256\n",
      "Step: 4087 Weights: [0.3524111  2.13284933] , error: 0.47374591947291544\n",
      "Step: 4088 Weights: [0.35241966 2.13284835] , error: 0.4737459120598322\n",
      "Step: 4089 Weights: [0.3524282  2.13284738] , error: 0.47374590468051997\n",
      "Step: 4090 Weights: [0.35243672 2.1328464 ] , error: 0.47374589733482597\n",
      "Step: 4091 Weights: [0.35244522 2.13284543] , error: 0.4737458900225946\n",
      "Step: 4092 Weights: [0.3524537  2.13284446] , error: 0.473745882743675\n",
      "Step: 4093 Weights: [0.35246216 2.13284349] , error: 0.4737458754979167\n",
      "Step: 4094 Weights: [0.3524706  2.13284253] , error: 0.4737458682851661\n",
      "Step: 4095 Weights: [0.35247903 2.13284156] , error: 0.47374586110527495\n",
      "Step: 4096 Weights: [0.35248743 2.1328406 ] , error: 0.4737458539580939\n",
      "Step: 4097 Weights: [0.35249582 2.13283964] , error: 0.473745846843471\n",
      "Step: 4098 Weights: [0.35250418 2.13283869] , error: 0.47374583976126056\n",
      "Step: 4099 Weights: [0.35251253 2.13283773] , error: 0.47374583271131304\n",
      "Step: 4100 Weights: [0.35252086 2.13283678] , error: 0.4737458256934836\n",
      "Step: 4101 Weights: [0.35252917 2.13283583] , error: 0.47374581870762417\n",
      "Step: 4102 Weights: [0.35253746 2.13283488] , error: 0.4737458117535904\n",
      "Step: 4103 Weights: [0.35254573 2.13283394] , error: 0.47374580483123635\n",
      "Step: 4104 Weights: [0.35255398 2.13283299] , error: 0.47374579794041727\n",
      "Step: 4105 Weights: [0.35256221 2.13283205] , error: 0.4737457910809909\n",
      "Step: 4106 Weights: [0.35257043 2.13283111] , error: 0.4737457842528141\n",
      "Step: 4107 Weights: [0.35257862 2.13283017] , error: 0.47374577745574203\n",
      "Step: 4108 Weights: [0.3525868  2.13282924] , error: 0.473745770689637\n",
      "Step: 4109 Weights: [0.35259496 2.13282831] , error: 0.47374576395435475\n",
      "Step: 4110 Weights: [0.3526031  2.13282738] , error: 0.4737457572497569\n",
      "Step: 4111 Weights: [0.35261122 2.13282645] , error: 0.4737457505757018\n",
      "Step: 4112 Weights: [0.35261932 2.13282552] , error: 0.4737457439320518\n",
      "Step: 4113 Weights: [0.3526274 2.1328246] , error: 0.4737457373186666\n",
      "Step: 4114 Weights: [0.35263547 2.13282367] , error: 0.47374573073541043\n",
      "Step: 4115 Weights: [0.35264352 2.13282275] , error: 0.4737457241821449\n",
      "Step: 4116 Weights: [0.35265155 2.13282183] , error: 0.4737457176587349\n",
      "Step: 4117 Weights: [0.35265956 2.13282092] , error: 0.47374571116504194\n",
      "Step: 4118 Weights: [0.35266755 2.13282   ] , error: 0.4737457047009313\n",
      "Step: 4119 Weights: [0.35267552 2.13281909] , error: 0.4737456982662691\n",
      "Step: 4120 Weights: [0.35268348 2.13281818] , error: 0.47374569186092147\n",
      "Step: 4121 Weights: [0.35269142 2.13281727] , error: 0.47374568548475493\n",
      "Step: 4122 Weights: [0.35269934 2.13281637] , error: 0.4737456791376343\n",
      "Step: 4123 Weights: [0.35270724 2.13281546] , error: 0.47374567281942975\n",
      "Step: 4124 Weights: [0.35271512 2.13281456] , error: 0.47374566653000844\n",
      "Step: 4125 Weights: [0.35272299 2.13281366] , error: 0.47374566026923837\n",
      "Step: 4126 Weights: [0.35273084 2.13281277] , error: 0.47374565403699165\n",
      "Step: 4127 Weights: [0.35273867 2.13281187] , error: 0.47374564783313633\n",
      "Step: 4128 Weights: [0.35274648 2.13281098] , error: 0.4737456416575426\n",
      "Step: 4129 Weights: [0.35275427 2.13281009] , error: 0.4737456355100829\n",
      "Step: 4130 Weights: [0.35276205 2.1328092 ] , error: 0.47374562939062864\n",
      "Step: 4131 Weights: [0.35276981 2.13280831] , error: 0.47374562329905356\n",
      "Step: 4132 Weights: [0.35277755 2.13280742] , error: 0.47374561723522807\n",
      "Step: 4133 Weights: [0.35278527 2.13280654] , error: 0.47374561119902736\n",
      "Step: 4134 Weights: [0.35279298 2.13280566] , error: 0.4737456051903269\n",
      "Step: 4135 Weights: [0.35280067 2.13280478] , error: 0.4737455992089982\n",
      "Step: 4136 Weights: [0.35280834 2.1328039 ] , error: 0.4737455932549184\n",
      "Step: 4137 Weights: [0.35281599 2.13280303] , error: 0.47374558732796385\n",
      "Step: 4138 Weights: [0.35282363 2.13280215] , error: 0.4737455814280092\n",
      "Step: 4139 Weights: [0.35283124 2.13280128] , error: 0.4737455755549336\n",
      "Step: 4140 Weights: [0.35283885 2.13280041] , error: 0.4737455697086133\n",
      "Step: 4141 Weights: [0.35284643 2.13279955] , error: 0.4737455638889266\n",
      "Step: 4142 Weights: [0.352854   2.13279868] , error: 0.47374555809575236\n",
      "Step: 4143 Weights: [0.35286154 2.13279782] , error: 0.473745552328969\n",
      "Step: 4144 Weights: [0.35286908 2.13279696] , error: 0.4737455465884575\n",
      "Step: 4145 Weights: [0.35287659 2.1327961 ] , error: 0.47374554087409815\n",
      "Step: 4146 Weights: [0.35288409 2.13279524] , error: 0.4737455351857711\n",
      "Step: 4147 Weights: [0.35289157 2.13279438] , error: 0.473745529523357\n",
      "Step: 4148 Weights: [0.35289903 2.13279353] , error: 0.47374552388673974\n",
      "Step: 4149 Weights: [0.35290648 2.13279268] , error: 0.4737455182758012\n",
      "Step: 4150 Weights: [0.35291391 2.13279183] , error: 0.47374551269042253\n",
      "Step: 4151 Weights: [0.35292132 2.13279098] , error: 0.47374550713048963\n",
      "Step: 4152 Weights: [0.35292872 2.13279014] , error: 0.4737455015958859\n",
      "Step: 4153 Weights: [0.3529361  2.13278929] , error: 0.4737454960864953\n",
      "Step: 4154 Weights: [0.35294346 2.13278845] , error: 0.47374549060220394\n",
      "Step: 4155 Weights: [0.3529508  2.13278761] , error: 0.47374548514289694\n",
      "Step: 4156 Weights: [0.35295813 2.13278677] , error: 0.47374547970846037\n",
      "Step: 4157 Weights: [0.35296544 2.13278594] , error: 0.4737454742987811\n",
      "Step: 4158 Weights: [0.35297274 2.1327851 ] , error: 0.47374546891374725\n",
      "Step: 4159 Weights: [0.35298002 2.13278427] , error: 0.4737454635532447\n",
      "Step: 4160 Weights: [0.35298728 2.13278344] , error: 0.4737454582171617\n",
      "Step: 4161 Weights: [0.35299452 2.13278261] , error: 0.47374545290538983\n",
      "Step: 4162 Weights: [0.35300175 2.13278178] , error: 0.47374544761781545\n",
      "Step: 4163 Weights: [0.35300896 2.13278096] , error: 0.47374544235432836\n",
      "Step: 4164 Weights: [0.35301616 2.13278014] , error: 0.4737454371148211\n",
      "Step: 4165 Weights: [0.35302334 2.13277931] , error: 0.47374543189918333\n",
      "Step: 4166 Weights: [0.3530305 2.1327785] , error: 0.4737454267073051\n",
      "Step: 4167 Weights: [0.35303765 2.13277768] , error: 0.47374542153907984\n",
      "Step: 4168 Weights: [0.35304478 2.13277686] , error: 0.47374541639439827\n",
      "Step: 4169 Weights: [0.35305189 2.13277605] , error: 0.47374541127315467\n",
      "Step: 4170 Weights: [0.35305899 2.13277524] , error: 0.4737454061752406\n",
      "Step: 4171 Weights: [0.35306607 2.13277443] , error: 0.47374540110055247\n",
      "Step: 4172 Weights: [0.35307314 2.13277362] , error: 0.4737453960489811\n",
      "Step: 4173 Weights: [0.35308019 2.13277281] , error: 0.47374539102042384\n",
      "Step: 4174 Weights: [0.35308722 2.13277201] , error: 0.4737453860147745\n",
      "Step: 4175 Weights: [0.35309424 2.13277121] , error: 0.47374538103192865\n",
      "Step: 4176 Weights: [0.35310124 2.13277041] , error: 0.47374537607178335\n",
      "Step: 4177 Weights: [0.35310822 2.13276961] , error: 0.47374537113423487\n",
      "Step: 4178 Weights: [0.35311519 2.13276881] , error: 0.4737453662191802\n",
      "Step: 4179 Weights: [0.35312215 2.13276801] , error: 0.47374536132651607\n",
      "Step: 4180 Weights: [0.35312908 2.13276722] , error: 0.47374535645614124\n",
      "Step: 4181 Weights: [0.353136   2.13276643] , error: 0.47374535160795356\n",
      "Step: 4182 Weights: [0.35314291 2.13276564] , error: 0.4737453467818532\n",
      "Step: 4183 Weights: [0.3531498  2.13276485] , error: 0.4737453419777381\n",
      "Step: 4184 Weights: [0.35315668 2.13276407] , error: 0.4737453371955088\n",
      "Step: 4185 Weights: [0.35316353 2.13276328] , error: 0.47374533243506595\n",
      "Step: 4186 Weights: [0.35317038 2.1327625 ] , error: 0.47374532769631045\n",
      "Step: 4187 Weights: [0.3531772  2.13276172] , error: 0.4737453229791432\n",
      "Step: 4188 Weights: [0.35318402 2.13276094] , error: 0.47374531828346345\n",
      "Step: 4189 Weights: [0.35319081 2.13276016] , error: 0.47374531360917765\n",
      "Step: 4190 Weights: [0.35319759 2.13275939] , error: 0.4737453089561852\n",
      "Step: 4191 Weights: [0.35320436 2.13275861] , error: 0.4737453043243901\n",
      "Step: 4192 Weights: [0.35321111 2.13275784] , error: 0.4737452997136958\n",
      "Step: 4193 Weights: [0.35321784 2.13275707] , error: 0.4737452951240066\n",
      "Step: 4194 Weights: [0.35322456 2.1327563 ] , error: 0.47374529055522546\n",
      "Step: 4195 Weights: [0.35323127 2.13275553] , error: 0.4737452860072582\n",
      "Step: 4196 Weights: [0.35323796 2.13275477] , error: 0.4737452814800099\n",
      "Step: 4197 Weights: [0.35324463 2.13275401] , error: 0.47374527697338664\n",
      "Step: 4198 Weights: [0.35325129 2.13275325] , error: 0.4737452724872931\n",
      "Step: 4199 Weights: [0.35325793 2.13275249] , error: 0.47374526802163736\n",
      "Step: 4200 Weights: [0.35326456 2.13275173] , error: 0.47374526357632557\n",
      "Step: 4201 Weights: [0.35327117 2.13275097] , error: 0.47374525915126336\n",
      "Step: 4202 Weights: [0.35327777 2.13275022] , error: 0.4737452547463618\n",
      "Step: 4203 Weights: [0.35328435 2.13274946] , error: 0.4737452503615263\n",
      "Step: 4204 Weights: [0.35329092 2.13274871] , error: 0.47374524599666723\n",
      "Step: 4205 Weights: [0.35329747 2.13274796] , error: 0.47374524165169246\n",
      "Step: 4206 Weights: [0.35330401 2.13274722] , error: 0.47374523732651175\n",
      "Step: 4207 Weights: [0.35331053 2.13274647] , error: 0.47374523302103505\n",
      "Step: 4208 Weights: [0.35331704 2.13274573] , error: 0.47374522873517305\n",
      "Step: 4209 Weights: [0.35332353 2.13274498] , error: 0.4737452244688356\n",
      "Step: 4210 Weights: [0.35333001 2.13274424] , error: 0.473745220221934\n",
      "Step: 4211 Weights: [0.35333648 2.1327435 ] , error: 0.4737452159943783\n",
      "Step: 4212 Weights: [0.35334293 2.13274277] , error: 0.4737452117860834\n",
      "Step: 4213 Weights: [0.35334936 2.13274203] , error: 0.4737452075969595\n",
      "Step: 4214 Weights: [0.35335578 2.1327413 ] , error: 0.4737452034269199\n",
      "Step: 4215 Weights: [0.35336218 2.13274056] , error: 0.4737451992758774\n",
      "Step: 4216 Weights: [0.35336857 2.13273983] , error: 0.473745195143745\n",
      "Step: 4217 Weights: [0.35337495 2.1327391 ] , error: 0.47374519103043755\n",
      "Step: 4218 Weights: [0.35338131 2.13273838] , error: 0.47374518693586853\n",
      "Step: 4219 Weights: [0.35338766 2.13273765] , error: 0.4737451828599534\n",
      "Step: 4220 Weights: [0.35339399 2.13273693] , error: 0.4737451788026058\n",
      "Step: 4221 Weights: [0.35340031 2.1327362 ] , error: 0.47374517476374217\n",
      "Step: 4222 Weights: [0.35340661 2.13273548] , error: 0.47374517074327915\n",
      "Step: 4223 Weights: [0.3534129  2.13273476] , error: 0.4737451667411311\n",
      "Step: 4224 Weights: [0.35341917 2.13273405] , error: 0.4737451627572154\n",
      "Step: 4225 Weights: [0.35342543 2.13273333] , error: 0.4737451587914486\n",
      "Step: 4226 Weights: [0.35343168 2.13273261] , error: 0.47374515484374935\n",
      "Step: 4227 Weights: [0.35343791 2.1327319 ] , error: 0.4737451509140338\n",
      "Step: 4228 Weights: [0.35344413 2.13273119] , error: 0.47374514700221976\n",
      "Step: 4229 Weights: [0.35345033 2.13273048] , error: 0.47374514310822746\n",
      "Step: 4230 Weights: [0.35345652 2.13272977] , error: 0.47374513923197437\n",
      "Step: 4231 Weights: [0.3534627  2.13272907] , error: 0.4737451353733806\n",
      "Step: 4232 Weights: [0.35346886 2.13272836] , error: 0.47374513153236464\n",
      "Step: 4233 Weights: [0.353475   2.13272766] , error: 0.4737451277088469\n",
      "Step: 4234 Weights: [0.35348114 2.13272696] , error: 0.4737451239027477\n",
      "Step: 4235 Weights: [0.35348726 2.13272626] , error: 0.4737451201139876\n",
      "Step: 4236 Weights: [0.35349336 2.13272556] , error: 0.4737451163424876\n",
      "Step: 4237 Weights: [0.35349945 2.13272486] , error: 0.4737451125881705\n",
      "Step: 4238 Weights: [0.35350553 2.13272417] , error: 0.4737451088509558\n",
      "Step: 4239 Weights: [0.35351159 2.13272348] , error: 0.4737451051307662\n",
      "Step: 4240 Weights: [0.35351764 2.13272278] , error: 0.473745101427524\n",
      "Step: 4241 Weights: [0.35352368 2.13272209] , error: 0.4737450977411534\n",
      "Step: 4242 Weights: [0.3535297 2.1327214] , error: 0.47374509407157595\n",
      "Step: 4243 Weights: [0.35353571 2.13272072] , error: 0.47374509041871604\n",
      "Step: 4244 Weights: [0.3535417  2.13272003] , error: 0.4737450867824969\n",
      "Step: 4245 Weights: [0.35354768 2.13271935] , error: 0.47374508316284325\n",
      "Step: 4246 Weights: [0.35355365 2.13271867] , error: 0.47374507955967865\n",
      "Step: 4247 Weights: [0.3535596  2.13271798] , error: 0.47374507597292925\n",
      "Step: 4248 Weights: [0.35356554 2.13271731] , error: 0.47374507240252095\n",
      "Step: 4249 Weights: [0.35357147 2.13271663] , error: 0.4737450688483762\n",
      "Step: 4250 Weights: [0.35357738 2.13271595] , error: 0.4737450653104239\n",
      "Step: 4251 Weights: [0.35358328 2.13271528] , error: 0.473745061788589\n",
      "Step: 4252 Weights: [0.35358917 2.1327146 ] , error: 0.4737450582827992\n",
      "Step: 4253 Weights: [0.35359504 2.13271393] , error: 0.47374505479297946\n",
      "Step: 4254 Weights: [0.3536009  2.13271326] , error: 0.47374505131905814\n",
      "Step: 4255 Weights: [0.35360675 2.13271259] , error: 0.47374504786096205\n",
      "Step: 4256 Weights: [0.35361258 2.13271193] , error: 0.4737450444186201\n",
      "Step: 4257 Weights: [0.3536184  2.13271126] , error: 0.47374504099196074\n",
      "Step: 4258 Weights: [0.3536242 2.1327106] , error: 0.4737450375809118\n",
      "Step: 4259 Weights: [0.35363    2.13270993] , error: 0.47374503418540226\n",
      "Step: 4260 Weights: [0.35363578 2.13270927] , error: 0.47374503080536207\n",
      "Step: 4261 Weights: [0.35364154 2.13270861] , error: 0.47374502744071945\n",
      "Step: 4262 Weights: [0.35364729 2.13270796] , error: 0.4737450240914044\n",
      "Step: 4263 Weights: [0.35365303 2.1327073 ] , error: 0.47374502075734815\n",
      "Step: 4264 Weights: [0.35365876 2.13270664] , error: 0.4737450174384806\n",
      "Step: 4265 Weights: [0.35366448 2.13270599] , error: 0.4737450141347328\n",
      "Step: 4266 Weights: [0.35367018 2.13270534] , error: 0.47374501084603565\n",
      "Step: 4267 Weights: [0.35367586 2.13270469] , error: 0.47374500757231996\n",
      "Step: 4268 Weights: [0.35368154 2.13270404] , error: 0.4737450043135194\n",
      "Step: 4269 Weights: [0.3536872  2.13270339] , error: 0.4737450010695632\n",
      "Step: 4270 Weights: [0.35369285 2.13270275] , error: 0.4737449978403855\n",
      "Step: 4271 Weights: [0.35369849 2.1327021 ] , error: 0.47374499462592\n",
      "Step: 4272 Weights: [0.35370411 2.13270146] , error: 0.47374499142609683\n",
      "Step: 4273 Weights: [0.35370972 2.13270082] , error: 0.473744988240852\n",
      "Step: 4274 Weights: [0.35371532 2.13270018] , error: 0.473744985070117\n",
      "Step: 4275 Weights: [0.3537209  2.13269954] , error: 0.4737449819138283\n",
      "Step: 4276 Weights: [0.35372647 2.1326989 ] , error: 0.4737449787719172\n",
      "Step: 4277 Weights: [0.35373203 2.13269827] , error: 0.47374497564432033\n",
      "Step: 4278 Weights: [0.35373758 2.13269763] , error: 0.47374497253097025\n",
      "Step: 4279 Weights: [0.35374311 2.132697  ] , error: 0.4737449694318042\n",
      "Step: 4280 Weights: [0.35374864 2.13269637] , error: 0.4737449663467566\n",
      "Step: 4281 Weights: [0.35375415 2.13269574] , error: 0.4737449632757643\n",
      "Step: 4282 Weights: [0.35375964 2.13269511] , error: 0.47374496021876167\n",
      "Step: 4283 Weights: [0.35376513 2.13269448] , error: 0.47374495717568554\n",
      "Step: 4284 Weights: [0.3537706  2.13269385] , error: 0.4737449541464727\n",
      "Step: 4285 Weights: [0.35377606 2.13269323] , error: 0.4737449511310594\n",
      "Step: 4286 Weights: [0.3537815  2.13269261] , error: 0.47374494812938417\n",
      "Step: 4287 Weights: [0.35378694 2.13269199] , error: 0.4737449451413822\n",
      "Step: 4288 Weights: [0.35379236 2.13269137] , error: 0.47374494216699276\n",
      "Step: 4289 Weights: [0.35379777 2.13269075] , error: 0.473744939206154\n",
      "Step: 4290 Weights: [0.35380316 2.13269013] , error: 0.473744936258804\n",
      "Step: 4291 Weights: [0.35380855 2.13268951] , error: 0.4737449333248809\n",
      "Step: 4292 Weights: [0.35381392 2.1326889 ] , error: 0.4737449304043224\n",
      "Step: 4293 Weights: [0.35381928 2.13268829] , error: 0.47374492749707\n",
      "Step: 4294 Weights: [0.35382463 2.13268768] , error: 0.4737449246030615\n",
      "Step: 4295 Weights: [0.35382996 2.13268707] , error: 0.47374492172223803\n",
      "Step: 4296 Weights: [0.35383529 2.13268646] , error: 0.47374491885453757\n",
      "Step: 4297 Weights: [0.3538406  2.13268585] , error: 0.47374491599990187\n",
      "Step: 4298 Weights: [0.3538459  2.13268524] , error: 0.4737449131582707\n",
      "Step: 4299 Weights: [0.35385118 2.13268464] , error: 0.473744910329584\n",
      "Step: 4300 Weights: [0.35385646 2.13268404] , error: 0.47374490751378495\n",
      "Step: 4301 Weights: [0.35386172 2.13268343] , error: 0.47374490471081365\n",
      "Step: 4302 Weights: [0.35386697 2.13268283] , error: 0.4737449019206107\n",
      "Step: 4303 Weights: [0.35387221 2.13268223] , error: 0.4737448991431201\n",
      "Step: 4304 Weights: [0.35387744 2.13268164] , error: 0.47374489637828127\n",
      "Step: 4305 Weights: [0.35388266 2.13268104] , error: 0.4737448936260392\n",
      "Step: 4306 Weights: [0.35388786 2.13268044] , error: 0.47374489088633526\n",
      "Step: 4307 Weights: [0.35389305 2.13267985] , error: 0.47374488815911164\n",
      "Step: 4308 Weights: [0.35389823 2.13267926] , error: 0.47374488544431265\n",
      "Step: 4309 Weights: [0.3539034  2.13267867] , error: 0.47374488274188115\n",
      "Step: 4310 Weights: [0.35390855 2.13267808] , error: 0.47374488005176196\n",
      "Step: 4311 Weights: [0.3539137  2.13267749] , error: 0.47374487737389703\n",
      "Step: 4312 Weights: [0.35391883 2.1326769 ] , error: 0.4737448747082311\n",
      "Step: 4313 Weights: [0.35392395 2.13267632] , error: 0.47374487205470983\n",
      "Step: 4314 Weights: [0.35392906 2.13267573] , error: 0.4737448694132754\n",
      "Step: 4315 Weights: [0.35393416 2.13267515] , error: 0.4737448667838764\n",
      "Step: 4316 Weights: [0.35393924 2.13267457] , error: 0.4737448641664551\n",
      "Step: 4317 Weights: [0.35394432 2.13267399] , error: 0.47374486156095813\n",
      "Step: 4318 Weights: [0.35394938 2.13267341] , error: 0.47374485896733026\n",
      "Step: 4319 Weights: [0.35395443 2.13267283] , error: 0.4737448563855176\n",
      "Step: 4320 Weights: [0.35395947 2.13267225] , error: 0.4737448538154679\n",
      "Step: 4321 Weights: [0.3539645  2.13267168] , error: 0.4737448512571262\n",
      "Step: 4322 Weights: [0.35396952 2.13267111] , error: 0.47374484871043804\n",
      "Step: 4323 Weights: [0.35397452 2.13267053] , error: 0.47374484617535256\n",
      "Step: 4324 Weights: [0.35397951 2.13266996] , error: 0.47374484365181646\n",
      "Step: 4325 Weights: [0.3539845  2.13266939] , error: 0.4737448411397766\n",
      "Step: 4326 Weights: [0.35398947 2.13266882] , error: 0.47374483863917993\n",
      "Step: 4327 Weights: [0.35399443 2.13266826] , error: 0.4737448361499759\n",
      "Step: 4328 Weights: [0.35399938 2.13266769] , error: 0.4737448336721112\n",
      "Step: 4329 Weights: [0.35400431 2.13266713] , error: 0.47374483120553484\n",
      "Step: 4330 Weights: [0.35400924 2.13266656] , error: 0.47374482875019486\n",
      "Step: 4331 Weights: [0.35401415 2.132666  ] , error: 0.4737448263060414\n",
      "Step: 4332 Weights: [0.35401906 2.13266544] , error: 0.47374482387302264\n",
      "Step: 4333 Weights: [0.35402395 2.13266488] , error: 0.473744821451087\n",
      "Step: 4334 Weights: [0.35402883 2.13266432] , error: 0.4737448190401851\n",
      "Step: 4335 Weights: [0.3540337  2.13266377] , error: 0.47374481664026624\n",
      "Step: 4336 Weights: [0.35403856 2.13266321] , error: 0.47374481425128045\n",
      "Step: 4337 Weights: [0.35404341 2.13266266] , error: 0.4737448118731788\n",
      "Step: 4338 Weights: [0.35404824 2.1326621 ] , error: 0.4737448095059111\n",
      "Step: 4339 Weights: [0.35405307 2.13266155] , error: 0.4737448071494258\n",
      "Step: 4340 Weights: [0.35405788 2.132661  ] , error: 0.47374480480367703\n",
      "Step: 4341 Weights: [0.35406269 2.13266045] , error: 0.4737448024686149\n",
      "Step: 4342 Weights: [0.35406748 2.1326599 ] , error: 0.47374480014419074\n",
      "Step: 4343 Weights: [0.35407226 2.13265936] , error: 0.47374479783035484\n",
      "Step: 4344 Weights: [0.35407703 2.13265881] , error: 0.47374479552706045\n",
      "Step: 4345 Weights: [0.35408179 2.13265827] , error: 0.4737447932342589\n",
      "Step: 4346 Weights: [0.35408654 2.13265772] , error: 0.4737447909519032\n",
      "Step: 4347 Weights: [0.35409128 2.13265718] , error: 0.47374478867994363\n",
      "Step: 4348 Weights: [0.35409601 2.13265664] , error: 0.47374478641833506\n",
      "Step: 4349 Weights: [0.35410073 2.1326561 ] , error: 0.4737447841670296\n",
      "Step: 4350 Weights: [0.35410543 2.13265556] , error: 0.47374478192597996\n",
      "Step: 4351 Weights: [0.35411013 2.13265502] , error: 0.47374477969513984\n",
      "Step: 4352 Weights: [0.35411481 2.13265449] , error: 0.473744777474463\n",
      "Step: 4353 Weights: [0.35411948 2.13265395] , error: 0.4737447752639022\n",
      "Step: 4354 Weights: [0.35412415 2.13265342] , error: 0.4737447730634121\n",
      "Step: 4355 Weights: [0.3541288  2.13265289] , error: 0.47374477087294653\n",
      "Step: 4356 Weights: [0.35413344 2.13265236] , error: 0.4737447686924598\n",
      "Step: 4357 Weights: [0.35413807 2.13265183] , error: 0.47374476652190717\n",
      "Step: 4358 Weights: [0.35414269 2.1326513 ] , error: 0.47374476436124163\n",
      "Step: 4359 Weights: [0.35414731 2.13265077] , error: 0.4737447622104203\n",
      "Step: 4360 Weights: [0.35415191 2.13265025] , error: 0.47374476006939736\n",
      "Step: 4361 Weights: [0.35415649 2.13264972] , error: 0.47374475793812754\n",
      "Step: 4362 Weights: [0.35416107 2.1326492 ] , error: 0.4737447558165675\n",
      "Step: 4363 Weights: [0.35416564 2.13264868] , error: 0.47374475370467206\n",
      "Step: 4364 Weights: [0.3541702  2.13264815] , error: 0.47374475160239793\n",
      "Step: 4365 Weights: [0.35417475 2.13264763] , error: 0.4737447495097009\n",
      "Step: 4366 Weights: [0.35417928 2.13264712] , error: 0.4737447474265373\n",
      "Step: 4367 Weights: [0.35418381 2.1326466 ] , error: 0.4737447453528641\n",
      "Step: 4368 Weights: [0.35418833 2.13264608] , error: 0.4737447432886379\n",
      "Step: 4369 Weights: [0.35419283 2.13264557] , error: 0.4737447412338156\n",
      "Step: 4370 Weights: [0.35419733 2.13264505] , error: 0.47374473918835314\n",
      "Step: 4371 Weights: [0.35420182 2.13264454] , error: 0.4737447371522102\n",
      "Step: 4372 Weights: [0.35420629 2.13264403] , error: 0.47374473512534276\n",
      "Step: 4373 Weights: [0.35421076 2.13264352] , error: 0.4737447331077095\n",
      "Step: 4374 Weights: [0.35421521 2.13264301] , error: 0.4737447310992667\n",
      "Step: 4375 Weights: [0.35421966 2.1326425 ] , error: 0.4737447290999756\n",
      "Step: 4376 Weights: [0.35422409 2.13264199] , error: 0.4737447271097901\n",
      "Step: 4377 Weights: [0.35422852 2.13264149] , error: 0.47374472512867294\n",
      "Step: 4378 Weights: [0.35423293 2.13264098] , error: 0.47374472315658\n",
      "Step: 4379 Weights: [0.35423733 2.13264048] , error: 0.4737447211934723\n",
      "Step: 4380 Weights: [0.35424173 2.13263997] , error: 0.47374471923930717\n",
      "Step: 4381 Weights: [0.35424611 2.13263947] , error: 0.4737447172940441\n",
      "Step: 4382 Weights: [0.35425049 2.13263897] , error: 0.4737447153576434\n",
      "Step: 4383 Weights: [0.35425485 2.13263847] , error: 0.47374471343006364\n",
      "Step: 4384 Weights: [0.35425921 2.13263798] , error: 0.473744711511266\n",
      "Step: 4385 Weights: [0.35426355 2.13263748] , error: 0.4737447096012086\n",
      "Step: 4386 Weights: [0.35426789 2.13263698] , error: 0.4737447076998541\n",
      "Step: 4387 Weights: [0.35427221 2.13263649] , error: 0.47374470580716094\n",
      "Step: 4388 Weights: [0.35427653 2.13263599] , error: 0.47374470392309065\n",
      "Step: 4389 Weights: [0.35428083 2.1326355 ] , error: 0.4737447020476021\n",
      "Step: 4390 Weights: [0.35428513 2.13263501] , error: 0.4737447001806585\n",
      "Step: 4391 Weights: [0.35428941 2.13263452] , error: 0.47374469832222027\n",
      "Step: 4392 Weights: [0.35429369 2.13263403] , error: 0.47374469647224793\n",
      "Step: 4393 Weights: [0.35429795 2.13263354] , error: 0.47374469463070323\n",
      "Step: 4394 Weights: [0.35430221 2.13263306] , error: 0.47374469279754805\n",
      "Step: 4395 Weights: [0.35430646 2.13263257] , error: 0.4737446909727443\n",
      "Step: 4396 Weights: [0.35431069 2.13263209] , error: 0.4737446891562541\n",
      "Step: 4397 Weights: [0.35431492 2.1326316 ] , error: 0.4737446873480378\n",
      "Step: 4398 Weights: [0.35431914 2.13263112] , error: 0.47374468554806093\n",
      "Step: 4399 Weights: [0.35432335 2.13263064] , error: 0.4737446837562825\n",
      "Step: 4400 Weights: [0.35432754 2.13263016] , error: 0.47374468197266684\n",
      "Step: 4401 Weights: [0.35433173 2.13262968] , error: 0.47374468019717786\n",
      "Step: 4402 Weights: [0.35433591 2.1326292 ] , error: 0.47374467842977613\n",
      "Step: 4403 Weights: [0.35434008 2.13262873] , error: 0.47374467667042636\n",
      "Step: 4404 Weights: [0.35434424 2.13262825] , error: 0.4737446749190929\n",
      "Step: 4405 Weights: [0.35434839 2.13262778] , error: 0.47374467317573626\n",
      "Step: 4406 Weights: [0.35435253 2.1326273 ] , error: 0.4737446714403222\n",
      "Step: 4407 Weights: [0.35435667 2.13262683] , error: 0.47374466971281426\n",
      "Step: 4408 Weights: [0.35436079 2.13262636] , error: 0.47374466799317533\n",
      "Step: 4409 Weights: [0.3543649  2.13262589] , error: 0.4737446662813711\n",
      "Step: 4410 Weights: [0.354369   2.13262542] , error: 0.4737446645773651\n",
      "Step: 4411 Weights: [0.3543731  2.13262495] , error: 0.4737446628811227\n",
      "Step: 4412 Weights: [0.35437718 2.13262448] , error: 0.4737446611926059\n",
      "Step: 4413 Weights: [0.35438126 2.13262402] , error: 0.47374465951178235\n",
      "Step: 4414 Weights: [0.35438533 2.13262355] , error: 0.4737446578386165\n",
      "Step: 4415 Weights: [0.35438938 2.13262309] , error: 0.4737446561730725\n",
      "Step: 4416 Weights: [0.35439343 2.13262263] , error: 0.47374465451511666\n",
      "Step: 4417 Weights: [0.35439747 2.13262216] , error: 0.47374465286471357\n",
      "Step: 4418 Weights: [0.3544015 2.1326217] , error: 0.47374465122182813\n",
      "Step: 4419 Weights: [0.35440552 2.13262124] , error: 0.47374464958642876\n",
      "Step: 4420 Weights: [0.35440953 2.13262078] , error: 0.4737446479584789\n",
      "Step: 4421 Weights: [0.35441353 2.13262033] , error: 0.47374464633794455\n",
      "Step: 4422 Weights: [0.35441752 2.13261987] , error: 0.4737446447247933\n",
      "Step: 4423 Weights: [0.35442151 2.13261941] , error: 0.4737446431189914\n",
      "Step: 4424 Weights: [0.35442548 2.13261896] , error: 0.47374464152050566\n",
      "Step: 4425 Weights: [0.35442945 2.13261851] , error: 0.47374463992930077\n",
      "Step: 4426 Weights: [0.3544334  2.13261805] , error: 0.47374463834534447\n",
      "Step: 4427 Weights: [0.35443735 2.1326176 ] , error: 0.47374463676860507\n",
      "Step: 4428 Weights: [0.35444129 2.13261715] , error: 0.473744635199048\n",
      "Step: 4429 Weights: [0.35444522 2.1326167 ] , error: 0.4737446336366422\n",
      "Step: 4430 Weights: [0.35444914 2.13261625] , error: 0.4737446320813536\n",
      "Step: 4431 Weights: [0.35445305 2.13261581] , error: 0.47374463053314997\n",
      "Step: 4432 Weights: [0.35445695 2.13261536] , error: 0.47374462899199987\n",
      "Step: 4433 Weights: [0.35446085 2.13261491] , error: 0.4737446274578703\n",
      "Step: 4434 Weights: [0.35446473 2.13261447] , error: 0.4737446259307297\n",
      "Step: 4435 Weights: [0.35446861 2.13261403] , error: 0.4737446244105465\n",
      "Step: 4436 Weights: [0.35447247 2.13261359] , error: 0.47374462289728836\n",
      "Step: 4437 Weights: [0.35447633 2.13261314] , error: 0.47374462139092466\n",
      "Step: 4438 Weights: [0.35448018 2.1326127 ] , error: 0.4737446198914229\n",
      "Step: 4439 Weights: [0.35448402 2.13261226] , error: 0.47374461839875226\n",
      "Step: 4440 Weights: [0.35448785 2.13261183] , error: 0.4737446169128823\n",
      "Step: 4441 Weights: [0.35449168 2.13261139] , error: 0.47374461543378066\n",
      "Step: 4442 Weights: [0.35449549 2.13261095] , error: 0.47374461396141776\n",
      "Step: 4443 Weights: [0.3544993  2.13261052] , error: 0.47374461249576205\n",
      "Step: 4444 Weights: [0.3545031  2.13261008] , error: 0.47374461103678295\n",
      "Step: 4445 Weights: [0.35450688 2.13260965] , error: 0.4737446095844511\n",
      "Step: 4446 Weights: [0.35451066 2.13260922] , error: 0.47374460813873603\n",
      "Step: 4447 Weights: [0.35451443 2.13260879] , error: 0.4737446066996054\n",
      "Step: 4448 Weights: [0.3545182  2.13260836] , error: 0.47374460526703205\n",
      "Step: 4449 Weights: [0.35452195 2.13260793] , error: 0.4737446038409857\n",
      "Step: 4450 Weights: [0.3545257 2.1326075] , error: 0.47374460242143496\n",
      "Step: 4451 Weights: [0.35452943 2.13260707] , error: 0.47374460100835103\n",
      "Step: 4452 Weights: [0.35453316 2.13260664] , error: 0.47374459960170456\n",
      "Step: 4453 Weights: [0.35453688 2.13260622] , error: 0.4737445982014671\n",
      "Step: 4454 Weights: [0.35454059 2.13260579] , error: 0.47374459680760783\n",
      "Step: 4455 Weights: [0.3545443  2.13260537] , error: 0.473744595420099\n",
      "Step: 4456 Weights: [0.35454799 2.13260495] , error: 0.4737445940389103\n",
      "Step: 4457 Weights: [0.35455168 2.13260453] , error: 0.4737445926640147\n",
      "Step: 4458 Weights: [0.35455535 2.13260411] , error: 0.47374459129538227\n",
      "Step: 4459 Weights: [0.35455902 2.13260369] , error: 0.47374458993298485\n",
      "Step: 4460 Weights: [0.35456268 2.13260327] , error: 0.4737445885767941\n",
      "Step: 4461 Weights: [0.35456634 2.13260285] , error: 0.4737445872267807\n",
      "Step: 4462 Weights: [0.35456998 2.13260243] , error: 0.4737445858829191\n",
      "Step: 4463 Weights: [0.35457362 2.13260202] , error: 0.47374458454517776\n",
      "Step: 4464 Weights: [0.35457724 2.1326016 ] , error: 0.47374458321353285\n",
      "Step: 4465 Weights: [0.35458086 2.13260119] , error: 0.47374458188795265\n",
      "Step: 4466 Weights: [0.35458447 2.13260078] , error: 0.4737445805684116\n",
      "Step: 4467 Weights: [0.35458808 2.13260036] , error: 0.4737445792548826\n",
      "Step: 4468 Weights: [0.35459167 2.13259995] , error: 0.4737445779473375\n",
      "Step: 4469 Weights: [0.35459526 2.13259954] , error: 0.47374457664574854\n",
      "Step: 4470 Weights: [0.35459884 2.13259913] , error: 0.47374457535008974\n",
      "Step: 4471 Weights: [0.35460241 2.13259873] , error: 0.47374457406033244\n",
      "Step: 4472 Weights: [0.35460597 2.13259832] , error: 0.47374457277645193\n",
      "Step: 4473 Weights: [0.35460952 2.13259791] , error: 0.473744571498419\n",
      "Step: 4474 Weights: [0.35461307 2.13259751] , error: 0.4737445702262095\n",
      "Step: 4475 Weights: [0.35461661 2.1325971 ] , error: 0.4737445689597963\n",
      "Step: 4476 Weights: [0.35462014 2.1325967 ] , error: 0.4737445676991506\n",
      "Step: 4477 Weights: [0.35462366 2.1325963 ] , error: 0.47374456644424967\n",
      "Step: 4478 Weights: [0.35462717 2.13259589] , error: 0.4737445651950639\n",
      "Step: 4479 Weights: [0.35463068 2.13259549] , error: 0.4737445639515696\n",
      "Step: 4480 Weights: [0.35463417 2.13259509] , error: 0.4737445627137404\n",
      "Step: 4481 Weights: [0.35463766 2.13259469] , error: 0.47374456148155036\n",
      "Step: 4482 Weights: [0.35464115 2.1325943 ] , error: 0.4737445602549739\n",
      "Step: 4483 Weights: [0.35464462 2.1325939 ] , error: 0.4737445590339854\n",
      "Step: 4484 Weights: [0.35464808 2.1325935 ] , error: 0.4737445578185592\n",
      "Step: 4485 Weights: [0.35465154 2.13259311] , error: 0.4737445566086697\n",
      "Step: 4486 Weights: [0.35465499 2.13259271] , error: 0.4737445554042919\n",
      "Step: 4487 Weights: [0.35465843 2.13259232] , error: 0.47374455420540085\n",
      "Step: 4488 Weights: [0.35466187 2.13259193] , error: 0.4737445530119718\n",
      "Step: 4489 Weights: [0.35466529 2.13259153] , error: 0.47374455182397907\n",
      "Step: 4490 Weights: [0.35466871 2.13259114] , error: 0.47374455064139825\n",
      "Step: 4491 Weights: [0.35467212 2.13259075] , error: 0.47374454946420647\n",
      "Step: 4492 Weights: [0.35467553 2.13259036] , error: 0.4737445482923762\n",
      "Step: 4493 Weights: [0.35467892 2.13258997] , error: 0.47374454712588426\n",
      "Step: 4494 Weights: [0.35468231 2.13258959] , error: 0.4737445459647065\n",
      "Step: 4495 Weights: [0.35468569 2.1325892 ] , error: 0.4737445448088189\n",
      "Step: 4496 Weights: [0.35468906 2.13258882] , error: 0.47374454365819707\n",
      "Step: 4497 Weights: [0.35469243 2.13258843] , error: 0.47374454251281617\n",
      "Step: 4498 Weights: [0.35469578 2.13258805] , error: 0.4737445413726543\n",
      "Step: 4499 Weights: [0.35469913 2.13258766] , error: 0.47374454023768675\n",
      "Step: 4500 Weights: [0.35470247 2.13258728] , error: 0.4737445391078891\n",
      "Step: 4501 Weights: [0.35470581 2.1325869 ] , error: 0.473744537983239\n",
      "Step: 4502 Weights: [0.35470913 2.13258652] , error: 0.473744536863712\n",
      "Step: 4503 Weights: [0.35471245 2.13258614] , error: 0.47374453574928466\n",
      "Step: 4504 Weights: [0.35471576 2.13258576] , error: 0.47374453463993504\n",
      "Step: 4505 Weights: [0.35471907 2.13258538] , error: 0.4737445335356387\n",
      "Step: 4506 Weights: [0.35472236 2.13258501] , error: 0.47374453243637316\n",
      "Step: 4507 Weights: [0.35472565 2.13258463] , error: 0.4737445313421161\n",
      "Step: 4508 Weights: [0.35472893 2.13258426] , error: 0.47374453025284274\n",
      "Step: 4509 Weights: [0.3547322  2.13258388] , error: 0.47374452916853277\n",
      "Step: 4510 Weights: [0.35473547 2.13258351] , error: 0.4737445280891624\n",
      "Step: 4511 Weights: [0.35473873 2.13258314] , error: 0.47374452701470937\n",
      "Step: 4512 Weights: [0.35474198 2.13258276] , error: 0.4737445259451503\n",
      "Step: 4513 Weights: [0.35474522 2.13258239] , error: 0.47374452488046437\n",
      "Step: 4514 Weights: [0.35474846 2.13258202] , error: 0.47374452382062904\n",
      "Step: 4515 Weights: [0.35475169 2.13258165] , error: 0.4737445227656212\n",
      "Step: 4516 Weights: [0.35475491 2.13258128] , error: 0.4737445217154204\n",
      "Step: 4517 Weights: [0.35475812 2.13258092] , error: 0.47374452067000344\n",
      "Step: 4518 Weights: [0.35476133 2.13258055] , error: 0.4737445196293491\n",
      "Step: 4519 Weights: [0.35476453 2.13258018] , error: 0.47374451859343525\n",
      "Step: 4520 Weights: [0.35476772 2.13257982] , error: 0.473744517562241\n",
      "Step: 4521 Weights: [0.35477091 2.13257946] , error: 0.47374451653574434\n",
      "Step: 4522 Weights: [0.35477409 2.13257909] , error: 0.4737445155139238\n",
      "Step: 4523 Weights: [0.35477726 2.13257873] , error: 0.4737445144967589\n",
      "Step: 4524 Weights: [0.35478042 2.13257837] , error: 0.47374451348422847\n",
      "Step: 4525 Weights: [0.35478358 2.13257801] , error: 0.473744512476309\n",
      "Step: 4526 Weights: [0.35478672 2.13257765] , error: 0.47374451147298213\n",
      "Step: 4527 Weights: [0.35478987 2.13257729] , error: 0.4737445104742263\n",
      "Step: 4528 Weights: [0.354793   2.13257693] , error: 0.4737445094800201\n",
      "Step: 4529 Weights: [0.35479613 2.13257657] , error: 0.47374450849034333\n",
      "Step: 4530 Weights: [0.35479925 2.13257621] , error: 0.4737445075051756\n",
      "Step: 4531 Weights: [0.35480236 2.13257586] , error: 0.4737445065244935\n",
      "Step: 4532 Weights: [0.35480547 2.1325755 ] , error: 0.4737445055482813\n",
      "Step: 4533 Weights: [0.35480857 2.13257515] , error: 0.47374450457651684\n",
      "Step: 4534 Weights: [0.35481166 2.13257479] , error: 0.47374450360917897\n",
      "Step: 4535 Weights: [0.35481474 2.13257444] , error: 0.4737445026462469\n",
      "Step: 4536 Weights: [0.35481782 2.13257409] , error: 0.4737445016877022\n",
      "Step: 4537 Weights: [0.35482089 2.13257374] , error: 0.4737445007335233\n",
      "Step: 4538 Weights: [0.35482395 2.13257339] , error: 0.4737444997836934\n",
      "Step: 4539 Weights: [0.35482701 2.13257304] , error: 0.4737444988381886\n",
      "Step: 4540 Weights: [0.35483006 2.13257269] , error: 0.4737444978969916\n",
      "Step: 4541 Weights: [0.3548331  2.13257234] , error: 0.47374449696008264\n",
      "Step: 4542 Weights: [0.35483614 2.13257199] , error: 0.4737444960274423\n",
      "Step: 4543 Weights: [0.35483917 2.13257165] , error: 0.47374449509905076\n",
      "Step: 4544 Weights: [0.35484219 2.1325713 ] , error: 0.47374449417488784\n",
      "Step: 4545 Weights: [0.35484521 2.13257096] , error: 0.4737444932549363\n",
      "Step: 4546 Weights: [0.35484821 2.13257061] , error: 0.4737444923391746\n",
      "Step: 4547 Weights: [0.35485122 2.13257027] , error: 0.4737444914275848\n",
      "Step: 4548 Weights: [0.35485421 2.13256993] , error: 0.4737444905201483\n",
      "Step: 4549 Weights: [0.3548572  2.13256959] , error: 0.4737444896168456\n",
      "Step: 4550 Weights: [0.35486018 2.13256925] , error: 0.4737444887176572\n",
      "Step: 4551 Weights: [0.35486315 2.13256891] , error: 0.4737444878225655\n",
      "Step: 4552 Weights: [0.35486612 2.13256857] , error: 0.47374448693155297\n",
      "Step: 4553 Weights: [0.35486908 2.13256823] , error: 0.4737444860445975\n",
      "Step: 4554 Weights: [0.35487203 2.13256789] , error: 0.47374448516168466\n",
      "Step: 4555 Weights: [0.35487498 2.13256755] , error: 0.4737444842827926\n",
      "Step: 4556 Weights: [0.35487792 2.13256722] , error: 0.4737444834079046\n",
      "Step: 4557 Weights: [0.35488086 2.13256688] , error: 0.4737444825370029\n",
      "Step: 4558 Weights: [0.35488378 2.13256655] , error: 0.4737444816700688\n",
      "Step: 4559 Weights: [0.3548867  2.13256621] , error: 0.4737444808070834\n",
      "Step: 4560 Weights: [0.35488962 2.13256588] , error: 0.47374447994803015\n",
      "Step: 4561 Weights: [0.35489252 2.13256555] , error: 0.4737444790928901\n",
      "Step: 4562 Weights: [0.35489542 2.13256521] , error: 0.47374447824164534\n",
      "Step: 4563 Weights: [0.35489832 2.13256488] , error: 0.4737444773942791\n",
      "Step: 4564 Weights: [0.35490121 2.13256455] , error: 0.47374447655077223\n",
      "Step: 4565 Weights: [0.35490409 2.13256422] , error: 0.4737444757111101\n",
      "Step: 4566 Weights: [0.35490696 2.1325639 ] , error: 0.4737444748752717\n",
      "Step: 4567 Weights: [0.35490983 2.13256357] , error: 0.47374447404324094\n",
      "Step: 4568 Weights: [0.35491269 2.13256324] , error: 0.4737444732150006\n",
      "Step: 4569 Weights: [0.35491554 2.13256291] , error: 0.4737444723905343\n",
      "Step: 4570 Weights: [0.35491839 2.13256259] , error: 0.4737444715698227\n",
      "Step: 4571 Weights: [0.35492123 2.13256226] , error: 0.47374447075285164\n",
      "Step: 4572 Weights: [0.35492407 2.13256194] , error: 0.4737444699396012\n",
      "Step: 4573 Weights: [0.3549269  2.13256162] , error: 0.4737444691300554\n",
      "Step: 4574 Weights: [0.35492972 2.13256129] , error: 0.4737444683241978\n",
      "Step: 4575 Weights: [0.35493253 2.13256097] , error: 0.4737444675220118\n",
      "Step: 4576 Weights: [0.35493534 2.13256065] , error: 0.47374446672348003\n",
      "Step: 4577 Weights: [0.35493814 2.13256033] , error: 0.4737444659285855\n",
      "Step: 4578 Weights: [0.35494094 2.13256001] , error: 0.47374446513731333\n",
      "Step: 4579 Weights: [0.35494373 2.13255969] , error: 0.4737444643496461\n",
      "Step: 4580 Weights: [0.35494651 2.13255937] , error: 0.47374446356556577\n",
      "Step: 4581 Weights: [0.35494929 2.13255905] , error: 0.47374446278505816\n",
      "Step: 4582 Weights: [0.35495206 2.13255874] , error: 0.4737444620081063\n",
      "Step: 4583 Weights: [0.35495483 2.13255842] , error: 0.47374446123469394\n",
      "Step: 4584 Weights: [0.35495759 2.13255811] , error: 0.47374446046480473\n",
      "Step: 4585 Weights: [0.35496034 2.13255779] , error: 0.47374445969842355\n",
      "Step: 4586 Weights: [0.35496308 2.13255748] , error: 0.47374445893553335\n",
      "Step: 4587 Weights: [0.35496582 2.13255716] , error: 0.47374445817611754\n",
      "Step: 4588 Weights: [0.35496856 2.13255685] , error: 0.47374445742016247\n",
      "Step: 4589 Weights: [0.35497128 2.13255654] , error: 0.4737444566676512\n",
      "Step: 4590 Weights: [0.354974   2.13255623] , error: 0.47374445591856623\n",
      "Step: 4591 Weights: [0.35497672 2.13255592] , error: 0.47374445517289715\n",
      "Step: 4592 Weights: [0.35497943 2.13255561] , error: 0.47374445443062274\n",
      "Step: 4593 Weights: [0.35498213 2.1325553 ] , error: 0.47374445369173107\n",
      "Step: 4594 Weights: [0.35498482 2.13255499] , error: 0.47374445295620526\n",
      "Step: 4595 Weights: [0.35498751 2.13255468] , error: 0.47374445222402956\n",
      "Step: 4596 Weights: [0.3549902  2.13255438] , error: 0.47374445149519046\n",
      "Step: 4597 Weights: [0.35499288 2.13255407] , error: 0.47374445076967014\n",
      "Step: 4598 Weights: [0.35499555 2.13255376] , error: 0.47374445004745613\n",
      "Step: 4599 Weights: [0.35499821 2.13255346] , error: 0.47374444932853166\n",
      "Step: 4600 Weights: [0.35500087 2.13255316] , error: 0.4737444486128827\n",
      "Step: 4601 Weights: [0.35500353 2.13255285] , error: 0.47374444790049464\n",
      "Step: 4602 Weights: [0.35500617 2.13255255] , error: 0.47374444719135117\n",
      "Step: 4603 Weights: [0.35500881 2.13255225] , error: 0.4737444464854381\n",
      "Step: 4604 Weights: [0.35501145 2.13255195] , error: 0.4737444457827414\n",
      "Step: 4605 Weights: [0.35501408 2.13255165] , error: 0.4737444450832464\n",
      "Step: 4606 Weights: [0.3550167  2.13255135] , error: 0.473744444386937\n",
      "Step: 4607 Weights: [0.35501932 2.13255105] , error: 0.47374444369379975\n",
      "Step: 4608 Weights: [0.35502193 2.13255075] , error: 0.47374444300382024\n",
      "Step: 4609 Weights: [0.35502454 2.13255045] , error: 0.4737444423169844\n",
      "Step: 4610 Weights: [0.35502713 2.13255015] , error: 0.47374444163327745\n",
      "Step: 4611 Weights: [0.35502973 2.13254986] , error: 0.4737444409526859\n",
      "Step: 4612 Weights: [0.35503232 2.13254956] , error: 0.47374444027519397\n",
      "Step: 4613 Weights: [0.3550349  2.13254926] , error: 0.4737444396007882\n",
      "Step: 4614 Weights: [0.35503747 2.13254897] , error: 0.4737444389294563\n",
      "Step: 4615 Weights: [0.35504004 2.13254868] , error: 0.47374443826118107\n",
      "Step: 4616 Weights: [0.35504261 2.13254838] , error: 0.4737444375959502\n",
      "Step: 4617 Weights: [0.35504516 2.13254809] , error: 0.47374443693375096\n",
      "Step: 4618 Weights: [0.35504772 2.1325478 ] , error: 0.4737444362745683\n",
      "Step: 4619 Weights: [0.35505026 2.13254751] , error: 0.47374443561838847\n",
      "Step: 4620 Weights: [0.3550528  2.13254722] , error: 0.4737444349651979\n",
      "Step: 4621 Weights: [0.35505534 2.13254693] , error: 0.4737444343149827\n",
      "Step: 4622 Weights: [0.35505787 2.13254664] , error: 0.4737444336677299\n",
      "Step: 4623 Weights: [0.35506039 2.13254635] , error: 0.47374443302342545\n",
      "Step: 4624 Weights: [0.35506291 2.13254606] , error: 0.47374443238205644\n",
      "Step: 4625 Weights: [0.35506542 2.13254577] , error: 0.4737444317436096\n",
      "Step: 4626 Weights: [0.35506793 2.13254549] , error: 0.4737444311080712\n",
      "Step: 4627 Weights: [0.35507043 2.1325452 ] , error: 0.4737444304754279\n",
      "Step: 4628 Weights: [0.35507292 2.13254492] , error: 0.47374442984566745\n",
      "Step: 4629 Weights: [0.35507541 2.13254463] , error: 0.47374442921877424\n",
      "Step: 4630 Weights: [0.35507789 2.13254435] , error: 0.47374442859473803\n",
      "Step: 4631 Weights: [0.35508037 2.13254406] , error: 0.4737444279735448\n",
      "Step: 4632 Weights: [0.35508284 2.13254378] , error: 0.4737444273551817\n",
      "Step: 4633 Weights: [0.35508531 2.1325435 ] , error: 0.47374442673963413\n",
      "Step: 4634 Weights: [0.35508777 2.13254322] , error: 0.47374442612689227\n",
      "Step: 4635 Weights: [0.35509023 2.13254294] , error: 0.4737444255169418\n",
      "Step: 4636 Weights: [0.35509268 2.13254266] , error: 0.47374442490976965\n",
      "Step: 4637 Weights: [0.35509512 2.13254238] , error: 0.4737444243053635\n",
      "Step: 4638 Weights: [0.35509756 2.1325421 ] , error: 0.47374442370371045\n",
      "Step: 4639 Weights: [0.35509999 2.13254182] , error: 0.4737444231047987\n",
      "Step: 4640 Weights: [0.35510242 2.13254154] , error: 0.47374442250861526\n",
      "Step: 4641 Weights: [0.35510484 2.13254127] , error: 0.4737444219151485\n",
      "Step: 4642 Weights: [0.35510726 2.13254099] , error: 0.4737444213243841\n",
      "Step: 4643 Weights: [0.35510967 2.13254071] , error: 0.4737444207363125\n",
      "Step: 4644 Weights: [0.35511207 2.13254044] , error: 0.4737444201509188\n",
      "Step: 4645 Weights: [0.35511447 2.13254016] , error: 0.4737444195681926\n",
      "Step: 4646 Weights: [0.35511687 2.13253989] , error: 0.4737444189881203\n",
      "Step: 4647 Weights: [0.35511925 2.13253962] , error: 0.4737444184106916\n",
      "Step: 4648 Weights: [0.35512164 2.13253934] , error: 0.47374441783589194\n",
      "Step: 4649 Weights: [0.35512402 2.13253907] , error: 0.47374441726371186\n",
      "Step: 4650 Weights: [0.35512639 2.1325388 ] , error: 0.47374441669413836\n",
      "Step: 4651 Weights: [0.35512876 2.13253853] , error: 0.47374441612715995\n",
      "Step: 4652 Weights: [0.35513112 2.13253826] , error: 0.47374441556276414\n",
      "Step: 4653 Weights: [0.35513347 2.13253799] , error: 0.47374441500093956\n",
      "Step: 4654 Weights: [0.35513582 2.13253772] , error: 0.47374441444167426\n",
      "Step: 4655 Weights: [0.35513817 2.13253745] , error: 0.47374441388495736\n",
      "Step: 4656 Weights: [0.35514051 2.13253719] , error: 0.4737444133307754\n",
      "Step: 4657 Weights: [0.35514284 2.13253692] , error: 0.4737444127791195\n",
      "Step: 4658 Weights: [0.35514517 2.13253665] , error: 0.47374441222997676\n",
      "Step: 4659 Weights: [0.3551475  2.13253639] , error: 0.4737444116833349\n",
      "Step: 4660 Weights: [0.35514982 2.13253612] , error: 0.4737444111391837\n",
      "Step: 4661 Weights: [0.35515213 2.13253586] , error: 0.4737444105975106\n",
      "Step: 4662 Weights: [0.35515444 2.13253559] , error: 0.4737444100583066\n",
      "Step: 4663 Weights: [0.35515674 2.13253533] , error: 0.4737444095215581\n",
      "Step: 4664 Weights: [0.35515904 2.13253507] , error: 0.47374440898725456\n",
      "Step: 4665 Weights: [0.35516133 2.1325348 ] , error: 0.4737444084553859\n",
      "Step: 4666 Weights: [0.35516362 2.13253454] , error: 0.47374440792593986\n",
      "Step: 4667 Weights: [0.3551659  2.13253428] , error: 0.4737444073989052\n",
      "Step: 4668 Weights: [0.35516818 2.13253402] , error: 0.4737444068742726\n",
      "Step: 4669 Weights: [0.35517045 2.13253376] , error: 0.4737444063520297\n",
      "Step: 4670 Weights: [0.35517272 2.1325335 ] , error: 0.47374440583216537\n",
      "Step: 4671 Weights: [0.35517498 2.13253324] , error: 0.47374440531467005\n",
      "Step: 4672 Weights: [0.35517724 2.13253299] , error: 0.4737444047995311\n",
      "Step: 4673 Weights: [0.35517949 2.13253273] , error: 0.47374440428674014\n",
      "Step: 4674 Weights: [0.35518173 2.13253247] , error: 0.473744403776285\n",
      "Step: 4675 Weights: [0.35518397 2.13253222] , error: 0.47374440326815587\n",
      "Step: 4676 Weights: [0.35518621 2.13253196] , error: 0.473744402762341\n",
      "Step: 4677 Weights: [0.35518844 2.1325317 ] , error: 0.4737444022588303\n",
      "Step: 4678 Weights: [0.35519067 2.13253145] , error: 0.47374440175761345\n",
      "Step: 4679 Weights: [0.35519289 2.1325312 ] , error: 0.47374440125868056\n",
      "Step: 4680 Weights: [0.3551951  2.13253094] , error: 0.4737444007620188\n",
      "Step: 4681 Weights: [0.35519731 2.13253069] , error: 0.47374440026762143\n",
      "Step: 4682 Weights: [0.35519952 2.13253044] , error: 0.4737443997754756\n",
      "Step: 4683 Weights: [0.35520172 2.13253019] , error: 0.4737443992855722\n",
      "Step: 4684 Weights: [0.35520391 2.13252993] , error: 0.47374439879790065\n",
      "Step: 4685 Weights: [0.3552061  2.13252968] , error: 0.47374439831245\n",
      "Step: 4686 Weights: [0.35520829 2.13252943] , error: 0.4737443978292124\n",
      "Step: 4687 Weights: [0.35521047 2.13252919] , error: 0.4737443973481744\n",
      "Step: 4688 Weights: [0.35521264 2.13252894] , error: 0.4737443968693294\n",
      "Step: 4689 Weights: [0.35521481 2.13252869] , error: 0.4737443963926646\n",
      "Step: 4690 Weights: [0.35521698 2.13252844] , error: 0.47374439591817236\n",
      "Step: 4691 Weights: [0.35521914 2.13252819] , error: 0.47374439544584146\n",
      "Step: 4692 Weights: [0.3552213  2.13252795] , error: 0.4737443949756616\n",
      "Step: 4693 Weights: [0.35522345 2.1325277 ] , error: 0.47374439450762407\n",
      "Step: 4694 Weights: [0.35522559 2.13252746] , error: 0.47374439404171825\n",
      "Step: 4695 Weights: [0.35522773 2.13252721] , error: 0.47374439357793663\n",
      "Step: 4696 Weights: [0.35522987 2.13252697] , error: 0.4737443931162666\n",
      "Step: 4697 Weights: [0.355232   2.13252672] , error: 0.4737443926567002\n",
      "Step: 4698 Weights: [0.35523413 2.13252648] , error: 0.4737443921992266\n",
      "Step: 4699 Weights: [0.35523625 2.13252624] , error: 0.47374439174383787\n",
      "Step: 4700 Weights: [0.35523836 2.13252599] , error: 0.4737443912905238\n",
      "Step: 4701 Weights: [0.35524048 2.13252575] , error: 0.4737443908392747\n",
      "Step: 4702 Weights: [0.35524258 2.13252551] , error: 0.4737443903900816\n",
      "Step: 4703 Weights: [0.35524468 2.13252527] , error: 0.47374438994293444\n",
      "Step: 4704 Weights: [0.35524678 2.13252503] , error: 0.4737443894978237\n",
      "Step: 4705 Weights: [0.35524887 2.13252479] , error: 0.4737443890547417\n",
      "Step: 4706 Weights: [0.35525096 2.13252455] , error: 0.4737443886136773\n",
      "Step: 4707 Weights: [0.35525304 2.13252432] , error: 0.4737443881746228\n",
      "Step: 4708 Weights: [0.35525512 2.13252408] , error: 0.47374438773756844\n",
      "Step: 4709 Weights: [0.3552572  2.13252384] , error: 0.47374438730250557\n",
      "Step: 4710 Weights: [0.35525927 2.1325236 ] , error: 0.47374438686942394\n",
      "Step: 4711 Weights: [0.35526133 2.13252337] , error: 0.47374438643831546\n",
      "Step: 4712 Weights: [0.35526339 2.13252313] , error: 0.47374438600917196\n",
      "Step: 4713 Weights: [0.35526544 2.1325229 ] , error: 0.47374438558198145\n",
      "Step: 4714 Weights: [0.35526749 2.13252266] , error: 0.4737443851567388\n",
      "Step: 4715 Weights: [0.35526954 2.13252243] , error: 0.4737443847334326\n",
      "Step: 4716 Weights: [0.35527158 2.1325222 ] , error: 0.47374438431205534\n",
      "Step: 4717 Weights: [0.35527362 2.13252196] , error: 0.47374438389259677\n",
      "Step: 4718 Weights: [0.35527565 2.13252173] , error: 0.47374438347504977\n",
      "Step: 4719 Weights: [0.35527767 2.1325215 ] , error: 0.47374438305940547\n",
      "Step: 4720 Weights: [0.3552797  2.13252127] , error: 0.47374438264565416\n",
      "Step: 4721 Weights: [0.35528171 2.13252104] , error: 0.47374438223378806\n",
      "Step: 4722 Weights: [0.35528373 2.13252081] , error: 0.47374438182379763\n",
      "Step: 4723 Weights: [0.35528573 2.13252058] , error: 0.47374438141567504\n",
      "Step: 4724 Weights: [0.35528774 2.13252035] , error: 0.47374438100941213\n",
      "Step: 4725 Weights: [0.35528974 2.13252012] , error: 0.4737443806049999\n",
      "Step: 4726 Weights: [0.35529173 2.13251989] , error: 0.4737443802024297\n",
      "Step: 4727 Weights: [0.35529372 2.13251966] , error: 0.47374437980169426\n",
      "Step: 4728 Weights: [0.35529571 2.13251944] , error: 0.47374437940278363\n",
      "Step: 4729 Weights: [0.35529769 2.13251921] , error: 0.47374437900569055\n",
      "Step: 4730 Weights: [0.35529966 2.13251898] , error: 0.47374437861040675\n",
      "Step: 4731 Weights: [0.35530164 2.13251876] , error: 0.4737443782169231\n",
      "Step: 4732 Weights: [0.3553036  2.13251853] , error: 0.4737443778252328\n",
      "Step: 4733 Weights: [0.35530557 2.13251831] , error: 0.47374437743532577\n",
      "Step: 4734 Weights: [0.35530752 2.13251809] , error: 0.4737443770471956\n",
      "Step: 4735 Weights: [0.35530948 2.13251786] , error: 0.47374437666083435\n",
      "Step: 4736 Weights: [0.35531143 2.13251764] , error: 0.47374437627623245\n",
      "Step: 4737 Weights: [0.35531337 2.13251742] , error: 0.4737443758933829\n",
      "Step: 4738 Weights: [0.35531531 2.13251719] , error: 0.4737443755122769\n",
      "Step: 4739 Weights: [0.35531725 2.13251697] , error: 0.4737443751329075\n",
      "Step: 4740 Weights: [0.35531918 2.13251675] , error: 0.47374437475526693\n",
      "Step: 4741 Weights: [0.35532111 2.13251653] , error: 0.4737443743793453\n",
      "Step: 4742 Weights: [0.35532303 2.13251631] , error: 0.4737443740051378\n",
      "Step: 4743 Weights: [0.35532495 2.13251609] , error: 0.47374437363263455\n",
      "Step: 4744 Weights: [0.35532687 2.13251587] , error: 0.4737443732618283\n",
      "Step: 4745 Weights: [0.35532878 2.13251565] , error: 0.47374437289271065\n",
      "Step: 4746 Weights: [0.35533068 2.13251544] , error: 0.4737443725252752\n",
      "Step: 4747 Weights: [0.35533258 2.13251522] , error: 0.47374437215951354\n",
      "Step: 4748 Weights: [0.35533448 2.132515  ] , error: 0.4737443717954186\n",
      "Step: 4749 Weights: [0.35533637 2.13251479] , error: 0.4737443714329812\n",
      "Step: 4750 Weights: [0.35533826 2.13251457] , error: 0.47374437107219564\n",
      "Step: 4751 Weights: [0.35534014 2.13251435] , error: 0.47374437071305386\n",
      "Step: 4752 Weights: [0.35534202 2.13251414] , error: 0.47374437035554784\n",
      "Step: 4753 Weights: [0.3553439  2.13251393] , error: 0.4737443699996705\n",
      "Step: 4754 Weights: [0.35534577 2.13251371] , error: 0.4737443696454144\n",
      "Step: 4755 Weights: [0.35534764 2.1325135 ] , error: 0.4737443692927725\n",
      "Step: 4756 Weights: [0.3553495  2.13251328] , error: 0.4737443689417373\n",
      "Step: 4757 Weights: [0.35535136 2.13251307] , error: 0.47374436859229985\n",
      "Step: 4758 Weights: [0.35535321 2.13251286] , error: 0.473744368244456\n",
      "Step: 4759 Weights: [0.35535506 2.13251265] , error: 0.47374436789819585\n",
      "Step: 4760 Weights: [0.35535691 2.13251244] , error: 0.47374436755351323\n",
      "Step: 4761 Weights: [0.35535875 2.13251223] , error: 0.4737443672104016\n",
      "Step: 4762 Weights: [0.35536059 2.13251202] , error: 0.4737443668688518\n",
      "Step: 4763 Weights: [0.35536242 2.13251181] , error: 0.4737443665288592\n",
      "Step: 4764 Weights: [0.35536425 2.1325116 ] , error: 0.47374436619041543\n",
      "Step: 4765 Weights: [0.35536607 2.13251139] , error: 0.47374436585351254\n",
      "Step: 4766 Weights: [0.35536789 2.13251118] , error: 0.4737443655181452\n",
      "Step: 4767 Weights: [0.35536971 2.13251097] , error: 0.47374436518430474\n",
      "Step: 4768 Weights: [0.35537152 2.13251077] , error: 0.4737443648519859\n",
      "Step: 4769 Weights: [0.35537333 2.13251056] , error: 0.4737443645211811\n",
      "Step: 4770 Weights: [0.35537513 2.13251035] , error: 0.473744364191883\n",
      "Step: 4771 Weights: [0.35537693 2.13251015] , error: 0.473744363864085\n",
      "Step: 4772 Weights: [0.35537873 2.13250994] , error: 0.4737443635377807\n",
      "Step: 4773 Weights: [0.35538052 2.13250974] , error: 0.47374436321296265\n",
      "Step: 4774 Weights: [0.35538231 2.13250953] , error: 0.47374436288962457\n",
      "Step: 4775 Weights: [0.35538409 2.13250933] , error: 0.4737443625677592\n",
      "Step: 4776 Weights: [0.35538587 2.13250913] , error: 0.4737443622473604\n",
      "Step: 4777 Weights: [0.35538765 2.13250892] , error: 0.47374436192842073\n",
      "Step: 4778 Weights: [0.35538942 2.13250872] , error: 0.47374436161093497\n",
      "Step: 4779 Weights: [0.35539118 2.13250852] , error: 0.47374436129489456\n",
      "Step: 4780 Weights: [0.35539295 2.13250832] , error: 0.4737443609802943\n",
      "Step: 4781 Weights: [0.35539471 2.13250811] , error: 0.47374436066712694\n",
      "Step: 4782 Weights: [0.35539646 2.13250791] , error: 0.47374436035538653\n",
      "Step: 4783 Weights: [0.35539821 2.13250771] , error: 0.473744360045067\n",
      "Step: 4784 Weights: [0.35539996 2.13250751] , error: 0.4737443597361606\n",
      "Step: 4785 Weights: [0.3554017  2.13250731] , error: 0.4737443594286608\n",
      "Step: 4786 Weights: [0.35540344 2.13250712] , error: 0.4737443591225625\n",
      "Step: 4787 Weights: [0.35540518 2.13250692] , error: 0.4737443588178585\n",
      "Step: 4788 Weights: [0.35540691 2.13250672] , error: 0.47374435851454316\n",
      "Step: 4789 Weights: [0.35540864 2.13250652] , error: 0.4737443582126089\n",
      "Step: 4790 Weights: [0.35541036 2.13250632] , error: 0.47374435791205055\n",
      "Step: 4791 Weights: [0.35541208 2.13250613] , error: 0.4737443576128611\n",
      "Step: 4792 Weights: [0.35541379 2.13250593] , error: 0.47374435731503506\n",
      "Step: 4793 Weights: [0.35541551 2.13250574] , error: 0.47374435701856404\n",
      "Step: 4794 Weights: [0.35541721 2.13250554] , error: 0.47374435672344695\n",
      "Step: 4795 Weights: [0.35541892 2.13250535] , error: 0.4737443564296723\n",
      "Step: 4796 Weights: [0.35542062 2.13250515] , error: 0.4737443561372362\n",
      "Step: 4797 Weights: [0.35542231 2.13250496] , error: 0.4737443558461323\n",
      "Step: 4798 Weights: [0.35542401 2.13250476] , error: 0.4737443555563551\n",
      "Step: 4799 Weights: [0.35542569 2.13250457] , error: 0.473744355267897\n",
      "Step: 4800 Weights: [0.35542738 2.13250438] , error: 0.47374435498075435\n",
      "Step: 4801 Weights: [0.35542906 2.13250419] , error: 0.47374435469491843\n",
      "Step: 4802 Weights: [0.35543074 2.13250399] , error: 0.4737443544103854\n",
      "Step: 4803 Weights: [0.35543241 2.1325038 ] , error: 0.47374435412714844\n",
      "Step: 4804 Weights: [0.35543408 2.13250361] , error: 0.47374435384520164\n",
      "Step: 4805 Weights: [0.35543574 2.13250342] , error: 0.4737443535645398\n",
      "Step: 4806 Weights: [0.35543741 2.13250323] , error: 0.4737443532851558\n",
      "Step: 4807 Weights: [0.35543906 2.13250304] , error: 0.4737443530070446\n",
      "Step: 4808 Weights: [0.35544072 2.13250285] , error: 0.47374435273020077\n",
      "Step: 4809 Weights: [0.35544237 2.13250266] , error: 0.4737443524546182\n",
      "Step: 4810 Weights: [0.35544401 2.13250248] , error: 0.47374435218029115\n",
      "Step: 4811 Weights: [0.35544566 2.13250229] , error: 0.47374435190721426\n",
      "Step: 4812 Weights: [0.3554473 2.1325021] , error: 0.47374435163537965\n",
      "Step: 4813 Weights: [0.35544893 2.13250191] , error: 0.47374435136478577\n",
      "Step: 4814 Weights: [0.35545056 2.13250173] , error: 0.473744351095423\n",
      "Step: 4815 Weights: [0.35545219 2.13250154] , error: 0.47374435082728794\n",
      "Step: 4816 Weights: [0.35545381 2.13250135] , error: 0.47374435056037417\n",
      "Step: 4817 Weights: [0.35545544 2.13250117] , error: 0.47374435029467665\n",
      "Step: 4818 Weights: [0.35545705 2.13250098] , error: 0.473744350030189\n",
      "Step: 4819 Weights: [0.35545867 2.1325008 ] , error: 0.4737443497669066\n",
      "Step: 4820 Weights: [0.35546027 2.13250062] , error: 0.4737443495048234\n",
      "Step: 4821 Weights: [0.35546188 2.13250043] , error: 0.47374434924393416\n",
      "Step: 4822 Weights: [0.35546348 2.13250025] , error: 0.47374434898423334\n",
      "Step: 4823 Weights: [0.35546508 2.13250007] , error: 0.4737443487257169\n",
      "Step: 4824 Weights: [0.35546668 2.13249988] , error: 0.47374434846837543\n",
      "Step: 4825 Weights: [0.35546827 2.1324997 ] , error: 0.4737443482122101\n",
      "Step: 4826 Weights: [0.35546985 2.13249952] , error: 0.4737443479572091\n",
      "Step: 4827 Weights: [0.35547144 2.13249934] , error: 0.47374434770337015\n",
      "Step: 4828 Weights: [0.35547302 2.13249916] , error: 0.473744347450688\n",
      "Step: 4829 Weights: [0.35547459 2.13249898] , error: 0.4737443471991574\n",
      "Step: 4830 Weights: [0.35547617 2.1324988 ] , error: 0.4737443469487721\n",
      "Step: 4831 Weights: [0.35547774 2.13249862] , error: 0.4737443466995279\n",
      "Step: 4832 Weights: [0.3554793  2.13249844] , error: 0.47374434645141844\n",
      "Step: 4833 Weights: [0.35548086 2.13249826] , error: 0.47374434620443917\n",
      "Step: 4834 Weights: [0.35548242 2.13249808] , error: 0.47374434595858583\n",
      "Step: 4835 Weights: [0.35548398 2.13249791] , error: 0.4737443457138517\n",
      "Step: 4836 Weights: [0.35548553 2.13249773] , error: 0.4737443454702331\n",
      "Step: 4837 Weights: [0.35548708 2.13249755] , error: 0.4737443452277241\n",
      "Step: 4838 Weights: [0.35548862 2.13249737] , error: 0.47374434498632023\n",
      "Step: 4839 Weights: [0.35549016 2.1324972 ] , error: 0.47374434474601523\n",
      "Step: 4840 Weights: [0.3554917  2.13249702] , error: 0.47374434450680625\n",
      "Step: 4841 Weights: [0.35549324 2.13249685] , error: 0.4737443442686864\n",
      "Step: 4842 Weights: [0.35549477 2.13249667] , error: 0.47374434403165044\n",
      "Step: 4843 Weights: [0.35549629 2.1324965 ] , error: 0.4737443437956955\n",
      "Step: 4844 Weights: [0.35549782 2.13249632] , error: 0.4737443435608158\n",
      "Step: 4845 Weights: [0.35549934 2.13249615] , error: 0.4737443433270043\n",
      "Step: 4846 Weights: [0.35550085 2.13249598] , error: 0.4737443430942597\n",
      "Step: 4847 Weights: [0.35550237 2.1324958 ] , error: 0.4737443428625751\n",
      "Step: 4848 Weights: [0.35550388 2.13249563] , error: 0.47374434263194615\n",
      "Step: 4849 Weights: [0.35550538 2.13249546] , error: 0.473744342402367\n",
      "Step: 4850 Weights: [0.35550688 2.13249529] , error: 0.4737443421738341\n",
      "Step: 4851 Weights: [0.35550838 2.13249511] , error: 0.4737443419463422\n",
      "Step: 4852 Weights: [0.35550988 2.13249494] , error: 0.4737443417198866\n",
      "Step: 4853 Weights: [0.35551137 2.13249477] , error: 0.47374434149446254\n",
      "Step: 4854 Weights: [0.35551286 2.1324946 ] , error: 0.473744341270066\n",
      "Step: 4855 Weights: [0.35551435 2.13249443] , error: 0.47374434104669183\n",
      "Step: 4856 Weights: [0.35551583 2.13249426] , error: 0.4737443408243349\n",
      "Step: 4857 Weights: [0.35551731 2.13249409] , error: 0.47374434060299153\n",
      "Step: 4858 Weights: [0.35551878 2.13249392] , error: 0.4737443403826557\n",
      "Step: 4859 Weights: [0.35552026 2.13249376] , error: 0.4737443401633238\n",
      "Step: 4860 Weights: [0.35552173 2.13249359] , error: 0.47374433994499127\n",
      "Step: 4861 Weights: [0.35552319 2.13249342] , error: 0.47374433972765245\n",
      "Step: 4862 Weights: [0.35552465 2.13249325] , error: 0.47374433951130546\n",
      "Step: 4863 Weights: [0.35552611 2.13249309] , error: 0.4737443392959425\n",
      "Step: 4864 Weights: [0.35552757 2.13249292] , error: 0.47374433908156105\n",
      "Step: 4865 Weights: [0.35552902 2.13249275] , error: 0.4737443388681576\n",
      "Step: 4866 Weights: [0.35553047 2.13249259] , error: 0.4737443386557245\n",
      "Step: 4867 Weights: [0.35553191 2.13249242] , error: 0.4737443384442609\n",
      "Step: 4868 Weights: [0.35553336 2.13249226] , error: 0.4737443382337591\n",
      "Step: 4869 Weights: [0.3555348  2.13249209] , error: 0.4737443380242173\n",
      "Step: 4870 Weights: [0.35553623 2.13249193] , error: 0.47374433781562997\n",
      "Step: 4871 Weights: [0.35553766 2.13249177] , error: 0.47374433760799195\n",
      "Step: 4872 Weights: [0.35553909 2.1324916 ] , error: 0.47374433740130073\n",
      "Step: 4873 Weights: [0.35554052 2.13249144] , error: 0.473744337195551\n",
      "Step: 4874 Weights: [0.35554194 2.13249128] , error: 0.4737443369907381\n",
      "Step: 4875 Weights: [0.35554336 2.13249111] , error: 0.47374433678685834\n",
      "Step: 4876 Weights: [0.35554478 2.13249095] , error: 0.47374433658390835\n",
      "Step: 4877 Weights: [0.35554619 2.13249079] , error: 0.47374433638188207\n",
      "Step: 4878 Weights: [0.3555476  2.13249063] , error: 0.473744336180776\n",
      "Step: 4879 Weights: [0.35554901 2.13249047] , error: 0.4737443359805865\n",
      "Step: 4880 Weights: [0.35555041 2.13249031] , error: 0.4737443357813088\n",
      "Step: 4881 Weights: [0.35555181 2.13249015] , error: 0.4737443355829393\n",
      "Step: 4882 Weights: [0.35555321 2.13248999] , error: 0.4737443353854733\n",
      "Step: 4883 Weights: [0.3555546  2.13248983] , error: 0.47374433518890596\n",
      "Step: 4884 Weights: [0.35555599 2.13248967] , error: 0.4737443349932359\n",
      "Step: 4885 Weights: [0.35555738 2.13248951] , error: 0.4737443347984559\n",
      "Step: 4886 Weights: [0.35555876 2.13248935] , error: 0.47374433460456333\n",
      "Step: 4887 Weights: [0.35556014 2.13248919] , error: 0.4737443344115547\n",
      "Step: 4888 Weights: [0.35556152 2.13248904] , error: 0.4737443342194249\n",
      "Step: 4889 Weights: [0.3555629  2.13248888] , error: 0.47374433402817023\n",
      "Step: 4890 Weights: [0.35556427 2.13248872] , error: 0.47374433383778763\n",
      "Step: 4891 Weights: [0.35556564 2.13248857] , error: 0.47374433364827195\n",
      "Step: 4892 Weights: [0.355567   2.13248841] , error: 0.4737443334596192\n",
      "Step: 4893 Weights: [0.35556836 2.13248825] , error: 0.47374433327182663\n",
      "Step: 4894 Weights: [0.35556972 2.1324881 ] , error: 0.47374433308488934\n",
      "Step: 4895 Weights: [0.35557108 2.13248794] , error: 0.47374433289880324\n",
      "Step: 4896 Weights: [0.35557243 2.13248779] , error: 0.47374433271356503\n",
      "Step: 4897 Weights: [0.35557378 2.13248763] , error: 0.4737443325291707\n",
      "Step: 4898 Weights: [0.35557513 2.13248748] , error: 0.4737443323456163\n",
      "Step: 4899 Weights: [0.35557647 2.13248733] , error: 0.4737443321628987\n",
      "Step: 4900 Weights: [0.35557781 2.13248717] , error: 0.4737443319810125\n",
      "Step: 4901 Weights: [0.35557915 2.13248702] , error: 0.4737443317999558\n",
      "Step: 4902 Weights: [0.35558049 2.13248687] , error: 0.473744331619724\n",
      "Step: 4903 Weights: [0.35558182 2.13248672] , error: 0.47374433144031275\n",
      "Step: 4904 Weights: [0.35558315 2.13248656] , error: 0.4737443312617189\n",
      "Step: 4905 Weights: [0.35558447 2.13248641] , error: 0.4737443310839383\n",
      "Step: 4906 Weights: [0.35558579 2.13248626] , error: 0.473744330906968\n",
      "Step: 4907 Weights: [0.35558711 2.13248611] , error: 0.4737443307308044\n",
      "Step: 4908 Weights: [0.35558843 2.13248596] , error: 0.4737443305554426\n",
      "Step: 4909 Weights: [0.35558974 2.13248581] , error: 0.47374433038088004\n",
      "Step: 4910 Weights: [0.35559105 2.13248566] , error: 0.4737443302071132\n",
      "Step: 4911 Weights: [0.35559236 2.13248551] , error: 0.47374433003413674\n",
      "Step: 4912 Weights: [0.35559367 2.13248536] , error: 0.4737443298619487\n",
      "Step: 4913 Weights: [0.35559497 2.13248521] , error: 0.4737443296905449\n",
      "Step: 4914 Weights: [0.35559627 2.13248506] , error: 0.4737443295199233\n",
      "Step: 4915 Weights: [0.35559756 2.13248492] , error: 0.4737443293500781\n",
      "Step: 4916 Weights: [0.35559885 2.13248477] , error: 0.4737443291810066\n",
      "Step: 4917 Weights: [0.35560014 2.13248462] , error: 0.47374432901270486\n",
      "Step: 4918 Weights: [0.35560143 2.13248447] , error: 0.47374432884517054\n",
      "Step: 4919 Weights: [0.35560271 2.13248433] , error: 0.4737443286783993\n",
      "Step: 4920 Weights: [0.35560399 2.13248418] , error: 0.47374432851238774\n",
      "Step: 4921 Weights: [0.35560527 2.13248403] , error: 0.47374432834713254\n",
      "Step: 4922 Weights: [0.35560655 2.13248389] , error: 0.4737443281826299\n",
      "Step: 4923 Weights: [0.35560782 2.13248374] , error: 0.4737443280188771\n",
      "Step: 4924 Weights: [0.35560909 2.1324836 ] , error: 0.47374432785587006\n",
      "Step: 4925 Weights: [0.35561035 2.13248345] , error: 0.473744327693606\n",
      "Step: 4926 Weights: [0.35561162 2.13248331] , error: 0.47374432753208096\n",
      "Step: 4927 Weights: [0.35561288 2.13248316] , error: 0.47374432737129146\n",
      "Step: 4928 Weights: [0.35561414 2.13248302] , error: 0.4737443272112341\n",
      "Step: 4929 Weights: [0.35561539 2.13248288] , error: 0.4737443270519074\n",
      "Step: 4930 Weights: [0.35561664 2.13248273] , error: 0.47374432689330503\n",
      "Step: 4931 Weights: [0.35561789 2.13248259] , error: 0.47374432673542605\n",
      "Step: 4932 Weights: [0.35561914 2.13248245] , error: 0.47374432657826593\n",
      "Step: 4933 Weights: [0.35562038 2.13248231] , error: 0.4737443264218215\n",
      "Step: 4934 Weights: [0.35562162 2.13248216] , error: 0.47374432626609\n",
      "Step: 4935 Weights: [0.35562286 2.13248202] , error: 0.47374432611106787\n",
      "Step: 4936 Weights: [0.3556241  2.13248188] , error: 0.4737443259567523\n",
      "Step: 4937 Weights: [0.35562533 2.13248174] , error: 0.47374432580313974\n",
      "Step: 4938 Weights: [0.35562656 2.1324816 ] , error: 0.4737443256502265\n",
      "Step: 4939 Weights: [0.35562778 2.13248146] , error: 0.4737443254980108\n",
      "Step: 4940 Weights: [0.35562901 2.13248132] , error: 0.47374432534648797\n",
      "Step: 4941 Weights: [0.35563023 2.13248118] , error: 0.4737443251956551\n",
      "Step: 4942 Weights: [0.35563145 2.13248104] , error: 0.4737443250455097\n",
      "Step: 4943 Weights: [0.35563266 2.1324809 ] , error: 0.4737443248960485\n",
      "Step: 4944 Weights: [0.35563387 2.13248076] , error: 0.473744324747267\n",
      "Step: 4945 Weights: [0.35563508 2.13248062] , error: 0.4737443245991651\n",
      "Step: 4946 Weights: [0.35563629 2.13248049] , error: 0.47374432445173703\n",
      "Step: 4947 Weights: [0.35563749 2.13248035] , error: 0.4737443243049812\n",
      "Step: 4948 Weights: [0.3556387  2.13248021] , error: 0.4737443241588929\n",
      "Step: 4949 Weights: [0.35563989 2.13248007] , error: 0.4737443240134701\n",
      "Step: 4950 Weights: [0.35564109 2.13247994] , error: 0.47374432386871057\n",
      "Step: 4951 Weights: [0.35564228 2.1324798 ] , error: 0.47374432372461023\n",
      "Step: 4952 Weights: [0.35564347 2.13247966] , error: 0.4737443235811662\n",
      "Step: 4953 Weights: [0.35564466 2.13247953] , error: 0.4737443234383759\n",
      "Step: 4954 Weights: [0.35564585 2.13247939] , error: 0.4737443232962364\n",
      "Step: 4955 Weights: [0.35564703 2.13247926] , error: 0.4737443231547437\n",
      "Step: 4956 Weights: [0.35564821 2.13247912] , error: 0.4737443230138954\n",
      "Step: 4957 Weights: [0.35564939 2.13247899] , error: 0.4737443228736892\n",
      "Step: 4958 Weights: [0.35565056 2.13247885] , error: 0.47374432273412226\n",
      "Step: 4959 Weights: [0.35565173 2.13247872] , error: 0.47374432259519006\n",
      "Step: 4960 Weights: [0.3556529  2.13247859] , error: 0.47374432245689196\n",
      "Step: 4961 Weights: [0.35565407 2.13247845] , error: 0.4737443223192229\n",
      "Step: 4962 Weights: [0.35565523 2.13247832] , error: 0.4737443221821821\n",
      "Step: 4963 Weights: [0.35565639 2.13247819] , error: 0.47374432204576433\n",
      "Step: 4964 Weights: [0.35565755 2.13247805] , error: 0.4737443219099691\n",
      "Step: 4965 Weights: [0.35565871 2.13247792] , error: 0.47374432177479187\n",
      "Step: 4966 Weights: [0.35565986 2.13247779] , error: 0.4737443216402306\n",
      "Step: 4967 Weights: [0.35566101 2.13247766] , error: 0.47374432150628293\n",
      "Step: 4968 Weights: [0.35566216 2.13247753] , error: 0.47374432137294425\n",
      "Step: 4969 Weights: [0.3556633 2.1324774] , error: 0.4737443212402135\n",
      "Step: 4970 Weights: [0.35566445 2.13247727] , error: 0.47374432110808773\n",
      "Step: 4971 Weights: [0.35566559 2.13247714] , error: 0.47374432097656405\n",
      "Step: 4972 Weights: [0.35566672 2.13247701] , error: 0.4737443208456384\n",
      "Step: 4973 Weights: [0.35566786 2.13247688] , error: 0.4737443207153108\n",
      "Step: 4974 Weights: [0.35566899 2.13247675] , error: 0.4737443205855759\n",
      "Step: 4975 Weights: [0.35567012 2.13247662] , error: 0.47374432045643217\n",
      "Step: 4976 Weights: [0.35567125 2.13247649] , error: 0.4737443203278776\n",
      "Step: 4977 Weights: [0.35567237 2.13247636] , error: 0.47374432019990736\n",
      "Step: 4978 Weights: [0.3556735  2.13247623] , error: 0.473744320072521\n",
      "Step: 4979 Weights: [0.35567461 2.1324761 ] , error: 0.4737443199457142\n",
      "Step: 4980 Weights: [0.35567573 2.13247598] , error: 0.47374431981948617\n",
      "Step: 4981 Weights: [0.35567685 2.13247585] , error: 0.47374431969383185\n",
      "Step: 4982 Weights: [0.35567796 2.13247572] , error: 0.47374431956875035\n",
      "Step: 4983 Weights: [0.35567907 2.13247559] , error: 0.47374431944423967\n",
      "Step: 4984 Weights: [0.35568017 2.13247547] , error: 0.47374431932029565\n",
      "Step: 4985 Weights: [0.35568128 2.13247534] , error: 0.473744319196916\n",
      "Step: 4986 Weights: [0.35568238 2.13247522] , error: 0.473744319074098\n",
      "Step: 4987 Weights: [0.35568348 2.13247509] , error: 0.47374431895184077\n",
      "Step: 4988 Weights: [0.35568458 2.13247496] , error: 0.47374431883014023\n",
      "Step: 4989 Weights: [0.35568567 2.13247484] , error: 0.4737443187089939\n",
      "Step: 4990 Weights: [0.35568676 2.13247471] , error: 0.473744318588399\n",
      "Step: 4991 Weights: [0.35568785 2.13247459] , error: 0.4737443184683534\n",
      "Step: 4992 Weights: [0.35568894 2.13247447] , error: 0.47374431834885533\n",
      "Step: 4993 Weights: [0.35569002 2.13247434] , error: 0.4737443182299014\n",
      "Step: 4994 Weights: [0.3556911  2.13247422] , error: 0.47374431811148887\n",
      "Step: 4995 Weights: [0.35569218 2.13247409] , error: 0.47374431799361727\n",
      "Step: 4996 Weights: [0.35569326 2.13247397] , error: 0.4737443178762811\n",
      "Step: 4997 Weights: [0.35569433 2.13247385] , error: 0.47374431775948\n",
      "Step: 4998 Weights: [0.35569541 2.13247373] , error: 0.47374431764321123\n",
      "Step: 4999 Weights: [0.35569648 2.1324736 ] , error: 0.47374431752747137\n",
      "Step: 5000 Weights: [0.35569754 2.13247348] , error: 0.47374431741225975\n",
      "Step: 5001 Weights: [0.35569861 2.13247336] , error: 0.4737443172975723\n",
      "Step: 5002 Weights: [0.35569967 2.13247324] , error: 0.47374431718340704\n",
      "Step: 5003 Weights: [0.35570073 2.13247312] , error: 0.47374431706976283\n",
      "Step: 5004 Weights: [0.35570179 2.132473  ] , error: 0.47374431695663644\n",
      "Step: 5005 Weights: [0.35570284 2.13247288] , error: 0.4737443168440246\n",
      "Step: 5006 Weights: [0.35570389 2.13247275] , error: 0.4737443167319267\n",
      "Step: 5007 Weights: [0.35570494 2.13247263] , error: 0.47374431662033917\n",
      "Step: 5008 Weights: [0.35570599 2.13247252] , error: 0.47374431650925897\n",
      "Step: 5009 Weights: [0.35570704 2.1324724 ] , error: 0.47374431639868536\n",
      "Step: 5010 Weights: [0.35570808 2.13247228] , error: 0.4737443162886164\n",
      "Step: 5011 Weights: [0.35570912 2.13247216] , error: 0.4737443161790475\n",
      "Step: 5012 Weights: [0.35571016 2.13247204] , error: 0.4737443160699788\n",
      "Step: 5013 Weights: [0.35571119 2.13247192] , error: 0.473744315961406\n",
      "Step: 5014 Weights: [0.35571223 2.1324718 ] , error: 0.47374431585332827\n",
      "Step: 5015 Weights: [0.35571326 2.13247168] , error: 0.47374431574574355\n",
      "Step: 5016 Weights: [0.35571429 2.13247157] , error: 0.47374431563864816\n",
      "Step: 5017 Weights: [0.35571531 2.13247145] , error: 0.4737443155320407\n",
      "Step: 5018 Weights: [0.35571634 2.13247133] , error: 0.47374431542591927\n",
      "Step: 5019 Weights: [0.35571736 2.13247121] , error: 0.47374431532028116\n",
      "Step: 5020 Weights: [0.35571838 2.1324711 ] , error: 0.47374431521512456\n",
      "Step: 5021 Weights: [0.3557194  2.13247098] , error: 0.4737443151104471\n",
      "Step: 5022 Weights: [0.35572041 2.13247087] , error: 0.473744315006246\n",
      "Step: 5023 Weights: [0.35572142 2.13247075] , error: 0.4737443149025192\n",
      "Step: 5024 Weights: [0.35572243 2.13247063] , error: 0.4737443147992656\n",
      "Step: 5025 Weights: [0.35572344 2.13247052] , error: 0.47374431469648276\n",
      "Step: 5026 Weights: [0.35572445 2.1324704 ] , error: 0.4737443145941684\n",
      "Step: 5027 Weights: [0.35572545 2.13247029] , error: 0.47374431449231835\n",
      "Step: 5028 Weights: [0.35572645 2.13247018] , error: 0.47374431439093373\n",
      "Step: 5029 Weights: [0.35572745 2.13247006] , error: 0.47374431429001085\n",
      "Step: 5030 Weights: [0.35572845 2.13246995] , error: 0.47374431418954654\n",
      "Step: 5031 Weights: [0.35572944 2.13246983] , error: 0.4737443140895415\n",
      "Step: 5032 Weights: [0.35573043 2.13246972] , error: 0.4737443139899912\n",
      "Step: 5033 Weights: [0.35573142 2.13246961] , error: 0.4737443138908941\n",
      "Step: 5034 Weights: [0.35573241 2.13246949] , error: 0.47374431379224935\n",
      "Step: 5035 Weights: [0.35573339 2.13246938] , error: 0.47374431369405334\n",
      "Step: 5036 Weights: [0.35573438 2.13246927] , error: 0.4737443135963051\n",
      "Step: 5037 Weights: [0.35573536 2.13246916] , error: 0.4737443134990014\n",
      "Step: 5038 Weights: [0.35573634 2.13246904] , error: 0.4737443134021426\n",
      "Step: 5039 Weights: [0.35573731 2.13246893] , error: 0.47374431330572453\n",
      "Step: 5040 Weights: [0.35573829 2.13246882] , error: 0.4737443132097441\n",
      "Step: 5041 Weights: [0.35573926 2.13246871] , error: 0.47374431311420245\n",
      "Step: 5042 Weights: [0.35574023 2.1324686 ] , error: 0.4737443130190952\n",
      "Step: 5043 Weights: [0.35574119 2.13246849] , error: 0.4737443129244222\n",
      "Step: 5044 Weights: [0.35574216 2.13246838] , error: 0.4737443128301795\n",
      "Step: 5045 Weights: [0.35574312 2.13246827] , error: 0.47374431273636736\n",
      "Step: 5046 Weights: [0.35574408 2.13246816] , error: 0.4737443126429813\n",
      "Step: 5047 Weights: [0.35574504 2.13246805] , error: 0.4737443125500212\n",
      "Step: 5048 Weights: [0.355746   2.13246794] , error: 0.47374431245748483\n",
      "Step: 5049 Weights: [0.35574695 2.13246783] , error: 0.4737443123653691\n",
      "Step: 5050 Weights: [0.3557479  2.13246772] , error: 0.473744312273674\n",
      "Step: 5051 Weights: [0.35574885 2.13246761] , error: 0.47374431218239704\n",
      "Step: 5052 Weights: [0.3557498 2.1324675] , error: 0.4737443120915353\n",
      "Step: 5053 Weights: [0.35575075 2.1324674 ] , error: 0.47374431200108635\n",
      "Step: 5054 Weights: [0.35575169 2.13246729] , error: 0.4737443119110512\n",
      "Step: 5055 Weights: [0.35575263 2.13246718] , error: 0.4737443118214249\n",
      "Step: 5056 Weights: [0.35575357 2.13246707] , error: 0.47374431173220727\n",
      "Step: 5057 Weights: [0.35575451 2.13246697] , error: 0.4737443116433977\n",
      "Step: 5058 Weights: [0.35575544 2.13246686] , error: 0.4737443115549911\n",
      "Step: 5059 Weights: [0.35575637 2.13246675] , error: 0.47374431146698626\n",
      "Step: 5060 Weights: [0.3557573  2.13246665] , error: 0.47374431137938505\n",
      "Step: 5061 Weights: [0.35575823 2.13246654] , error: 0.4737443112921814\n",
      "Step: 5062 Weights: [0.35575916 2.13246643] , error: 0.4737443112053741\n",
      "Step: 5063 Weights: [0.35576008 2.13246633] , error: 0.4737443111189633\n",
      "Step: 5064 Weights: [0.355761   2.13246622] , error: 0.4737443110329464\n",
      "Step: 5065 Weights: [0.35576192 2.13246612] , error: 0.47374431094732117\n",
      "Step: 5066 Weights: [0.35576284 2.13246601] , error: 0.4737443108620859\n",
      "Step: 5067 Weights: [0.35576376 2.13246591] , error: 0.473744310777239\n",
      "Step: 5068 Weights: [0.35576467 2.1324658 ] , error: 0.47374431069277856\n",
      "Step: 5069 Weights: [0.35576558 2.1324657 ] , error: 0.4737443106087025\n",
      "Step: 5070 Weights: [0.35576649 2.1324656 ] , error: 0.4737443105250099\n",
      "Step: 5071 Weights: [0.3557674  2.13246549] , error: 0.4737443104416981\n",
      "Step: 5072 Weights: [0.35576831 2.13246539] , error: 0.4737443103587664\n",
      "Step: 5073 Weights: [0.35576921 2.13246529] , error: 0.473744310276213\n",
      "Step: 5074 Weights: [0.35577011 2.13246518] , error: 0.47374431019403435\n",
      "Step: 5075 Weights: [0.35577101 2.13246508] , error: 0.473744310112231\n",
      "Step: 5076 Weights: [0.35577191 2.13246498] , error: 0.47374431003080025\n",
      "Step: 5077 Weights: [0.3557728  2.13246487] , error: 0.47374430994974026\n",
      "Step: 5078 Weights: [0.35577369 2.13246477] , error: 0.4737443098690493\n",
      "Step: 5079 Weights: [0.35577458 2.13246467] , error: 0.47374430978872595\n",
      "Step: 5080 Weights: [0.35577547 2.13246457] , error: 0.47374430970876935\n",
      "Step: 5081 Weights: [0.35577636 2.13246447] , error: 0.47374430962917646\n",
      "Step: 5082 Weights: [0.35577725 2.13246437] , error: 0.47374430954994573\n",
      "Step: 5083 Weights: [0.35577813 2.13246427] , error: 0.4737443094710765\n",
      "Step: 5084 Weights: [0.35577901 2.13246416] , error: 0.47374430939256673\n",
      "Step: 5085 Weights: [0.35577989 2.13246406] , error: 0.4737443093144135\n",
      "Step: 5086 Weights: [0.35578076 2.13246396] , error: 0.4737443092366175\n",
      "Step: 5087 Weights: [0.35578164 2.13246386] , error: 0.47374430915917565\n",
      "Step: 5088 Weights: [0.35578251 2.13246376] , error: 0.4737443090820859\n",
      "Step: 5089 Weights: [0.35578338 2.13246366] , error: 0.4737443090053483\n",
      "Step: 5090 Weights: [0.35578425 2.13246356] , error: 0.4737443089289602\n",
      "Step: 5091 Weights: [0.35578512 2.13246347] , error: 0.4737443088529205\n",
      "Step: 5092 Weights: [0.35578598 2.13246337] , error: 0.4737443087772258\n",
      "Step: 5093 Weights: [0.35578685 2.13246327] , error: 0.47374430870187817\n",
      "Step: 5094 Weights: [0.35578771 2.13246317] , error: 0.4737443086268706\n",
      "Step: 5095 Weights: [0.35578857 2.13246307] , error: 0.4737443085522066\n",
      "Step: 5096 Weights: [0.35578942 2.13246297] , error: 0.4737443084778831\n",
      "Step: 5097 Weights: [0.35579028 2.13246288] , error: 0.47374430840389714\n",
      "Step: 5098 Weights: [0.35579113 2.13246278] , error: 0.4737443083302486\n",
      "Step: 5099 Weights: [0.35579198 2.13246268] , error: 0.47374430825693614\n",
      "Step: 5100 Weights: [0.35579283 2.13246258] , error: 0.47374430818395713\n",
      "Step: 5101 Weights: [0.35579368 2.13246249] , error: 0.47374430811131096\n",
      "Step: 5102 Weights: [0.35579452 2.13246239] , error: 0.4737443080389949\n",
      "Step: 5103 Weights: [0.35579537 2.13246229] , error: 0.47374430796700917\n",
      "Step: 5104 Weights: [0.35579621 2.1324622 ] , error: 0.47374430789535105\n",
      "Step: 5105 Weights: [0.35579705 2.1324621 ] , error: 0.4737443078240193\n",
      "Step: 5106 Weights: [0.35579789 2.13246201] , error: 0.4737443077530129\n",
      "Step: 5107 Weights: [0.35579872 2.13246191] , error: 0.4737443076823297\n",
      "Step: 5108 Weights: [0.35579956 2.13246181] , error: 0.4737443076119686\n",
      "Step: 5109 Weights: [0.35580039 2.13246172] , error: 0.4737443075419279\n",
      "Step: 5110 Weights: [0.35580122 2.13246162] , error: 0.473744307472206\n",
      "Step: 5111 Weights: [0.35580205 2.13246153] , error: 0.47374430740280216\n",
      "Step: 5112 Weights: [0.35580287 2.13246144] , error: 0.4737443073337144\n",
      "Step: 5113 Weights: [0.3558037  2.13246134] , error: 0.4737443072649411\n",
      "Step: 5114 Weights: [0.35580452 2.13246125] , error: 0.47374430719648136\n",
      "Step: 5115 Weights: [0.35580534 2.13246115] , error: 0.4737443071283337\n",
      "Step: 5116 Weights: [0.35580616 2.13246106] , error: 0.47374430706049625\n",
      "Step: 5117 Weights: [0.35580698 2.13246097] , error: 0.47374430699296816\n",
      "Step: 5118 Weights: [0.35580779 2.13246087] , error: 0.47374430692574704\n",
      "Step: 5119 Weights: [0.3558086  2.13246078] , error: 0.47374430685883223\n",
      "Step: 5120 Weights: [0.35580942 2.13246069] , error: 0.47374430679222357\n",
      "Step: 5121 Weights: [0.35581023 2.13246059] , error: 0.47374430672591694\n",
      "Step: 5122 Weights: [0.35581103 2.1324605 ] , error: 0.4737443066599127\n",
      "Step: 5123 Weights: [0.35581184 2.13246041] , error: 0.4737443065942095\n",
      "Step: 5124 Weights: [0.35581264 2.13246032] , error: 0.47374430652880484\n",
      "Step: 5125 Weights: [0.35581344 2.13246023] , error: 0.4737443064636992\n",
      "Step: 5126 Weights: [0.35581424 2.13246013] , error: 0.47374430639888937\n",
      "Step: 5127 Weights: [0.35581504 2.13246004] , error: 0.47374430633437525\n",
      "Step: 5128 Weights: [0.35581584 2.13245995] , error: 0.4737443062701548\n",
      "Step: 5129 Weights: [0.35581663 2.13245986] , error: 0.4737443062062265\n",
      "Step: 5130 Weights: [0.35581743 2.13245977] , error: 0.47374430614258944\n",
      "Step: 5131 Weights: [0.35581822 2.13245968] , error: 0.47374430607924334\n",
      "Step: 5132 Weights: [0.35581901 2.13245959] , error: 0.4737443060161855\n",
      "Step: 5133 Weights: [0.3558198 2.1324595] , error: 0.4737443059534147\n",
      "Step: 5134 Weights: [0.35582058 2.13245941] , error: 0.47374430589093003\n",
      "Step: 5135 Weights: [0.35582137 2.13245932] , error: 0.47374430582872906\n",
      "Step: 5136 Weights: [0.35582215 2.13245923] , error: 0.4737443057668126\n",
      "Step: 5137 Weights: [0.35582293 2.13245914] , error: 0.47374430570517734\n",
      "Step: 5138 Weights: [0.35582371 2.13245905] , error: 0.47374430564382347\n",
      "Step: 5139 Weights: [0.35582448 2.13245896] , error: 0.4737443055827492\n",
      "Step: 5140 Weights: [0.35582526 2.13245888] , error: 0.473744305521953\n",
      "Step: 5141 Weights: [0.35582603 2.13245879] , error: 0.47374430546143387\n",
      "Step: 5142 Weights: [0.3558268 2.1324587] , error: 0.47374430540118945\n",
      "Step: 5143 Weights: [0.35582757 2.13245861] , error: 0.4737443053412206\n",
      "Step: 5144 Weights: [0.35582834 2.13245852] , error: 0.47374430528152545\n",
      "Step: 5145 Weights: [0.35582911 2.13245843] , error: 0.47374430522210115\n",
      "Step: 5146 Weights: [0.35582987 2.13245835] , error: 0.47374430516294724\n",
      "Step: 5147 Weights: [0.35583064 2.13245826] , error: 0.47374430510406385\n",
      "Step: 5148 Weights: [0.3558314  2.13245817] , error: 0.47374430504544807\n",
      "Step: 5149 Weights: [0.35583216 2.13245809] , error: 0.47374430498709924\n",
      "Step: 5150 Weights: [0.35583291 2.132458  ] , error: 0.47374430492901637\n",
      "Step: 5151 Weights: [0.35583367 2.13245791] , error: 0.47374430487119895\n",
      "Step: 5152 Weights: [0.35583442 2.13245783] , error: 0.47374430481364416\n",
      "Step: 5153 Weights: [0.35583518 2.13245774] , error: 0.47374430475635143\n",
      "Step: 5154 Weights: [0.35583593 2.13245766] , error: 0.4737443046993197\n",
      "Step: 5155 Weights: [0.35583668 2.13245757] , error: 0.4737443046425483\n",
      "Step: 5156 Weights: [0.35583742 2.13245748] , error: 0.4737443045860348\n",
      "Step: 5157 Weights: [0.35583817 2.1324574 ] , error: 0.47374430452977967\n",
      "Step: 5158 Weights: [0.35583891 2.13245731] , error: 0.4737443044737805\n",
      "Step: 5159 Weights: [0.35583965 2.13245723] , error: 0.47374430441803533\n",
      "Step: 5160 Weights: [0.3558404  2.13245714] , error: 0.4737443043625459\n",
      "Step: 5161 Weights: [0.35584113 2.13245706] , error: 0.47374430430730796\n",
      "Step: 5162 Weights: [0.35584187 2.13245698] , error: 0.47374430425232217\n",
      "Step: 5163 Weights: [0.35584261 2.13245689] , error: 0.4737443041975862\n",
      "Step: 5164 Weights: [0.35584334 2.13245681] , error: 0.4737443041431012\n",
      "Step: 5165 Weights: [0.35584407 2.13245672] , error: 0.47374430408886276\n",
      "Step: 5166 Weights: [0.3558448  2.13245664] , error: 0.47374430403487283\n",
      "Step: 5167 Weights: [0.35584553 2.13245656] , error: 0.4737443039811283\n",
      "Step: 5168 Weights: [0.35584626 2.13245647] , error: 0.4737443039276278\n",
      "Step: 5169 Weights: [0.35584698 2.13245639] , error: 0.47374430387437166\n",
      "Step: 5170 Weights: [0.35584771 2.13245631] , error: 0.4737443038213584\n",
      "Step: 5171 Weights: [0.35584843 2.13245623] , error: 0.4737443037685858\n",
      "Step: 5172 Weights: [0.35584915 2.13245614] , error: 0.47374430371605447\n",
      "Step: 5173 Weights: [0.35584987 2.13245606] , error: 0.473744303663762\n",
      "Step: 5174 Weights: [0.35585059 2.13245598] , error: 0.4737443036117078\n",
      "Step: 5175 Weights: [0.3558513 2.1324559] , error: 0.4737443035598914\n",
      "Step: 5176 Weights: [0.35585202 2.13245581] , error: 0.4737443035083098\n",
      "Step: 5177 Weights: [0.35585273 2.13245573] , error: 0.4737443034569646\n",
      "Step: 5178 Weights: [0.35585344 2.13245565] , error: 0.4737443034058527\n",
      "Step: 5179 Weights: [0.35585415 2.13245557] , error: 0.4737443033549734\n",
      "Step: 5180 Weights: [0.35585486 2.13245549] , error: 0.4737443033043258\n",
      "Step: 5181 Weights: [0.35585556 2.13245541] , error: 0.4737443032539095\n",
      "Step: 5182 Weights: [0.35585627 2.13245533] , error: 0.4737443032037221\n",
      "Step: 5183 Weights: [0.35585697 2.13245525] , error: 0.4737443031537645\n",
      "Step: 5184 Weights: [0.35585767 2.13245517] , error: 0.4737443031040331\n",
      "Step: 5185 Weights: [0.35585837 2.13245509] , error: 0.47374430305452886\n",
      "Step: 5186 Weights: [0.35585907 2.13245501] , error: 0.47374430300525094\n",
      "Step: 5187 Weights: [0.35585976 2.13245493] , error: 0.4737443029561965\n",
      "Step: 5188 Weights: [0.35586046 2.13245485] , error: 0.47374430290736536\n",
      "Step: 5189 Weights: [0.35586115 2.13245477] , error: 0.47374430285875785\n",
      "Step: 5190 Weights: [0.35586184 2.13245469] , error: 0.4737443028103702\n",
      "Step: 5191 Weights: [0.35586253 2.13245461] , error: 0.4737443027622046\n",
      "Step: 5192 Weights: [0.35586322 2.13245453] , error: 0.4737443027142568\n",
      "Step: 5193 Weights: [0.35586391 2.13245445] , error: 0.47374430266652867\n",
      "Step: 5194 Weights: [0.35586459 2.13245438] , error: 0.4737443026190178\n",
      "Step: 5195 Weights: [0.35586528 2.1324543 ] , error: 0.4737443025717232\n",
      "Step: 5196 Weights: [0.35586596 2.13245422] , error: 0.47374430252464433\n",
      "Step: 5197 Weights: [0.35586664 2.13245414] , error: 0.4737443024777791\n",
      "Step: 5198 Weights: [0.35586732 2.13245406] , error: 0.47374430243112775\n",
      "Step: 5199 Weights: [0.355868   2.13245399] , error: 0.4737443023846896\n",
      "Step: 5200 Weights: [0.35586867 2.13245391] , error: 0.47374430233846254\n",
      "Step: 5201 Weights: [0.35586935 2.13245383] , error: 0.4737443022924462\n",
      "Step: 5202 Weights: [0.35587002 2.13245376] , error: 0.47374430224663944\n",
      "Step: 5203 Weights: [0.35587069 2.13245368] , error: 0.4737443022010408\n",
      "Step: 5204 Weights: [0.35587136 2.1324536 ] , error: 0.4737443021556498\n",
      "Step: 5205 Weights: [0.35587203 2.13245353] , error: 0.47374430211046653\n",
      "Step: 5206 Weights: [0.35587269 2.13245345] , error: 0.47374430206548934\n",
      "Step: 5207 Weights: [0.35587336 2.13245337] , error: 0.4737443020207152\n",
      "Step: 5208 Weights: [0.35587402 2.1324533 ] , error: 0.4737443019761475\n",
      "Step: 5209 Weights: [0.35587469 2.13245322] , error: 0.47374430193178113\n",
      "Step: 5210 Weights: [0.35587535 2.13245315] , error: 0.47374430188761657\n",
      "Step: 5211 Weights: [0.35587601 2.13245307] , error: 0.4737443018436547\n",
      "Step: 5212 Weights: [0.35587666 2.132453  ] , error: 0.4737443017998923\n",
      "Step: 5213 Weights: [0.35587732 2.13245292] , error: 0.4737443017563293\n",
      "Step: 5214 Weights: [0.35587797 2.13245285] , error: 0.4737443017129645\n",
      "Step: 5215 Weights: [0.35587863 2.13245277] , error: 0.4737443016697969\n",
      "Step: 5216 Weights: [0.35587928 2.1324527 ] , error: 0.4737443016268279\n",
      "Step: 5217 Weights: [0.35587993 2.13245262] , error: 0.47374430158405223\n",
      "Step: 5218 Weights: [0.35588058 2.13245255] , error: 0.47374430154147307\n",
      "Step: 5219 Weights: [0.35588122 2.13245247] , error: 0.47374430149908764\n",
      "Step: 5220 Weights: [0.35588187 2.1324524 ] , error: 0.4737443014568947\n",
      "Step: 5221 Weights: [0.35588251 2.13245233] , error: 0.47374430141489443\n",
      "Step: 5222 Weights: [0.35588316 2.13245225] , error: 0.47374430137308454\n",
      "Step: 5223 Weights: [0.3558838  2.13245218] , error: 0.473744301331467\n",
      "Step: 5224 Weights: [0.35588444 2.13245211] , error: 0.4737443012900372\n",
      "Step: 5225 Weights: [0.35588508 2.13245203] , error: 0.4737443012487969\n",
      "Step: 5226 Weights: [0.35588571 2.13245196] , error: 0.4737443012077442\n",
      "Step: 5227 Weights: [0.35588635 2.13245189] , error: 0.47374430116688\n",
      "Step: 5228 Weights: [0.35588698 2.13245182] , error: 0.4737443011261999\n",
      "Step: 5229 Weights: [0.35588762 2.13245174] , error: 0.47374430108570614\n",
      "Step: 5230 Weights: [0.35588825 2.13245167] , error: 0.4737443010453969\n",
      "Step: 5231 Weights: [0.35588888 2.1324516 ] , error: 0.4737443010052708\n",
      "Step: 5232 Weights: [0.35588951 2.13245153] , error: 0.473744300965328\n",
      "Step: 5233 Weights: [0.35589013 2.13245146] , error: 0.4737443009255667\n",
      "Step: 5234 Weights: [0.35589076 2.13245138] , error: 0.4737443008859876\n",
      "Step: 5235 Weights: [0.35589138 2.13245131] , error: 0.4737443008465873\n",
      "Step: 5236 Weights: [0.355892   2.13245124] , error: 0.47374430080736785\n",
      "Step: 5237 Weights: [0.35589262 2.13245117] , error: 0.4737443007683254\n",
      "Step: 5238 Weights: [0.35589324 2.1324511 ] , error: 0.47374430072946233\n",
      "Step: 5239 Weights: [0.35589386 2.13245103] , error: 0.4737443006907766\n",
      "Step: 5240 Weights: [0.35589448 2.13245096] , error: 0.47374430065226597\n",
      "Step: 5241 Weights: [0.3558951  2.13245089] , error: 0.47374430061393086\n",
      "Step: 5242 Weights: [0.35589571 2.13245082] , error: 0.47374430057577044\n",
      "Step: 5243 Weights: [0.35589632 2.13245075] , error: 0.4737443005377849\n",
      "Step: 5244 Weights: [0.35589693 2.13245068] , error: 0.4737443004999714\n",
      "Step: 5245 Weights: [0.35589754 2.13245061] , error: 0.47374430046232985\n",
      "Step: 5246 Weights: [0.35589815 2.13245054] , error: 0.4737443004248599\n",
      "Step: 5247 Weights: [0.35589876 2.13245047] , error: 0.47374430038756105\n",
      "Step: 5248 Weights: [0.35589936 2.1324504 ] , error: 0.4737443003504328\n",
      "Step: 5249 Weights: [0.35589997 2.13245033] , error: 0.4737443003134729\n",
      "Step: 5250 Weights: [0.35590057 2.13245026] , error: 0.47374430027668313\n",
      "Step: 5251 Weights: [0.35590117 2.13245019] , error: 0.4737443002400573\n",
      "Step: 5252 Weights: [0.35590177 2.13245012] , error: 0.4737443002036009\n",
      "Step: 5253 Weights: [0.35590237 2.13245006] , error: 0.47374430016731006\n",
      "Step: 5254 Weights: [0.35590297 2.13244999] , error: 0.4737443001311852\n",
      "Step: 5255 Weights: [0.35590357 2.13244992] , error: 0.47374430009522295\n",
      "Step: 5256 Weights: [0.35590416 2.13244985] , error: 0.4737443000594262\n",
      "Step: 5257 Weights: [0.35590475 2.13244978] , error: 0.4737443000237924\n",
      "Step: 5258 Weights: [0.35590535 2.13244972] , error: 0.47374429998832035\n",
      "Step: 5259 Weights: [0.35590594 2.13244965] , error: 0.4737442999530101\n",
      "Step: 5260 Weights: [0.35590653 2.13244958] , error: 0.47374429991786127\n",
      "Step: 5261 Weights: [0.35590711 2.13244951] , error: 0.47374429988287187\n",
      "Step: 5262 Weights: [0.3559077  2.13244945] , error: 0.47374429984804206\n",
      "Step: 5263 Weights: [0.35590829 2.13244938] , error: 0.47374429981337174\n",
      "Step: 5264 Weights: [0.35590887 2.13244931] , error: 0.4737442997788579\n",
      "Step: 5265 Weights: [0.35590945 2.13244925] , error: 0.47374429974450266\n",
      "Step: 5266 Weights: [0.35591003 2.13244918] , error: 0.4737442997103024\n",
      "Step: 5267 Weights: [0.35591061 2.13244911] , error: 0.4737442996762598\n",
      "Step: 5268 Weights: [0.35591119 2.13244905] , error: 0.473744299642371\n",
      "Step: 5269 Weights: [0.35591177 2.13244898] , error: 0.4737442996086364\n",
      "Step: 5270 Weights: [0.35591235 2.13244892] , error: 0.47374429957505626\n",
      "Step: 5271 Weights: [0.35591292 2.13244885] , error: 0.47374429954162905\n",
      "Step: 5272 Weights: [0.3559135  2.13244878] , error: 0.47374429950835345\n",
      "Step: 5273 Weights: [0.35591407 2.13244872] , error: 0.47374429947522945\n",
      "Step: 5274 Weights: [0.35591464 2.13244865] , error: 0.4737442994422573\n",
      "Step: 5275 Weights: [0.35591521 2.13244859] , error: 0.47374429940943447\n",
      "Step: 5276 Weights: [0.35591578 2.13244852] , error: 0.4737442993767625\n",
      "Step: 5277 Weights: [0.35591634 2.13244846] , error: 0.47374429934423795\n",
      "Step: 5278 Weights: [0.35591691 2.13244839] , error: 0.47374429931186146\n",
      "Step: 5279 Weights: [0.35591747 2.13244833] , error: 0.47374429927963374\n",
      "Step: 5280 Weights: [0.35591804 2.13244826] , error: 0.4737442992475513\n",
      "Step: 5281 Weights: [0.3559186 2.1324482] , error: 0.4737442992156164\n",
      "Step: 5282 Weights: [0.35591916 2.13244814] , error: 0.47374429918382654\n",
      "Step: 5283 Weights: [0.35591972 2.13244807] , error: 0.47374429915218086\n",
      "Step: 5284 Weights: [0.35592028 2.13244801] , error: 0.4737442991206802\n",
      "Step: 5285 Weights: [0.35592083 2.13244794] , error: 0.4737442990893221\n",
      "Step: 5286 Weights: [0.35592139 2.13244788] , error: 0.473744299058108\n",
      "Step: 5287 Weights: [0.35592194 2.13244782] , error: 0.47374429902703497\n",
      "Step: 5288 Weights: [0.35592249 2.13244775] , error: 0.4737442989961044\n",
      "Step: 5289 Weights: [0.35592305 2.13244769] , error: 0.4737442989653143\n",
      "Step: 5290 Weights: [0.3559236  2.13244763] , error: 0.47374429893466447\n",
      "Step: 5291 Weights: [0.35592415 2.13244757] , error: 0.47374429890415476\n",
      "Step: 5292 Weights: [0.35592469 2.1324475 ] , error: 0.47374429887378416\n",
      "Step: 5293 Weights: [0.35592524 2.13244744] , error: 0.4737442988435514\n",
      "Step: 5294 Weights: [0.35592579 2.13244738] , error: 0.47374429881345603\n",
      "Step: 5295 Weights: [0.35592633 2.13244732] , error: 0.47374429878349805\n",
      "Step: 5296 Weights: [0.35592687 2.13244725] , error: 0.47374429875367763\n",
      "Step: 5297 Weights: [0.35592741 2.13244719] , error: 0.4737442987239909\n",
      "Step: 5298 Weights: [0.35592795 2.13244713] , error: 0.4737442986944413\n",
      "Step: 5299 Weights: [0.35592849 2.13244707] , error: 0.4737442986650246\n",
      "Step: 5300 Weights: [0.35592903 2.13244701] , error: 0.47374429863574374\n",
      "Step: 5301 Weights: [0.35592957 2.13244695] , error: 0.4737442986065957\n",
      "Step: 5302 Weights: [0.3559301  2.13244688] , error: 0.4737442985775797\n",
      "Step: 5303 Weights: [0.35593064 2.13244682] , error: 0.4737442985486962\n",
      "Step: 5304 Weights: [0.35593117 2.13244676] , error: 0.47374429851994515\n",
      "Step: 5305 Weights: [0.3559317 2.1324467] , error: 0.47374429849132355\n",
      "Step: 5306 Weights: [0.35593223 2.13244664] , error: 0.4737442984628336\n",
      "Step: 5307 Weights: [0.35593276 2.13244658] , error: 0.47374429843447463\n",
      "Step: 5308 Weights: [0.35593329 2.13244652] , error: 0.4737442984062421\n",
      "Step: 5309 Weights: [0.35593382 2.13244646] , error: 0.47374429837813914\n",
      "Step: 5310 Weights: [0.35593434 2.1324464 ] , error: 0.47374429835016457\n",
      "Step: 5311 Weights: [0.35593487 2.13244634] , error: 0.4737442983223164\n",
      "Step: 5312 Weights: [0.35593539 2.13244628] , error: 0.47374429829459697\n",
      "Step: 5313 Weights: [0.35593591 2.13244622] , error: 0.4737442982670024\n",
      "Step: 5314 Weights: [0.35593643 2.13244616] , error: 0.4737442982395331\n",
      "Step: 5315 Weights: [0.35593695 2.1324461 ] , error: 0.47374429821219066\n",
      "Step: 5316 Weights: [0.35593747 2.13244604] , error: 0.47374429818497177\n",
      "Step: 5317 Weights: [0.35593799 2.13244598] , error: 0.4737442981578773\n",
      "Step: 5318 Weights: [0.35593851 2.13244592] , error: 0.4737442981309056\n",
      "Step: 5319 Weights: [0.35593902 2.13244586] , error: 0.4737442981040568\n",
      "Step: 5320 Weights: [0.35593954 2.13244581] , error: 0.473744298077331\n",
      "Step: 5321 Weights: [0.35594005 2.13244575] , error: 0.4737442980507265\n",
      "Step: 5322 Weights: [0.35594056 2.13244569] , error: 0.47374429802424345\n",
      "Step: 5323 Weights: [0.35594107 2.13244563] , error: 0.4737442979978811\n",
      "Step: 5324 Weights: [0.35594158 2.13244557] , error: 0.4737442979716388\n",
      "Step: 5325 Weights: [0.35594209 2.13244551] , error: 0.4737442979455159\n",
      "Step: 5326 Weights: [0.35594259 2.13244546] , error: 0.473744297919512\n",
      "Step: 5327 Weights: [0.3559431 2.1324454] , error: 0.47374429789362693\n",
      "Step: 5328 Weights: [0.35594361 2.13244534] , error: 0.4737442978678589\n",
      "Step: 5329 Weights: [0.35594411 2.13244528] , error: 0.47374429784220945\n",
      "Step: 5330 Weights: [0.35594461 2.13244523] , error: 0.47374429781667526\n",
      "Step: 5331 Weights: [0.35594511 2.13244517] , error: 0.47374429779125815\n",
      "Step: 5332 Weights: [0.35594561 2.13244511] , error: 0.47374429776595717\n",
      "Step: 5333 Weights: [0.35594611 2.13244505] , error: 0.47374429774077154\n",
      "Step: 5334 Weights: [0.35594661 2.132445  ] , error: 0.47374429771570126\n",
      "Step: 5335 Weights: [0.35594711 2.13244494] , error: 0.4737442976907437\n",
      "Step: 5336 Weights: [0.3559476  2.13244488] , error: 0.47374429766590104\n",
      "Step: 5337 Weights: [0.3559481  2.13244483] , error: 0.4737442976411704\n",
      "Step: 5338 Weights: [0.35594859 2.13244477] , error: 0.47374429761655273\n",
      "Step: 5339 Weights: [0.35594908 2.13244471] , error: 0.4737442975920485\n",
      "Step: 5340 Weights: [0.35594957 2.13244466] , error: 0.47374429756765446\n",
      "Step: 5341 Weights: [0.35595006 2.1324446 ] , error: 0.47374429754337144\n",
      "Step: 5342 Weights: [0.35595055 2.13244455] , error: 0.4737442975192003\n",
      "Step: 5343 Weights: [0.35595104 2.13244449] , error: 0.4737442974951379\n",
      "Step: 5344 Weights: [0.35595152 2.13244443] , error: 0.473744297471186\n",
      "Step: 5345 Weights: [0.35595201 2.13244438] , error: 0.47374429744734303\n",
      "Step: 5346 Weights: [0.35595249 2.13244432] , error: 0.47374429742360874\n",
      "Step: 5347 Weights: [0.35595298 2.13244427] , error: 0.4737442973999827\n",
      "Step: 5348 Weights: [0.35595346 2.13244421] , error: 0.473744297376464\n",
      "Step: 5349 Weights: [0.35595394 2.13244416] , error: 0.47374429735305257\n",
      "Step: 5350 Weights: [0.35595442 2.1324441 ] , error: 0.4737442973297476\n",
      "Step: 5351 Weights: [0.3559549  2.13244405] , error: 0.47374429730654827\n",
      "Step: 5352 Weights: [0.35595538 2.13244399] , error: 0.47374429728345524\n",
      "Step: 5353 Weights: [0.35595585 2.13244394] , error: 0.4737442972604682\n",
      "Step: 5354 Weights: [0.35595633 2.13244389] , error: 0.4737442972375852\n",
      "Step: 5355 Weights: [0.3559568  2.13244383] , error: 0.47374429721480604\n",
      "Step: 5356 Weights: [0.35595728 2.13244378] , error: 0.47374429719213085\n",
      "Step: 5357 Weights: [0.35595775 2.13244372] , error: 0.47374429716956\n",
      "Step: 5358 Weights: [0.35595822 2.13244367] , error: 0.47374429714709076\n",
      "Step: 5359 Weights: [0.35595869 2.13244362] , error: 0.4737442971247237\n",
      "Step: 5360 Weights: [0.35595916 2.13244356] , error: 0.473744297102459\n",
      "Step: 5361 Weights: [0.35595963 2.13244351] , error: 0.47374429708029603\n",
      "Step: 5362 Weights: [0.35596009 2.13244345] , error: 0.4737442970582333\n",
      "Step: 5363 Weights: [0.35596056 2.1324434 ] , error: 0.4737442970362723\n",
      "Step: 5364 Weights: [0.35596102 2.13244335] , error: 0.4737442970144099\n",
      "Step: 5365 Weights: [0.35596149 2.1324433 ] , error: 0.4737442969926481\n",
      "Step: 5366 Weights: [0.35596195 2.13244324] , error: 0.4737442969709851\n",
      "Step: 5367 Weights: [0.35596241 2.13244319] , error: 0.47374429694942166\n",
      "Step: 5368 Weights: [0.35596287 2.13244314] , error: 0.4737442969279552\n",
      "Step: 5369 Weights: [0.35596333 2.13244308] , error: 0.47374429690658726\n",
      "Step: 5370 Weights: [0.35596379 2.13244303] , error: 0.4737442968853159\n",
      "Step: 5371 Weights: [0.35596425 2.13244298] , error: 0.47374429686414143\n",
      "Step: 5372 Weights: [0.35596471 2.13244293] , error: 0.4737442968430645\n",
      "Step: 5373 Weights: [0.35596516 2.13244288] , error: 0.4737442968220828\n",
      "Step: 5374 Weights: [0.35596562 2.13244282] , error: 0.4737442968011971\n",
      "Step: 5375 Weights: [0.35596607 2.13244277] , error: 0.4737442967804061\n",
      "Step: 5376 Weights: [0.35596652 2.13244272] , error: 0.47374429675971014\n",
      "Step: 5377 Weights: [0.35596697 2.13244267] , error: 0.4737442967391087\n",
      "Step: 5378 Weights: [0.35596742 2.13244262] , error: 0.473744296718601\n",
      "Step: 5379 Weights: [0.35596787 2.13244257] , error: 0.4737442966981862\n",
      "Step: 5380 Weights: [0.35596832 2.13244251] , error: 0.473744296677865\n",
      "Step: 5381 Weights: [0.35596877 2.13244246] , error: 0.4737442966576355\n",
      "Step: 5382 Weights: [0.35596921 2.13244241] , error: 0.47374429663749906\n",
      "Step: 5383 Weights: [0.35596966 2.13244236] , error: 0.4737442966174532\n",
      "Step: 5384 Weights: [0.3559701  2.13244231] , error: 0.4737442965974995\n",
      "Step: 5385 Weights: [0.35597054 2.13244226] , error: 0.47374429657763717\n",
      "Step: 5386 Weights: [0.35597099 2.13244221] , error: 0.47374429655786465\n",
      "Step: 5387 Weights: [0.35597143 2.13244216] , error: 0.4737442965381831\n",
      "Step: 5388 Weights: [0.35597187 2.13244211] , error: 0.4737442965185902\n",
      "Step: 5389 Weights: [0.35597231 2.13244206] , error: 0.4737442964990866\n",
      "Step: 5390 Weights: [0.35597274 2.13244201] , error: 0.4737442964796721\n",
      "Step: 5391 Weights: [0.35597318 2.13244196] , error: 0.47374429646034627\n",
      "Step: 5392 Weights: [0.35597362 2.13244191] , error: 0.47374429644110794\n",
      "Step: 5393 Weights: [0.35597405 2.13244186] , error: 0.4737442964219578\n",
      "Step: 5394 Weights: [0.35597449 2.13244181] , error: 0.4737442964028951\n",
      "Step: 5395 Weights: [0.35597492 2.13244176] , error: 0.4737442963839186\n",
      "Step: 5396 Weights: [0.35597535 2.13244171] , error: 0.473744296365029\n",
      "Step: 5397 Weights: [0.35597578 2.13244166] , error: 0.4737442963462246\n",
      "Step: 5398 Weights: [0.35597621 2.13244161] , error: 0.47374429632750675\n",
      "Step: 5399 Weights: [0.35597664 2.13244156] , error: 0.4737442963088746\n",
      "Step: 5400 Weights: [0.35597707 2.13244151] , error: 0.4737442962903264\n",
      "Step: 5401 Weights: [0.3559775  2.13244146] , error: 0.4737442962718632\n",
      "Step: 5402 Weights: [0.35597792 2.13244142] , error: 0.4737442962534836\n",
      "Step: 5403 Weights: [0.35597835 2.13244137] , error: 0.47374429623518793\n",
      "Step: 5404 Weights: [0.35597877 2.13244132] , error: 0.47374429621697534\n",
      "Step: 5405 Weights: [0.3559792  2.13244127] , error: 0.4737442961988462\n",
      "Step: 5406 Weights: [0.35597962 2.13244122] , error: 0.473744296180799\n",
      "Step: 5407 Weights: [0.35598004 2.13244117] , error: 0.4737442961628352\n",
      "Step: 5408 Weights: [0.35598046 2.13244113] , error: 0.4737442961449523\n",
      "Step: 5409 Weights: [0.35598088 2.13244108] , error: 0.4737442961271513\n",
      "Step: 5410 Weights: [0.3559813  2.13244103] , error: 0.4737442961094309\n",
      "Step: 5411 Weights: [0.35598172 2.13244098] , error: 0.47374429609179197\n",
      "Step: 5412 Weights: [0.35598213 2.13244093] , error: 0.47374429607423285\n",
      "Step: 5413 Weights: [0.35598255 2.13244089] , error: 0.47374429605675394\n",
      "Step: 5414 Weights: [0.35598296 2.13244084] , error: 0.4737442960393543\n",
      "Step: 5415 Weights: [0.35598338 2.13244079] , error: 0.47374429602203394\n",
      "Step: 5416 Weights: [0.35598379 2.13244074] , error: 0.47374429600479345\n",
      "Step: 5417 Weights: [0.3559842 2.1324407] , error: 0.47374429598763096\n",
      "Step: 5418 Weights: [0.35598461 2.13244065] , error: 0.47374429597054574\n",
      "Step: 5419 Weights: [0.35598502 2.1324406 ] , error: 0.4737442959535396\n",
      "Step: 5420 Weights: [0.35598543 2.13244056] , error: 0.47374429593661055\n",
      "Step: 5421 Weights: [0.35598584 2.13244051] , error: 0.4737442959197582\n",
      "Step: 5422 Weights: [0.35598625 2.13244046] , error: 0.47374429590298267\n",
      "Step: 5423 Weights: [0.35598665 2.13244042] , error: 0.47374429588628364\n",
      "Step: 5424 Weights: [0.35598706 2.13244037] , error: 0.4737442958696611\n",
      "Step: 5425 Weights: [0.35598746 2.13244032] , error: 0.4737442958531143\n",
      "Step: 5426 Weights: [0.35598787 2.13244028] , error: 0.4737442958366432\n",
      "Step: 5427 Weights: [0.35598827 2.13244023] , error: 0.473744295820246\n",
      "Step: 5428 Weights: [0.35598867 2.13244019] , error: 0.4737442958039241\n",
      "Step: 5429 Weights: [0.35598907 2.13244014] , error: 0.473744295787677\n",
      "Step: 5430 Weights: [0.35598947 2.1324401 ] , error: 0.47374429577150273\n",
      "Step: 5431 Weights: [0.35598987 2.13244005] , error: 0.473744295755403\n",
      "Step: 5432 Weights: [0.35599027 2.13244   ] , error: 0.47374429573937615\n",
      "Step: 5433 Weights: [0.35599066 2.13243996] , error: 0.4737442957234233\n",
      "Step: 5434 Weights: [0.35599106 2.13243991] , error: 0.4737442957075422\n",
      "Step: 5435 Weights: [0.35599146 2.13243987] , error: 0.4737442956917339\n",
      "Step: 5436 Weights: [0.35599185 2.13243982] , error: 0.4737442956759975\n",
      "Step: 5437 Weights: [0.35599224 2.13243978] , error: 0.4737442956603326\n",
      "Step: 5438 Weights: [0.35599264 2.13243973] , error: 0.4737442956447388\n",
      "Step: 5439 Weights: [0.35599303 2.13243969] , error: 0.4737442956292169\n",
      "Step: 5440 Weights: [0.35599342 2.13243964] , error: 0.47374429561376497\n",
      "Step: 5441 Weights: [0.35599381 2.1324396 ] , error: 0.47374429559838355\n",
      "Step: 5442 Weights: [0.3559942  2.13243955] , error: 0.4737442955830722\n",
      "Step: 5443 Weights: [0.35599459 2.13243951] , error: 0.4737442955678316\n",
      "Step: 5444 Weights: [0.35599497 2.13243947] , error: 0.4737442955526592\n",
      "Step: 5445 Weights: [0.35599536 2.13243942] , error: 0.4737442955375558\n",
      "Step: 5446 Weights: [0.35599574 2.13243938] , error: 0.4737442955225222\n",
      "Step: 5447 Weights: [0.35599613 2.13243933] , error: 0.47374429550755714\n",
      "Step: 5448 Weights: [0.35599651 2.13243929] , error: 0.4737442954926594\n",
      "Step: 5449 Weights: [0.3559969  2.13243925] , error: 0.47374429547783\n",
      "Step: 5450 Weights: [0.35599728 2.1324392 ] , error: 0.4737442954630672\n",
      "Step: 5451 Weights: [0.35599766 2.13243916] , error: 0.4737442954483727\n",
      "Step: 5452 Weights: [0.35599804 2.13243912] , error: 0.47374429543374486\n",
      "Step: 5453 Weights: [0.35599842 2.13243907] , error: 0.47374429541918384\n",
      "Step: 5454 Weights: [0.3559988  2.13243903] , error: 0.47374429540468943\n",
      "Step: 5455 Weights: [0.35599917 2.13243899] , error: 0.47374429539026064\n",
      "Step: 5456 Weights: [0.35599955 2.13243894] , error: 0.4737442953758977\n",
      "Step: 5457 Weights: [0.35599993 2.1324389 ] , error: 0.47374429536159907\n",
      "Step: 5458 Weights: [0.3560003  2.13243886] , error: 0.4737442953473672\n",
      "Step: 5459 Weights: [0.35600068 2.13243881] , error: 0.4737442953331992\n",
      "Step: 5460 Weights: [0.35600105 2.13243877] , error: 0.47374429531909634\n",
      "Step: 5461 Weights: [0.35600142 2.13243873] , error: 0.4737442953050574\n",
      "Step: 5462 Weights: [0.35600179 2.13243869] , error: 0.4737442952910828\n",
      "Step: 5463 Weights: [0.35600216 2.13243864] , error: 0.4737442952771713\n",
      "Step: 5464 Weights: [0.35600253 2.1324386 ] , error: 0.4737442952633233\n",
      "Step: 5465 Weights: [0.3560029  2.13243856] , error: 0.4737442952495381\n",
      "Step: 5466 Weights: [0.35600327 2.13243852] , error: 0.4737442952358162\n",
      "Step: 5467 Weights: [0.35600364 2.13243847] , error: 0.4737442952221566\n",
      "Step: 5468 Weights: [0.35600401 2.13243843] , error: 0.4737442952085599\n",
      "Step: 5469 Weights: [0.35600437 2.13243839] , error: 0.4737442951950247\n",
      "Step: 5470 Weights: [0.35600474 2.13243835] , error: 0.47374429518155065\n",
      "Step: 5471 Weights: [0.3560051  2.13243831] , error: 0.47374429516813876\n",
      "Step: 5472 Weights: [0.35600546 2.13243827] , error: 0.47374429515478744\n",
      "Step: 5473 Weights: [0.35600583 2.13243822] , error: 0.47374429514149696\n",
      "Step: 5474 Weights: [0.35600619 2.13243818] , error: 0.47374429512826555\n",
      "Step: 5475 Weights: [0.35600655 2.13243814] , error: 0.4737442951150974\n",
      "Step: 5476 Weights: [0.35600691 2.1324381 ] , error: 0.4737442951019882\n",
      "Step: 5477 Weights: [0.35600727 2.13243806] , error: 0.4737442950889382\n",
      "Step: 5478 Weights: [0.35600763 2.13243802] , error: 0.47374429507594784\n",
      "Step: 5479 Weights: [0.35600798 2.13243798] , error: 0.4737442950630169\n",
      "Step: 5480 Weights: [0.35600834 2.13243794] , error: 0.4737442950501444\n",
      "Step: 5481 Weights: [0.3560087 2.1324379] , error: 0.4737442950373306\n",
      "Step: 5482 Weights: [0.35600905 2.13243786] , error: 0.4737442950245755\n",
      "Step: 5483 Weights: [0.3560094  2.13243782] , error: 0.4737442950118778\n",
      "Step: 5484 Weights: [0.35600976 2.13243777] , error: 0.4737442949992388\n",
      "Step: 5485 Weights: [0.35601011 2.13243773] , error: 0.4737442949866571\n",
      "Step: 5486 Weights: [0.35601046 2.13243769] , error: 0.47374429497413284\n",
      "Step: 5487 Weights: [0.35601081 2.13243765] , error: 0.4737442949616657\n",
      "Step: 5488 Weights: [0.35601116 2.13243761] , error: 0.4737442949492551\n",
      "Step: 5489 Weights: [0.35601151 2.13243757] , error: 0.4737442949369008\n",
      "Step: 5490 Weights: [0.35601186 2.13243753] , error: 0.47374429492460257\n",
      "Step: 5491 Weights: [0.35601221 2.13243749] , error: 0.4737442949123614\n",
      "Step: 5492 Weights: [0.35601256 2.13243745] , error: 0.4737442949001772\n",
      "Step: 5493 Weights: [0.3560129  2.13243742] , error: 0.4737442948880451\n",
      "Step: 5494 Weights: [0.35601325 2.13243738] , error: 0.47374429487597036\n",
      "Step: 5495 Weights: [0.35601359 2.13243734] , error: 0.4737442948639505\n",
      "Step: 5496 Weights: [0.35601394 2.1324373 ] , error: 0.47374429485198477\n",
      "Step: 5497 Weights: [0.35601428 2.13243726] , error: 0.4737442948400732\n",
      "Step: 5498 Weights: [0.35601462 2.13243722] , error: 0.473744294828217\n",
      "Step: 5499 Weights: [0.35601496 2.13243718] , error: 0.4737442948164141\n",
      "Step: 5500 Weights: [0.3560153  2.13243714] , error: 0.4737442948046651\n",
      "Step: 5501 Weights: [0.35601564 2.1324371 ] , error: 0.47374429479297026\n",
      "Step: 5502 Weights: [0.35601598 2.13243706] , error: 0.47374429478132885\n",
      "Step: 5503 Weights: [0.35601632 2.13243702] , error: 0.4737442947697396\n",
      "Step: 5504 Weights: [0.35601666 2.13243699] , error: 0.47374429475820284\n",
      "Step: 5505 Weights: [0.356017   2.13243695] , error: 0.4737442947467196\n",
      "Step: 5506 Weights: [0.35601733 2.13243691] , error: 0.4737442947352873\n",
      "Step: 5507 Weights: [0.35601767 2.13243687] , error: 0.47374429472390844\n",
      "Step: 5508 Weights: [0.356018   2.13243683] , error: 0.47374429471258156\n",
      "Step: 5509 Weights: [0.35601834 2.13243679] , error: 0.47374429470130547\n",
      "Step: 5510 Weights: [0.35601867 2.13243676] , error: 0.47374429469008106\n",
      "Step: 5511 Weights: [0.356019   2.13243672] , error: 0.47374429467890833\n",
      "Step: 5512 Weights: [0.35601933 2.13243668] , error: 0.47374429466778517\n",
      "Step: 5513 Weights: [0.35601966 2.13243664] , error: 0.4737442946567134\n",
      "Step: 5514 Weights: [0.35601999 2.1324366 ] , error: 0.4737442946456921\n",
      "Step: 5515 Weights: [0.35602032 2.13243657] , error: 0.47374429463472145\n",
      "Step: 5516 Weights: [0.35602065 2.13243653] , error: 0.4737442946237999\n",
      "Step: 5517 Weights: [0.35602098 2.13243649] , error: 0.4737442946129283\n",
      "Step: 5518 Weights: [0.35602131 2.13243645] , error: 0.47374429460210676\n",
      "Step: 5519 Weights: [0.35602163 2.13243642] , error: 0.4737442945913342\n",
      "Step: 5520 Weights: [0.35602196 2.13243638] , error: 0.47374429458061046\n",
      "Step: 5521 Weights: [0.35602228 2.13243634] , error: 0.4737442945699361\n",
      "Step: 5522 Weights: [0.35602261 2.13243631] , error: 0.47374429455931016\n",
      "Step: 5523 Weights: [0.35602293 2.13243627] , error: 0.47374429454873285\n",
      "Step: 5524 Weights: [0.35602325 2.13243623] , error: 0.47374429453820277\n",
      "Step: 5525 Weights: [0.35602357 2.13243619] , error: 0.47374429452772204\n",
      "Step: 5526 Weights: [0.3560239  2.13243616] , error: 0.4737442945172884\n",
      "Step: 5527 Weights: [0.35602422 2.13243612] , error: 0.4737442945069024\n",
      "Step: 5528 Weights: [0.35602454 2.13243608] , error: 0.4737442944965629\n",
      "Step: 5529 Weights: [0.35602485 2.13243605] , error: 0.47374429448627114\n",
      "Step: 5530 Weights: [0.35602517 2.13243601] , error: 0.47374429447602734\n",
      "Step: 5531 Weights: [0.35602549 2.13243598] , error: 0.47374429446582933\n",
      "Step: 5532 Weights: [0.35602581 2.13243594] , error: 0.47374429445567756\n",
      "Step: 5533 Weights: [0.35602612 2.1324359 ] , error: 0.4737442944455714\n",
      "Step: 5534 Weights: [0.35602644 2.13243587] , error: 0.4737442944355123\n",
      "Step: 5535 Weights: [0.35602675 2.13243583] , error: 0.4737442944254983\n",
      "Step: 5536 Weights: [0.35602707 2.1324358 ] , error: 0.47374429441553\n",
      "Step: 5537 Weights: [0.35602738 2.13243576] , error: 0.47374429440560734\n",
      "Step: 5538 Weights: [0.35602769 2.13243572] , error: 0.4737442943957304\n",
      "Step: 5539 Weights: [0.356028   2.13243569] , error: 0.47374429438589816\n",
      "Step: 5540 Weights: [0.35602831 2.13243565] , error: 0.47374429437611065\n",
      "Step: 5541 Weights: [0.35602863 2.13243562] , error: 0.4737442943663676\n",
      "Step: 5542 Weights: [0.35602893 2.13243558] , error: 0.47374429435666904\n",
      "Step: 5543 Weights: [0.35602924 2.13243555] , error: 0.47374429434701393\n",
      "Step: 5544 Weights: [0.35602955 2.13243551] , error: 0.4737442943374039\n",
      "Step: 5545 Weights: [0.35602986 2.13243548] , error: 0.4737442943278381\n",
      "Step: 5546 Weights: [0.35603017 2.13243544] , error: 0.47374429431831433\n",
      "Step: 5547 Weights: [0.35603047 2.13243541] , error: 0.47374429430883436\n",
      "Step: 5548 Weights: [0.35603078 2.13243537] , error: 0.47374429429939874\n",
      "Step: 5549 Weights: [0.35603108 2.13243534] , error: 0.4737442942900052\n",
      "Step: 5550 Weights: [0.35603139 2.1324353 ] , error: 0.4737442942806539\n",
      "Step: 5551 Weights: [0.35603169 2.13243527] , error: 0.4737442942713465\n",
      "Step: 5552 Weights: [0.35603199 2.13243523] , error: 0.47374429426208053\n",
      "Step: 5553 Weights: [0.35603229 2.1324352 ] , error: 0.4737442942528566\n",
      "Step: 5554 Weights: [0.3560326  2.13243516] , error: 0.4737442942436746\n",
      "Step: 5555 Weights: [0.3560329  2.13243513] , error: 0.47374429423453507\n",
      "Step: 5556 Weights: [0.3560332  2.13243509] , error: 0.47374429422543707\n",
      "Step: 5557 Weights: [0.35603349 2.13243506] , error: 0.47374429421638087\n",
      "Step: 5558 Weights: [0.35603379 2.13243503] , error: 0.4737442942073663\n",
      "Step: 5559 Weights: [0.35603409 2.13243499] , error: 0.4737442941983915\n",
      "Step: 5560 Weights: [0.35603439 2.13243496] , error: 0.47374429418945796\n",
      "Step: 5561 Weights: [0.35603468 2.13243492] , error: 0.4737442941805656\n",
      "Step: 5562 Weights: [0.35603498 2.13243489] , error: 0.4737442941717134\n",
      "Step: 5563 Weights: [0.35603528 2.13243486] , error: 0.4737442941629013\n",
      "Step: 5564 Weights: [0.35603557 2.13243482] , error: 0.4737442941541295\n",
      "Step: 5565 Weights: [0.35603586 2.13243479] , error: 0.473744294145398\n",
      "Step: 5566 Weights: [0.35603616 2.13243476] , error: 0.4737442941367066\n",
      "Step: 5567 Weights: [0.35603645 2.13243472] , error: 0.47374429412805436\n",
      "Step: 5568 Weights: [0.35603674 2.13243469] , error: 0.4737442941194409\n",
      "Step: 5569 Weights: [0.35603703 2.13243466] , error: 0.4737442941108678\n",
      "Step: 5570 Weights: [0.35603732 2.13243462] , error: 0.47374429410233243\n",
      "Step: 5571 Weights: [0.35603761 2.13243459] , error: 0.47374429409383656\n",
      "Step: 5572 Weights: [0.3560379  2.13243456] , error: 0.47374429408537977\n",
      "Step: 5573 Weights: [0.35603819 2.13243452] , error: 0.4737442940769611\n",
      "Step: 5574 Weights: [0.35603848 2.13243449] , error: 0.4737442940685814\n",
      "Step: 5575 Weights: [0.35603876 2.13243446] , error: 0.47374429406023844\n",
      "Step: 5576 Weights: [0.35603905 2.13243442] , error: 0.47374429405193574\n",
      "Step: 5577 Weights: [0.35603934 2.13243439] , error: 0.47374429404366886\n",
      "Step: 5578 Weights: [0.35603962 2.13243436] , error: 0.47374429403544105\n",
      "Step: 5579 Weights: [0.35603991 2.13243433] , error: 0.47374429402724927\n",
      "Step: 5580 Weights: [0.35604019 2.13243429] , error: 0.4737442940190956\n",
      "Step: 5581 Weights: [0.35604047 2.13243426] , error: 0.47374429401097906\n",
      "Step: 5582 Weights: [0.35604076 2.13243423] , error: 0.4737442940029001\n",
      "Step: 5583 Weights: [0.35604104 2.1324342 ] , error: 0.47374429399485674\n",
      "Step: 5584 Weights: [0.35604132 2.13243417] , error: 0.4737442939868507\n",
      "Step: 5585 Weights: [0.3560416  2.13243413] , error: 0.4737442939788813\n",
      "Step: 5586 Weights: [0.35604188 2.1324341 ] , error: 0.47374429397094814\n",
      "Step: 5587 Weights: [0.35604216 2.13243407] , error: 0.47374429396305084\n",
      "Step: 5588 Weights: [0.35604244 2.13243404] , error: 0.47374429395519047\n",
      "Step: 5589 Weights: [0.35604272 2.13243401] , error: 0.4737442939473636\n",
      "Step: 5590 Weights: [0.35604299 2.13243397] , error: 0.4737442939395737\n",
      "Step: 5591 Weights: [0.35604327 2.13243394] , error: 0.4737442939318201\n",
      "Step: 5592 Weights: [0.35604355 2.13243391] , error: 0.473744293924101\n",
      "Step: 5593 Weights: [0.35604382 2.13243388] , error: 0.4737442939164168\n",
      "Step: 5594 Weights: [0.3560441  2.13243385] , error: 0.47374429390876815\n",
      "Step: 5595 Weights: [0.35604437 2.13243382] , error: 0.47374429390115436\n",
      "Step: 5596 Weights: [0.35604465 2.13243379] , error: 0.473744293893575\n",
      "Step: 5597 Weights: [0.35604492 2.13243375] , error: 0.4737442938860307\n",
      "Step: 5598 Weights: [0.35604519 2.13243372] , error: 0.47374429387852035\n",
      "Step: 5599 Weights: [0.35604546 2.13243369] , error: 0.473744293871044\n",
      "Step: 5600 Weights: [0.35604573 2.13243366] , error: 0.4737442938636015\n",
      "Step: 5601 Weights: [0.356046   2.13243363] , error: 0.47374429385619377\n",
      "Step: 5602 Weights: [0.35604627 2.1324336 ] , error: 0.47374429384881944\n",
      "Step: 5603 Weights: [0.35604654 2.13243357] , error: 0.47374429384147837\n",
      "Step: 5604 Weights: [0.35604681 2.13243354] , error: 0.4737442938341715\n",
      "Step: 5605 Weights: [0.35604708 2.13243351] , error: 0.47374429382689653\n",
      "Step: 5606 Weights: [0.35604735 2.13243348] , error: 0.4737442938196556\n",
      "Step: 5607 Weights: [0.35604761 2.13243345] , error: 0.47374429381244787\n",
      "Step: 5608 Weights: [0.35604788 2.13243342] , error: 0.47374429380527294\n",
      "Step: 5609 Weights: [0.35604815 2.13243338] , error: 0.4737442937981302\n",
      "Step: 5610 Weights: [0.35604841 2.13243335] , error: 0.47374429379102084\n",
      "Step: 5611 Weights: [0.35604868 2.13243332] , error: 0.473744293783943\n",
      "Step: 5612 Weights: [0.35604894 2.13243329] , error: 0.47374429377689803\n",
      "Step: 5613 Weights: [0.3560492  2.13243326] , error: 0.4737442937698844\n",
      "Step: 5614 Weights: [0.35604947 2.13243323] , error: 0.4737442937629032\n",
      "Step: 5615 Weights: [0.35604973 2.1324332 ] , error: 0.47374429375595445\n",
      "Step: 5616 Weights: [0.35604999 2.13243317] , error: 0.473744293749036\n",
      "Step: 5617 Weights: [0.35605025 2.13243314] , error: 0.4737442937421493\n",
      "Step: 5618 Weights: [0.35605051 2.13243311] , error: 0.47374429373529536\n",
      "Step: 5619 Weights: [0.35605077 2.13243308] , error: 0.4737442937284705\n",
      "Step: 5620 Weights: [0.35605103 2.13243305] , error: 0.473744293721679\n",
      "Step: 5621 Weights: [0.35605129 2.13243303] , error: 0.4737442937149164\n",
      "Step: 5622 Weights: [0.35605155 2.132433  ] , error: 0.47374429370818605\n",
      "Step: 5623 Weights: [0.3560518  2.13243297] , error: 0.4737442937014854\n",
      "Step: 5624 Weights: [0.35605206 2.13243294] , error: 0.4737442936948166\n",
      "Step: 5625 Weights: [0.35605232 2.13243291] , error: 0.47374429368817705\n",
      "Step: 5626 Weights: [0.35605257 2.13243288] , error: 0.47374429368156795\n",
      "Step: 5627 Weights: [0.35605283 2.13243285] , error: 0.4737442936749893\n",
      "Step: 5628 Weights: [0.35605308 2.13243282] , error: 0.47374429366844006\n",
      "Step: 5629 Weights: [0.35605333 2.13243279] , error: 0.4737442936619211\n",
      "Step: 5630 Weights: [0.35605359 2.13243276] , error: 0.47374429365543186\n",
      "Step: 5631 Weights: [0.35605384 2.13243273] , error: 0.4737442936489715\n",
      "Step: 5632 Weights: [0.35605409 2.1324327 ] , error: 0.4737442936425416\n",
      "Step: 5633 Weights: [0.35605434 2.13243268] , error: 0.4737442936361407\n",
      "Step: 5634 Weights: [0.3560546  2.13243265] , error: 0.4737442936297687\n",
      "Step: 5635 Weights: [0.35605485 2.13243262] , error: 0.47374429362342585\n",
      "Step: 5636 Weights: [0.3560551  2.13243259] , error: 0.47374429361711107\n",
      "Step: 5637 Weights: [0.35605534 2.13243256] , error: 0.4737442936108265\n",
      "Step: 5638 Weights: [0.35605559 2.13243253] , error: 0.47374429360457004\n",
      "Step: 5639 Weights: [0.35605584 2.1324325 ] , error: 0.4737442935983411\n",
      "Step: 5640 Weights: [0.35605609 2.13243248] , error: 0.4737442935921413\n",
      "Step: 5641 Weights: [0.35605634 2.13243245] , error: 0.47374429358596953\n",
      "Step: 5642 Weights: [0.35605658 2.13243242] , error: 0.47374429357982717\n",
      "Step: 5643 Weights: [0.35605683 2.13243239] , error: 0.47374429357371145\n",
      "Step: 5644 Weights: [0.35605707 2.13243236] , error: 0.4737442935676237\n",
      "Step: 5645 Weights: [0.35605732 2.13243234] , error: 0.47374429356156394\n",
      "Step: 5646 Weights: [0.35605756 2.13243231] , error: 0.47374429355553177\n",
      "Step: 5647 Weights: [0.35605781 2.13243228] , error: 0.47374429354952713\n",
      "Step: 5648 Weights: [0.35605805 2.13243225] , error: 0.4737442935435499\n",
      "Step: 5649 Weights: [0.35605829 2.13243222] , error: 0.4737442935375995\n",
      "Step: 5650 Weights: [0.35605853 2.1324322 ] , error: 0.47374429353167674\n",
      "Step: 5651 Weights: [0.35605877 2.13243217] , error: 0.4737442935257804\n",
      "Step: 5652 Weights: [0.35605902 2.13243214] , error: 0.4737442935199119\n",
      "Step: 5653 Weights: [0.35605926 2.13243211] , error: 0.4737442935140695\n",
      "Step: 5654 Weights: [0.3560595  2.13243209] , error: 0.4737442935082529\n",
      "Step: 5655 Weights: [0.35605973 2.13243206] , error: 0.4737442935024637\n",
      "Step: 5656 Weights: [0.35605997 2.13243203] , error: 0.47374429349670055\n",
      "Step: 5657 Weights: [0.35606021 2.132432  ] , error: 0.4737442934909639\n",
      "Step: 5658 Weights: [0.35606045 2.13243198] , error: 0.47374429348525376\n",
      "Step: 5659 Weights: [0.35606069 2.13243195] , error: 0.47374429347956937\n",
      "Step: 5660 Weights: [0.35606092 2.13243192] , error: 0.4737442934739103\n",
      "Step: 5661 Weights: [0.35606116 2.1324319 ] , error: 0.47374429346827773\n",
      "Step: 5662 Weights: [0.35606139 2.13243187] , error: 0.47374429346267\n",
      "Step: 5663 Weights: [0.35606163 2.13243184] , error: 0.4737442934570887\n",
      "Step: 5664 Weights: [0.35606186 2.13243182] , error: 0.4737442934515324\n",
      "Step: 5665 Weights: [0.3560621  2.13243179] , error: 0.4737442934460014\n",
      "Step: 5666 Weights: [0.35606233 2.13243176] , error: 0.4737442934404952\n",
      "Step: 5667 Weights: [0.35606256 2.13243174] , error: 0.47374429343501484\n",
      "Step: 5668 Weights: [0.35606279 2.13243171] , error: 0.47374429342955904\n",
      "Step: 5669 Weights: [0.35606303 2.13243168] , error: 0.4737442934241279\n",
      "Step: 5670 Weights: [0.35606326 2.13243166] , error: 0.47374429341872165\n",
      "Step: 5671 Weights: [0.35606349 2.13243163] , error: 0.473744293413341\n",
      "Step: 5672 Weights: [0.35606372 2.1324316 ] , error: 0.4737442934079841\n",
      "Step: 5673 Weights: [0.35606395 2.13243158] , error: 0.47374429340265095\n",
      "Step: 5674 Weights: [0.35606418 2.13243155] , error: 0.473744293397343\n",
      "Step: 5675 Weights: [0.35606441 2.13243153] , error: 0.47374429339205915\n",
      "Step: 5676 Weights: [0.35606463 2.1324315 ] , error: 0.47374429338679913\n",
      "Step: 5677 Weights: [0.35606486 2.13243147] , error: 0.4737442933815634\n",
      "Step: 5678 Weights: [0.35606509 2.13243145] , error: 0.4737442933763505\n",
      "Step: 5679 Weights: [0.35606531 2.13243142] , error: 0.47374429337116175\n",
      "Step: 5680 Weights: [0.35606554 2.1324314 ] , error: 0.4737442933659974\n",
      "Step: 5681 Weights: [0.35606577 2.13243137] , error: 0.4737442933608557\n",
      "Step: 5682 Weights: [0.35606599 2.13243134] , error: 0.47374429335573787\n",
      "Step: 5683 Weights: [0.35606621 2.13243132] , error: 0.47374429335064405\n",
      "Step: 5684 Weights: [0.35606644 2.13243129] , error: 0.4737442933455723\n",
      "Step: 5685 Weights: [0.35606666 2.13243127] , error: 0.4737442933405245\n",
      "Step: 5686 Weights: [0.35606688 2.13243124] , error: 0.47374429333549856\n",
      "Step: 5687 Weights: [0.35606711 2.13243122] , error: 0.4737442933304973\n",
      "Step: 5688 Weights: [0.35606733 2.13243119] , error: 0.47374429332551704\n",
      "Step: 5689 Weights: [0.35606755 2.13243117] , error: 0.47374429332056034\n",
      "Step: 5690 Weights: [0.35606777 2.13243114] , error: 0.4737442933156256\n",
      "Step: 5691 Weights: [0.35606799 2.13243112] , error: 0.47374429331071427\n",
      "Step: 5692 Weights: [0.35606821 2.13243109] , error: 0.47374429330582485\n",
      "Step: 5693 Weights: [0.35606843 2.13243106] , error: 0.47374429330095724\n",
      "Step: 5694 Weights: [0.35606865 2.13243104] , error: 0.4737442932961124\n",
      "Step: 5695 Weights: [0.35606887 2.13243101] , error: 0.47374429329128964\n",
      "Step: 5696 Weights: [0.35606909 2.13243099] , error: 0.47374429328648887\n",
      "Step: 5697 Weights: [0.3560693  2.13243097] , error: 0.4737442932817102\n",
      "Step: 5698 Weights: [0.35606952 2.13243094] , error: 0.47374429327695267\n",
      "Step: 5699 Weights: [0.35606974 2.13243092] , error: 0.4737442932722167\n",
      "Step: 5700 Weights: [0.35606995 2.13243089] , error: 0.47374429326750245\n",
      "Step: 5701 Weights: [0.35607017 2.13243087] , error: 0.47374429326281026\n",
      "Step: 5702 Weights: [0.35607038 2.13243084] , error: 0.4737442932581385\n",
      "Step: 5703 Weights: [0.3560706  2.13243082] , error: 0.4737442932534894\n",
      "Step: 5704 Weights: [0.35607081 2.13243079] , error: 0.4737442932488608\n",
      "Step: 5705 Weights: [0.35607102 2.13243077] , error: 0.4737442932442528\n",
      "Step: 5706 Weights: [0.35607124 2.13243074] , error: 0.4737442932396662\n",
      "Step: 5707 Weights: [0.35607145 2.13243072] , error: 0.4737442932351005\n",
      "Step: 5708 Weights: [0.35607166 2.1324307 ] , error: 0.4737442932305549\n",
      "Step: 5709 Weights: [0.35607187 2.13243067] , error: 0.4737442932260311\n",
      "Step: 5710 Weights: [0.35607208 2.13243065] , error: 0.4737442932215276\n",
      "Step: 5711 Weights: [0.35607229 2.13243062] , error: 0.4737442932170444\n",
      "Step: 5712 Weights: [0.3560725 2.1324306] , error: 0.4737442932125817\n",
      "Step: 5713 Weights: [0.35607271 2.13243058] , error: 0.47374429320813916\n",
      "Step: 5714 Weights: [0.35607292 2.13243055] , error: 0.4737442932037177\n",
      "Step: 5715 Weights: [0.35607313 2.13243053] , error: 0.4737442931993154\n",
      "Step: 5716 Weights: [0.35607334 2.1324305 ] , error: 0.4737442931949335\n",
      "Step: 5717 Weights: [0.35607355 2.13243048] , error: 0.4737442931905708\n",
      "Step: 5718 Weights: [0.35607375 2.13243046] , error: 0.4737442931862296\n",
      "Step: 5719 Weights: [0.35607396 2.13243043] , error: 0.47374429318190686\n",
      "Step: 5720 Weights: [0.35607417 2.13243041] , error: 0.47374429317760364\n",
      "Step: 5721 Weights: [0.35607437 2.13243039] , error: 0.47374429317332095\n",
      "Step: 5722 Weights: [0.35607458 2.13243036] , error: 0.4737442931690574\n",
      "Step: 5723 Weights: [0.35607478 2.13243034] , error: 0.4737442931648136\n",
      "Step: 5724 Weights: [0.35607499 2.13243032] , error: 0.47374429316058897\n",
      "Step: 5725 Weights: [0.35607519 2.13243029] , error: 0.4737442931563831\n",
      "Step: 5726 Weights: [0.35607539 2.13243027] , error: 0.47374429315219657\n",
      "Step: 5727 Weights: [0.3560756  2.13243025] , error: 0.47374429314802957\n",
      "Step: 5728 Weights: [0.3560758  2.13243022] , error: 0.4737442931438812\n",
      "Step: 5729 Weights: [0.356076  2.1324302] , error: 0.47374429313975197\n",
      "Step: 5730 Weights: [0.3560762  2.13243018] , error: 0.4737442931356417\n",
      "Step: 5731 Weights: [0.3560764  2.13243015] , error: 0.4737442931315494\n",
      "Step: 5732 Weights: [0.3560766  2.13243013] , error: 0.47374429312747646\n",
      "Step: 5733 Weights: [0.3560768  2.13243011] , error: 0.47374429312342137\n",
      "Step: 5734 Weights: [0.356077   2.13243008] , error: 0.4737442931193854\n",
      "Step: 5735 Weights: [0.3560772  2.13243006] , error: 0.47374429311536725\n",
      "Step: 5736 Weights: [0.3560774  2.13243004] , error: 0.473744293111368\n",
      "Step: 5737 Weights: [0.3560776  2.13243002] , error: 0.47374429310738686\n",
      "Step: 5738 Weights: [0.3560778  2.13242999] , error: 0.4737442931034236\n",
      "Step: 5739 Weights: [0.356078   2.13242997] , error: 0.47374429309947885\n",
      "Step: 5740 Weights: [0.35607819 2.13242995] , error: 0.473744293095551\n",
      "Step: 5741 Weights: [0.35607839 2.13242993] , error: 0.47374429309164173\n",
      "Step: 5742 Weights: [0.35607859 2.1324299 ] , error: 0.4737442930877508\n",
      "Step: 5743 Weights: [0.35607878 2.13242988] , error: 0.4737442930838765\n",
      "Step: 5744 Weights: [0.35607898 2.13242986] , error: 0.4737442930800214\n",
      "Step: 5745 Weights: [0.35607917 2.13242984] , error: 0.47374429307618227\n",
      "Step: 5746 Weights: [0.35607937 2.13242981] , error: 0.47374429307236154\n",
      "Step: 5747 Weights: [0.35607956 2.13242979] , error: 0.47374429306855814\n",
      "Step: 5748 Weights: [0.35607975 2.13242977] , error: 0.47374429306477217\n",
      "Step: 5749 Weights: [0.35607995 2.13242975] , error: 0.4737442930610026\n",
      "Step: 5750 Weights: [0.35608014 2.13242973] , error: 0.4737442930572509\n",
      "Step: 5751 Weights: [0.35608033 2.1324297 ] , error: 0.47374429305351573\n",
      "Step: 5752 Weights: [0.35608052 2.13242968] , error: 0.4737442930497982\n",
      "Step: 5753 Weights: [0.35608071 2.13242966] , error: 0.4737442930460976\n",
      "Step: 5754 Weights: [0.3560809  2.13242964] , error: 0.4737442930424133\n",
      "Step: 5755 Weights: [0.3560811  2.13242962] , error: 0.473744293038747\n",
      "Step: 5756 Weights: [0.35608129 2.13242959] , error: 0.4737442930350957\n",
      "Step: 5757 Weights: [0.35608147 2.13242957] , error: 0.4737442930314627\n",
      "Step: 5758 Weights: [0.35608166 2.13242955] , error: 0.4737442930278453\n",
      "Step: 5759 Weights: [0.35608185 2.13242953] , error: 0.47374429302424415\n",
      "Step: 5760 Weights: [0.35608204 2.13242951] , error: 0.47374429302065946\n",
      "Step: 5761 Weights: [0.35608223 2.13242949] , error: 0.4737442930170918\n",
      "Step: 5762 Weights: [0.35608242 2.13242947] , error: 0.47374429301353965\n",
      "Step: 5763 Weights: [0.3560826  2.13242944] , error: 0.47374429301000387\n",
      "Step: 5764 Weights: [0.35608279 2.13242942] , error: 0.4737442930064844\n",
      "Step: 5765 Weights: [0.35608298 2.1324294 ] , error: 0.47374429300298154\n",
      "Step: 5766 Weights: [0.35608316 2.13242938] , error: 0.4737442929994935\n",
      "Step: 5767 Weights: [0.35608335 2.13242936] , error: 0.473744292996023\n",
      "Step: 5768 Weights: [0.35608353 2.13242934] , error: 0.47374429299256676\n",
      "Step: 5769 Weights: [0.35608372 2.13242932] , error: 0.4737442929891263\n",
      "Step: 5770 Weights: [0.3560839 2.1324293] , error: 0.4737442929857019\n",
      "Step: 5771 Weights: [0.35608408 2.13242927] , error: 0.47374429298229304\n",
      "Step: 5772 Weights: [0.35608427 2.13242925] , error: 0.4737442929789003\n",
      "Step: 5773 Weights: [0.35608445 2.13242923] , error: 0.47374429297552245\n",
      "Step: 5774 Weights: [0.35608463 2.13242921] , error: 0.47374429297216003\n",
      "Step: 5775 Weights: [0.35608481 2.13242919] , error: 0.4737442929688127\n",
      "Step: 5776 Weights: [0.35608499 2.13242917] , error: 0.4737442929654806\n",
      "Step: 5777 Weights: [0.35608518 2.13242915] , error: 0.4737442929621646\n",
      "Step: 5778 Weights: [0.35608536 2.13242913] , error: 0.47374429295886317\n",
      "Step: 5779 Weights: [0.35608554 2.13242911] , error: 0.4737442929555759\n",
      "Step: 5780 Weights: [0.35608572 2.13242909] , error: 0.4737442929523045\n",
      "Step: 5781 Weights: [0.3560859  2.13242907] , error: 0.47374429294904746\n",
      "Step: 5782 Weights: [0.35608607 2.13242905] , error: 0.4737442929458067\n",
      "Step: 5783 Weights: [0.35608625 2.13242903] , error: 0.4737442929425788\n",
      "Step: 5784 Weights: [0.35608643 2.13242901] , error: 0.4737442929393668\n",
      "Step: 5785 Weights: [0.35608661 2.13242899] , error: 0.473744292936169\n",
      "Step: 5786 Weights: [0.35608679 2.13242897] , error: 0.4737442929329864\n",
      "Step: 5787 Weights: [0.35608696 2.13242895] , error: 0.47374429292981773\n",
      "Step: 5788 Weights: [0.35608714 2.13242893] , error: 0.47374429292666276\n",
      "Step: 5789 Weights: [0.35608732 2.13242891] , error: 0.47374429292352355\n",
      "Step: 5790 Weights: [0.35608749 2.13242889] , error: 0.47374429292039794\n",
      "Step: 5791 Weights: [0.35608767 2.13242886] , error: 0.4737442929172865\n",
      "Step: 5792 Weights: [0.35608784 2.13242884] , error: 0.47374429291418924\n",
      "Step: 5793 Weights: [0.35608802 2.13242883] , error: 0.47374429291110637\n",
      "Step: 5794 Weights: [0.35608819 2.13242881] , error: 0.4737442929080369\n",
      "Step: 5795 Weights: [0.35608836 2.13242879] , error: 0.4737442929049822\n",
      "Step: 5796 Weights: [0.35608854 2.13242877] , error: 0.4737442929019407\n",
      "Step: 5797 Weights: [0.35608871 2.13242875] , error: 0.4737442928989139\n",
      "Step: 5798 Weights: [0.35608888 2.13242873] , error: 0.4737442928959002\n",
      "Step: 5799 Weights: [0.35608906 2.13242871] , error: 0.47374429289290065\n",
      "Step: 5800 Weights: [0.35608923 2.13242869] , error: 0.47374429288991476\n",
      "Step: 5801 Weights: [0.3560894  2.13242867] , error: 0.4737442928869423\n",
      "Step: 5802 Weights: [0.35608957 2.13242865] , error: 0.47374429288398334\n",
      "Step: 5803 Weights: [0.35608974 2.13242863] , error: 0.4737442928810377\n",
      "Step: 5804 Weights: [0.35608991 2.13242861] , error: 0.47374429287810604\n",
      "Step: 5805 Weights: [0.35609008 2.13242859] , error: 0.47374429287518754\n",
      "Step: 5806 Weights: [0.35609025 2.13242857] , error: 0.4737442928722825\n",
      "Step: 5807 Weights: [0.35609042 2.13242855] , error: 0.4737442928693902\n",
      "Step: 5808 Weights: [0.35609059 2.13242853] , error: 0.473744292866511\n",
      "Step: 5809 Weights: [0.35609076 2.13242851] , error: 0.47374429286364544\n",
      "Step: 5810 Weights: [0.35609092 2.13242849] , error: 0.47374429286079284\n",
      "Step: 5811 Weights: [0.35609109 2.13242847] , error: 0.4737442928579525\n",
      "Step: 5812 Weights: [0.35609126 2.13242845] , error: 0.4737442928551257\n",
      "Step: 5813 Weights: [0.35609142 2.13242844] , error: 0.47374429285231245\n",
      "Step: 5814 Weights: [0.35609159 2.13242842] , error: 0.47374429284951136\n",
      "Step: 5815 Weights: [0.35609176 2.1324284 ] , error: 0.47374429284672287\n",
      "Step: 5816 Weights: [0.35609192 2.13242838] , error: 0.47374429284394737\n",
      "Step: 5817 Weights: [0.35609209 2.13242836] , error: 0.4737442928411838\n",
      "Step: 5818 Weights: [0.35609225 2.13242834] , error: 0.47374429283843317\n",
      "Step: 5819 Weights: [0.35609242 2.13242832] , error: 0.47374429283569564\n",
      "Step: 5820 Weights: [0.35609258 2.1324283 ] , error: 0.47374429283297104\n",
      "Step: 5821 Weights: [0.35609275 2.13242828] , error: 0.4737442928302576\n",
      "Step: 5822 Weights: [0.35609291 2.13242827] , error: 0.4737442928275569\n",
      "Step: 5823 Weights: [0.35609307 2.13242825] , error: 0.4737442928248681\n",
      "Step: 5824 Weights: [0.35609323 2.13242823] , error: 0.473744292822192\n",
      "Step: 5825 Weights: [0.3560934  2.13242821] , error: 0.4737442928195289\n",
      "Step: 5826 Weights: [0.35609356 2.13242819] , error: 0.4737442928168763\n",
      "Step: 5827 Weights: [0.35609372 2.13242817] , error: 0.4737442928142368\n",
      "Step: 5828 Weights: [0.35609388 2.13242815] , error: 0.4737442928116096\n",
      "Step: 5829 Weights: [0.35609404 2.13242814] , error: 0.47374429280899366\n",
      "Step: 5830 Weights: [0.3560942  2.13242812] , error: 0.4737442928063903\n",
      "Step: 5831 Weights: [0.35609436 2.1324281 ] , error: 0.4737442928037978\n",
      "Step: 5832 Weights: [0.35609452 2.13242808] , error: 0.47374429280121705\n",
      "Step: 5833 Weights: [0.35609468 2.13242806] , error: 0.47374429279864916\n",
      "Step: 5834 Weights: [0.35609484 2.13242804] , error: 0.4737442927960924\n",
      "Step: 5835 Weights: [0.356095   2.13242803] , error: 0.47374429279354724\n",
      "Step: 5836 Weights: [0.35609516 2.13242801] , error: 0.4737442927910146\n",
      "Step: 5837 Weights: [0.35609531 2.13242799] , error: 0.4737442927884928\n",
      "Step: 5838 Weights: [0.35609547 2.13242797] , error: 0.47374429278598224\n",
      "Step: 5839 Weights: [0.35609563 2.13242795] , error: 0.4737442927834834\n",
      "Step: 5840 Weights: [0.35609579 2.13242794] , error: 0.4737442927809956\n",
      "Step: 5841 Weights: [0.35609594 2.13242792] , error: 0.4737442927785197\n",
      "Step: 5842 Weights: [0.3560961 2.1324279] , error: 0.47374429277605457\n",
      "Step: 5843 Weights: [0.35609625 2.13242788] , error: 0.473744292773601\n",
      "Step: 5844 Weights: [0.35609641 2.13242787] , error: 0.47374429277115804\n",
      "Step: 5845 Weights: [0.35609656 2.13242785] , error: 0.47374429276872615\n",
      "Step: 5846 Weights: [0.35609672 2.13242783] , error: 0.4737442927663064\n",
      "Step: 5847 Weights: [0.35609687 2.13242781] , error: 0.47374429276389785\n",
      "Step: 5848 Weights: [0.35609703 2.13242779] , error: 0.4737442927614994\n",
      "Step: 5849 Weights: [0.35609718 2.13242778] , error: 0.4737442927591113\n",
      "Step: 5850 Weights: [0.35609733 2.13242776] , error: 0.4737442927567347\n",
      "Step: 5851 Weights: [0.35609749 2.13242774] , error: 0.47374429275436947\n",
      "Step: 5852 Weights: [0.35609764 2.13242772] , error: 0.4737442927520138\n",
      "Step: 5853 Weights: [0.35609779 2.13242771] , error: 0.4737442927496706\n",
      "Step: 5854 Weights: [0.35609794 2.13242769] , error: 0.4737442927473368\n",
      "Step: 5855 Weights: [0.3560981  2.13242767] , error: 0.4737442927450135\n",
      "Step: 5856 Weights: [0.35609825 2.13242766] , error: 0.473744292742702\n",
      "Step: 5857 Weights: [0.3560984  2.13242764] , error: 0.4737442927403997\n",
      "Step: 5858 Weights: [0.35609855 2.13242762] , error: 0.4737442927381088\n",
      "Step: 5859 Weights: [0.3560987 2.1324276] , error: 0.4737442927358275\n",
      "Step: 5860 Weights: [0.35609885 2.13242759] , error: 0.473744292733557\n",
      "Step: 5861 Weights: [0.356099   2.13242757] , error: 0.4737442927312969\n",
      "Step: 5862 Weights: [0.35609915 2.13242755] , error: 0.4737442927290469\n",
      "Step: 5863 Weights: [0.3560993  2.13242754] , error: 0.4737442927268069\n",
      "Step: 5864 Weights: [0.35609944 2.13242752] , error: 0.47374429272457835\n",
      "Step: 5865 Weights: [0.35609959 2.1324275 ] , error: 0.4737442927223605\n",
      "Step: 5866 Weights: [0.35609974 2.13242748] , error: 0.47374429272014995\n",
      "Step: 5867 Weights: [0.35609989 2.13242747] , error: 0.4737442927179511\n",
      "Step: 5868 Weights: [0.35610003 2.13242745] , error: 0.47374429271576146\n",
      "Step: 5869 Weights: [0.35610018 2.13242743] , error: 0.47374429271358215\n",
      "Step: 5870 Weights: [0.35610033 2.13242742] , error: 0.4737442927114138\n",
      "Step: 5871 Weights: [0.35610047 2.1324274 ] , error: 0.4737442927092541\n",
      "Step: 5872 Weights: [0.35610062 2.13242738] , error: 0.4737442927071052\n",
      "Step: 5873 Weights: [0.35610076 2.13242737] , error: 0.4737442927049656\n",
      "Step: 5874 Weights: [0.35610091 2.13242735] , error: 0.47374429270283547\n",
      "Step: 5875 Weights: [0.35610105 2.13242733] , error: 0.4737442927007152\n",
      "Step: 5876 Weights: [0.3561012  2.13242732] , error: 0.47374429269860474\n",
      "Step: 5877 Weights: [0.35610134 2.1324273 ] , error: 0.4737442926965038\n",
      "Step: 5878 Weights: [0.35610149 2.13242728] , error: 0.4737442926944124\n",
      "Step: 5879 Weights: [0.35610163 2.13242727] , error: 0.47374429269233126\n",
      "Step: 5880 Weights: [0.35610177 2.13242725] , error: 0.4737442926902587\n",
      "Step: 5881 Weights: [0.35610192 2.13242724] , error: 0.4737442926881953\n",
      "Step: 5882 Weights: [0.35610206 2.13242722] , error: 0.47374429268614215\n",
      "Step: 5883 Weights: [0.3561022 2.1324272] , error: 0.47374429268409785\n",
      "Step: 5884 Weights: [0.35610234 2.13242719] , error: 0.47374429268206275\n",
      "Step: 5885 Weights: [0.35610248 2.13242717] , error: 0.47374429268003754\n",
      "Step: 5886 Weights: [0.35610262 2.13242715] , error: 0.4737442926780211\n",
      "Step: 5887 Weights: [0.35610277 2.13242714] , error: 0.47374429267601514\n",
      "Step: 5888 Weights: [0.35610291 2.13242712] , error: 0.4737442926740149\n",
      "Step: 5889 Weights: [0.35610305 2.13242711] , error: 0.47374429267202767\n",
      "Step: 5890 Weights: [0.35610319 2.13242709] , error: 0.4737442926700479\n",
      "Step: 5891 Weights: [0.35610333 2.13242707] , error: 0.4737442926680765\n",
      "Step: 5892 Weights: [0.35610347 2.13242706] , error: 0.4737442926661152\n",
      "Step: 5893 Weights: [0.3561036  2.13242704] , error: 0.4737442926641622\n",
      "Step: 5894 Weights: [0.35610374 2.13242703] , error: 0.4737442926622182\n",
      "Step: 5895 Weights: [0.35610388 2.13242701] , error: 0.4737442926602829\n",
      "Step: 5896 Weights: [0.35610402 2.13242699] , error: 0.4737442926583568\n",
      "Step: 5897 Weights: [0.35610416 2.13242698] , error: 0.47374429265643864\n",
      "Step: 5898 Weights: [0.35610429 2.13242696] , error: 0.4737442926545303\n",
      "Step: 5899 Weights: [0.35610443 2.13242695] , error: 0.47374429265263057\n",
      "Step: 5900 Weights: [0.35610457 2.13242693] , error: 0.4737442926507393\n",
      "Step: 5901 Weights: [0.3561047  2.13242692] , error: 0.47374429264885554\n",
      "Step: 5902 Weights: [0.35610484 2.1324269 ] , error: 0.4737442926469818\n",
      "Step: 5903 Weights: [0.35610498 2.13242689] , error: 0.4737442926451164\n",
      "Step: 5904 Weights: [0.35610511 2.13242687] , error: 0.47374429264325874\n",
      "Step: 5905 Weights: [0.35610525 2.13242685] , error: 0.4737442926414104\n",
      "Step: 5906 Weights: [0.35610538 2.13242684] , error: 0.47374429263956963\n",
      "Step: 5907 Weights: [0.35610552 2.13242682] , error: 0.47374429263773854\n",
      "Step: 5908 Weights: [0.35610565 2.13242681] , error: 0.4737442926359139\n",
      "Step: 5909 Weights: [0.35610578 2.13242679] , error: 0.47374429263409923\n",
      "Step: 5910 Weights: [0.35610592 2.13242678] , error: 0.47374429263229184\n",
      "Step: 5911 Weights: [0.35610605 2.13242676] , error: 0.4737442926304929\n",
      "Step: 5912 Weights: [0.35610618 2.13242675] , error: 0.47374429262870277\n",
      "Step: 5913 Weights: [0.35610632 2.13242673] , error: 0.4737442926269202\n",
      "Step: 5914 Weights: [0.35610645 2.13242672] , error: 0.47374429262514595\n",
      "Step: 5915 Weights: [0.35610658 2.1324267 ] , error: 0.4737442926233792\n",
      "Step: 5916 Weights: [0.35610671 2.13242669] , error: 0.47374429262162154\n",
      "Step: 5917 Weights: [0.35610684 2.13242667] , error: 0.4737442926198715\n",
      "Step: 5918 Weights: [0.35610698 2.13242666] , error: 0.4737442926181289\n",
      "Step: 5919 Weights: [0.35610711 2.13242664] , error: 0.47374429261639517\n",
      "Step: 5920 Weights: [0.35610724 2.13242663] , error: 0.47374429261466855\n",
      "Step: 5921 Weights: [0.35610737 2.13242661] , error: 0.47374429261295015\n",
      "Step: 5922 Weights: [0.3561075 2.1324266] , error: 0.47374429261123924\n",
      "Step: 5923 Weights: [0.35610763 2.13242658] , error: 0.47374429260953693\n",
      "Step: 5924 Weights: [0.35610776 2.13242657] , error: 0.4737442926078418\n",
      "Step: 5925 Weights: [0.35610789 2.13242655] , error: 0.47374429260615447\n",
      "Step: 5926 Weights: [0.35610801 2.13242654] , error: 0.47374429260447415\n",
      "Step: 5927 Weights: [0.35610814 2.13242652] , error: 0.47374429260280265\n",
      "Step: 5928 Weights: [0.35610827 2.13242651] , error: 0.47374429260113765\n",
      "Step: 5929 Weights: [0.3561084  2.13242649] , error: 0.4737442925994806\n",
      "Step: 5930 Weights: [0.35610853 2.13242648] , error: 0.47374429259783163\n",
      "Step: 5931 Weights: [0.35610865 2.13242646] , error: 0.47374429259618955\n",
      "Step: 5932 Weights: [0.35610878 2.13242645] , error: 0.47374429259455575\n",
      "Step: 5933 Weights: [0.35610891 2.13242644] , error: 0.47374429259292805\n",
      "Step: 5934 Weights: [0.35610904 2.13242642] , error: 0.47374429259130885\n",
      "Step: 5935 Weights: [0.35610916 2.13242641] , error: 0.4737442925896973\n",
      "Step: 5936 Weights: [0.35610929 2.13242639] , error: 0.4737442925880925\n",
      "Step: 5937 Weights: [0.35610941 2.13242638] , error: 0.4737442925864954\n",
      "Step: 5938 Weights: [0.35610954 2.13242636] , error: 0.4737442925849049\n",
      "Step: 5939 Weights: [0.35610966 2.13242635] , error: 0.4737442925833222\n",
      "Step: 5940 Weights: [0.35610979 2.13242634] , error: 0.4737442925817467\n",
      "Step: 5941 Weights: [0.35610991 2.13242632] , error: 0.47374429258017764\n",
      "Step: 5942 Weights: [0.35611004 2.13242631] , error: 0.4737442925786165\n",
      "Step: 5943 Weights: [0.35611016 2.13242629] , error: 0.473744292577062\n",
      "Step: 5944 Weights: [0.35611028 2.13242628] , error: 0.47374429257551537\n",
      "Step: 5945 Weights: [0.35611041 2.13242626] , error: 0.4737442925739745\n",
      "Step: 5946 Weights: [0.35611053 2.13242625] , error: 0.47374429257244155\n",
      "Step: 5947 Weights: [0.35611065 2.13242624] , error: 0.4737442925709156\n",
      "Step: 5948 Weights: [0.35611078 2.13242622] , error: 0.47374429256939615\n",
      "Step: 5949 Weights: [0.3561109  2.13242621] , error: 0.47374429256788414\n",
      "Step: 5950 Weights: [0.35611102 2.13242619] , error: 0.47374429256637907\n",
      "Step: 5951 Weights: [0.35611114 2.13242618] , error: 0.47374429256487954\n",
      "Step: 5952 Weights: [0.35611126 2.13242617] , error: 0.4737442925633887\n",
      "Step: 5953 Weights: [0.35611138 2.13242615] , error: 0.47374429256190387\n",
      "Step: 5954 Weights: [0.35611151 2.13242614] , error: 0.4737442925604253\n",
      "Step: 5955 Weights: [0.35611163 2.13242612] , error: 0.4737442925589539\n",
      "Step: 5956 Weights: [0.35611175 2.13242611] , error: 0.4737442925574896\n",
      "Step: 5957 Weights: [0.35611187 2.1324261 ] , error: 0.47374429255603134\n",
      "Step: 5958 Weights: [0.35611199 2.13242608] , error: 0.4737442925545803\n",
      "Step: 5959 Weights: [0.35611211 2.13242607] , error: 0.47374429255313466\n",
      "Step: 5960 Weights: [0.35611222 2.13242606] , error: 0.4737442925516976\n",
      "Step: 5961 Weights: [0.35611234 2.13242604] , error: 0.4737442925502653\n",
      "Step: 5962 Weights: [0.35611246 2.13242603] , error: 0.4737442925488401\n",
      "Step: 5963 Weights: [0.35611258 2.13242602] , error: 0.473744292547422\n",
      "Step: 5964 Weights: [0.3561127 2.132426 ] , error: 0.47374429254600925\n",
      "Step: 5965 Weights: [0.35611282 2.13242599] , error: 0.473744292544604\n",
      "Step: 5966 Weights: [0.35611293 2.13242598] , error: 0.47374429254320427\n",
      "Step: 5967 Weights: [0.35611305 2.13242596] , error: 0.47374429254181155\n",
      "Step: 5968 Weights: [0.35611317 2.13242595] , error: 0.4737442925404248\n",
      "Step: 5969 Weights: [0.35611329 2.13242594] , error: 0.4737442925390448\n",
      "Step: 5970 Weights: [0.3561134  2.13242592] , error: 0.4737442925376713\n",
      "Step: 5971 Weights: [0.35611352 2.13242591] , error: 0.47374429253630335\n",
      "Step: 5972 Weights: [0.35611363 2.1324259 ] , error: 0.47374429253494077\n",
      "Step: 5973 Weights: [0.35611375 2.13242588] , error: 0.4737442925335859\n",
      "Step: 5974 Weights: [0.35611387 2.13242587] , error: 0.47374429253223777\n",
      "Step: 5975 Weights: [0.35611398 2.13242586] , error: 0.4737442925308944\n",
      "Step: 5976 Weights: [0.3561141  2.13242584] , error: 0.47374429252955713\n",
      "Step: 5977 Weights: [0.35611421 2.13242583] , error: 0.473744292528226\n",
      "Step: 5978 Weights: [0.35611432 2.13242582] , error: 0.47374429252690176\n",
      "Step: 5979 Weights: [0.35611444 2.1324258 ] , error: 0.4737442925255836\n",
      "Step: 5980 Weights: [0.35611455 2.13242579] , error: 0.47374429252427036\n",
      "Step: 5981 Weights: [0.35611467 2.13242578] , error: 0.4737442925229641\n",
      "Step: 5982 Weights: [0.35611478 2.13242576] , error: 0.47374429252166295\n",
      "Step: 5983 Weights: [0.35611489 2.13242575] , error: 0.47374429252036854\n",
      "Step: 5984 Weights: [0.35611501 2.13242574] , error: 0.4737442925190788\n",
      "Step: 5985 Weights: [0.35611512 2.13242573] , error: 0.4737442925177964\n",
      "Step: 5986 Weights: [0.35611523 2.13242571] , error: 0.47374429251651884\n",
      "Step: 5987 Weights: [0.35611534 2.1324257 ] , error: 0.4737442925152479\n",
      "Step: 5988 Weights: [0.35611545 2.13242569] , error: 0.4737442925139821\n",
      "Step: 5989 Weights: [0.35611557 2.13242567] , error: 0.47374429251272215\n",
      "Step: 5990 Weights: [0.35611568 2.13242566] , error: 0.47374429251146905\n",
      "Step: 5991 Weights: [0.35611579 2.13242565] , error: 0.4737442925102197\n",
      "Step: 5992 Weights: [0.3561159  2.13242564] , error: 0.473744292508977\n",
      "Step: 5993 Weights: [0.35611601 2.13242562] , error: 0.47374429250773986\n",
      "Step: 5994 Weights: [0.35611612 2.13242561] , error: 0.4737442925065093\n",
      "Step: 5995 Weights: [0.35611623 2.1324256 ] , error: 0.4737442925052836\n",
      "Step: 5996 Weights: [0.35611634 2.13242559] , error: 0.4737442925040628\n",
      "Step: 5997 Weights: [0.35611645 2.13242557] , error: 0.4737442925028489\n",
      "Step: 5998 Weights: [0.35611656 2.13242556] , error: 0.47374429250163913\n",
      "Step: 5999 Weights: [0.35611667 2.13242555] , error: 0.4737442925004358\n",
      "Step: 6000 Weights: [0.35611678 2.13242554] , error: 0.4737442924992373\n",
      "Step: 6001 Weights: [0.35611689 2.13242552] , error: 0.47374429249804517\n",
      "Step: 6002 Weights: [0.35611699 2.13242551] , error: 0.4737442924968584\n",
      "Step: 6003 Weights: [0.3561171 2.1324255] , error: 0.47374429249567607\n",
      "Step: 6004 Weights: [0.35611721 2.13242549] , error: 0.47374429249450006\n",
      "Step: 6005 Weights: [0.35611732 2.13242547] , error: 0.4737442924933287\n",
      "Step: 6006 Weights: [0.35611742 2.13242546] , error: 0.47374429249216304\n",
      "Step: 6007 Weights: [0.35611753 2.13242545] , error: 0.4737442924910022\n",
      "Step: 6008 Weights: [0.35611764 2.13242544] , error: 0.4737442924898472\n",
      "Step: 6009 Weights: [0.35611775 2.13242543] , error: 0.4737442924886972\n",
      "Step: 6010 Weights: [0.35611785 2.13242541] , error: 0.47374429248755423\n",
      "Step: 6011 Weights: [0.35611796 2.1324254 ] , error: 0.47374429248641303\n",
      "Step: 6012 Weights: [0.35611806 2.13242539] , error: 0.4737442924852792\n",
      "Step: 6013 Weights: [0.35611817 2.13242538] , error: 0.47374429248415045\n",
      "Step: 6014 Weights: [0.35611827 2.13242536] , error: 0.47374429248302674\n",
      "Step: 6015 Weights: [0.35611838 2.13242535] , error: 0.4737442924819074\n",
      "Step: 6016 Weights: [0.35611848 2.13242534] , error: 0.47374429248079364\n",
      "Step: 6017 Weights: [0.35611859 2.13242533] , error: 0.4737442924796853\n",
      "Step: 6018 Weights: [0.35611869 2.13242532] , error: 0.473744292478582\n",
      "Step: 6019 Weights: [0.3561188 2.1324253] , error: 0.4737442924774832\n",
      "Step: 6020 Weights: [0.3561189  2.13242529] , error: 0.47374429247638894\n",
      "Step: 6021 Weights: [0.35611901 2.13242528] , error: 0.47374429247530114\n",
      "Step: 6022 Weights: [0.35611911 2.13242527] , error: 0.47374429247421745\n",
      "Step: 6023 Weights: [0.35611921 2.13242526] , error: 0.4737442924731383\n",
      "Step: 6024 Weights: [0.35611932 2.13242525] , error: 0.4737442924720652\n",
      "Step: 6025 Weights: [0.35611942 2.13242523] , error: 0.47374429247099537\n",
      "Step: 6026 Weights: [0.35611952 2.13242522] , error: 0.47374429246993205\n",
      "Step: 6027 Weights: [0.35611962 2.13242521] , error: 0.4737442924688726\n",
      "Step: 6028 Weights: [0.35611973 2.1324252 ] , error: 0.473744292467819\n",
      "Step: 6029 Weights: [0.35611983 2.13242519] , error: 0.4737442924667689\n",
      "Step: 6030 Weights: [0.35611993 2.13242518] , error: 0.4737442924657242\n",
      "Step: 6031 Weights: [0.35612003 2.13242516] , error: 0.47374429246468397\n",
      "Step: 6032 Weights: [0.35612013 2.13242515] , error: 0.4737442924636497\n",
      "Step: 6033 Weights: [0.35612023 2.13242514] , error: 0.47374429246261873\n",
      "Step: 6034 Weights: [0.35612033 2.13242513] , error: 0.4737442924615921\n",
      "Step: 6035 Weights: [0.35612043 2.13242512] , error: 0.47374429246057115\n",
      "Step: 6036 Weights: [0.35612053 2.13242511] , error: 0.47374429245955574\n",
      "Step: 6037 Weights: [0.35612063 2.13242509] , error: 0.4737442924585434\n",
      "Step: 6038 Weights: [0.35612073 2.13242508] , error: 0.47374429245753547\n",
      "Step: 6039 Weights: [0.35612083 2.13242507] , error: 0.4737442924565328\n",
      "Step: 6040 Weights: [0.35612093 2.13242506] , error: 0.47374429245553584\n",
      "Step: 6041 Weights: [0.35612103 2.13242505] , error: 0.47374429245454164\n",
      "Step: 6042 Weights: [0.35612113 2.13242504] , error: 0.47374429245355276\n",
      "Step: 6043 Weights: [0.35612123 2.13242503] , error: 0.473744292452568\n",
      "Step: 6044 Weights: [0.35612133 2.13242502] , error: 0.4737442924515885\n",
      "Step: 6045 Weights: [0.35612143 2.132425  ] , error: 0.47374429245061245\n",
      "Step: 6046 Weights: [0.35612152 2.13242499] , error: 0.4737442924496419\n",
      "Step: 6047 Weights: [0.35612162 2.13242498] , error: 0.4737442924486751\n",
      "Step: 6048 Weights: [0.35612172 2.13242497] , error: 0.47374429244771193\n",
      "Step: 6049 Weights: [0.35612182 2.13242496] , error: 0.4737442924467544\n",
      "Step: 6050 Weights: [0.35612191 2.13242495] , error: 0.47374429244580035\n",
      "Step: 6051 Weights: [0.35612201 2.13242494] , error: 0.47374429244485244\n",
      "Step: 6052 Weights: [0.35612211 2.13242493] , error: 0.473744292443907\n",
      "Step: 6053 Weights: [0.3561222  2.13242492] , error: 0.47374429244296584\n",
      "Step: 6054 Weights: [0.3561223 2.1324249] , error: 0.4737442924420303\n",
      "Step: 6055 Weights: [0.35612239 2.13242489] , error: 0.47374429244109767\n",
      "Step: 6056 Weights: [0.35612249 2.13242488] , error: 0.47374429244017\n",
      "Step: 6057 Weights: [0.35612259 2.13242487] , error: 0.47374429243924676\n",
      "Step: 6058 Weights: [0.35612268 2.13242486] , error: 0.47374429243832744\n",
      "Step: 6059 Weights: [0.35612278 2.13242485] , error: 0.4737442924374122\n",
      "Step: 6060 Weights: [0.35612287 2.13242484] , error: 0.4737442924365013\n",
      "Step: 6061 Weights: [0.35612297 2.13242483] , error: 0.47374429243559457\n",
      "Step: 6062 Weights: [0.35612306 2.13242482] , error: 0.47374429243469174\n",
      "Step: 6063 Weights: [0.35612315 2.13242481] , error: 0.47374429243379257\n",
      "Step: 6064 Weights: [0.35612325 2.1324248 ] , error: 0.4737442924328988\n",
      "Step: 6065 Weights: [0.35612334 2.13242478] , error: 0.4737442924320078\n",
      "Step: 6066 Weights: [0.35612344 2.13242477] , error: 0.4737442924311216\n",
      "Step: 6067 Weights: [0.35612353 2.13242476] , error: 0.4737442924302395\n",
      "Step: 6068 Weights: [0.35612362 2.13242475] , error: 0.4737442924293618\n",
      "Step: 6069 Weights: [0.35612372 2.13242474] , error: 0.47374429242848703\n",
      "Step: 6070 Weights: [0.35612381 2.13242473] , error: 0.47374429242761673\n",
      "Step: 6071 Weights: [0.3561239  2.13242472] , error: 0.47374429242675054\n",
      "Step: 6072 Weights: [0.35612399 2.13242471] , error: 0.4737442924258879\n",
      "Step: 6073 Weights: [0.35612409 2.1324247 ] , error: 0.47374429242502947\n",
      "Step: 6074 Weights: [0.35612418 2.13242469] , error: 0.47374429242417515\n",
      "Step: 6075 Weights: [0.35612427 2.13242468] , error: 0.4737442924233245\n",
      "Step: 6076 Weights: [0.35612436 2.13242467] , error: 0.47374429242247795\n",
      "Step: 6077 Weights: [0.35612445 2.13242466] , error: 0.47374429242163435\n",
      "Step: 6078 Weights: [0.35612454 2.13242465] , error: 0.4737442924207953\n",
      "Step: 6079 Weights: [0.35612463 2.13242464] , error: 0.47374429241995997\n",
      "Step: 6080 Weights: [0.35612472 2.13242463] , error: 0.47374429241912874\n",
      "Step: 6081 Weights: [0.35612481 2.13242462] , error: 0.4737442924183005\n",
      "Step: 6082 Weights: [0.3561249  2.13242461] , error: 0.47374429241747695\n",
      "Step: 6083 Weights: [0.35612499 2.1324246 ] , error: 0.4737442924166564\n",
      "Step: 6084 Weights: [0.35612508 2.13242459] , error: 0.4737442924158401\n",
      "Step: 6085 Weights: [0.35612517 2.13242458] , error: 0.47374429241502775\n",
      "Step: 6086 Weights: [0.35612526 2.13242457] , error: 0.47374429241421834\n",
      "Step: 6087 Weights: [0.35612535 2.13242456] , error: 0.4737442924134132\n",
      "Step: 6088 Weights: [0.35612544 2.13242454] , error: 0.47374429241261184\n",
      "Step: 6089 Weights: [0.35612553 2.13242453] , error: 0.47374429241181326\n",
      "Step: 6090 Weights: [0.35612562 2.13242452] , error: 0.47374429241101856\n",
      "Step: 6091 Weights: [0.35612571 2.13242451] , error: 0.4737442924102286\n",
      "Step: 6092 Weights: [0.3561258 2.1324245] , error: 0.47374429240944127\n",
      "Step: 6093 Weights: [0.35612588 2.13242449] , error: 0.47374429240865784\n",
      "Step: 6094 Weights: [0.35612597 2.13242448] , error: 0.4737442924078774\n",
      "Step: 6095 Weights: [0.35612606 2.13242447] , error: 0.4737442924071007\n",
      "Step: 6096 Weights: [0.35612615 2.13242446] , error: 0.4737442924063282\n",
      "Step: 6097 Weights: [0.35612623 2.13242445] , error: 0.4737442924055595\n",
      "Step: 6098 Weights: [0.35612632 2.13242444] , error: 0.473744292404793\n",
      "Step: 6099 Weights: [0.35612641 2.13242443] , error: 0.4737442924040307\n",
      "Step: 6100 Weights: [0.35612649 2.13242442] , error: 0.4737442924032719\n",
      "Step: 6101 Weights: [0.35612658 2.13242441] , error: 0.4737442924025168\n",
      "Step: 6102 Weights: [0.35612667 2.1324244 ] , error: 0.47374429240176447\n",
      "Step: 6103 Weights: [0.35612675 2.13242439] , error: 0.4737442924010155\n",
      "Step: 6104 Weights: [0.35612684 2.13242439] , error: 0.47374429240027016\n",
      "Step: 6105 Weights: [0.35612692 2.13242438] , error: 0.47374429239952887\n",
      "Step: 6106 Weights: [0.35612701 2.13242437] , error: 0.4737442923987905\n",
      "Step: 6107 Weights: [0.35612709 2.13242436] , error: 0.4737442923980559\n",
      "Step: 6108 Weights: [0.35612718 2.13242435] , error: 0.47374429239732324\n",
      "Step: 6109 Weights: [0.35612726 2.13242434] , error: 0.4737442923965947\n",
      "Step: 6110 Weights: [0.35612735 2.13242433] , error: 0.47374429239586996\n",
      "Step: 6111 Weights: [0.35612743 2.13242432] , error: 0.4737442923951484\n",
      "Step: 6112 Weights: [0.35612752 2.13242431] , error: 0.47374429239442983\n",
      "Step: 6113 Weights: [0.3561276 2.1324243] , error: 0.47374429239371435\n",
      "Step: 6114 Weights: [0.35612769 2.13242429] , error: 0.47374429239300353\n",
      "Step: 6115 Weights: [0.35612777 2.13242428] , error: 0.4737442923922949\n",
      "Step: 6116 Weights: [0.35612785 2.13242427] , error: 0.473744292391589\n",
      "Step: 6117 Weights: [0.35612794 2.13242426] , error: 0.4737442923908869\n",
      "Step: 6118 Weights: [0.35612802 2.13242425] , error: 0.4737442923901881\n",
      "Step: 6119 Weights: [0.3561281  2.13242424] , error: 0.4737442923894919\n",
      "Step: 6120 Weights: [0.35612819 2.13242423] , error: 0.47374429238879934\n",
      "Step: 6121 Weights: [0.35612827 2.13242422] , error: 0.47374429238810956\n",
      "Step: 6122 Weights: [0.35612835 2.13242421] , error: 0.47374429238742277\n",
      "Step: 6123 Weights: [0.35612843 2.1324242 ] , error: 0.4737442923867393\n",
      "Step: 6124 Weights: [0.35612851 2.13242419] , error: 0.4737442923860592\n",
      "Step: 6125 Weights: [0.3561286  2.13242418] , error: 0.4737442923853833\n",
      "Step: 6126 Weights: [0.35612868 2.13242417] , error: 0.4737442923847085\n",
      "Step: 6127 Weights: [0.35612876 2.13242417] , error: 0.47374429238403815\n",
      "Step: 6128 Weights: [0.35612884 2.13242416] , error: 0.47374429238337035\n",
      "Step: 6129 Weights: [0.35612892 2.13242415] , error: 0.47374429238270543\n",
      "Step: 6130 Weights: [0.356129   2.13242414] , error: 0.47374429238204396\n",
      "Step: 6131 Weights: [0.35612908 2.13242413] , error: 0.47374429238138516\n",
      "Step: 6132 Weights: [0.35612916 2.13242412] , error: 0.473744292380729\n",
      "Step: 6133 Weights: [0.35612924 2.13242411] , error: 0.4737442923800761\n",
      "Step: 6134 Weights: [0.35612932 2.1324241 ] , error: 0.47374429237942633\n",
      "Step: 6135 Weights: [0.3561294  2.13242409] , error: 0.4737442923787794\n",
      "Step: 6136 Weights: [0.35612948 2.13242408] , error: 0.4737442923781352\n",
      "Step: 6137 Weights: [0.35612956 2.13242407] , error: 0.4737442923774944\n",
      "Step: 6138 Weights: [0.35612964 2.13242406] , error: 0.47374429237685695\n",
      "Step: 6139 Weights: [0.35612972 2.13242406] , error: 0.4737442923762213\n",
      "Step: 6140 Weights: [0.3561298  2.13242405] , error: 0.4737442923755891\n",
      "Step: 6141 Weights: [0.35612988 2.13242404] , error: 0.4737442923749603\n",
      "Step: 6142 Weights: [0.35612996 2.13242403] , error: 0.473744292374333\n",
      "Step: 6143 Weights: [0.35613004 2.13242402] , error: 0.4737442923737102\n",
      "Step: 6144 Weights: [0.35613012 2.13242401] , error: 0.4737442923730889\n",
      "Step: 6145 Weights: [0.35613019 2.132424  ] , error: 0.47374429237247134\n",
      "Step: 6146 Weights: [0.35613027 2.13242399] , error: 0.473744292371856\n",
      "Step: 6147 Weights: [0.35613035 2.13242398] , error: 0.47374429237124405\n",
      "Step: 6148 Weights: [0.35613043 2.13242397] , error: 0.473744292370635\n",
      "Step: 6149 Weights: [0.3561305  2.13242397] , error: 0.47374429237002735\n",
      "Step: 6150 Weights: [0.35613058 2.13242396] , error: 0.4737442923694234\n",
      "Step: 6151 Weights: [0.35613066 2.13242395] , error: 0.4737442923688221\n",
      "Step: 6152 Weights: [0.35613074 2.13242394] , error: 0.4737442923682238\n",
      "Step: 6153 Weights: [0.35613081 2.13242393] , error: 0.4737442923676276\n",
      "Step: 6154 Weights: [0.35613089 2.13242392] , error: 0.4737442923670351\n",
      "Step: 6155 Weights: [0.35613097 2.13242391] , error: 0.4737442923664448\n",
      "Step: 6156 Weights: [0.35613104 2.1324239 ] , error: 0.47374429236585663\n",
      "Step: 6157 Weights: [0.35613112 2.1324239 ] , error: 0.47374429236527205\n",
      "Step: 6158 Weights: [0.35613119 2.13242389] , error: 0.47374429236468946\n",
      "Step: 6159 Weights: [0.35613127 2.13242388] , error: 0.47374429236410986\n",
      "Step: 6160 Weights: [0.35613134 2.13242387] , error: 0.4737442923635332\n",
      "Step: 6161 Weights: [0.35613142 2.13242386] , error: 0.47374429236295784\n",
      "Step: 6162 Weights: [0.3561315  2.13242385] , error: 0.4737442923623859\n",
      "Step: 6163 Weights: [0.35613157 2.13242384] , error: 0.47374429236181725\n",
      "Step: 6164 Weights: [0.35613164 2.13242384] , error: 0.4737442923612505\n",
      "Step: 6165 Weights: [0.35613172 2.13242383] , error: 0.4737442923606865\n",
      "Step: 6166 Weights: [0.35613179 2.13242382] , error: 0.47374429236012594\n",
      "Step: 6167 Weights: [0.35613187 2.13242381] , error: 0.4737442923595665\n",
      "Step: 6168 Weights: [0.35613194 2.1324238 ] , error: 0.47374429235900994\n",
      "Step: 6169 Weights: [0.35613202 2.13242379] , error: 0.473744292358456\n",
      "Step: 6170 Weights: [0.35613209 2.13242378] , error: 0.4737442923579053\n",
      "Step: 6171 Weights: [0.35613216 2.13242378] , error: 0.47374429235735593\n",
      "Step: 6172 Weights: [0.35613224 2.13242377] , error: 0.47374429235680954\n",
      "Step: 6173 Weights: [0.35613231 2.13242376] , error: 0.47374429235626614\n",
      "Step: 6174 Weights: [0.35613238 2.13242375] , error: 0.47374429235572496\n",
      "Step: 6175 Weights: [0.35613246 2.13242374] , error: 0.4737442923551853\n",
      "Step: 6176 Weights: [0.35613253 2.13242373] , error: 0.4737442923546497\n",
      "Step: 6177 Weights: [0.3561326  2.13242373] , error: 0.4737442923541151\n",
      "Step: 6178 Weights: [0.35613267 2.13242372] , error: 0.47374429235358384\n",
      "Step: 6179 Weights: [0.35613275 2.13242371] , error: 0.47374429235305443\n",
      "Step: 6180 Weights: [0.35613282 2.1324237 ] , error: 0.4737442923525279\n",
      "Step: 6181 Weights: [0.35613289 2.13242369] , error: 0.4737442923520038\n",
      "Step: 6182 Weights: [0.35613296 2.13242368] , error: 0.47374429235148185\n",
      "Step: 6183 Weights: [0.35613303 2.13242368] , error: 0.4737442923509627\n",
      "Step: 6184 Weights: [0.35613311 2.13242367] , error: 0.4737442923504458\n",
      "Step: 6185 Weights: [0.35613318 2.13242366] , error: 0.47374429234993026\n",
      "Step: 6186 Weights: [0.35613325 2.13242365] , error: 0.47374429234941856\n",
      "Step: 6187 Weights: [0.35613332 2.13242364] , error: 0.47374429234890836\n",
      "Step: 6188 Weights: [0.35613339 2.13242364] , error: 0.4737442923484003\n",
      "Step: 6189 Weights: [0.35613346 2.13242363] , error: 0.47374429234789456\n",
      "Step: 6190 Weights: [0.35613353 2.13242362] , error: 0.4737442923473909\n",
      "Step: 6191 Weights: [0.3561336  2.13242361] , error: 0.4737442923468909\n",
      "Step: 6192 Weights: [0.35613367 2.1324236 ] , error: 0.47374429234639187\n",
      "Step: 6193 Weights: [0.35613374 2.1324236 ] , error: 0.47374429234589566\n",
      "Step: 6194 Weights: [0.35613381 2.13242359] , error: 0.4737442923454015\n",
      "Step: 6195 Weights: [0.35613388 2.13242358] , error: 0.47374429234491056\n",
      "Step: 6196 Weights: [0.35613395 2.13242357] , error: 0.4737442923444206\n",
      "Step: 6197 Weights: [0.35613402 2.13242356] , error: 0.47374429234393317\n",
      "Step: 6198 Weights: [0.35613409 2.13242356] , error: 0.47374429234344806\n",
      "Step: 6199 Weights: [0.35613416 2.13242355] , error: 0.47374429234296456\n",
      "Step: 6200 Weights: [0.35613423 2.13242354] , error: 0.4737442923424844\n",
      "Step: 6201 Weights: [0.3561343  2.13242353] , error: 0.4737442923420053\n",
      "Step: 6202 Weights: [0.35613437 2.13242352] , error: 0.4737442923415289\n",
      "Step: 6203 Weights: [0.35613443 2.13242352] , error: 0.4737442923410548\n",
      "Step: 6204 Weights: [0.3561345  2.13242351] , error: 0.47374429234058274\n",
      "Step: 6205 Weights: [0.35613457 2.1324235 ] , error: 0.4737442923401135\n",
      "Step: 6206 Weights: [0.35613464 2.13242349] , error: 0.47374429233964516\n",
      "Step: 6207 Weights: [0.35613471 2.13242349] , error: 0.4737442923391796\n",
      "Step: 6208 Weights: [0.35613477 2.13242348] , error: 0.47374429233871607\n",
      "Step: 6209 Weights: [0.35613484 2.13242347] , error: 0.4737442923382549\n",
      "Step: 6210 Weights: [0.35613491 2.13242346] , error: 0.47374429233779647\n",
      "Step: 6211 Weights: [0.35613498 2.13242345] , error: 0.473744292337339\n",
      "Step: 6212 Weights: [0.35613504 2.13242345] , error: 0.47374429233688325\n",
      "Step: 6213 Weights: [0.35613511 2.13242344] , error: 0.4737442923364303\n",
      "Step: 6214 Weights: [0.35613518 2.13242343] , error: 0.4737442923359794\n",
      "Step: 6215 Weights: [0.35613524 2.13242342] , error: 0.47374429233553117\n",
      "Step: 6216 Weights: [0.35613531 2.13242342] , error: 0.4737442923350839\n",
      "Step: 6217 Weights: [0.35613538 2.13242341] , error: 0.47374429233463894\n",
      "Step: 6218 Weights: [0.35613544 2.1324234 ] , error: 0.47374429233419557\n",
      "Step: 6219 Weights: [0.35613551 2.13242339] , error: 0.47374429233375526\n",
      "Step: 6220 Weights: [0.35613557 2.13242339] , error: 0.47374429233331605\n",
      "Step: 6221 Weights: [0.35613564 2.13242338] , error: 0.473744292332881\n",
      "Step: 6222 Weights: [0.35613571 2.13242337] , error: 0.4737442923324447\n",
      "Step: 6223 Weights: [0.35613577 2.13242336] , error: 0.47374429233201176\n",
      "Step: 6224 Weights: [0.35613584 2.13242336] , error: 0.47374429233158133\n",
      "Step: 6225 Weights: [0.3561359  2.13242335] , error: 0.4737442923311528\n",
      "Step: 6226 Weights: [0.35613597 2.13242334] , error: 0.4737442923307254\n",
      "Step: 6227 Weights: [0.35613603 2.13242333] , error: 0.47374429233030035\n",
      "Step: 6228 Weights: [0.3561361  2.13242333] , error: 0.4737442923298774\n",
      "Step: 6229 Weights: [0.35613616 2.13242332] , error: 0.4737442923294571\n",
      "Step: 6230 Weights: [0.35613622 2.13242331] , error: 0.47374429232903703\n",
      "Step: 6231 Weights: [0.35613629 2.1324233 ] , error: 0.4737442923286196\n",
      "Step: 6232 Weights: [0.35613635 2.1324233 ] , error: 0.47374429232820536\n",
      "Step: 6233 Weights: [0.35613642 2.13242329] , error: 0.473744292327792\n",
      "Step: 6234 Weights: [0.35613648 2.13242328] , error: 0.47374429232737986\n",
      "Step: 6235 Weights: [0.35613654 2.13242328] , error: 0.47374429232697013\n",
      "Step: 6236 Weights: [0.35613661 2.13242327] , error: 0.47374429232656257\n",
      "Step: 6237 Weights: [0.35613667 2.13242326] , error: 0.47374429232615617\n",
      "Step: 6238 Weights: [0.35613673 2.13242325] , error: 0.473744292325752\n",
      "Step: 6239 Weights: [0.3561368  2.13242325] , error: 0.4737442923253501\n",
      "Step: 6240 Weights: [0.35613686 2.13242324] , error: 0.4737442923249497\n",
      "Step: 6241 Weights: [0.35613692 2.13242323] , error: 0.4737442923245506\n",
      "Step: 6242 Weights: [0.35613699 2.13242322] , error: 0.47374429232415377\n",
      "Step: 6243 Weights: [0.35613705 2.13242322] , error: 0.4737442923237589\n",
      "Step: 6244 Weights: [0.35613711 2.13242321] , error: 0.47374429232336523\n",
      "Step: 6245 Weights: [0.35613717 2.1324232 ] , error: 0.47374429232297394\n",
      "Step: 6246 Weights: [0.35613723 2.1324232 ] , error: 0.473744292322584\n",
      "Step: 6247 Weights: [0.3561373  2.13242319] , error: 0.473744292322197\n",
      "Step: 6248 Weights: [0.35613736 2.13242318] , error: 0.47374429232181103\n",
      "Step: 6249 Weights: [0.35613742 2.13242318] , error: 0.47374429232142684\n",
      "Step: 6250 Weights: [0.35613748 2.13242317] , error: 0.4737442923210435\n",
      "Step: 6251 Weights: [0.35613754 2.13242316] , error: 0.47374429232066306\n",
      "Step: 6252 Weights: [0.3561376  2.13242315] , error: 0.47374429232028326\n",
      "Step: 6253 Weights: [0.35613766 2.13242315] , error: 0.47374429231990584\n",
      "Step: 6254 Weights: [0.35613773 2.13242314] , error: 0.47374429231953075\n",
      "Step: 6255 Weights: [0.35613779 2.13242313] , error: 0.4737442923191558\n",
      "Step: 6256 Weights: [0.35613785 2.13242313] , error: 0.4737442923187849\n",
      "Step: 6257 Weights: [0.35613791 2.13242312] , error: 0.4737442923184136\n",
      "Step: 6258 Weights: [0.35613797 2.13242311] , error: 0.4737442923180444\n",
      "Step: 6259 Weights: [0.35613803 2.13242311] , error: 0.47374429231767745\n",
      "Step: 6260 Weights: [0.35613809 2.1324231 ] , error: 0.4737442923173116\n",
      "Step: 6261 Weights: [0.35613815 2.13242309] , error: 0.47374429231694803\n",
      "Step: 6262 Weights: [0.35613821 2.13242308] , error: 0.47374429231658566\n",
      "Step: 6263 Weights: [0.35613827 2.13242308] , error: 0.47374429231622484\n",
      "Step: 6264 Weights: [0.35613833 2.13242307] , error: 0.4737442923158665\n",
      "Step: 6265 Weights: [0.35613839 2.13242306] , error: 0.4737442923155089\n",
      "Step: 6266 Weights: [0.35613845 2.13242306] , error: 0.4737442923151534\n",
      "Step: 6267 Weights: [0.35613851 2.13242305] , error: 0.4737442923147998\n",
      "Step: 6268 Weights: [0.35613856 2.13242304] , error: 0.47374429231444726\n",
      "Step: 6269 Weights: [0.35613862 2.13242304] , error: 0.47374429231409676\n",
      "Step: 6270 Weights: [0.35613868 2.13242303] , error: 0.47374429231374715\n",
      "Step: 6271 Weights: [0.35613874 2.13242302] , error: 0.47374429231339976\n",
      "Step: 6272 Weights: [0.3561388  2.13242302] , error: 0.4737442923130536\n",
      "Step: 6273 Weights: [0.35613886 2.13242301] , error: 0.47374429231270887\n",
      "Step: 6274 Weights: [0.35613892 2.132423  ] , error: 0.47374429231236614\n",
      "Step: 6275 Weights: [0.35613897 2.132423  ] , error: 0.47374429231202525\n",
      "Step: 6276 Weights: [0.35613903 2.13242299] , error: 0.4737442923116848\n",
      "Step: 6277 Weights: [0.35613909 2.13242298] , error: 0.47374429231134674\n",
      "Step: 6278 Weights: [0.35613915 2.13242298] , error: 0.47374429231101\n",
      "Step: 6279 Weights: [0.3561392  2.13242297] , error: 0.47374429231067505\n",
      "Step: 6280 Weights: [0.35613926 2.13242296] , error: 0.4737442923103421\n",
      "Step: 6281 Weights: [0.35613932 2.13242296] , error: 0.47374429231000875\n",
      "Step: 6282 Weights: [0.35613938 2.13242295] , error: 0.47374429230967885\n",
      "Step: 6283 Weights: [0.35613943 2.13242294] , error: 0.4737442923093492\n",
      "Step: 6284 Weights: [0.35613949 2.13242294] , error: 0.47374429230902176\n",
      "Step: 6285 Weights: [0.35613955 2.13242293] , error: 0.47374429230869636\n",
      "Step: 6286 Weights: [0.3561396  2.13242293] , error: 0.4737442923083717\n",
      "Step: 6287 Weights: [0.35613966 2.13242292] , error: 0.47374429230804854\n",
      "Step: 6288 Weights: [0.35613972 2.13242291] , error: 0.4737442923077266\n",
      "Step: 6289 Weights: [0.35613977 2.13242291] , error: 0.4737442923074063\n",
      "Step: 6290 Weights: [0.35613983 2.1324229 ] , error: 0.47374429230708837\n",
      "Step: 6291 Weights: [0.35613989 2.13242289] , error: 0.4737442923067711\n",
      "Step: 6292 Weights: [0.35613994 2.13242289] , error: 0.4737442923064549\n",
      "Step: 6293 Weights: [0.35614    2.13242288] , error: 0.4737442923061401\n",
      "Step: 6294 Weights: [0.35614005 2.13242287] , error: 0.47374429230582776\n",
      "Step: 6295 Weights: [0.35614011 2.13242287] , error: 0.4737442923055158\n",
      "Step: 6296 Weights: [0.35614016 2.13242286] , error: 0.47374429230520543\n",
      "Step: 6297 Weights: [0.35614022 2.13242285] , error: 0.4737442923048963\n",
      "Step: 6298 Weights: [0.35614027 2.13242285] , error: 0.4737442923045898\n",
      "Step: 6299 Weights: [0.35614033 2.13242284] , error: 0.47374429230428383\n",
      "Step: 6300 Weights: [0.35614038 2.13242284] , error: 0.47374429230397913\n",
      "Step: 6301 Weights: [0.35614044 2.13242283] , error: 0.4737442923036763\n",
      "Step: 6302 Weights: [0.35614049 2.13242282] , error: 0.4737442923033741\n",
      "Step: 6303 Weights: [0.35614055 2.13242282] , error: 0.47374429230307424\n",
      "Step: 6304 Weights: [0.3561406  2.13242281] , error: 0.4737442923027752\n",
      "Step: 6305 Weights: [0.35614066 2.1324228 ] , error: 0.4737442923024775\n",
      "Step: 6306 Weights: [0.35614071 2.1324228 ] , error: 0.4737442923021812\n",
      "Step: 6307 Weights: [0.35614076 2.13242279] , error: 0.47374429230188597\n",
      "Step: 6308 Weights: [0.35614082 2.13242279] , error: 0.4737442923015925\n",
      "Step: 6309 Weights: [0.35614087 2.13242278] , error: 0.4737442923013009\n",
      "Step: 6310 Weights: [0.35614093 2.13242277] , error: 0.4737442923010097\n",
      "Step: 6311 Weights: [0.35614098 2.13242277] , error: 0.47374429230072046\n",
      "Step: 6312 Weights: [0.35614103 2.13242276] , error: 0.47374429230043225\n",
      "Step: 6313 Weights: [0.35614109 2.13242276] , error: 0.47374429230014525\n",
      "Step: 6314 Weights: [0.35614114 2.13242275] , error: 0.47374429229985904\n",
      "Step: 6315 Weights: [0.35614119 2.13242274] , error: 0.4737442922995746\n",
      "Step: 6316 Weights: [0.35614124 2.13242274] , error: 0.4737442922992917\n",
      "Step: 6317 Weights: [0.3561413  2.13242273] , error: 0.47374429229900983\n",
      "Step: 6318 Weights: [0.35614135 2.13242273] , error: 0.47374429229872944\n",
      "Step: 6319 Weights: [0.3561414  2.13242272] , error: 0.4737442922984504\n",
      "Step: 6320 Weights: [0.35614145 2.13242271] , error: 0.4737442922981726\n",
      "Step: 6321 Weights: [0.35614151 2.13242271] , error: 0.47374429229789594\n",
      "Step: 6322 Weights: [0.35614156 2.1324227 ] , error: 0.47374429229761983\n",
      "Step: 6323 Weights: [0.35614161 2.1324227 ] , error: 0.4737442922973458\n",
      "Step: 6324 Weights: [0.35614166 2.13242269] , error: 0.4737442922970731\n",
      "Step: 6325 Weights: [0.35614171 2.13242268] , error: 0.4737442922968027\n",
      "Step: 6326 Weights: [0.35614177 2.13242268] , error: 0.47374429229653076\n",
      "Step: 6327 Weights: [0.35614182 2.13242267] , error: 0.4737442922962614\n",
      "Step: 6328 Weights: [0.35614187 2.13242267] , error: 0.4737442922959936\n",
      "Step: 6329 Weights: [0.35614192 2.13242266] , error: 0.4737442922957267\n",
      "Step: 6330 Weights: [0.35614197 2.13242265] , error: 0.4737442922954616\n",
      "Step: 6331 Weights: [0.35614202 2.13242265] , error: 0.473744292295198\n",
      "Step: 6332 Weights: [0.35614207 2.13242264] , error: 0.4737442922949344\n",
      "Step: 6333 Weights: [0.35614213 2.13242264] , error: 0.4737442922946725\n",
      "Step: 6334 Weights: [0.35614218 2.13242263] , error: 0.47374429229441195\n",
      "Step: 6335 Weights: [0.35614223 2.13242263] , error: 0.4737442922941519\n",
      "Step: 6336 Weights: [0.35614228 2.13242262] , error: 0.47374429229389386\n",
      "Step: 6337 Weights: [0.35614233 2.13242261] , error: 0.4737442922936368\n",
      "Step: 6338 Weights: [0.35614238 2.13242261] , error: 0.4737442922933802\n",
      "Step: 6339 Weights: [0.35614243 2.1324226 ] , error: 0.4737442922931258\n",
      "Step: 6340 Weights: [0.35614248 2.1324226 ] , error: 0.47374429229287157\n",
      "Step: 6341 Weights: [0.35614253 2.13242259] , error: 0.4737442922926195\n",
      "Step: 6342 Weights: [0.35614258 2.13242259] , error: 0.4737442922923685\n",
      "Step: 6343 Weights: [0.35614263 2.13242258] , error: 0.4737442922921178\n",
      "Step: 6344 Weights: [0.35614268 2.13242257] , error: 0.47374429229186826\n",
      "Step: 6345 Weights: [0.35614273 2.13242257] , error: 0.47374429229162063\n",
      "Step: 6346 Weights: [0.35614278 2.13242256] , error: 0.47374429229137477\n",
      "Step: 6347 Weights: [0.35614283 2.13242256] , error: 0.47374429229112824\n",
      "Step: 6348 Weights: [0.35614287 2.13242255] , error: 0.4737442922908844\n",
      "Step: 6349 Weights: [0.35614292 2.13242255] , error: 0.4737442922906403\n",
      "Step: 6350 Weights: [0.35614297 2.13242254] , error: 0.4737442922903987\n",
      "Step: 6351 Weights: [0.35614302 2.13242253] , error: 0.47374429229015624\n",
      "Step: 6352 Weights: [0.35614307 2.13242253] , error: 0.4737442922899163\n",
      "Step: 6353 Weights: [0.35614312 2.13242252] , error: 0.47374429228967796\n",
      "Step: 6354 Weights: [0.35614317 2.13242252] , error: 0.4737442922894402\n",
      "Step: 6355 Weights: [0.35614322 2.13242251] , error: 0.4737442922892021\n",
      "Step: 6356 Weights: [0.35614326 2.13242251] , error: 0.473744292288967\n",
      "Step: 6357 Weights: [0.35614331 2.1324225 ] , error: 0.4737442922887326\n",
      "Step: 6358 Weights: [0.35614336 2.1324225 ] , error: 0.4737442922884987\n",
      "Step: 6359 Weights: [0.35614341 2.13242249] , error: 0.4737442922882661\n",
      "Step: 6360 Weights: [0.35614346 2.13242248] , error: 0.4737442922880343\n",
      "Step: 6361 Weights: [0.3561435  2.13242248] , error: 0.4737442922878046\n",
      "Step: 6362 Weights: [0.35614355 2.13242247] , error: 0.4737442922875752\n",
      "Step: 6363 Weights: [0.3561436  2.13242247] , error: 0.47374429228734644\n",
      "Step: 6364 Weights: [0.35614365 2.13242246] , error: 0.4737442922871187\n",
      "Step: 6365 Weights: [0.35614369 2.13242246] , error: 0.47374429228689285\n",
      "Step: 6366 Weights: [0.35614374 2.13242245] , error: 0.4737442922866672\n",
      "Step: 6367 Weights: [0.35614379 2.13242245] , error: 0.47374429228644277\n",
      "Step: 6368 Weights: [0.35614383 2.13242244] , error: 0.47374429228621995\n",
      "Step: 6369 Weights: [0.35614388 2.13242244] , error: 0.47374429228599824\n",
      "Step: 6370 Weights: [0.35614393 2.13242243] , error: 0.4737442922857762\n",
      "Step: 6371 Weights: [0.35614397 2.13242243] , error: 0.47374429228555587\n",
      "Step: 6372 Weights: [0.35614402 2.13242242] , error: 0.47374429228533704\n",
      "Step: 6373 Weights: [0.35614407 2.13242241] , error: 0.47374429228511905\n",
      "Step: 6374 Weights: [0.35614411 2.13242241] , error: 0.473744292284901\n",
      "Step: 6375 Weights: [0.35614416 2.1324224 ] , error: 0.47374429228468606\n",
      "Step: 6376 Weights: [0.35614421 2.1324224 ] , error: 0.47374429228447024\n",
      "Step: 6377 Weights: [0.35614425 2.13242239] , error: 0.473744292284256\n",
      "Step: 6378 Weights: [0.3561443  2.13242239] , error: 0.4737442922840417\n",
      "Step: 6379 Weights: [0.35614434 2.13242238] , error: 0.47374429228383075\n",
      "Step: 6380 Weights: [0.35614439 2.13242238] , error: 0.4737442922836189\n",
      "Step: 6381 Weights: [0.35614444 2.13242237] , error: 0.47374429228340864\n",
      "Step: 6382 Weights: [0.35614448 2.13242237] , error: 0.4737442922832\n",
      "Step: 6383 Weights: [0.35614453 2.13242236] , error: 0.4737442922829908\n",
      "Step: 6384 Weights: [0.35614457 2.13242236] , error: 0.4737442922827835\n",
      "Step: 6385 Weights: [0.35614462 2.13242235] , error: 0.4737442922825766\n",
      "Step: 6386 Weights: [0.35614466 2.13242235] , error: 0.473744292282371\n",
      "Step: 6387 Weights: [0.35614471 2.13242234] , error: 0.47374429228216713\n",
      "Step: 6388 Weights: [0.35614475 2.13242234] , error: 0.4737442922819632\n",
      "Step: 6389 Weights: [0.3561448  2.13242233] , error: 0.4737442922817602\n",
      "Step: 6390 Weights: [0.35614484 2.13242233] , error: 0.473744292281558\n",
      "Step: 6391 Weights: [0.35614489 2.13242232] , error: 0.47374429228135706\n",
      "Step: 6392 Weights: [0.35614493 2.13242232] , error: 0.4737442922811572\n",
      "Step: 6393 Weights: [0.35614497 2.13242231] , error: 0.4737442922809578\n",
      "Step: 6394 Weights: [0.35614502 2.13242231] , error: 0.4737442922807603\n",
      "Step: 6395 Weights: [0.35614506 2.1324223 ] , error: 0.47374429228056236\n",
      "Step: 6396 Weights: [0.35614511 2.1324223 ] , error: 0.4737442922803665\n",
      "Step: 6397 Weights: [0.35614515 2.13242229] , error: 0.47374429228017023\n",
      "Step: 6398 Weights: [0.35614519 2.13242229] , error: 0.4737442922799758\n",
      "Step: 6399 Weights: [0.35614524 2.13242228] , error: 0.4737442922797827\n",
      "Step: 6400 Weights: [0.35614528 2.13242228] , error: 0.47374429227958914\n",
      "Step: 6401 Weights: [0.35614533 2.13242227] , error: 0.4737442922793972\n",
      "Step: 6402 Weights: [0.35614537 2.13242227] , error: 0.47374429227920567\n",
      "Step: 6403 Weights: [0.35614541 2.13242226] , error: 0.4737442922790155\n",
      "Step: 6404 Weights: [0.35614546 2.13242226] , error: 0.4737442922788271\n",
      "Step: 6405 Weights: [0.3561455  2.13242225] , error: 0.4737442922786377\n",
      "Step: 6406 Weights: [0.35614554 2.13242225] , error: 0.47374429227845044\n",
      "Step: 6407 Weights: [0.35614558 2.13242224] , error: 0.47374429227826365\n",
      "Step: 6408 Weights: [0.35614563 2.13242224] , error: 0.4737442922780777\n",
      "Step: 6409 Weights: [0.35614567 2.13242223] , error: 0.47374429227789194\n",
      "Step: 6410 Weights: [0.35614571 2.13242223] , error: 0.473744292277708\n",
      "Step: 6411 Weights: [0.35614576 2.13242222] , error: 0.47374429227752424\n",
      "Step: 6412 Weights: [0.3561458  2.13242222] , error: 0.4737442922773424\n",
      "Step: 6413 Weights: [0.35614584 2.13242221] , error: 0.47374429227716075\n",
      "Step: 6414 Weights: [0.35614588 2.13242221] , error: 0.4737442922769795\n",
      "Step: 6415 Weights: [0.35614593 2.1324222 ] , error: 0.4737442922767998\n",
      "Step: 6416 Weights: [0.35614597 2.1324222 ] , error: 0.4737442922766195\n",
      "Step: 6417 Weights: [0.35614601 2.13242219] , error: 0.4737442922764415\n",
      "Step: 6418 Weights: [0.35614605 2.13242219] , error: 0.47374429227626375\n",
      "Step: 6419 Weights: [0.35614609 2.13242218] , error: 0.473744292276087\n",
      "Step: 6420 Weights: [0.35614613 2.13242218] , error: 0.47374429227591136\n",
      "Step: 6421 Weights: [0.35614618 2.13242217] , error: 0.47374429227573545\n",
      "Step: 6422 Weights: [0.35614622 2.13242217] , error: 0.47374429227556103\n",
      "Step: 6423 Weights: [0.35614626 2.13242216] , error: 0.4737442922753876\n",
      "Step: 6424 Weights: [0.3561463  2.13242216] , error: 0.4737442922752145\n",
      "Step: 6425 Weights: [0.35614634 2.13242215] , error: 0.47374429227504233\n",
      "Step: 6426 Weights: [0.35614638 2.13242215] , error: 0.47374429227487197\n",
      "Step: 6427 Weights: [0.35614642 2.13242215] , error: 0.47374429227470016\n",
      "Step: 6428 Weights: [0.35614646 2.13242214] , error: 0.47374429227453074\n",
      "Step: 6429 Weights: [0.35614651 2.13242214] , error: 0.4737442922743622\n",
      "Step: 6430 Weights: [0.35614655 2.13242213] , error: 0.4737442922741941\n",
      "Step: 6431 Weights: [0.35614659 2.13242213] , error: 0.4737442922740268\n",
      "Step: 6432 Weights: [0.35614663 2.13242212] , error: 0.4737442922738593\n",
      "Step: 6433 Weights: [0.35614667 2.13242212] , error: 0.4737442922736936\n",
      "Step: 6434 Weights: [0.35614671 2.13242211] , error: 0.473744292273529\n",
      "Step: 6435 Weights: [0.35614675 2.13242211] , error: 0.4737442922733636\n",
      "Step: 6436 Weights: [0.35614679 2.1324221 ] , error: 0.47374429227320014\n",
      "Step: 6437 Weights: [0.35614683 2.1324221 ] , error: 0.4737442922730375\n",
      "Step: 6438 Weights: [0.35614687 2.13242209] , error: 0.47374429227287507\n",
      "Step: 6439 Weights: [0.35614691 2.13242209] , error: 0.47374429227271364\n",
      "Step: 6440 Weights: [0.35614695 2.13242209] , error: 0.47374429227255327\n",
      "Step: 6441 Weights: [0.35614699 2.13242208] , error: 0.4737442922723939\n",
      "Step: 6442 Weights: [0.35614703 2.13242208] , error: 0.4737442922722338\n",
      "Step: 6443 Weights: [0.35614707 2.13242207] , error: 0.4737442922720757\n",
      "Step: 6444 Weights: [0.35614711 2.13242207] , error: 0.47374429227191794\n",
      "Step: 6445 Weights: [0.35614715 2.13242206] , error: 0.4737442922717609\n",
      "Step: 6446 Weights: [0.35614719 2.13242206] , error: 0.47374429227160497\n",
      "Step: 6447 Weights: [0.35614723 2.13242205] , error: 0.47374429227144915\n",
      "Step: 6448 Weights: [0.35614726 2.13242205] , error: 0.473744292271294\n",
      "Step: 6449 Weights: [0.3561473  2.13242204] , error: 0.47374429227113957\n",
      "Step: 6450 Weights: [0.35614734 2.13242204] , error: 0.4737442922709859\n",
      "Step: 6451 Weights: [0.35614738 2.13242204] , error: 0.47374429227083364\n",
      "Step: 6452 Weights: [0.35614742 2.13242203] , error: 0.4737442922706813\n",
      "Step: 6453 Weights: [0.35614746 2.13242203] , error: 0.47374429227053033\n",
      "Step: 6454 Weights: [0.3561475  2.13242202] , error: 0.47374429227037956\n",
      "Step: 6455 Weights: [0.35614754 2.13242202] , error: 0.47374429227022863\n",
      "Step: 6456 Weights: [0.35614757 2.13242201] , error: 0.47374429227007925\n",
      "Step: 6457 Weights: [0.35614761 2.13242201] , error: 0.4737442922699318\n",
      "Step: 6458 Weights: [0.35614765 2.132422  ] , error: 0.4737442922697834\n",
      "Step: 6459 Weights: [0.35614769 2.132422  ] , error: 0.4737442922696362\n",
      "Step: 6460 Weights: [0.35614773 2.132422  ] , error: 0.47374429226948966\n",
      "Step: 6461 Weights: [0.35614777 2.13242199] , error: 0.4737442922693432\n",
      "Step: 6462 Weights: [0.3561478  2.13242199] , error: 0.4737442922691985\n",
      "Step: 6463 Weights: [0.35614784 2.13242198] , error: 0.4737442922690532\n",
      "Step: 6464 Weights: [0.35614788 2.13242198] , error: 0.4737442922689087\n",
      "Step: 6465 Weights: [0.35614792 2.13242197] , error: 0.4737442922687658\n",
      "Step: 6466 Weights: [0.35614795 2.13242197] , error: 0.4737442922686231\n",
      "Step: 6467 Weights: [0.35614799 2.13242197] , error: 0.47374429226848147\n",
      "Step: 6468 Weights: [0.35614803 2.13242196] , error: 0.4737442922683399\n",
      "Step: 6469 Weights: [0.35614807 2.13242196] , error: 0.4737442922681988\n",
      "Step: 6470 Weights: [0.3561481  2.13242195] , error: 0.47374429226805864\n",
      "Step: 6471 Weights: [0.35614814 2.13242195] , error: 0.47374429226791986\n",
      "Step: 6472 Weights: [0.35614818 2.13242194] , error: 0.4737442922677806\n",
      "Step: 6473 Weights: [0.35614821 2.13242194] , error: 0.4737442922676431\n",
      "Step: 6474 Weights: [0.35614825 2.13242194] , error: 0.47374429226750436\n",
      "Step: 6475 Weights: [0.35614829 2.13242193] , error: 0.4737442922673678\n",
      "Step: 6476 Weights: [0.35614832 2.13242193] , error: 0.4737442922672318\n",
      "Step: 6477 Weights: [0.35614836 2.13242192] , error: 0.47374429226709636\n",
      "Step: 6478 Weights: [0.3561484  2.13242192] , error: 0.473744292266961\n",
      "Step: 6479 Weights: [0.35614843 2.13242192] , error: 0.47374429226682596\n",
      "Step: 6480 Weights: [0.35614847 2.13242191] , error: 0.47374429226669307\n",
      "Step: 6481 Weights: [0.35614851 2.13242191] , error: 0.47374429226655923\n",
      "Step: 6482 Weights: [0.35614854 2.1324219 ] , error: 0.4737442922664266\n",
      "Step: 6483 Weights: [0.35614858 2.1324219 ] , error: 0.47374429226629433\n",
      "Step: 6484 Weights: [0.35614862 2.13242189] , error: 0.4737442922661633\n",
      "Step: 6485 Weights: [0.35614865 2.13242189] , error: 0.47374429226603276\n",
      "Step: 6486 Weights: [0.35614869 2.13242189] , error: 0.4737442922659022\n",
      "Step: 6487 Weights: [0.35614872 2.13242188] , error: 0.47374429226577214\n",
      "Step: 6488 Weights: [0.35614876 2.13242188] , error: 0.4737442922656437\n",
      "Step: 6489 Weights: [0.35614879 2.13242187] , error: 0.47374429226551407\n",
      "Step: 6490 Weights: [0.35614883 2.13242187] , error: 0.47374429226538706\n",
      "Step: 6491 Weights: [0.35614887 2.13242187] , error: 0.47374429226525994\n",
      "Step: 6492 Weights: [0.3561489  2.13242186] , error: 0.4737442922651329\n",
      "Step: 6493 Weights: [0.35614894 2.13242186] , error: 0.47374429226500614\n",
      "Step: 6494 Weights: [0.35614897 2.13242185] , error: 0.4737442922648814\n",
      "Step: 6495 Weights: [0.35614901 2.13242185] , error: 0.4737442922647559\n",
      "Step: 6496 Weights: [0.35614904 2.13242185] , error: 0.47374429226463155\n",
      "Step: 6497 Weights: [0.35614908 2.13242184] , error: 0.4737442922645073\n",
      "Step: 6498 Weights: [0.35614911 2.13242184] , error: 0.4737442922643844\n",
      "Step: 6499 Weights: [0.35614915 2.13242183] , error: 0.47374429226426196\n",
      "Step: 6500 Weights: [0.35614918 2.13242183] , error: 0.47374429226413967\n",
      "Step: 6501 Weights: [0.35614922 2.13242183] , error: 0.47374429226401826\n",
      "Step: 6502 Weights: [0.35614925 2.13242182] , error: 0.473744292263897\n",
      "Step: 6503 Weights: [0.35614928 2.13242182] , error: 0.47374429226377573\n",
      "Step: 6504 Weights: [0.35614932 2.13242181] , error: 0.4737442922636565\n",
      "Step: 6505 Weights: [0.35614935 2.13242181] , error: 0.47374429226353765\n",
      "Step: 6506 Weights: [0.35614939 2.13242181] , error: 0.47374429226341874\n",
      "Step: 6507 Weights: [0.35614942 2.1324218 ] , error: 0.47374429226330045\n",
      "Step: 6508 Weights: [0.35614946 2.1324218 ] , error: 0.47374429226318177\n",
      "Step: 6509 Weights: [0.35614949 2.13242179] , error: 0.4737442922630649\n",
      "Step: 6510 Weights: [0.35614952 2.13242179] , error: 0.4737442922629478\n",
      "Step: 6511 Weights: [0.35614956 2.13242179] , error: 0.4737442922628318\n",
      "Step: 6512 Weights: [0.35614959 2.13242178] , error: 0.47374429226271686\n",
      "Step: 6513 Weights: [0.35614963 2.13242178] , error: 0.4737442922626011\n",
      "Step: 6514 Weights: [0.35614966 2.13242178] , error: 0.47374429226248665\n",
      "Step: 6515 Weights: [0.35614969 2.13242177] , error: 0.47374429226237347\n",
      "Step: 6516 Weights: [0.35614973 2.13242177] , error: 0.4737442922622584\n",
      "Step: 6517 Weights: [0.35614976 2.13242176] , error: 0.47374429226214576\n",
      "Step: 6518 Weights: [0.35614979 2.13242176] , error: 0.4737442922620335\n",
      "Step: 6519 Weights: [0.35614983 2.13242176] , error: 0.47374429226192133\n",
      "Step: 6520 Weights: [0.35614986 2.13242175] , error: 0.47374429226181\n",
      "Step: 6521 Weights: [0.35614989 2.13242175] , error: 0.47374429226169923\n",
      "Step: 6522 Weights: [0.35614993 2.13242174] , error: 0.47374429226158804\n",
      "Step: 6523 Weights: [0.35614996 2.13242174] , error: 0.4737442922614783\n",
      "Step: 6524 Weights: [0.35614999 2.13242174] , error: 0.4737442922613687\n",
      "Step: 6525 Weights: [0.35615002 2.13242173] , error: 0.4737442922612599\n",
      "Step: 6526 Weights: [0.35615006 2.13242173] , error: 0.47374429226115145\n",
      "Step: 6527 Weights: [0.35615009 2.13242173] , error: 0.4737442922610431\n",
      "Step: 6528 Weights: [0.35615012 2.13242172] , error: 0.47374429226093623\n",
      "Step: 6529 Weights: [0.35615015 2.13242172] , error: 0.47374429226082887\n",
      "Step: 6530 Weights: [0.35615019 2.13242171] , error: 0.47374429226072184\n",
      "Step: 6531 Weights: [0.35615022 2.13242171] , error: 0.47374429226061576\n",
      "Step: 6532 Weights: [0.35615025 2.13242171] , error: 0.4737442922605106\n",
      "Step: 6533 Weights: [0.35615028 2.1324217 ] , error: 0.4737442922604057\n",
      "Step: 6534 Weights: [0.35615032 2.1324217 ] , error: 0.4737442922603006\n",
      "Step: 6535 Weights: [0.35615035 2.1324217 ] , error: 0.47374429226019643\n",
      "Step: 6536 Weights: [0.35615038 2.13242169] , error: 0.47374429226009357\n",
      "Step: 6537 Weights: [0.35615041 2.13242169] , error: 0.4737442922599897\n",
      "Step: 6538 Weights: [0.35615044 2.13242169] , error: 0.473744292259887\n",
      "Step: 6539 Weights: [0.35615048 2.13242168] , error: 0.47374429225978426\n",
      "Step: 6540 Weights: [0.35615051 2.13242168] , error: 0.47374429225968323\n",
      "Step: 6541 Weights: [0.35615054 2.13242167] , error: 0.4737442922595816\n",
      "Step: 6542 Weights: [0.35615057 2.13242167] , error: 0.4737442922594808\n",
      "Step: 6543 Weights: [0.3561506  2.13242167] , error: 0.4737442922593806\n",
      "Step: 6544 Weights: [0.35615063 2.13242166] , error: 0.4737442922592804\n",
      "Step: 6545 Weights: [0.35615067 2.13242166] , error: 0.4737442922591814\n",
      "Step: 6546 Weights: [0.3561507  2.13242166] , error: 0.47374429225908243\n",
      "Step: 6547 Weights: [0.35615073 2.13242165] , error: 0.4737442922589833\n",
      "Step: 6548 Weights: [0.35615076 2.13242165] , error: 0.4737442922588852\n",
      "Step: 6549 Weights: [0.35615079 2.13242165] , error: 0.4737442922587878\n",
      "Step: 6550 Weights: [0.35615082 2.13242164] , error: 0.4737442922586904\n",
      "Step: 6551 Weights: [0.35615085 2.13242164] , error: 0.47374429225859405\n",
      "Step: 6552 Weights: [0.35615088 2.13242164] , error: 0.4737442922584967\n",
      "Step: 6553 Weights: [0.35615091 2.13242163] , error: 0.4737442922584012\n",
      "Step: 6554 Weights: [0.35615094 2.13242163] , error: 0.47374429225830583\n",
      "Step: 6555 Weights: [0.35615097 2.13242162] , error: 0.47374429225821113\n",
      "Step: 6556 Weights: [0.35615101 2.13242162] , error: 0.4737442922581163\n",
      "Step: 6557 Weights: [0.35615104 2.13242162] , error: 0.4737442922580215\n",
      "Step: 6558 Weights: [0.35615107 2.13242161] , error: 0.4737442922579286\n",
      "Step: 6559 Weights: [0.3561511  2.13242161] , error: 0.47374429225783554\n",
      "Step: 6560 Weights: [0.35615113 2.13242161] , error: 0.47374429225774206\n",
      "Step: 6561 Weights: [0.35615116 2.1324216 ] , error: 0.4737442922576496\n",
      "Step: 6562 Weights: [0.35615119 2.1324216 ] , error: 0.47374429225755765\n",
      "Step: 6563 Weights: [0.35615122 2.1324216 ] , error: 0.4737442922574657\n",
      "Step: 6564 Weights: [0.35615125 2.13242159] , error: 0.4737442922573748\n",
      "Step: 6565 Weights: [0.35615128 2.13242159] , error: 0.4737442922572842\n",
      "Step: 6566 Weights: [0.35615131 2.13242159] , error: 0.47374429225719333\n",
      "Step: 6567 Weights: [0.35615134 2.13242158] , error: 0.4737442922571033\n",
      "Step: 6568 Weights: [0.35615137 2.13242158] , error: 0.47374429225701387\n",
      "Step: 6569 Weights: [0.3561514  2.13242158] , error: 0.47374429225692505\n",
      "Step: 6570 Weights: [0.35615143 2.13242157] , error: 0.47374429225683645\n",
      "Step: 6571 Weights: [0.35615146 2.13242157] , error: 0.47374429225674797\n",
      "Step: 6572 Weights: [0.35615149 2.13242157] , error: 0.4737442922566603\n",
      "Step: 6573 Weights: [0.35615151 2.13242156] , error: 0.47374429225657183\n",
      "Step: 6574 Weights: [0.35615154 2.13242156] , error: 0.4737442922564852\n",
      "Step: 6575 Weights: [0.35615157 2.13242156] , error: 0.473744292256398\n",
      "Step: 6576 Weights: [0.3561516  2.13242155] , error: 0.47374429225631265\n",
      "Step: 6577 Weights: [0.35615163 2.13242155] , error: 0.47374429225622616\n",
      "Step: 6578 Weights: [0.35615166 2.13242155] , error: 0.4737442922561401\n",
      "Step: 6579 Weights: [0.35615169 2.13242154] , error: 0.47374429225605474\n",
      "Step: 6580 Weights: [0.35615172 2.13242154] , error: 0.47374429225597103\n",
      "Step: 6581 Weights: [0.35615175 2.13242154] , error: 0.47374429225588555\n",
      "Step: 6582 Weights: [0.35615178 2.13242153] , error: 0.4737442922558024\n",
      "Step: 6583 Weights: [0.35615181 2.13242153] , error: 0.4737442922557191\n",
      "Step: 6584 Weights: [0.35615183 2.13242153] , error: 0.47374429225563586\n",
      "Step: 6585 Weights: [0.35615186 2.13242152] , error: 0.47374429225555226\n",
      "Step: 6586 Weights: [0.35615189 2.13242152] , error: 0.4737442922554702\n",
      "Step: 6587 Weights: [0.35615192 2.13242152] , error: 0.4737442922553874\n",
      "Step: 6588 Weights: [0.35615195 2.13242151] , error: 0.47374429225530645\n",
      "Step: 6589 Weights: [0.35615198 2.13242151] , error: 0.4737442922552244\n",
      "Step: 6590 Weights: [0.356152   2.13242151] , error: 0.4737442922551439\n",
      "Step: 6591 Weights: [0.35615203 2.1324215 ] , error: 0.4737442922550624\n",
      "Step: 6592 Weights: [0.35615206 2.1324215 ] , error: 0.47374429225498244\n",
      "Step: 6593 Weights: [0.35615209 2.1324215 ] , error: 0.4737442922549027\n",
      "Step: 6594 Weights: [0.35615212 2.13242149] , error: 0.4737442922548229\n",
      "Step: 6595 Weights: [0.35615215 2.13242149] , error: 0.4737442922547438\n",
      "Step: 6596 Weights: [0.35615217 2.13242149] , error: 0.4737442922546653\n",
      "Step: 6597 Weights: [0.3561522  2.13242148] , error: 0.47374429225458675\n",
      "Step: 6598 Weights: [0.35615223 2.13242148] , error: 0.4737442922545093\n",
      "Step: 6599 Weights: [0.35615226 2.13242148] , error: 0.47374429225443065\n",
      "Step: 6600 Weights: [0.35615228 2.13242148] , error: 0.4737442922543541\n",
      "Step: 6601 Weights: [0.35615231 2.13242147] , error: 0.47374429225427606\n",
      "Step: 6602 Weights: [0.35615234 2.13242147] , error: 0.4737442922542003\n",
      "Step: 6603 Weights: [0.35615237 2.13242147] , error: 0.47374429225412384\n",
      "Step: 6604 Weights: [0.35615239 2.13242146] , error: 0.47374429225404696\n",
      "Step: 6605 Weights: [0.35615242 2.13242146] , error: 0.47374429225397147\n",
      "Step: 6606 Weights: [0.35615245 2.13242146] , error: 0.47374429225389647\n",
      "Step: 6607 Weights: [0.35615248 2.13242145] , error: 0.47374429225382186\n",
      "Step: 6608 Weights: [0.3561525  2.13242145] , error: 0.47374429225374715\n",
      "Step: 6609 Weights: [0.35615253 2.13242145] , error: 0.47374429225367315\n",
      "Step: 6610 Weights: [0.35615256 2.13242144] , error: 0.47374429225359893\n",
      "Step: 6611 Weights: [0.35615258 2.13242144] , error: 0.4737442922535251\n",
      "Step: 6612 Weights: [0.35615261 2.13242144] , error: 0.47374429225345155\n",
      "Step: 6613 Weights: [0.35615264 2.13242143] , error: 0.47374429225337816\n",
      "Step: 6614 Weights: [0.35615266 2.13242143] , error: 0.4737442922533061\n",
      "Step: 6615 Weights: [0.35615269 2.13242143] , error: 0.4737442922532337\n",
      "Step: 6616 Weights: [0.35615272 2.13242143] , error: 0.4737442922531618\n",
      "Step: 6617 Weights: [0.35615274 2.13242142] , error: 0.47374429225309045\n",
      "Step: 6618 Weights: [0.35615277 2.13242142] , error: 0.47374429225301895\n",
      "Step: 6619 Weights: [0.3561528  2.13242142] , error: 0.47374429225294834\n",
      "Step: 6620 Weights: [0.35615282 2.13242141] , error: 0.473744292252877\n",
      "Step: 6621 Weights: [0.35615285 2.13242141] , error: 0.4737442922528074\n",
      "Step: 6622 Weights: [0.35615288 2.13242141] , error: 0.4737442922527373\n",
      "Step: 6623 Weights: [0.3561529 2.1324214] , error: 0.473744292252668\n",
      "Step: 6624 Weights: [0.35615293 2.1324214 ] , error: 0.47374429225259823\n",
      "Step: 6625 Weights: [0.35615296 2.1324214 ] , error: 0.4737442922525289\n",
      "Step: 6626 Weights: [0.35615298 2.1324214 ] , error: 0.47374429225246073\n",
      "Step: 6627 Weights: [0.35615301 2.13242139] , error: 0.47374429225239234\n",
      "Step: 6628 Weights: [0.35615303 2.13242139] , error: 0.4737442922523235\n",
      "Step: 6629 Weights: [0.35615306 2.13242139] , error: 0.4737442922522559\n",
      "Step: 6630 Weights: [0.35615309 2.13242138] , error: 0.4737442922521891\n",
      "Step: 6631 Weights: [0.35615311 2.13242138] , error: 0.47374429225212084\n",
      "Step: 6632 Weights: [0.35615314 2.13242138] , error: 0.47374429225205505\n",
      "Step: 6633 Weights: [0.35615316 2.13242137] , error: 0.47374429225198766\n",
      "Step: 6634 Weights: [0.35615319 2.13242137] , error: 0.47374429225192183\n",
      "Step: 6635 Weights: [0.35615321 2.13242137] , error: 0.4737442922518557\n",
      "Step: 6636 Weights: [0.35615324 2.13242137] , error: 0.47374429225179043\n",
      "Step: 6637 Weights: [0.35615326 2.13242136] , error: 0.473744292251725\n",
      "Step: 6638 Weights: [0.35615329 2.13242136] , error: 0.4737442922516595\n",
      "Step: 6639 Weights: [0.35615331 2.13242136] , error: 0.4737442922515954\n",
      "Step: 6640 Weights: [0.35615334 2.13242135] , error: 0.47374429225153025\n",
      "Step: 6641 Weights: [0.35615337 2.13242135] , error: 0.47374429225146675\n",
      "Step: 6642 Weights: [0.35615339 2.13242135] , error: 0.4737442922514019\n",
      "Step: 6643 Weights: [0.35615342 2.13242135] , error: 0.4737442922513392\n",
      "Step: 6644 Weights: [0.35615344 2.13242134] , error: 0.4737442922512751\n",
      "Step: 6645 Weights: [0.35615347 2.13242134] , error: 0.4737442922512124\n",
      "Step: 6646 Weights: [0.35615349 2.13242134] , error: 0.47374429225114967\n",
      "Step: 6647 Weights: [0.35615352 2.13242133] , error: 0.47374429225108766\n",
      "Step: 6648 Weights: [0.35615354 2.13242133] , error: 0.4737442922510252\n",
      "Step: 6649 Weights: [0.35615356 2.13242133] , error: 0.47374429225096376\n",
      "Step: 6650 Weights: [0.35615359 2.13242133] , error: 0.47374429225090164\n",
      "Step: 6651 Weights: [0.35615361 2.13242132] , error: 0.4737442922508406\n",
      "Step: 6652 Weights: [0.35615364 2.13242132] , error: 0.4737442922507788\n",
      "Step: 6653 Weights: [0.35615366 2.13242132] , error: 0.4737442922507192\n",
      "Step: 6654 Weights: [0.35615369 2.13242131] , error: 0.47374429225065845\n",
      "Step: 6655 Weights: [0.35615371 2.13242131] , error: 0.47374429225059805\n",
      "Step: 6656 Weights: [0.35615374 2.13242131] , error: 0.4737442922505376\n",
      "Step: 6657 Weights: [0.35615376 2.13242131] , error: 0.47374429225047854\n",
      "Step: 6658 Weights: [0.35615378 2.1324213 ] , error: 0.4737442922504187\n",
      "Step: 6659 Weights: [0.35615381 2.1324213 ] , error: 0.47374429225035997\n",
      "Step: 6660 Weights: [0.35615383 2.1324213 ] , error: 0.4737442922503009\n",
      "Step: 6661 Weights: [0.35615386 2.1324213 ] , error: 0.4737442922502423\n",
      "Step: 6662 Weights: [0.35615388 2.13242129] , error: 0.4737442922501839\n",
      "Step: 6663 Weights: [0.35615391 2.13242129] , error: 0.47374429225012543\n",
      "Step: 6664 Weights: [0.35615393 2.13242129] , error: 0.47374429225006837\n",
      "Step: 6665 Weights: [0.35615395 2.13242128] , error: 0.4737442922500109\n",
      "Step: 6666 Weights: [0.35615398 2.13242128] , error: 0.4737442922499533\n",
      "Step: 6667 Weights: [0.356154   2.13242128] , error: 0.47374429224989645\n",
      "Step: 6668 Weights: [0.35615402 2.13242128] , error: 0.47374429224983927\n",
      "Step: 6669 Weights: [0.35615405 2.13242127] , error: 0.47374429224978354\n",
      "Step: 6670 Weights: [0.35615407 2.13242127] , error: 0.4737442922497269\n",
      "Step: 6671 Weights: [0.35615409 2.13242127] , error: 0.4737442922496712\n",
      "Step: 6672 Weights: [0.35615412 2.13242127] , error: 0.473744292249616\n",
      "Step: 6673 Weights: [0.35615414 2.13242126] , error: 0.4737442922495605\n",
      "Step: 6674 Weights: [0.35615416 2.13242126] , error: 0.47374429224950493\n",
      "Step: 6675 Weights: [0.35615419 2.13242126] , error: 0.4737442922494496\n",
      "Step: 6676 Weights: [0.35615421 2.13242125] , error: 0.4737442922493953\n",
      "Step: 6677 Weights: [0.35615423 2.13242125] , error: 0.47374429224934084\n",
      "Step: 6678 Weights: [0.35615426 2.13242125] , error: 0.47374429224928605\n",
      "Step: 6679 Weights: [0.35615428 2.13242125] , error: 0.4737442922492323\n",
      "Step: 6680 Weights: [0.3561543  2.13242124] , error: 0.4737442922491787\n",
      "Step: 6681 Weights: [0.35615433 2.13242124] , error: 0.47374429224912507\n",
      "Step: 6682 Weights: [0.35615435 2.13242124] , error: 0.47374429224907233\n",
      "Step: 6683 Weights: [0.35615437 2.13242124] , error: 0.47374429224901904\n",
      "Step: 6684 Weights: [0.3561544  2.13242123] , error: 0.4737442922489667\n",
      "Step: 6685 Weights: [0.35615442 2.13242123] , error: 0.4737442922489138\n",
      "Step: 6686 Weights: [0.35615444 2.13242123] , error: 0.4737442922488611\n",
      "Step: 6687 Weights: [0.35615446 2.13242123] , error: 0.4737442922488102\n",
      "Step: 6688 Weights: [0.35615449 2.13242122] , error: 0.4737442922487579\n",
      "Step: 6689 Weights: [0.35615451 2.13242122] , error: 0.47374429224870634\n",
      "Step: 6690 Weights: [0.35615453 2.13242122] , error: 0.47374429224865483\n",
      "Step: 6691 Weights: [0.35615455 2.13242122] , error: 0.47374429224860465\n",
      "Step: 6692 Weights: [0.35615458 2.13242121] , error: 0.47374429224855313\n",
      "Step: 6693 Weights: [0.3561546  2.13242121] , error: 0.4737442922485028\n",
      "Step: 6694 Weights: [0.35615462 2.13242121] , error: 0.4737442922484514\n",
      "Step: 6695 Weights: [0.35615464 2.13242121] , error: 0.47374429224840153\n",
      "Step: 6696 Weights: [0.35615467 2.1324212 ] , error: 0.47374429224835235\n",
      "Step: 6697 Weights: [0.35615469 2.1324212 ] , error: 0.47374429224830245\n",
      "Step: 6698 Weights: [0.35615471 2.1324212 ] , error: 0.4737442922482527\n",
      "Step: 6699 Weights: [0.35615473 2.1324212 ] , error: 0.4737442922482033\n",
      "Step: 6700 Weights: [0.35615475 2.13242119] , error: 0.4737442922481552\n",
      "Step: 6701 Weights: [0.35615478 2.13242119] , error: 0.47374429224810594\n",
      "Step: 6702 Weights: [0.3561548  2.13242119] , error: 0.4737442922480575\n",
      "Step: 6703 Weights: [0.35615482 2.13242119] , error: 0.4737442922480092\n",
      "Step: 6704 Weights: [0.35615484 2.13242118] , error: 0.4737442922479607\n",
      "Step: 6705 Weights: [0.35615486 2.13242118] , error: 0.4737442922479129\n",
      "Step: 6706 Weights: [0.35615488 2.13242118] , error: 0.4737442922478655\n",
      "Step: 6707 Weights: [0.35615491 2.13242118] , error: 0.47374429224781817\n",
      "Step: 6708 Weights: [0.35615493 2.13242117] , error: 0.4737442922477698\n",
      "Step: 6709 Weights: [0.35615495 2.13242117] , error: 0.4737442922477233\n",
      "Step: 6710 Weights: [0.35615497 2.13242117] , error: 0.47374429224767645\n",
      "Step: 6711 Weights: [0.35615499 2.13242117] , error: 0.4737442922476297\n",
      "Step: 6712 Weights: [0.35615501 2.13242116] , error: 0.4737442922475842\n",
      "Step: 6713 Weights: [0.35615504 2.13242116] , error: 0.47374429224753767\n",
      "Step: 6714 Weights: [0.35615506 2.13242116] , error: 0.4737442922474913\n",
      "Step: 6715 Weights: [0.35615508 2.13242116] , error: 0.47374429224744524\n",
      "Step: 6716 Weights: [0.3561551  2.13242115] , error: 0.47374429224739956\n",
      "Step: 6717 Weights: [0.35615512 2.13242115] , error: 0.4737442922473547\n",
      "Step: 6718 Weights: [0.35615514 2.13242115] , error: 0.47374429224730885\n",
      "Step: 6719 Weights: [0.35615516 2.13242115] , error: 0.473744292247265\n",
      "Step: 6720 Weights: [0.35615518 2.13242114] , error: 0.4737442922472194\n",
      "Step: 6721 Weights: [0.3561552  2.13242114] , error: 0.4737442922471746\n",
      "Step: 6722 Weights: [0.35615523 2.13242114] , error: 0.47374429224713055\n",
      "Step: 6723 Weights: [0.35615525 2.13242114] , error: 0.4737442922470868\n",
      "Step: 6724 Weights: [0.35615527 2.13242113] , error: 0.47374429224704306\n",
      "Step: 6725 Weights: [0.35615529 2.13242113] , error: 0.473744292246999\n",
      "Step: 6726 Weights: [0.35615531 2.13242113] , error: 0.47374429224695563\n",
      "Step: 6727 Weights: [0.35615533 2.13242113] , error: 0.47374429224691234\n",
      "Step: 6728 Weights: [0.35615535 2.13242112] , error: 0.4737442922468689\n",
      "Step: 6729 Weights: [0.35615537 2.13242112] , error: 0.4737442922468258\n",
      "Step: 6730 Weights: [0.35615539 2.13242112] , error: 0.47374429224678405\n",
      "Step: 6731 Weights: [0.35615541 2.13242112] , error: 0.4737442922467408\n",
      "Step: 6732 Weights: [0.35615543 2.13242112] , error: 0.47374429224669845\n",
      "Step: 6733 Weights: [0.35615545 2.13242111] , error: 0.47374429224665615\n",
      "Step: 6734 Weights: [0.35615547 2.13242111] , error: 0.47374429224661463\n",
      "Step: 6735 Weights: [0.35615549 2.13242111] , error: 0.47374429224657233\n",
      "Step: 6736 Weights: [0.35615551 2.13242111] , error: 0.4737442922465311\n",
      "Step: 6737 Weights: [0.35615553 2.1324211 ] , error: 0.4737442922464894\n",
      "Step: 6738 Weights: [0.35615555 2.1324211 ] , error: 0.4737442922464483\n",
      "Step: 6739 Weights: [0.35615557 2.1324211 ] , error: 0.4737442922464074\n",
      "Step: 6740 Weights: [0.35615559 2.1324211 ] , error: 0.47374429224636616\n",
      "Step: 6741 Weights: [0.35615561 2.13242109] , error: 0.47374429224632597\n",
      "Step: 6742 Weights: [0.35615563 2.13242109] , error: 0.47374429224628556\n",
      "Step: 6743 Weights: [0.35615565 2.13242109] , error: 0.4737442922462448\n",
      "Step: 6744 Weights: [0.35615567 2.13242109] , error: 0.4737442922462055\n",
      "Step: 6745 Weights: [0.35615569 2.13242109] , error: 0.47374429224616543\n",
      "Step: 6746 Weights: [0.35615571 2.13242108] , error: 0.4737442922461253\n",
      "Step: 6747 Weights: [0.35615573 2.13242108] , error: 0.47374429224608605\n",
      "Step: 6748 Weights: [0.35615575 2.13242108] , error: 0.47374429224604697\n",
      "Step: 6749 Weights: [0.35615577 2.13242108] , error: 0.4737442922460077\n",
      "Step: 6750 Weights: [0.35615579 2.13242107] , error: 0.47374429224596804\n",
      "Step: 6751 Weights: [0.35615581 2.13242107] , error: 0.4737442922459286\n",
      "Step: 6752 Weights: [0.35615583 2.13242107] , error: 0.47374429224589076\n",
      "Step: 6753 Weights: [0.35615585 2.13242107] , error: 0.47374429224585246\n",
      "Step: 6754 Weights: [0.35615587 2.13242106] , error: 0.4737442922458136\n",
      "Step: 6755 Weights: [0.35615589 2.13242106] , error: 0.47374429224577586\n",
      "Step: 6756 Weights: [0.35615591 2.13242106] , error: 0.47374429224573794\n",
      "Step: 6757 Weights: [0.35615593 2.13242106] , error: 0.4737442922457\n",
      "Step: 6758 Weights: [0.35615595 2.13242106] , error: 0.47374429224566184\n",
      "Step: 6759 Weights: [0.35615597 2.13242105] , error: 0.47374429224562536\n",
      "Step: 6760 Weights: [0.35615599 2.13242105] , error: 0.47374429224558706\n",
      "Step: 6761 Weights: [0.35615601 2.13242105] , error: 0.4737442922455508\n",
      "Step: 6762 Weights: [0.35615602 2.13242105] , error: 0.47374429224551307\n",
      "Step: 6763 Weights: [0.35615604 2.13242105] , error: 0.473744292245477\n",
      "Step: 6764 Weights: [0.35615606 2.13242104] , error: 0.47374429224544035\n",
      "Step: 6765 Weights: [0.35615608 2.13242104] , error: 0.4737442922454035\n",
      "Step: 6766 Weights: [0.3561561  2.13242104] , error: 0.4737442922453674\n",
      "Step: 6767 Weights: [0.35615612 2.13242104] , error: 0.47374429224533116\n",
      "Step: 6768 Weights: [0.35615614 2.13242103] , error: 0.47374429224529524\n",
      "Step: 6769 Weights: [0.35615616 2.13242103] , error: 0.47374429224526027\n",
      "Step: 6770 Weights: [0.35615618 2.13242103] , error: 0.4737442922452243\n",
      "Step: 6771 Weights: [0.35615619 2.13242103] , error: 0.47374429224518866\n",
      "Step: 6772 Weights: [0.35615621 2.13242103] , error: 0.47374429224515296\n",
      "Step: 6773 Weights: [0.35615623 2.13242102] , error: 0.4737442922451185\n",
      "Step: 6774 Weights: [0.35615625 2.13242102] , error: 0.473744292245083\n",
      "Step: 6775 Weights: [0.35615627 2.13242102] , error: 0.4737442922450483\n",
      "Step: 6776 Weights: [0.35615629 2.13242102] , error: 0.4737442922450136\n",
      "Step: 6777 Weights: [0.35615631 2.13242102] , error: 0.47374429224498005\n",
      "Step: 6778 Weights: [0.35615632 2.13242101] , error: 0.4737442922449457\n",
      "Step: 6779 Weights: [0.35615634 2.13242101] , error: 0.47374429224491055\n",
      "Step: 6780 Weights: [0.35615636 2.13242101] , error: 0.4737442922448769\n",
      "Step: 6781 Weights: [0.35615638 2.13242101] , error: 0.47374429224484266\n",
      "Step: 6782 Weights: [0.3561564 2.132421 ] , error: 0.4737442922448088\n",
      "Step: 6783 Weights: [0.35615642 2.132421  ] , error: 0.47374429224477554\n",
      "Step: 6784 Weights: [0.35615643 2.132421  ] , error: 0.47374429224474257\n",
      "Step: 6785 Weights: [0.35615645 2.132421  ] , error: 0.4737442922447084\n",
      "Step: 6786 Weights: [0.35615647 2.132421  ] , error: 0.4737442922446765\n",
      "Step: 6787 Weights: [0.35615649 2.13242099] , error: 0.47374429224464354\n",
      "Step: 6788 Weights: [0.35615651 2.13242099] , error: 0.47374429224461\n",
      "Step: 6789 Weights: [0.35615652 2.13242099] , error: 0.47374429224457737\n",
      "Step: 6790 Weights: [0.35615654 2.13242099] , error: 0.4737442922445449\n",
      "Step: 6791 Weights: [0.35615656 2.13242099] , error: 0.47374429224451264\n",
      "Step: 6792 Weights: [0.35615658 2.13242098] , error: 0.4737442922444808\n",
      "Step: 6793 Weights: [0.3561566  2.13242098] , error: 0.47374429224444814\n",
      "Step: 6794 Weights: [0.35615661 2.13242098] , error: 0.4737442922444158\n",
      "Step: 6795 Weights: [0.35615663 2.13242098] , error: 0.4737442922443841\n",
      "Step: 6796 Weights: [0.35615665 2.13242098] , error: 0.4737442922443532\n",
      "Step: 6797 Weights: [0.35615667 2.13242097] , error: 0.47374429224432174\n",
      "Step: 6798 Weights: [0.35615668 2.13242097] , error: 0.47374429224429\n",
      "Step: 6799 Weights: [0.3561567  2.13242097] , error: 0.4737442922442593\n",
      "Step: 6800 Weights: [0.35615672 2.13242097] , error: 0.4737442922442287\n",
      "Step: 6801 Weights: [0.35615674 2.13242097] , error: 0.473744292244197\n",
      "Step: 6802 Weights: [0.35615675 2.13242096] , error: 0.47374429224416637\n",
      "Step: 6803 Weights: [0.35615677 2.13242096] , error: 0.47374429224413556\n",
      "Step: 6804 Weights: [0.35615679 2.13242096] , error: 0.4737442922441052\n",
      "Step: 6805 Weights: [0.35615681 2.13242096] , error: 0.47374429224407455\n",
      "Step: 6806 Weights: [0.35615682 2.13242096] , error: 0.47374429224404435\n",
      "Step: 6807 Weights: [0.35615684 2.13242095] , error: 0.47374429224401426\n",
      "Step: 6808 Weights: [0.35615686 2.13242095] , error: 0.4737442922439845\n",
      "Step: 6809 Weights: [0.35615688 2.13242095] , error: 0.4737442922439546\n",
      "Step: 6810 Weights: [0.35615689 2.13242095] , error: 0.47374429224392545\n",
      "Step: 6811 Weights: [0.35615691 2.13242095] , error: 0.47374429224389575\n",
      "Step: 6812 Weights: [0.35615693 2.13242094] , error: 0.4737442922438658\n",
      "Step: 6813 Weights: [0.35615694 2.13242094] , error: 0.4737442922438369\n",
      "Step: 6814 Weights: [0.35615696 2.13242094] , error: 0.4737442922438077\n",
      "Step: 6815 Weights: [0.35615698 2.13242094] , error: 0.4737442922437791\n",
      "Step: 6816 Weights: [0.35615699 2.13242094] , error: 0.4737442922437495\n",
      "Step: 6817 Weights: [0.35615701 2.13242093] , error: 0.47374429224372183\n",
      "Step: 6818 Weights: [0.35615703 2.13242093] , error: 0.4737442922436925\n",
      "Step: 6819 Weights: [0.35615704 2.13242093] , error: 0.4737442922436642\n",
      "Step: 6820 Weights: [0.35615706 2.13242093] , error: 0.47374429224363646\n",
      "Step: 6821 Weights: [0.35615708 2.13242093] , error: 0.47374429224360753\n",
      "Step: 6822 Weights: [0.35615709 2.13242092] , error: 0.47374429224357917\n",
      "Step: 6823 Weights: [0.35615711 2.13242092] , error: 0.473744292243552\n",
      "Step: 6824 Weights: [0.35615713 2.13242092] , error: 0.4737442922435243\n",
      "Step: 6825 Weights: [0.35615714 2.13242092] , error: 0.4737442922434957\n",
      "Step: 6826 Weights: [0.35615716 2.13242092] , error: 0.4737442922434669\n",
      "Step: 6827 Weights: [0.35615718 2.13242092] , error: 0.47374429224344133\n",
      "Step: 6828 Weights: [0.35615719 2.13242091] , error: 0.47374429224341386\n",
      "Step: 6829 Weights: [0.35615721 2.13242091] , error: 0.4737442922433861\n",
      "Step: 6830 Weights: [0.35615723 2.13242091] , error: 0.47374429224335945\n",
      "Step: 6831 Weights: [0.35615724 2.13242091] , error: 0.4737442922433322\n",
      "Step: 6832 Weights: [0.35615726 2.13242091] , error: 0.47374429224330533\n",
      "Step: 6833 Weights: [0.35615728 2.1324209 ] , error: 0.47374429224327896\n",
      "Step: 6834 Weights: [0.35615729 2.1324209 ] , error: 0.4737442922432522\n",
      "Step: 6835 Weights: [0.35615731 2.1324209 ] , error: 0.473744292243226\n",
      "Step: 6836 Weights: [0.35615732 2.1324209 ] , error: 0.4737442922431996\n",
      "Step: 6837 Weights: [0.35615734 2.1324209 ] , error: 0.4737442922431727\n",
      "Step: 6838 Weights: [0.35615736 2.13242089] , error: 0.4737442922431473\n",
      "Step: 6839 Weights: [0.35615737 2.13242089] , error: 0.47374429224312103\n",
      "Step: 6840 Weights: [0.35615739 2.13242089] , error: 0.4737442922430955\n",
      "Step: 6841 Weights: [0.3561574  2.13242089] , error: 0.47374429224306963\n",
      "Step: 6842 Weights: [0.35615742 2.13242089] , error: 0.47374429224304426\n",
      "Step: 6843 Weights: [0.35615744 2.13242089] , error: 0.4737442922430179\n",
      "Step: 6844 Weights: [0.35615745 2.13242088] , error: 0.47374429224299375\n",
      "Step: 6845 Weights: [0.35615747 2.13242088] , error: 0.4737442922429676\n",
      "Step: 6846 Weights: [0.35615748 2.13242088] , error: 0.47374429224294284\n",
      "Step: 6847 Weights: [0.3561575  2.13242088] , error: 0.47374429224291725\n",
      "Step: 6848 Weights: [0.35615751 2.13242088] , error: 0.4737442922428927\n",
      "Step: 6849 Weights: [0.35615753 2.13242088] , error: 0.4737442922428679\n",
      "Step: 6850 Weights: [0.35615755 2.13242087] , error: 0.47374429224284303\n",
      "Step: 6851 Weights: [0.35615756 2.13242087] , error: 0.47374429224281817\n",
      "Step: 6852 Weights: [0.35615758 2.13242087] , error: 0.47374429224279396\n",
      "Step: 6853 Weights: [0.35615759 2.13242087] , error: 0.47374429224276965\n",
      "Step: 6854 Weights: [0.35615761 2.13242087] , error: 0.47374429224274683\n",
      "Step: 6855 Weights: [0.35615762 2.13242086] , error: 0.4737442922427212\n",
      "Step: 6856 Weights: [0.35615764 2.13242086] , error: 0.47374429224269765\n",
      "Step: 6857 Weights: [0.35615765 2.13242086] , error: 0.4737442922426732\n",
      "Step: 6858 Weights: [0.35615767 2.13242086] , error: 0.47374429224264925\n",
      "Step: 6859 Weights: [0.35615769 2.13242086] , error: 0.47374429224262554\n",
      "Step: 6860 Weights: [0.3561577  2.13242086] , error: 0.4737442922426028\n",
      "Step: 6861 Weights: [0.35615772 2.13242085] , error: 0.4737442922425788\n",
      "Step: 6862 Weights: [0.35615773 2.13242085] , error: 0.47374429224255443\n",
      "Step: 6863 Weights: [0.35615775 2.13242085] , error: 0.47374429224253173\n",
      "Step: 6864 Weights: [0.35615776 2.13242085] , error: 0.47374429224250836\n",
      "Step: 6865 Weights: [0.35615778 2.13242085] , error: 0.47374429224248576\n",
      "Step: 6866 Weights: [0.35615779 2.13242085] , error: 0.47374429224246317\n",
      "Step: 6867 Weights: [0.35615781 2.13242084] , error: 0.4737442922424399\n",
      "Step: 6868 Weights: [0.35615782 2.13242084] , error: 0.4737442922424164\n",
      "Step: 6869 Weights: [0.35615784 2.13242084] , error: 0.47374429224239445\n",
      "Step: 6870 Weights: [0.35615785 2.13242084] , error: 0.47374429224237247\n",
      "Step: 6871 Weights: [0.35615787 2.13242084] , error: 0.4737442922423495\n",
      "Step: 6872 Weights: [0.35615788 2.13242083] , error: 0.4737442922423273\n",
      "Step: 6873 Weights: [0.3561579  2.13242083] , error: 0.4737442922423043\n",
      "Step: 6874 Weights: [0.35615791 2.13242083] , error: 0.4737442922422823\n",
      "Step: 6875 Weights: [0.35615793 2.13242083] , error: 0.47374429224226045\n",
      "Step: 6876 Weights: [0.35615794 2.13242083] , error: 0.4737442922422383\n",
      "Step: 6877 Weights: [0.35615795 2.13242083] , error: 0.4737442922422165\n",
      "Step: 6878 Weights: [0.35615797 2.13242082] , error: 0.47374429224219516\n",
      "Step: 6879 Weights: [0.35615798 2.13242082] , error: 0.47374429224217274\n",
      "Step: 6880 Weights: [0.356158   2.13242082] , error: 0.47374429224215164\n",
      "Step: 6881 Weights: [0.35615801 2.13242082] , error: 0.47374429224212966\n",
      "Step: 6882 Weights: [0.35615803 2.13242082] , error: 0.47374429224210873\n",
      "Step: 6883 Weights: [0.35615804 2.13242082] , error: 0.47374429224208786\n",
      "Step: 6884 Weights: [0.35615806 2.13242081] , error: 0.47374429224206654\n",
      "Step: 6885 Weights: [0.35615807 2.13242081] , error: 0.4737442922420452\n",
      "Step: 6886 Weights: [0.35615809 2.13242081] , error: 0.47374429224202425\n",
      "Step: 6887 Weights: [0.3561581  2.13242081] , error: 0.4737442922420035\n",
      "Step: 6888 Weights: [0.35615811 2.13242081] , error: 0.47374429224198256\n",
      "Step: 6889 Weights: [0.35615813 2.13242081] , error: 0.47374429224196246\n",
      "Step: 6890 Weights: [0.35615814 2.13242081] , error: 0.4737442922419419\n",
      "Step: 6891 Weights: [0.35615816 2.1324208 ] , error: 0.4737442922419214\n",
      "Step: 6892 Weights: [0.35615817 2.1324208 ] , error: 0.4737442922419005\n",
      "Step: 6893 Weights: [0.35615819 2.1324208 ] , error: 0.47374429224188075\n",
      "Step: 6894 Weights: [0.3561582 2.1324208] , error: 0.4737442922418603\n",
      "Step: 6895 Weights: [0.35615821 2.1324208 ] , error: 0.4737442922418401\n",
      "Step: 6896 Weights: [0.35615823 2.1324208 ] , error: 0.47374429224182046\n",
      "Step: 6897 Weights: [0.35615824 2.13242079] , error: 0.47374429224180054\n",
      "Step: 6898 Weights: [0.35615826 2.13242079] , error: 0.47374429224177994\n",
      "Step: 6899 Weights: [0.35615827 2.13242079] , error: 0.4737442922417609\n",
      "Step: 6900 Weights: [0.35615828 2.13242079] , error: 0.47374429224174097\n",
      "Step: 6901 Weights: [0.3561583  2.13242079] , error: 0.47374429224172154\n",
      "Step: 6902 Weights: [0.35615831 2.13242079] , error: 0.4737442922417021\n",
      "Step: 6903 Weights: [0.35615833 2.13242078] , error: 0.47374429224168263\n",
      "Step: 6904 Weights: [0.35615834 2.13242078] , error: 0.47374429224166303\n",
      "Step: 6905 Weights: [0.35615835 2.13242078] , error: 0.47374429224164366\n",
      "Step: 6906 Weights: [0.35615837 2.13242078] , error: 0.4737442922416244\n",
      "Step: 6907 Weights: [0.35615838 2.13242078] , error: 0.4737442922416059\n",
      "Step: 6908 Weights: [0.35615839 2.13242078] , error: 0.47374429224158593\n",
      "Step: 6909 Weights: [0.35615841 2.13242077] , error: 0.47374429224156805\n",
      "Step: 6910 Weights: [0.35615842 2.13242077] , error: 0.47374429224154885\n",
      "Step: 6911 Weights: [0.35615844 2.13242077] , error: 0.47374429224153025\n",
      "Step: 6912 Weights: [0.35615845 2.13242077] , error: 0.47374429224151166\n",
      "Step: 6913 Weights: [0.35615846 2.13242077] , error: 0.4737442922414935\n",
      "Step: 6914 Weights: [0.35615848 2.13242077] , error: 0.47374429224147496\n",
      "Step: 6915 Weights: [0.35615849 2.13242077] , error: 0.4737442922414563\n",
      "Step: 6916 Weights: [0.3561585  2.13242076] , error: 0.4737442922414373\n",
      "Step: 6917 Weights: [0.35615852 2.13242076] , error: 0.4737442922414194\n",
      "Step: 6918 Weights: [0.35615853 2.13242076] , error: 0.47374429224140185\n",
      "Step: 6919 Weights: [0.35615854 2.13242076] , error: 0.47374429224138354\n",
      "Step: 6920 Weights: [0.35615856 2.13242076] , error: 0.4737442922413659\n",
      "Step: 6921 Weights: [0.35615857 2.13242076] , error: 0.473744292241348\n",
      "Step: 6922 Weights: [0.35615858 2.13242075] , error: 0.47374429224133047\n",
      "Step: 6923 Weights: [0.3561586  2.13242075] , error: 0.4737442922413125\n",
      "Step: 6924 Weights: [0.35615861 2.13242075] , error: 0.47374429224129483\n",
      "Step: 6925 Weights: [0.35615862 2.13242075] , error: 0.47374429224127645\n",
      "Step: 6926 Weights: [0.35615864 2.13242075] , error: 0.47374429224125947\n",
      "Step: 6927 Weights: [0.35615865 2.13242075] , error: 0.47374429224124176\n",
      "Step: 6928 Weights: [0.35615866 2.13242075] , error: 0.47374429224122555\n",
      "Step: 6929 Weights: [0.35615867 2.13242074] , error: 0.4737442922412072\n",
      "Step: 6930 Weights: [0.35615869 2.13242074] , error: 0.4737442922411905\n",
      "Step: 6931 Weights: [0.3561587  2.13242074] , error: 0.4737442922411733\n",
      "Step: 6932 Weights: [0.35615871 2.13242074] , error: 0.47374429224115655\n",
      "Step: 6933 Weights: [0.35615873 2.13242074] , error: 0.47374429224113995\n",
      "Step: 6934 Weights: [0.35615874 2.13242074] , error: 0.47374429224112247\n",
      "Step: 6935 Weights: [0.35615875 2.13242074] , error: 0.47374429224110626\n",
      "Step: 6936 Weights: [0.35615877 2.13242073] , error: 0.4737442922410894\n",
      "Step: 6937 Weights: [0.35615878 2.13242073] , error: 0.47374429224107245\n",
      "Step: 6938 Weights: [0.35615879 2.13242073] , error: 0.4737442922410562\n",
      "Step: 6939 Weights: [0.3561588  2.13242073] , error: 0.4737442922410395\n",
      "Step: 6940 Weights: [0.35615882 2.13242073] , error: 0.4737442922410232\n",
      "Step: 6941 Weights: [0.35615883 2.13242073] , error: 0.47374429224100734\n",
      "Step: 6942 Weights: [0.35615884 2.13242073] , error: 0.4737442922409907\n",
      "Step: 6943 Weights: [0.35615885 2.13242072] , error: 0.47374429224097525\n",
      "Step: 6944 Weights: [0.35615887 2.13242072] , error: 0.47374429224095826\n",
      "Step: 6945 Weights: [0.35615888 2.13242072] , error: 0.4737442922409423\n",
      "Step: 6946 Weights: [0.35615889 2.13242072] , error: 0.4737442922409259\n",
      "Step: 6947 Weights: [0.3561589  2.13242072] , error: 0.4737442922409103\n",
      "Step: 6948 Weights: [0.35615892 2.13242072] , error: 0.4737442922408955\n",
      "Step: 6949 Weights: [0.35615893 2.13242072] , error: 0.4737442922408792\n",
      "Step: 6950 Weights: [0.35615894 2.13242071] , error: 0.4737442922408641\n",
      "Step: 6951 Weights: [0.35615895 2.13242071] , error: 0.47374429224084785\n",
      "Step: 6952 Weights: [0.35615897 2.13242071] , error: 0.4737442922408324\n",
      "Step: 6953 Weights: [0.35615898 2.13242071] , error: 0.4737442922408168\n",
      "Step: 6954 Weights: [0.35615899 2.13242071] , error: 0.4737442922408015\n",
      "Step: 6955 Weights: [0.356159   2.13242071] , error: 0.4737442922407866\n",
      "Step: 6956 Weights: [0.35615902 2.13242071] , error: 0.4737442922407717\n",
      "Step: 6957 Weights: [0.35615903 2.1324207 ] , error: 0.47374429224075565\n",
      "Step: 6958 Weights: [0.35615904 2.1324207 ] , error: 0.4737442922407408\n",
      "Step: 6959 Weights: [0.35615905 2.1324207 ] , error: 0.4737442922407261\n",
      "Step: 6960 Weights: [0.35615906 2.1324207 ] , error: 0.4737442922407106\n",
      "Step: 6961 Weights: [0.35615908 2.1324207 ] , error: 0.47374429224069653\n",
      "Step: 6962 Weights: [0.35615909 2.1324207 ] , error: 0.4737442922406812\n",
      "Step: 6963 Weights: [0.3561591 2.1324207] , error: 0.47374429224066616\n",
      "Step: 6964 Weights: [0.35615911 2.13242069] , error: 0.4737442922406523\n",
      "Step: 6965 Weights: [0.35615913 2.13242069] , error: 0.47374429224063724\n",
      "Step: 6966 Weights: [0.35615914 2.13242069] , error: 0.4737442922406223\n",
      "Step: 6967 Weights: [0.35615915 2.13242069] , error: 0.4737442922406074\n",
      "Step: 6968 Weights: [0.35615916 2.13242069] , error: 0.4737442922405932\n",
      "Step: 6969 Weights: [0.35615917 2.13242069] , error: 0.47374429224057946\n",
      "Step: 6970 Weights: [0.35615918 2.13242069] , error: 0.47374429224056447\n",
      "Step: 6971 Weights: [0.3561592  2.13242068] , error: 0.4737442922405508\n",
      "Step: 6972 Weights: [0.35615921 2.13242068] , error: 0.4737442922405365\n",
      "Step: 6973 Weights: [0.35615922 2.13242068] , error: 0.4737442922405224\n",
      "Step: 6974 Weights: [0.35615923 2.13242068] , error: 0.47374429224050907\n",
      "Step: 6975 Weights: [0.35615924 2.13242068] , error: 0.4737442922404945\n",
      "Step: 6976 Weights: [0.35615926 2.13242068] , error: 0.47374429224048065\n",
      "Step: 6977 Weights: [0.35615927 2.13242068] , error: 0.47374429224046666\n",
      "Step: 6978 Weights: [0.35615928 2.13242068] , error: 0.47374429224045345\n",
      "Step: 6979 Weights: [0.35615929 2.13242067] , error: 0.4737442922404393\n",
      "Step: 6980 Weights: [0.3561593  2.13242067] , error: 0.47374429224042564\n",
      "Step: 6981 Weights: [0.35615931 2.13242067] , error: 0.4737442922404125\n",
      "Step: 6982 Weights: [0.35615933 2.13242067] , error: 0.47374429224039843\n",
      "Step: 6983 Weights: [0.35615934 2.13242067] , error: 0.4737442922403856\n",
      "Step: 6984 Weights: [0.35615935 2.13242067] , error: 0.4737442922403711\n",
      "Step: 6985 Weights: [0.35615936 2.13242067] , error: 0.4737442922403579\n",
      "Step: 6986 Weights: [0.35615937 2.13242066] , error: 0.47374429224034437\n",
      "Step: 6987 Weights: [0.35615938 2.13242066] , error: 0.47374429224033254\n",
      "Step: 6988 Weights: [0.35615939 2.13242066] , error: 0.47374429224031794\n",
      "Step: 6989 Weights: [0.35615941 2.13242066] , error: 0.47374429224030584\n",
      "Step: 6990 Weights: [0.35615942 2.13242066] , error: 0.4737442922402924\n",
      "Step: 6991 Weights: [0.35615943 2.13242066] , error: 0.47374429224027986\n",
      "Step: 6992 Weights: [0.35615944 2.13242066] , error: 0.47374429224026654\n",
      "Step: 6993 Weights: [0.35615945 2.13242066] , error: 0.47374429224025305\n",
      "Step: 6994 Weights: [0.35615946 2.13242065] , error: 0.4737442922402406\n",
      "Step: 6995 Weights: [0.35615947 2.13242065] , error: 0.4737442922402288\n",
      "Step: 6996 Weights: [0.35615948 2.13242065] , error: 0.4737442922402157\n",
      "Step: 6997 Weights: [0.3561595  2.13242065] , error: 0.47374429224020215\n",
      "Step: 6998 Weights: [0.35615951 2.13242065] , error: 0.4737442922401905\n",
      "Step: 6999 Weights: [0.35615952 2.13242065] , error: 0.4737442922401775\n",
      "Step: 7000 Weights: [0.35615953 2.13242065] , error: 0.47374429224016534\n",
      "Step: 7001 Weights: [0.35615954 2.13242065] , error: 0.4737442922401529\n",
      "Step: 7002 Weights: [0.35615955 2.13242064] , error: 0.4737442922401406\n",
      "Step: 7003 Weights: [0.35615956 2.13242064] , error: 0.4737442922401285\n",
      "Step: 7004 Weights: [0.35615957 2.13242064] , error: 0.4737442922401163\n",
      "Step: 7005 Weights: [0.35615958 2.13242064] , error: 0.47374429224010445\n",
      "Step: 7006 Weights: [0.35615959 2.13242064] , error: 0.47374429224009246\n",
      "Step: 7007 Weights: [0.35615961 2.13242064] , error: 0.47374429224007986\n",
      "Step: 7008 Weights: [0.35615962 2.13242064] , error: 0.47374429224006737\n",
      "Step: 7009 Weights: [0.35615963 2.13242064] , error: 0.473744292240056\n",
      "Step: 7010 Weights: [0.35615964 2.13242063] , error: 0.4737442922400443\n",
      "Step: 7011 Weights: [0.35615965 2.13242063] , error: 0.4737442922400323\n",
      "Step: 7012 Weights: [0.35615966 2.13242063] , error: 0.4737442922400196\n",
      "Step: 7013 Weights: [0.35615967 2.13242063] , error: 0.47374429224000847\n",
      "Step: 7014 Weights: [0.35615968 2.13242063] , error: 0.4737442922399969\n",
      "Step: 7015 Weights: [0.35615969 2.13242063] , error: 0.47374429223998527\n",
      "Step: 7016 Weights: [0.3561597  2.13242063] , error: 0.4737442922399734\n",
      "Step: 7017 Weights: [0.35615971 2.13242063] , error: 0.47374429223996206\n",
      "Step: 7018 Weights: [0.35615972 2.13242062] , error: 0.4737442922399505\n",
      "Step: 7019 Weights: [0.35615973 2.13242062] , error: 0.47374429223993897\n",
      "Step: 7020 Weights: [0.35615975 2.13242062] , error: 0.4737442922399283\n",
      "Step: 7021 Weights: [0.35615976 2.13242062] , error: 0.4737442922399162\n",
      "Step: 7022 Weights: [0.35615977 2.13242062] , error: 0.473744292239905\n",
      "Step: 7023 Weights: [0.35615978 2.13242062] , error: 0.47374429223989406\n",
      "Step: 7024 Weights: [0.35615979 2.13242062] , error: 0.47374429223988246\n",
      "Step: 7025 Weights: [0.3561598  2.13242062] , error: 0.4737442922398705\n",
      "Step: 7026 Weights: [0.35615981 2.13242061] , error: 0.47374429223986086\n",
      "Step: 7027 Weights: [0.35615982 2.13242061] , error: 0.4737442922398489\n",
      "Step: 7028 Weights: [0.35615983 2.13242061] , error: 0.4737442922398386\n",
      "Step: 7029 Weights: [0.35615984 2.13242061] , error: 0.47374429223982784\n",
      "Step: 7030 Weights: [0.35615985 2.13242061] , error: 0.4737442922398167\n",
      "Step: 7031 Weights: [0.35615986 2.13242061] , error: 0.47374429223980585\n",
      "Step: 7032 Weights: [0.35615987 2.13242061] , error: 0.473744292239795\n",
      "Step: 7033 Weights: [0.35615988 2.13242061] , error: 0.47374429223978465\n",
      "Step: 7034 Weights: [0.35615989 2.13242061] , error: 0.4737442922397739\n",
      "Step: 7035 Weights: [0.3561599 2.1324206] , error: 0.4737442922397629\n",
      "Step: 7036 Weights: [0.35615991 2.1324206 ] , error: 0.47374429223975256\n",
      "Step: 7037 Weights: [0.35615992 2.1324206 ] , error: 0.47374429223974224\n",
      "Step: 7038 Weights: [0.35615993 2.1324206 ] , error: 0.4737442922397318\n",
      "Step: 7039 Weights: [0.35615994 2.1324206 ] , error: 0.4737442922397207\n",
      "Step: 7040 Weights: [0.35615995 2.1324206 ] , error: 0.473744292239711\n",
      "Step: 7041 Weights: [0.35615996 2.1324206 ] , error: 0.47374429223969994\n",
      "Step: 7042 Weights: [0.35615997 2.1324206 ] , error: 0.4737442922396899\n",
      "Step: 7043 Weights: [0.35615998 2.13242059] , error: 0.4737442922396796\n",
      "Step: 7044 Weights: [0.35615999 2.13242059] , error: 0.47374429223966924\n",
      "Step: 7045 Weights: [0.35616    2.13242059] , error: 0.4737442922396595\n",
      "Step: 7046 Weights: [0.35616001 2.13242059] , error: 0.47374429223965\n",
      "Step: 7047 Weights: [0.35616002 2.13242059] , error: 0.47374429223963943\n",
      "Step: 7048 Weights: [0.35616003 2.13242059] , error: 0.47374429223962977\n",
      "Step: 7049 Weights: [0.35616004 2.13242059] , error: 0.47374429223961945\n",
      "Step: 7050 Weights: [0.35616005 2.13242059] , error: 0.47374429223960984\n",
      "Step: 7051 Weights: [0.35616006 2.13242059] , error: 0.47374429223959924\n",
      "Step: 7052 Weights: [0.35616007 2.13242058] , error: 0.47374429223959025\n",
      "Step: 7053 Weights: [0.35616008 2.13242058] , error: 0.4737442922395805\n",
      "Step: 7054 Weights: [0.35616009 2.13242058] , error: 0.47374429223957004\n",
      "Step: 7055 Weights: [0.3561601  2.13242058] , error: 0.47374429223956116\n",
      "Step: 7056 Weights: [0.35616011 2.13242058] , error: 0.47374429223955083\n",
      "Step: 7057 Weights: [0.35616012 2.13242058] , error: 0.4737442922395409\n",
      "Step: 7058 Weights: [0.35616013 2.13242058] , error: 0.4737442922395319\n",
      "Step: 7059 Weights: [0.35616014 2.13242058] , error: 0.47374429223952297\n",
      "Step: 7060 Weights: [0.35616015 2.13242058] , error: 0.4737442922395128\n",
      "Step: 7061 Weights: [0.35616016 2.13242057] , error: 0.4737442922395032\n",
      "Step: 7062 Weights: [0.35616017 2.13242057] , error: 0.47374429223949416\n",
      "Step: 7063 Weights: [0.35616018 2.13242057] , error: 0.47374429223948494\n",
      "Step: 7064 Weights: [0.35616019 2.13242057] , error: 0.47374429223947556\n",
      "Step: 7065 Weights: [0.3561602  2.13242057] , error: 0.47374429223946624\n",
      "Step: 7066 Weights: [0.35616021 2.13242057] , error: 0.47374429223945685\n",
      "Step: 7067 Weights: [0.35616022 2.13242057] , error: 0.473744292239448\n",
      "Step: 7068 Weights: [0.35616023 2.13242057] , error: 0.47374429223943815\n",
      "Step: 7069 Weights: [0.35616024 2.13242057] , error: 0.4737442922394293\n",
      "Step: 7070 Weights: [0.35616025 2.13242056] , error: 0.4737442922394207\n",
      "Step: 7071 Weights: [0.35616026 2.13242056] , error: 0.4737442922394114\n",
      "Step: 7072 Weights: [0.35616026 2.13242056] , error: 0.47374429223940207\n",
      "Step: 7073 Weights: [0.35616027 2.13242056] , error: 0.47374429223939424\n",
      "Step: 7074 Weights: [0.35616028 2.13242056] , error: 0.473744292239385\n",
      "Step: 7075 Weights: [0.35616029 2.13242056] , error: 0.47374429223937564\n",
      "Step: 7076 Weights: [0.3561603  2.13242056] , error: 0.4737442922393671\n",
      "Step: 7077 Weights: [0.35616031 2.13242056] , error: 0.47374429223935877\n",
      "Step: 7078 Weights: [0.35616032 2.13242056] , error: 0.47374429223935033\n",
      "Step: 7079 Weights: [0.35616033 2.13242055] , error: 0.4737442922393402\n",
      "Step: 7080 Weights: [0.35616034 2.13242055] , error: 0.4737442922393322\n",
      "Step: 7081 Weights: [0.35616035 2.13242055] , error: 0.4737442922393238\n",
      "Step: 7082 Weights: [0.35616036 2.13242055] , error: 0.47374429223931525\n",
      "Step: 7083 Weights: [0.35616037 2.13242055] , error: 0.4737442922393064\n",
      "Step: 7084 Weights: [0.35616038 2.13242055] , error: 0.47374429223929865\n",
      "Step: 7085 Weights: [0.35616039 2.13242055] , error: 0.4737442922392895\n",
      "Step: 7086 Weights: [0.35616039 2.13242055] , error: 0.47374429223928094\n",
      "Step: 7087 Weights: [0.3561604  2.13242055] , error: 0.47374429223927284\n",
      "Step: 7088 Weights: [0.35616041 2.13242055] , error: 0.4737442922392645\n",
      "Step: 7089 Weights: [0.35616042 2.13242054] , error: 0.4737442922392559\n",
      "Step: 7090 Weights: [0.35616043 2.13242054] , error: 0.47374429223924763\n",
      "Step: 7091 Weights: [0.35616044 2.13242054] , error: 0.47374429223924003\n",
      "Step: 7092 Weights: [0.35616045 2.13242054] , error: 0.4737442922392321\n",
      "Step: 7093 Weights: [0.35616046 2.13242054] , error: 0.4737442922392237\n",
      "Step: 7094 Weights: [0.35616047 2.13242054] , error: 0.4737442922392146\n",
      "Step: 7095 Weights: [0.35616048 2.13242054] , error: 0.4737442922392065\n",
      "Step: 7096 Weights: [0.35616048 2.13242054] , error: 0.4737442922391996\n",
      "Step: 7097 Weights: [0.35616049 2.13242054] , error: 0.47374429223919146\n",
      "Step: 7098 Weights: [0.3561605  2.13242054] , error: 0.47374429223918324\n",
      "Step: 7099 Weights: [0.35616051 2.13242053] , error: 0.47374429223917514\n",
      "Step: 7100 Weights: [0.35616052 2.13242053] , error: 0.47374429223916736\n",
      "Step: 7101 Weights: [0.35616053 2.13242053] , error: 0.47374429223915937\n",
      "Step: 7102 Weights: [0.35616054 2.13242053] , error: 0.47374429223915154\n",
      "Step: 7103 Weights: [0.35616055 2.13242053] , error: 0.47374429223914366\n",
      "Step: 7104 Weights: [0.35616055 2.13242053] , error: 0.47374429223913567\n",
      "Step: 7105 Weights: [0.35616056 2.13242053] , error: 0.4737442922391285\n",
      "Step: 7106 Weights: [0.35616057 2.13242053] , error: 0.47374429223912096\n",
      "Step: 7107 Weights: [0.35616058 2.13242053] , error: 0.4737442922391131\n",
      "Step: 7108 Weights: [0.35616059 2.13242053] , error: 0.4737442922391055\n",
      "Step: 7109 Weights: [0.3561606  2.13242052] , error: 0.4737442922390981\n",
      "Step: 7110 Weights: [0.35616061 2.13242052] , error: 0.47374429223909087\n",
      "Step: 7111 Weights: [0.35616062 2.13242052] , error: 0.4737442922390835\n",
      "Step: 7112 Weights: [0.35616062 2.13242052] , error: 0.4737442922390747\n",
      "Step: 7113 Weights: [0.35616063 2.13242052] , error: 0.47374429223906783\n",
      "Step: 7114 Weights: [0.35616064 2.13242052] , error: 0.4737442922390609\n",
      "Step: 7115 Weights: [0.35616065 2.13242052] , error: 0.47374429223905334\n",
      "Step: 7116 Weights: [0.35616066 2.13242052] , error: 0.4737442922390466\n",
      "Step: 7117 Weights: [0.35616067 2.13242052] , error: 0.4737442922390383\n",
      "Step: 7118 Weights: [0.35616068 2.13242052] , error: 0.47374429223903186\n",
      "Step: 7119 Weights: [0.35616068 2.13242051] , error: 0.4737442922390245\n",
      "Step: 7120 Weights: [0.35616069 2.13242051] , error: 0.4737442922390165\n",
      "Step: 7121 Weights: [0.3561607  2.13242051] , error: 0.47374429223900943\n",
      "Step: 7122 Weights: [0.35616071 2.13242051] , error: 0.47374429223900233\n",
      "Step: 7123 Weights: [0.35616072 2.13242051] , error: 0.4737442922389957\n",
      "Step: 7124 Weights: [0.35616073 2.13242051] , error: 0.47374429223898884\n",
      "Step: 7125 Weights: [0.35616073 2.13242051] , error: 0.4737442922389815\n",
      "Step: 7126 Weights: [0.35616074 2.13242051] , error: 0.4737442922389741\n",
      "Step: 7127 Weights: [0.35616075 2.13242051] , error: 0.47374429223896725\n",
      "Step: 7128 Weights: [0.35616076 2.13242051] , error: 0.4737442922389603\n",
      "Step: 7129 Weights: [0.35616077 2.1324205 ] , error: 0.4737442922389532\n",
      "Step: 7130 Weights: [0.35616078 2.1324205 ] , error: 0.47374429223894676\n",
      "Step: 7131 Weights: [0.35616078 2.1324205 ] , error: 0.4737442922389399\n",
      "Step: 7132 Weights: [0.35616079 2.1324205 ] , error: 0.4737442922389328\n",
      "Step: 7133 Weights: [0.3561608 2.1324205] , error: 0.4737442922389259\n",
      "Step: 7134 Weights: [0.35616081 2.1324205 ] , error: 0.47374429223892\n",
      "Step: 7135 Weights: [0.35616082 2.1324205 ] , error: 0.47374429223891257\n",
      "Step: 7136 Weights: [0.35616082 2.1324205 ] , error: 0.47374429223890596\n",
      "Step: 7137 Weights: [0.35616083 2.1324205 ] , error: 0.47374429223889936\n",
      "Step: 7138 Weights: [0.35616084 2.1324205 ] , error: 0.4737442922388926\n",
      "Step: 7139 Weights: [0.35616085 2.1324205 ] , error: 0.4737442922388855\n",
      "Step: 7140 Weights: [0.35616086 2.13242049] , error: 0.4737442922388797\n",
      "Step: 7141 Weights: [0.35616087 2.13242049] , error: 0.4737442922388724\n",
      "Step: 7142 Weights: [0.35616087 2.13242049] , error: 0.47374429223886616\n",
      "Step: 7143 Weights: [0.35616088 2.13242049] , error: 0.4737442922388592\n",
      "Step: 7144 Weights: [0.35616089 2.13242049] , error: 0.4737442922388536\n",
      "Step: 7145 Weights: [0.3561609  2.13242049] , error: 0.4737442922388473\n",
      "Step: 7146 Weights: [0.3561609  2.13242049] , error: 0.47374429223884074\n",
      "Step: 7147 Weights: [0.35616091 2.13242049] , error: 0.473744292238835\n",
      "Step: 7148 Weights: [0.35616092 2.13242049] , error: 0.4737442922388284\n",
      "Step: 7149 Weights: [0.35616093 2.13242049] , error: 0.473744292238822\n",
      "Step: 7150 Weights: [0.35616094 2.13242049] , error: 0.473744292238816\n",
      "Step: 7151 Weights: [0.35616094 2.13242048] , error: 0.47374429223880915\n",
      "Step: 7152 Weights: [0.35616095 2.13242048] , error: 0.4737442922388029\n",
      "Step: 7153 Weights: [0.35616096 2.13242048] , error: 0.47374429223879727\n",
      "Step: 7154 Weights: [0.35616097 2.13242048] , error: 0.4737442922387904\n",
      "Step: 7155 Weights: [0.35616098 2.13242048] , error: 0.4737442922387842\n",
      "Step: 7156 Weights: [0.35616098 2.13242048] , error: 0.47374429223877806\n",
      "Step: 7157 Weights: [0.35616099 2.13242048] , error: 0.4737442922387718\n",
      "Step: 7158 Weights: [0.356161   2.13242048] , error: 0.473744292238766\n",
      "Step: 7159 Weights: [0.35616101 2.13242048] , error: 0.4737442922387596\n",
      "Step: 7160 Weights: [0.35616101 2.13242048] , error: 0.47374429223875414\n",
      "Step: 7161 Weights: [0.35616102 2.13242048] , error: 0.47374429223874776\n",
      "Step: 7162 Weights: [0.35616103 2.13242047] , error: 0.47374429223874254\n",
      "Step: 7163 Weights: [0.35616104 2.13242047] , error: 0.47374429223873704\n",
      "Step: 7164 Weights: [0.35616105 2.13242047] , error: 0.47374429223873027\n",
      "Step: 7165 Weights: [0.35616105 2.13242047] , error: 0.4737442922387247\n",
      "Step: 7166 Weights: [0.35616106 2.13242047] , error: 0.473744292238719\n",
      "Step: 7167 Weights: [0.35616107 2.13242047] , error: 0.4737442922387129\n",
      "Step: 7168 Weights: [0.35616108 2.13242047] , error: 0.4737442922387074\n",
      "Step: 7169 Weights: [0.35616108 2.13242047] , error: 0.47374429223870196\n",
      "Step: 7170 Weights: [0.35616109 2.13242047] , error: 0.4737442922386958\n",
      "Step: 7171 Weights: [0.3561611  2.13242047] , error: 0.47374429223868947\n",
      "Step: 7172 Weights: [0.35616111 2.13242047] , error: 0.47374429223868453\n",
      "Step: 7173 Weights: [0.35616111 2.13242047] , error: 0.47374429223867826\n",
      "Step: 7174 Weights: [0.35616112 2.13242046] , error: 0.47374429223867354\n",
      "Step: 7175 Weights: [0.35616113 2.13242046] , error: 0.47374429223866704\n",
      "Step: 7176 Weights: [0.35616114 2.13242046] , error: 0.4737442922386623\n",
      "Step: 7177 Weights: [0.35616114 2.13242046] , error: 0.4737442922386547\n",
      "Step: 7178 Weights: [0.35616115 2.13242046] , error: 0.4737442922386503\n",
      "Step: 7179 Weights: [0.35616116 2.13242046] , error: 0.47374429223864506\n",
      "Step: 7180 Weights: [0.35616116 2.13242046] , error: 0.4737442922386397\n",
      "Step: 7181 Weights: [0.35616117 2.13242046] , error: 0.4737442922386347\n",
      "Step: 7182 Weights: [0.35616118 2.13242046] , error: 0.4737442922386287\n",
      "Step: 7183 Weights: [0.35616119 2.13242046] , error: 0.47374429223862313\n",
      "Step: 7184 Weights: [0.35616119 2.13242046] , error: 0.47374429223861875\n",
      "Step: 7185 Weights: [0.3561612  2.13242046] , error: 0.47374429223861253\n",
      "Step: 7186 Weights: [0.35616121 2.13242045] , error: 0.4737442922386071\n",
      "Step: 7187 Weights: [0.35616122 2.13242045] , error: 0.4737442922386022\n",
      "Step: 7188 Weights: [0.35616122 2.13242045] , error: 0.4737442922385965\n",
      "Step: 7189 Weights: [0.35616123 2.13242045] , error: 0.4737442922385915\n",
      "Step: 7190 Weights: [0.35616124 2.13242045] , error: 0.47374429223858644\n",
      "Step: 7191 Weights: [0.35616124 2.13242045] , error: 0.47374429223858094\n",
      "Step: 7192 Weights: [0.35616125 2.13242045] , error: 0.47374429223857545\n",
      "Step: 7193 Weights: [0.35616126 2.13242045] , error: 0.4737442922385706\n",
      "Step: 7194 Weights: [0.35616127 2.13242045] , error: 0.47374429223856573\n",
      "Step: 7195 Weights: [0.35616127 2.13242045] , error: 0.4737442922385605\n",
      "Step: 7196 Weights: [0.35616128 2.13242045] , error: 0.4737442922385555\n",
      "Step: 7197 Weights: [0.35616129 2.13242045] , error: 0.4737442922385502\n",
      "Step: 7198 Weights: [0.35616129 2.13242044] , error: 0.47374429223854514\n",
      "Step: 7199 Weights: [0.3561613  2.13242044] , error: 0.4737442922385401\n",
      "Step: 7200 Weights: [0.35616131 2.13242044] , error: 0.4737442922385351\n",
      "Step: 7201 Weights: [0.35616132 2.13242044] , error: 0.47374429223853\n",
      "Step: 7202 Weights: [0.35616132 2.13242044] , error: 0.4737442922385251\n",
      "Step: 7203 Weights: [0.35616133 2.13242044] , error: 0.4737442922385198\n",
      "Step: 7204 Weights: [0.35616134 2.13242044] , error: 0.47374429223851516\n",
      "Step: 7205 Weights: [0.35616134 2.13242044] , error: 0.4737442922385111\n",
      "Step: 7206 Weights: [0.35616135 2.13242044] , error: 0.4737442922385053\n",
      "Step: 7207 Weights: [0.35616136 2.13242044] , error: 0.4737442922385011\n",
      "Step: 7208 Weights: [0.35616136 2.13242044] , error: 0.4737442922384967\n",
      "Step: 7209 Weights: [0.35616137 2.13242044] , error: 0.47374429223849085\n",
      "Step: 7210 Weights: [0.35616138 2.13242044] , error: 0.4737442922384865\n",
      "Step: 7211 Weights: [0.35616138 2.13242043] , error: 0.4737442922384819\n",
      "Step: 7212 Weights: [0.35616139 2.13242043] , error: 0.47374429223847747\n",
      "Step: 7213 Weights: [0.3561614  2.13242043] , error: 0.4737442922384727\n",
      "Step: 7214 Weights: [0.35616141 2.13242043] , error: 0.4737442922384677\n",
      "Step: 7215 Weights: [0.35616141 2.13242043] , error: 0.4737442922384632\n",
      "Step: 7216 Weights: [0.35616142 2.13242043] , error: 0.4737442922384586\n",
      "Step: 7217 Weights: [0.35616143 2.13242043] , error: 0.4737442922384534\n",
      "Step: 7218 Weights: [0.35616143 2.13242043] , error: 0.47374429223844905\n",
      "Step: 7219 Weights: [0.35616144 2.13242043] , error: 0.4737442922384445\n",
      "Step: 7220 Weights: [0.35616145 2.13242043] , error: 0.47374429223843995\n",
      "Step: 7221 Weights: [0.35616145 2.13242043] , error: 0.4737442922384353\n",
      "Step: 7222 Weights: [0.35616146 2.13242043] , error: 0.47374429223843084\n",
      "Step: 7223 Weights: [0.35616147 2.13242043] , error: 0.4737442922384264\n",
      "Step: 7224 Weights: [0.35616147 2.13242042] , error: 0.473744292238422\n",
      "Step: 7225 Weights: [0.35616148 2.13242042] , error: 0.47374429223841774\n",
      "Step: 7226 Weights: [0.35616149 2.13242042] , error: 0.4737442922384133\n",
      "Step: 7227 Weights: [0.35616149 2.13242042] , error: 0.4737442922384085\n",
      "Step: 7228 Weights: [0.3561615  2.13242042] , error: 0.47374429223840425\n",
      "Step: 7229 Weights: [0.35616151 2.13242042] , error: 0.47374429223839976\n",
      "Step: 7230 Weights: [0.35616151 2.13242042] , error: 0.47374429223839537\n",
      "Step: 7231 Weights: [0.35616152 2.13242042] , error: 0.47374429223839076\n",
      "Step: 7232 Weights: [0.35616153 2.13242042] , error: 0.4737442922383873\n",
      "Step: 7233 Weights: [0.35616153 2.13242042] , error: 0.4737442922383826\n",
      "Step: 7234 Weights: [0.35616154 2.13242042] , error: 0.47374429223837844\n",
      "Step: 7235 Weights: [0.35616154 2.13242042] , error: 0.4737442922383735\n",
      "Step: 7236 Weights: [0.35616155 2.13242042] , error: 0.47374429223836945\n",
      "Step: 7237 Weights: [0.35616156 2.13242041] , error: 0.47374429223836534\n",
      "Step: 7238 Weights: [0.35616156 2.13242041] , error: 0.47374429223836156\n",
      "Step: 7239 Weights: [0.35616157 2.13242041] , error: 0.4737442922383573\n",
      "Step: 7240 Weights: [0.35616158 2.13242041] , error: 0.4737442922383528\n",
      "Step: 7241 Weights: [0.35616158 2.13242041] , error: 0.4737442922383488\n",
      "Step: 7242 Weights: [0.35616159 2.13242041] , error: 0.4737442922383447\n",
      "Step: 7243 Weights: [0.3561616  2.13242041] , error: 0.47374429223834036\n",
      "Step: 7244 Weights: [0.3561616  2.13242041] , error: 0.47374429223833603\n",
      "Step: 7245 Weights: [0.35616161 2.13242041] , error: 0.47374429223833237\n",
      "Step: 7246 Weights: [0.35616161 2.13242041] , error: 0.47374429223832865\n",
      "Step: 7247 Weights: [0.35616162 2.13242041] , error: 0.4737442922383243\n",
      "Step: 7248 Weights: [0.35616163 2.13242041] , error: 0.4737442922383196\n",
      "Step: 7249 Weights: [0.35616163 2.13242041] , error: 0.4737442922383159\n",
      "Step: 7250 Weights: [0.35616164 2.13242041] , error: 0.4737442922383125\n",
      "Step: 7251 Weights: [0.35616165 2.1324204 ] , error: 0.4737442922383082\n",
      "Step: 7252 Weights: [0.35616165 2.1324204 ] , error: 0.47374429223830383\n",
      "Step: 7253 Weights: [0.35616166 2.1324204 ] , error: 0.47374429223830045\n",
      "Step: 7254 Weights: [0.35616167 2.1324204 ] , error: 0.4737442922382966\n",
      "Step: 7255 Weights: [0.35616167 2.1324204 ] , error: 0.47374429223829295\n",
      "Step: 7256 Weights: [0.35616168 2.1324204 ] , error: 0.4737442922382895\n",
      "Step: 7257 Weights: [0.35616168 2.1324204 ] , error: 0.4737442922382854\n",
      "Step: 7258 Weights: [0.35616169 2.1324204 ] , error: 0.47374429223828124\n",
      "Step: 7259 Weights: [0.3561617 2.1324204] , error: 0.47374429223827774\n",
      "Step: 7260 Weights: [0.3561617 2.1324204] , error: 0.4737442922382733\n",
      "Step: 7261 Weights: [0.35616171 2.1324204 ] , error: 0.47374429223826986\n",
      "Step: 7262 Weights: [0.35616171 2.1324204 ] , error: 0.4737442922382658\n",
      "Step: 7263 Weights: [0.35616172 2.1324204 ] , error: 0.4737442922382623\n",
      "Step: 7264 Weights: [0.35616173 2.1324204 ] , error: 0.47374429223825787\n",
      "Step: 7265 Weights: [0.35616173 2.13242039] , error: 0.47374429223825515\n",
      "Step: 7266 Weights: [0.35616174 2.13242039] , error: 0.4737442922382513\n",
      "Step: 7267 Weights: [0.35616174 2.13242039] , error: 0.4737442922382471\n",
      "Step: 7268 Weights: [0.35616175 2.13242039] , error: 0.47374429223824366\n",
      "Step: 7269 Weights: [0.35616176 2.13242039] , error: 0.47374429223823994\n",
      "Step: 7270 Weights: [0.35616176 2.13242039] , error: 0.47374429223823583\n",
      "Step: 7271 Weights: [0.35616177 2.13242039] , error: 0.4737442922382331\n",
      "Step: 7272 Weights: [0.35616177 2.13242039] , error: 0.47374429223822917\n",
      "Step: 7273 Weights: [0.35616178 2.13242039] , error: 0.4737442922382259\n",
      "Step: 7274 Weights: [0.35616179 2.13242039] , error: 0.47374429223822223\n",
      "Step: 7275 Weights: [0.35616179 2.13242039] , error: 0.47374429223821823\n",
      "Step: 7276 Weights: [0.3561618  2.13242039] , error: 0.4737442922382151\n",
      "Step: 7277 Weights: [0.3561618  2.13242039] , error: 0.4737442922382112\n",
      "Step: 7278 Weights: [0.35616181 2.13242039] , error: 0.473744292238208\n",
      "Step: 7279 Weights: [0.35616182 2.13242038] , error: 0.47374429223820413\n",
      "Step: 7280 Weights: [0.35616182 2.13242038] , error: 0.47374429223820086\n",
      "Step: 7281 Weights: [0.35616183 2.13242038] , error: 0.47374429223819736\n",
      "Step: 7282 Weights: [0.35616183 2.13242038] , error: 0.4737442922381945\n",
      "Step: 7283 Weights: [0.35616184 2.13242038] , error: 0.47374429223819015\n",
      "Step: 7284 Weights: [0.35616185 2.13242038] , error: 0.4737442922381876\n",
      "Step: 7285 Weights: [0.35616185 2.13242038] , error: 0.47374429223818376\n",
      "Step: 7286 Weights: [0.35616186 2.13242038] , error: 0.47374429223818054\n",
      "Step: 7287 Weights: [0.35616186 2.13242038] , error: 0.47374429223817704\n",
      "Step: 7288 Weights: [0.35616187 2.13242038] , error: 0.47374429223817366\n",
      "Step: 7289 Weights: [0.35616187 2.13242038] , error: 0.4737442922381698\n",
      "Step: 7290 Weights: [0.35616188 2.13242038] , error: 0.47374429223816733\n",
      "Step: 7291 Weights: [0.35616189 2.13242038] , error: 0.4737442922381641\n",
      "Step: 7292 Weights: [0.35616189 2.13242038] , error: 0.4737442922381609\n",
      "Step: 7293 Weights: [0.3561619  2.13242038] , error: 0.47374429223815656\n",
      "Step: 7294 Weights: [0.3561619  2.13242038] , error: 0.4737442922381542\n",
      "Step: 7295 Weights: [0.35616191 2.13242037] , error: 0.4737442922381507\n",
      "Step: 7296 Weights: [0.35616191 2.13242037] , error: 0.47374429223814823\n",
      "Step: 7297 Weights: [0.35616192 2.13242037] , error: 0.4737442922381459\n",
      "Step: 7298 Weights: [0.35616192 2.13242037] , error: 0.4737442922381413\n",
      "Step: 7299 Weights: [0.35616193 2.13242037] , error: 0.473744292238138\n",
      "Step: 7300 Weights: [0.35616194 2.13242037] , error: 0.47374429223813475\n",
      "Step: 7301 Weights: [0.35616194 2.13242037] , error: 0.4737442922381317\n",
      "Step: 7302 Weights: [0.35616195 2.13242037] , error: 0.4737442922381287\n",
      "Step: 7303 Weights: [0.35616195 2.13242037] , error: 0.4737442922381254\n",
      "Step: 7304 Weights: [0.35616196 2.13242037] , error: 0.4737442922381225\n",
      "Step: 7305 Weights: [0.35616196 2.13242037] , error: 0.4737442922381189\n",
      "Step: 7306 Weights: [0.35616197 2.13242037] , error: 0.47374429223811654\n",
      "Step: 7307 Weights: [0.35616197 2.13242037] , error: 0.47374429223811276\n",
      "Step: 7308 Weights: [0.35616198 2.13242037] , error: 0.4737442922381102\n",
      "Step: 7309 Weights: [0.35616199 2.13242037] , error: 0.47374429223810643\n",
      "Step: 7310 Weights: [0.35616199 2.13242036] , error: 0.4737442922381041\n",
      "Step: 7311 Weights: [0.356162   2.13242036] , error: 0.47374429223810066\n",
      "Step: 7312 Weights: [0.356162   2.13242036] , error: 0.47374429223809733\n",
      "Step: 7313 Weights: [0.35616201 2.13242036] , error: 0.47374429223809467\n",
      "Step: 7314 Weights: [0.35616201 2.13242036] , error: 0.47374429223809184\n",
      "Step: 7315 Weights: [0.35616202 2.13242036] , error: 0.47374429223808956\n",
      "Step: 7316 Weights: [0.35616202 2.13242036] , error: 0.4737442922380861\n",
      "Step: 7317 Weights: [0.35616203 2.13242036] , error: 0.473744292238083\n",
      "Step: 7318 Weights: [0.35616203 2.13242036] , error: 0.4737442922380801\n",
      "Step: 7319 Weights: [0.35616204 2.13242036] , error: 0.4737442922380766\n",
      "Step: 7320 Weights: [0.35616205 2.13242036] , error: 0.47374429223807457\n",
      "Step: 7321 Weights: [0.35616205 2.13242036] , error: 0.47374429223807185\n",
      "Step: 7322 Weights: [0.35616206 2.13242036] , error: 0.47374429223806913\n",
      "Step: 7323 Weights: [0.35616206 2.13242036] , error: 0.47374429223806586\n",
      "Step: 7324 Weights: [0.35616207 2.13242036] , error: 0.473744292238063\n",
      "Step: 7325 Weights: [0.35616207 2.13242036] , error: 0.47374429223806\n",
      "Step: 7326 Weights: [0.35616208 2.13242036] , error: 0.47374429223805736\n",
      "Step: 7327 Weights: [0.35616208 2.13242035] , error: 0.4737442922380549\n",
      "Step: 7328 Weights: [0.35616209 2.13242035] , error: 0.4737442922380519\n",
      "Step: 7329 Weights: [0.35616209 2.13242035] , error: 0.47374429223804915\n",
      "Step: 7330 Weights: [0.3561621  2.13242035] , error: 0.4737442922380468\n",
      "Step: 7331 Weights: [0.3561621  2.13242035] , error: 0.4737442922380435\n",
      "Step: 7332 Weights: [0.35616211 2.13242035] , error: 0.4737442922380411\n",
      "Step: 7333 Weights: [0.35616211 2.13242035] , error: 0.47374429223803816\n",
      "Step: 7334 Weights: [0.35616212 2.13242035] , error: 0.4737442922380349\n",
      "Step: 7335 Weights: [0.35616212 2.13242035] , error: 0.4737442922380324\n",
      "Step: 7336 Weights: [0.35616213 2.13242035] , error: 0.4737442922380303\n",
      "Step: 7337 Weights: [0.35616213 2.13242035] , error: 0.47374429223802716\n",
      "Step: 7338 Weights: [0.35616214 2.13242035] , error: 0.4737442922380249\n",
      "Step: 7339 Weights: [0.35616214 2.13242035] , error: 0.4737442922380213\n",
      "Step: 7340 Weights: [0.35616215 2.13242035] , error: 0.4737442922380188\n",
      "Step: 7341 Weights: [0.35616215 2.13242035] , error: 0.473744292238017\n",
      "Step: 7342 Weights: [0.35616216 2.13242035] , error: 0.47374429223801395\n",
      "Step: 7343 Weights: [0.35616216 2.13242035] , error: 0.4737442922380112\n",
      "Step: 7344 Weights: [0.35616217 2.13242034] , error: 0.4737442922380092\n",
      "Step: 7345 Weights: [0.35616218 2.13242034] , error: 0.4737442922380062\n",
      "Step: 7346 Weights: [0.35616218 2.13242034] , error: 0.4737442922380039\n",
      "Step: 7347 Weights: [0.35616219 2.13242034] , error: 0.47374429223800146\n",
      "Step: 7348 Weights: [0.35616219 2.13242034] , error: 0.4737442922379991\n",
      "Step: 7349 Weights: [0.3561622  2.13242034] , error: 0.4737442922379964\n",
      "Step: 7350 Weights: [0.3561622  2.13242034] , error: 0.47374429223799375\n",
      "Step: 7351 Weights: [0.35616221 2.13242034] , error: 0.47374429223799097\n",
      "Step: 7352 Weights: [0.35616221 2.13242034] , error: 0.47374429223798914\n",
      "Step: 7353 Weights: [0.35616222 2.13242034] , error: 0.47374429223798575\n",
      "Step: 7354 Weights: [0.35616222 2.13242034] , error: 0.47374429223798376\n",
      "Step: 7355 Weights: [0.35616222 2.13242034] , error: 0.47374429223798176\n",
      "Step: 7356 Weights: [0.35616223 2.13242034] , error: 0.4737442922379781\n",
      "Step: 7357 Weights: [0.35616223 2.13242034] , error: 0.47374429223797626\n",
      "Step: 7358 Weights: [0.35616224 2.13242034] , error: 0.4737442922379743\n",
      "Step: 7359 Weights: [0.35616224 2.13242034] , error: 0.4737442922379713\n",
      "Step: 7360 Weights: [0.35616225 2.13242034] , error: 0.47374429223796916\n",
      "Step: 7361 Weights: [0.35616225 2.13242033] , error: 0.4737442922379669\n",
      "Step: 7362 Weights: [0.35616226 2.13242033] , error: 0.47374429223796455\n",
      "Step: 7363 Weights: [0.35616226 2.13242033] , error: 0.4737442922379616\n",
      "Step: 7364 Weights: [0.35616227 2.13242033] , error: 0.4737442922379598\n",
      "Step: 7365 Weights: [0.35616227 2.13242033] , error: 0.47374429223795783\n",
      "Step: 7366 Weights: [0.35616228 2.13242033] , error: 0.4737442922379551\n",
      "Step: 7367 Weights: [0.35616228 2.13242033] , error: 0.47374429223795234\n",
      "Step: 7368 Weights: [0.35616229 2.13242033] , error: 0.4737442922379499\n",
      "Step: 7369 Weights: [0.35616229 2.13242033] , error: 0.473744292237948\n",
      "Step: 7370 Weights: [0.3561623  2.13242033] , error: 0.47374429223794623\n",
      "Step: 7371 Weights: [0.3561623  2.13242033] , error: 0.4737442922379437\n",
      "Step: 7372 Weights: [0.35616231 2.13242033] , error: 0.47374429223794073\n",
      "Step: 7373 Weights: [0.35616231 2.13242033] , error: 0.47374429223793885\n",
      "Step: 7374 Weights: [0.35616232 2.13242033] , error: 0.4737442922379368\n",
      "Step: 7375 Weights: [0.35616232 2.13242033] , error: 0.47374429223793446\n",
      "Step: 7376 Weights: [0.35616233 2.13242033] , error: 0.4737442922379324\n",
      "Step: 7377 Weights: [0.35616233 2.13242033] , error: 0.4737442922379292\n",
      "Step: 7378 Weights: [0.35616234 2.13242033] , error: 0.4737442922379272\n",
      "Step: 7379 Weights: [0.35616234 2.13242033] , error: 0.47374429223792514\n",
      "Step: 7380 Weights: [0.35616234 2.13242032] , error: 0.4737442922379237\n",
      "Step: 7381 Weights: [0.35616235 2.13242032] , error: 0.4737442922379205\n",
      "Step: 7382 Weights: [0.35616235 2.13242032] , error: 0.47374429223791875\n",
      "Step: 7383 Weights: [0.35616236 2.13242032] , error: 0.4737442922379168\n",
      "Step: 7384 Weights: [0.35616236 2.13242032] , error: 0.4737442922379147\n",
      "Step: 7385 Weights: [0.35616237 2.13242032] , error: 0.47374429223791226\n",
      "Step: 7386 Weights: [0.35616237 2.13242032] , error: 0.47374429223791165\n",
      "Step: 7387 Weights: [0.35616238 2.13242032] , error: 0.4737442922379086\n",
      "Step: 7388 Weights: [0.35616238 2.13242032] , error: 0.4737442922379056\n",
      "Step: 7389 Weights: [0.35616239 2.13242032] , error: 0.4737442922379039\n",
      "Step: 7390 Weights: [0.35616239 2.13242032] , error: 0.4737442922379015\n",
      "Step: 7391 Weights: [0.3561624  2.13242032] , error: 0.4737442922378993\n",
      "Step: 7392 Weights: [0.3561624  2.13242032] , error: 0.4737442922378976\n",
      "Step: 7393 Weights: [0.3561624  2.13242032] , error: 0.4737442922378956\n",
      "Step: 7394 Weights: [0.35616241 2.13242032] , error: 0.4737442922378934\n",
      "Step: 7395 Weights: [0.35616241 2.13242032] , error: 0.47374429223789166\n",
      "Step: 7396 Weights: [0.35616242 2.13242032] , error: 0.47374429223788944\n",
      "Step: 7397 Weights: [0.35616242 2.13242032] , error: 0.47374429223788767\n",
      "Step: 7398 Weights: [0.35616243 2.13242032] , error: 0.4737442922378849\n",
      "Step: 7399 Weights: [0.35616243 2.13242031] , error: 0.4737442922378834\n",
      "Step: 7400 Weights: [0.35616244 2.13242031] , error: 0.4737442922378815\n",
      "Step: 7401 Weights: [0.35616244 2.13242031] , error: 0.4737442922378795\n",
      "Step: 7402 Weights: [0.35616244 2.13242031] , error: 0.47374429223787723\n",
      "Step: 7403 Weights: [0.35616245 2.13242031] , error: 0.4737442922378755\n",
      "Step: 7404 Weights: [0.35616245 2.13242031] , error: 0.4737442922378734\n",
      "Step: 7405 Weights: [0.35616246 2.13242031] , error: 0.4737442922378713\n",
      "Step: 7406 Weights: [0.35616246 2.13242031] , error: 0.47374429223786907\n",
      "Step: 7407 Weights: [0.35616247 2.13242031] , error: 0.473744292237867\n",
      "Step: 7408 Weights: [0.35616247 2.13242031] , error: 0.4737442922378657\n",
      "Step: 7409 Weights: [0.35616248 2.13242031] , error: 0.4737442922378642\n",
      "Step: 7410 Weights: [0.35616248 2.13242031] , error: 0.47374429223786124\n",
      "Step: 7411 Weights: [0.35616248 2.13242031] , error: 0.47374429223785985\n",
      "Step: 7412 Weights: [0.35616249 2.13242031] , error: 0.4737442922378573\n",
      "Step: 7413 Weights: [0.35616249 2.13242031] , error: 0.47374429223785564\n",
      "Step: 7414 Weights: [0.3561625  2.13242031] , error: 0.4737442922378539\n",
      "Step: 7415 Weights: [0.3561625  2.13242031] , error: 0.4737442922378528\n",
      "Step: 7416 Weights: [0.35616251 2.13242031] , error: 0.47374429223785064\n",
      "Step: 7417 Weights: [0.35616251 2.13242031] , error: 0.4737442922378485\n",
      "Step: 7418 Weights: [0.35616251 2.13242031] , error: 0.47374429223784675\n",
      "Step: 7419 Weights: [0.35616252 2.1324203 ] , error: 0.4737442922378442\n",
      "Step: 7420 Weights: [0.35616252 2.1324203 ] , error: 0.4737442922378428\n",
      "Step: 7421 Weights: [0.35616253 2.1324203 ] , error: 0.473744292237841\n",
      "Step: 7422 Weights: [0.35616253 2.1324203 ] , error: 0.47374429223783954\n",
      "Step: 7423 Weights: [0.35616254 2.1324203 ] , error: 0.4737442922378375\n",
      "Step: 7424 Weights: [0.35616254 2.1324203 ] , error: 0.473744292237836\n",
      "Step: 7425 Weights: [0.35616254 2.1324203 ] , error: 0.4737442922378339\n",
      "Step: 7426 Weights: [0.35616255 2.1324203 ] , error: 0.4737442922378327\n",
      "Step: 7427 Weights: [0.35616255 2.1324203 ] , error: 0.4737442922378305\n",
      "Step: 7428 Weights: [0.35616256 2.1324203 ] , error: 0.47374429223782927\n",
      "Step: 7429 Weights: [0.35616256 2.1324203 ] , error: 0.47374429223782627\n",
      "Step: 7430 Weights: [0.35616256 2.1324203 ] , error: 0.47374429223782477\n",
      "Step: 7431 Weights: [0.35616257 2.1324203 ] , error: 0.4737442922378232\n",
      "Step: 7432 Weights: [0.35616257 2.1324203 ] , error: 0.4737442922378214\n",
      "Step: 7433 Weights: [0.35616258 2.1324203 ] , error: 0.47374429223782016\n",
      "Step: 7434 Weights: [0.35616258 2.1324203 ] , error: 0.473744292237818\n",
      "Step: 7435 Weights: [0.35616259 2.1324203 ] , error: 0.4737442922378149\n",
      "Step: 7436 Weights: [0.35616259 2.1324203 ] , error: 0.4737442922378148\n",
      "Step: 7437 Weights: [0.35616259 2.1324203 ] , error: 0.47374429223781356\n",
      "Step: 7438 Weights: [0.3561626 2.1324203] , error: 0.47374429223781134\n",
      "Step: 7439 Weights: [0.3561626 2.1324203] , error: 0.47374429223780984\n",
      "Step: 7440 Weights: [0.35616261 2.13242029] , error: 0.473744292237808\n",
      "Step: 7441 Weights: [0.35616261 2.13242029] , error: 0.4737442922378068\n",
      "Step: 7442 Weights: [0.35616261 2.13242029] , error: 0.47374429223780407\n",
      "Step: 7443 Weights: [0.35616262 2.13242029] , error: 0.47374429223780334\n",
      "Step: 7444 Weights: [0.35616262 2.13242029] , error: 0.4737442922378021\n",
      "Step: 7445 Weights: [0.35616263 2.13242029] , error: 0.4737442922377995\n",
      "Step: 7446 Weights: [0.35616263 2.13242029] , error: 0.4737442922377982\n",
      "Step: 7447 Weights: [0.35616263 2.13242029] , error: 0.4737442922377963\n",
      "Step: 7448 Weights: [0.35616264 2.13242029] , error: 0.47374429223779496\n",
      "Step: 7449 Weights: [0.35616264 2.13242029] , error: 0.4737442922377931\n",
      "Step: 7450 Weights: [0.35616265 2.13242029] , error: 0.47374429223779163\n",
      "Step: 7451 Weights: [0.35616265 2.13242029] , error: 0.47374429223778974\n",
      "Step: 7452 Weights: [0.35616265 2.13242029] , error: 0.47374429223778874\n",
      "Step: 7453 Weights: [0.35616266 2.13242029] , error: 0.47374429223778675\n",
      "Step: 7454 Weights: [0.35616266 2.13242029] , error: 0.47374429223778614\n",
      "Step: 7455 Weights: [0.35616267 2.13242029] , error: 0.473744292237784\n",
      "Step: 7456 Weights: [0.35616267 2.13242029] , error: 0.4737442922377826\n",
      "Step: 7457 Weights: [0.35616267 2.13242029] , error: 0.4737442922377809\n",
      "Step: 7458 Weights: [0.35616268 2.13242029] , error: 0.47374429223777903\n",
      "Step: 7459 Weights: [0.35616268 2.13242029] , error: 0.47374429223777814\n",
      "Step: 7460 Weights: [0.35616269 2.13242029] , error: 0.47374429223777603\n",
      "Step: 7461 Weights: [0.35616269 2.13242029] , error: 0.4737442922377749\n",
      "Step: 7462 Weights: [0.35616269 2.13242028] , error: 0.4737442922377732\n",
      "Step: 7463 Weights: [0.3561627  2.13242028] , error: 0.47374429223777126\n",
      "Step: 7464 Weights: [0.3561627  2.13242028] , error: 0.47374429223777015\n",
      "Step: 7465 Weights: [0.3561627  2.13242028] , error: 0.4737442922377685\n",
      "Step: 7466 Weights: [0.35616271 2.13242028] , error: 0.47374429223776715\n",
      "Step: 7467 Weights: [0.35616271 2.13242028] , error: 0.4737442922377661\n",
      "Step: 7468 Weights: [0.35616272 2.13242028] , error: 0.4737442922377642\n",
      "Step: 7469 Weights: [0.35616272 2.13242028] , error: 0.4737442922377626\n",
      "Step: 7470 Weights: [0.35616272 2.13242028] , error: 0.4737442922377606\n",
      "Step: 7471 Weights: [0.35616273 2.13242028] , error: 0.4737442922377597\n",
      "Step: 7472 Weights: [0.35616273 2.13242028] , error: 0.4737442922377587\n",
      "Step: 7473 Weights: [0.35616273 2.13242028] , error: 0.47374429223775694\n",
      "Step: 7474 Weights: [0.35616274 2.13242028] , error: 0.4737442922377558\n",
      "Step: 7475 Weights: [0.35616274 2.13242028] , error: 0.47374429223775466\n",
      "Step: 7476 Weights: [0.35616275 2.13242028] , error: 0.4737442922377527\n",
      "Step: 7477 Weights: [0.35616275 2.13242028] , error: 0.47374429223775155\n",
      "Step: 7478 Weights: [0.35616275 2.13242028] , error: 0.47374429223775016\n",
      "Step: 7479 Weights: [0.35616276 2.13242028] , error: 0.4737442922377483\n",
      "Step: 7480 Weights: [0.35616276 2.13242028] , error: 0.47374429223774756\n",
      "Step: 7481 Weights: [0.35616276 2.13242028] , error: 0.473744292237746\n",
      "Step: 7482 Weights: [0.35616277 2.13242028] , error: 0.4737442922377446\n",
      "Step: 7483 Weights: [0.35616277 2.13242028] , error: 0.47374429223774306\n",
      "Step: 7484 Weights: [0.35616278 2.13242028] , error: 0.4737442922377417\n",
      "Step: 7485 Weights: [0.35616278 2.13242027] , error: 0.4737442922377401\n",
      "Step: 7486 Weights: [0.35616278 2.13242027] , error: 0.4737442922377391\n",
      "Step: 7487 Weights: [0.35616279 2.13242027] , error: 0.4737442922377378\n",
      "Step: 7488 Weights: [0.35616279 2.13242027] , error: 0.47374429223773673\n",
      "Step: 7489 Weights: [0.35616279 2.13242027] , error: 0.4737442922377348\n",
      "Step: 7490 Weights: [0.3561628  2.13242027] , error: 0.4737442922377336\n",
      "Step: 7491 Weights: [0.3561628  2.13242027] , error: 0.4737442922377319\n",
      "Step: 7492 Weights: [0.3561628  2.13242027] , error: 0.4737442922377314\n",
      "Step: 7493 Weights: [0.35616281 2.13242027] , error: 0.4737442922377294\n",
      "Step: 7494 Weights: [0.35616281 2.13242027] , error: 0.4737442922377284\n",
      "Step: 7495 Weights: [0.35616282 2.13242027] , error: 0.47374429223772696\n",
      "Step: 7496 Weights: [0.35616282 2.13242027] , error: 0.4737442922377258\n",
      "Step: 7497 Weights: [0.35616282 2.13242027] , error: 0.4737442922377244\n",
      "Step: 7498 Weights: [0.35616283 2.13242027] , error: 0.4737442922377235\n",
      "Step: 7499 Weights: [0.35616283 2.13242027] , error: 0.4737442922377223\n",
      "Step: 7500 Weights: [0.35616283 2.13242027] , error: 0.47374429223772085\n",
      "Step: 7501 Weights: [0.35616284 2.13242027] , error: 0.47374429223771986\n",
      "Step: 7502 Weights: [0.35616284 2.13242027] , error: 0.4737442922377176\n",
      "Step: 7503 Weights: [0.35616284 2.13242027] , error: 0.473744292237717\n",
      "Step: 7504 Weights: [0.35616285 2.13242027] , error: 0.47374429223771486\n",
      "Step: 7505 Weights: [0.35616285 2.13242027] , error: 0.47374429223771397\n",
      "Step: 7506 Weights: [0.35616285 2.13242027] , error: 0.473744292237713\n",
      "Step: 7507 Weights: [0.35616286 2.13242027] , error: 0.4737442922377117\n",
      "Step: 7508 Weights: [0.35616286 2.13242027] , error: 0.47374429223771125\n",
      "Step: 7509 Weights: [0.35616286 2.13242027] , error: 0.47374429223770925\n",
      "Step: 7510 Weights: [0.35616287 2.13242026] , error: 0.47374429223770803\n",
      "Step: 7511 Weights: [0.35616287 2.13242026] , error: 0.4737442922377068\n",
      "Step: 7512 Weights: [0.35616288 2.13242026] , error: 0.47374429223770576\n",
      "Step: 7513 Weights: [0.35616288 2.13242026] , error: 0.47374429223770453\n",
      "Step: 7514 Weights: [0.35616288 2.13242026] , error: 0.47374429223770337\n",
      "Step: 7515 Weights: [0.35616289 2.13242026] , error: 0.4737442922377023\n",
      "Step: 7516 Weights: [0.35616289 2.13242026] , error: 0.4737442922377008\n",
      "Step: 7517 Weights: [0.35616289 2.13242026] , error: 0.4737442922377004\n",
      "Step: 7518 Weights: [0.3561629  2.13242026] , error: 0.47374429223769904\n",
      "Step: 7519 Weights: [0.3561629  2.13242026] , error: 0.473744292237697\n",
      "Step: 7520 Weights: [0.3561629  2.13242026] , error: 0.4737442922376966\n",
      "Step: 7521 Weights: [0.35616291 2.13242026] , error: 0.47374429223769476\n",
      "Step: 7522 Weights: [0.35616291 2.13242026] , error: 0.47374429223769443\n",
      "Step: 7523 Weights: [0.35616291 2.13242026] , error: 0.4737442922376934\n",
      "Step: 7524 Weights: [0.35616292 2.13242026] , error: 0.4737442922376919\n",
      "Step: 7525 Weights: [0.35616292 2.13242026] , error: 0.473744292237691\n",
      "Step: 7526 Weights: [0.35616292 2.13242026] , error: 0.4737442922376889\n",
      "Step: 7527 Weights: [0.35616293 2.13242026] , error: 0.47374429223768794\n",
      "Step: 7528 Weights: [0.35616293 2.13242026] , error: 0.4737442922376867\n",
      "Step: 7529 Weights: [0.35616293 2.13242026] , error: 0.47374429223768566\n",
      "Step: 7530 Weights: [0.35616294 2.13242026] , error: 0.4737442922376847\n",
      "Step: 7531 Weights: [0.35616294 2.13242026] , error: 0.4737442922376845\n",
      "Step: 7532 Weights: [0.35616294 2.13242026] , error: 0.47374429223768266\n",
      "Step: 7533 Weights: [0.35616295 2.13242026] , error: 0.47374429223768183\n",
      "Step: 7534 Weights: [0.35616295 2.13242026] , error: 0.47374429223768094\n",
      "Step: 7535 Weights: [0.35616295 2.13242026] , error: 0.4737442922376791\n",
      "Step: 7536 Weights: [0.35616296 2.13242025] , error: 0.4737442922376779\n",
      "Step: 7537 Weights: [0.35616296 2.13242025] , error: 0.47374429223767767\n",
      "Step: 7538 Weights: [0.35616296 2.13242025] , error: 0.4737442922376768\n",
      "Step: 7539 Weights: [0.35616297 2.13242025] , error: 0.47374429223767545\n",
      "Step: 7540 Weights: [0.35616297 2.13242025] , error: 0.47374429223767367\n",
      "Step: 7541 Weights: [0.35616297 2.13242025] , error: 0.4737442922376729\n",
      "Step: 7542 Weights: [0.35616298 2.13242025] , error: 0.47374429223767156\n",
      "Step: 7543 Weights: [0.35616298 2.13242025] , error: 0.4737442922376709\n",
      "Step: 7544 Weights: [0.35616298 2.13242025] , error: 0.47374429223766984\n",
      "Step: 7545 Weights: [0.35616298 2.13242025] , error: 0.473744292237669\n",
      "Step: 7546 Weights: [0.35616299 2.13242025] , error: 0.4737442922376678\n",
      "Step: 7547 Weights: [0.35616299 2.13242025] , error: 0.47374429223766634\n",
      "Step: 7548 Weights: [0.35616299 2.13242025] , error: 0.47374429223766573\n",
      "Step: 7549 Weights: [0.356163   2.13242025] , error: 0.473744292237665\n",
      "Step: 7550 Weights: [0.356163   2.13242025] , error: 0.473744292237664\n",
      "Step: 7551 Weights: [0.356163   2.13242025] , error: 0.4737442922376644\n",
      "Step: 7552 Weights: [0.35616301 2.13242025] , error: 0.4737442922376619\n",
      "Step: 7553 Weights: [0.35616301 2.13242025] , error: 0.47374429223766035\n",
      "Step: 7554 Weights: [0.35616301 2.13242025] , error: 0.47374429223765985\n",
      "Step: 7555 Weights: [0.35616302 2.13242025] , error: 0.4737442922376589\n",
      "Step: 7556 Weights: [0.35616302 2.13242025] , error: 0.47374429223765735\n",
      "Step: 7557 Weights: [0.35616302 2.13242025] , error: 0.47374429223765735\n",
      "Step: 7558 Weights: [0.35616303 2.13242025] , error: 0.4737442922376558\n",
      "Step: 7559 Weights: [0.35616303 2.13242025] , error: 0.4737442922376543\n",
      "Step: 7560 Weights: [0.35616303 2.13242025] , error: 0.4737442922376539\n",
      "Step: 7561 Weights: [0.35616303 2.13242025] , error: 0.47374429223765246\n",
      "Step: 7562 Weights: [0.35616304 2.13242025] , error: 0.4737442922376517\n",
      "Step: 7563 Weights: [0.35616304 2.13242024] , error: 0.4737442922376517\n",
      "Step: 7564 Weights: [0.35616304 2.13242024] , error: 0.4737442922376509\n",
      "Step: 7565 Weights: [0.35616305 2.13242024] , error: 0.4737442922376495\n",
      "Step: 7566 Weights: [0.35616305 2.13242024] , error: 0.4737442922376482\n",
      "Step: 7567 Weights: [0.35616305 2.13242024] , error: 0.47374429223764725\n",
      "Step: 7568 Weights: [0.35616306 2.13242024] , error: 0.47374429223764647\n",
      "Step: 7569 Weights: [0.35616306 2.13242024] , error: 0.47374429223764497\n",
      "Step: 7570 Weights: [0.35616306 2.13242024] , error: 0.47374429223764447\n",
      "Step: 7571 Weights: [0.35616307 2.13242024] , error: 0.47374429223764325\n",
      "Step: 7572 Weights: [0.35616307 2.13242024] , error: 0.47374429223764336\n",
      "Step: 7573 Weights: [0.35616307 2.13242024] , error: 0.4737442922376423\n",
      "Step: 7574 Weights: [0.35616307 2.13242024] , error: 0.4737442922376411\n",
      "Step: 7575 Weights: [0.35616308 2.13242024] , error: 0.4737442922376399\n",
      "Step: 7576 Weights: [0.35616308 2.13242024] , error: 0.47374429223763903\n",
      "Step: 7577 Weights: [0.35616308 2.13242024] , error: 0.47374429223763836\n",
      "Step: 7578 Weights: [0.35616309 2.13242024] , error: 0.4737442922376372\n",
      "Step: 7579 Weights: [0.35616309 2.13242024] , error: 0.4737442922376366\n",
      "Step: 7580 Weights: [0.35616309 2.13242024] , error: 0.47374429223763553\n",
      "Step: 7581 Weights: [0.3561631  2.13242024] , error: 0.47374429223763453\n",
      "Step: 7582 Weights: [0.3561631  2.13242024] , error: 0.47374429223763337\n",
      "Step: 7583 Weights: [0.3561631  2.13242024] , error: 0.4737442922376331\n",
      "Step: 7584 Weights: [0.3561631  2.13242024] , error: 0.4737442922376319\n",
      "Step: 7585 Weights: [0.35616311 2.13242024] , error: 0.47374429223763115\n",
      "Step: 7586 Weights: [0.35616311 2.13242024] , error: 0.4737442922376307\n",
      "Step: 7587 Weights: [0.35616311 2.13242024] , error: 0.4737442922376297\n",
      "Step: 7588 Weights: [0.35616312 2.13242024] , error: 0.4737442922376292\n",
      "Step: 7589 Weights: [0.35616312 2.13242024] , error: 0.47374429223762726\n",
      "Step: 7590 Weights: [0.35616312 2.13242024] , error: 0.47374429223762654\n",
      "Step: 7591 Weights: [0.35616312 2.13242024] , error: 0.47374429223762643\n",
      "Step: 7592 Weights: [0.35616313 2.13242024] , error: 0.4737442922376249\n",
      "Step: 7593 Weights: [0.35616313 2.13242023] , error: 0.4737442922376241\n",
      "Step: 7594 Weights: [0.35616313 2.13242023] , error: 0.47374429223762354\n",
      "Step: 7595 Weights: [0.35616314 2.13242023] , error: 0.4737442922376231\n",
      "Step: 7596 Weights: [0.35616314 2.13242023] , error: 0.4737442922376225\n",
      "Step: 7597 Weights: [0.35616314 2.13242023] , error: 0.4737442922376215\n",
      "Step: 7598 Weights: [0.35616314 2.13242023] , error: 0.47374429223762077\n",
      "Step: 7599 Weights: [0.35616315 2.13242023] , error: 0.4737442922376194\n",
      "Step: 7600 Weights: [0.35616315 2.13242023] , error: 0.47374429223761894\n",
      "Step: 7601 Weights: [0.35616315 2.13242023] , error: 0.47374429223761827\n",
      "Step: 7602 Weights: [0.35616316 2.13242023] , error: 0.473744292237617\n",
      "Step: 7603 Weights: [0.35616316 2.13242023] , error: 0.4737442922376164\n",
      "Step: 7604 Weights: [0.35616316 2.13242023] , error: 0.47374429223761577\n",
      "Step: 7605 Weights: [0.35616316 2.13242023] , error: 0.4737442922376148\n",
      "Step: 7606 Weights: [0.35616317 2.13242023] , error: 0.47374429223761416\n",
      "Step: 7607 Weights: [0.35616317 2.13242023] , error: 0.47374429223761316\n",
      "Step: 7608 Weights: [0.35616317 2.13242023] , error: 0.4737442922376127\n",
      "Step: 7609 Weights: [0.35616317 2.13242023] , error: 0.47374429223761155\n",
      "Step: 7610 Weights: [0.35616318 2.13242023] , error: 0.4737442922376104\n",
      "Step: 7611 Weights: [0.35616318 2.13242023] , error: 0.47374429223761\n",
      "Step: 7612 Weights: [0.35616318 2.13242023] , error: 0.4737442922376096\n",
      "Step: 7613 Weights: [0.35616319 2.13242023] , error: 0.4737442922376085\n",
      "Step: 7614 Weights: [0.35616319 2.13242023] , error: 0.47374429223760733\n",
      "Step: 7615 Weights: [0.35616319 2.13242023] , error: 0.47374429223760695\n",
      "Step: 7616 Weights: [0.35616319 2.13242023] , error: 0.47374429223760706\n",
      "Step: 7617 Weights: [0.3561632  2.13242023] , error: 0.4737442922376056\n",
      "Step: 7618 Weights: [0.3561632  2.13242023] , error: 0.4737442922376045\n",
      "Step: 7619 Weights: [0.3561632  2.13242023] , error: 0.47374429223760417\n",
      "Step: 7620 Weights: [0.3561632  2.13242023] , error: 0.4737442922376027\n",
      "Step: 7621 Weights: [0.35616321 2.13242023] , error: 0.4737442922376025\n",
      "Step: 7622 Weights: [0.35616321 2.13242023] , error: 0.47374429223760184\n",
      "Step: 7623 Weights: [0.35616321 2.13242023] , error: 0.473744292237601\n",
      "Step: 7624 Weights: [0.35616322 2.13242022] , error: 0.4737442922376007\n",
      "Step: 7625 Weights: [0.35616322 2.13242022] , error: 0.47374429223759995\n",
      "Step: 7626 Weights: [0.35616322 2.13242022] , error: 0.4737442922375998\n",
      "Step: 7627 Weights: [0.35616322 2.13242022] , error: 0.4737442922375983\n",
      "Step: 7628 Weights: [0.35616323 2.13242022] , error: 0.4737442922375978\n",
      "Step: 7629 Weights: [0.35616323 2.13242022] , error: 0.47374429223759723\n",
      "Step: 7630 Weights: [0.35616323 2.13242022] , error: 0.47374429223759595\n",
      "Step: 7631 Weights: [0.35616323 2.13242022] , error: 0.4737442922375957\n",
      "Step: 7632 Weights: [0.35616324 2.13242022] , error: 0.473744292237595\n",
      "Step: 7633 Weights: [0.35616324 2.13242022] , error: 0.47374429223759473\n",
      "Step: 7634 Weights: [0.35616324 2.13242022] , error: 0.47374429223759346\n",
      "Step: 7635 Weights: [0.35616324 2.13242022] , error: 0.47374429223759223\n",
      "Step: 7636 Weights: [0.35616325 2.13242022] , error: 0.47374429223759285\n",
      "Step: 7637 Weights: [0.35616325 2.13242022] , error: 0.47374429223759174\n",
      "Step: 7638 Weights: [0.35616325 2.13242022] , error: 0.4737442922375906\n",
      "Step: 7639 Weights: [0.35616325 2.13242022] , error: 0.47374429223758996\n",
      "Step: 7640 Weights: [0.35616326 2.13242022] , error: 0.4737442922375893\n",
      "Step: 7641 Weights: [0.35616326 2.13242022] , error: 0.4737442922375889\n",
      "Step: 7642 Weights: [0.35616326 2.13242022] , error: 0.47374429223758835\n",
      "Step: 7643 Weights: [0.35616327 2.13242022] , error: 0.4737442922375876\n",
      "Step: 7644 Weights: [0.35616327 2.13242022] , error: 0.47374429223758735\n",
      "Step: 7645 Weights: [0.35616327 2.13242022] , error: 0.47374429223758596\n",
      "Step: 7646 Weights: [0.35616327 2.13242022] , error: 0.47374429223758585\n",
      "Step: 7647 Weights: [0.35616328 2.13242022] , error: 0.4737442922375851\n",
      "Step: 7648 Weights: [0.35616328 2.13242022] , error: 0.47374429223758413\n",
      "Step: 7649 Weights: [0.35616328 2.13242022] , error: 0.4737442922375836\n",
      "Step: 7650 Weights: [0.35616328 2.13242022] , error: 0.47374429223758274\n",
      "Step: 7651 Weights: [0.35616329 2.13242022] , error: 0.4737442922375819\n",
      "Step: 7652 Weights: [0.35616329 2.13242022] , error: 0.47374429223758147\n",
      "Step: 7653 Weights: [0.35616329 2.13242022] , error: 0.4737442922375804\n",
      "Step: 7654 Weights: [0.35616329 2.13242022] , error: 0.4737442922375802\n",
      "Step: 7655 Weights: [0.3561633  2.13242022] , error: 0.47374429223757986\n",
      "Step: 7656 Weights: [0.3561633  2.13242022] , error: 0.4737442922375794\n",
      "Step: 7657 Weights: [0.3561633  2.13242022] , error: 0.4737442922375784\n",
      "Step: 7658 Weights: [0.3561633  2.13242021] , error: 0.47374429223757786\n",
      "Step: 7659 Weights: [0.35616331 2.13242021] , error: 0.47374429223757747\n",
      "Step: 7660 Weights: [0.35616331 2.13242021] , error: 0.4737442922375769\n",
      "Step: 7661 Weights: [0.35616331 2.13242021] , error: 0.47374429223757586\n",
      "Step: 7662 Weights: [0.35616331 2.13242021] , error: 0.47374429223757575\n",
      "Step: 7663 Weights: [0.35616332 2.13242021] , error: 0.47374429223757497\n",
      "Step: 7664 Weights: [0.35616332 2.13242021] , error: 0.47374429223757436\n",
      "Step: 7665 Weights: [0.35616332 2.13242021] , error: 0.47374429223757397\n",
      "Step: 7666 Weights: [0.35616332 2.13242021] , error: 0.4737442922375733\n",
      "Step: 7667 Weights: [0.35616332 2.13242021] , error: 0.4737442922375724\n",
      "Step: 7668 Weights: [0.35616333 2.13242021] , error: 0.4737442922375713\n",
      "Step: 7669 Weights: [0.35616333 2.13242021] , error: 0.4737442922375713\n",
      "Step: 7670 Weights: [0.35616333 2.13242021] , error: 0.47374429223757053\n",
      "Step: 7671 Weights: [0.35616333 2.13242021] , error: 0.47374429223756953\n",
      "Step: 7672 Weights: [0.35616334 2.13242021] , error: 0.47374429223756964\n",
      "Step: 7673 Weights: [0.35616334 2.13242021] , error: 0.47374429223756853\n",
      "Step: 7674 Weights: [0.35616334 2.13242021] , error: 0.4737442922375681\n",
      "Step: 7675 Weights: [0.35616334 2.13242021] , error: 0.4737442922375675\n",
      "Step: 7676 Weights: [0.35616335 2.13242021] , error: 0.4737442922375671\n",
      "Step: 7677 Weights: [0.35616335 2.13242021] , error: 0.4737442922375672\n",
      "Step: 7678 Weights: [0.35616335 2.13242021] , error: 0.4737442922375654\n",
      "Step: 7679 Weights: [0.35616335 2.13242021] , error: 0.4737442922375655\n",
      "Step: 7680 Weights: [0.35616336 2.13242021] , error: 0.4737442922375644\n",
      "Step: 7681 Weights: [0.35616336 2.13242021] , error: 0.47374429223756426\n",
      "Step: 7682 Weights: [0.35616336 2.13242021] , error: 0.47374429223756426\n",
      "Step: 7683 Weights: [0.35616336 2.13242021] , error: 0.4737442922375634\n",
      "Step: 7684 Weights: [0.35616337 2.13242021] , error: 0.47374429223756304\n",
      "Step: 7685 Weights: [0.35616337 2.13242021] , error: 0.47374429223756165\n",
      "Step: 7686 Weights: [0.35616337 2.13242021] , error: 0.47374429223756176\n",
      "Step: 7687 Weights: [0.35616337 2.13242021] , error: 0.4737442922375616\n",
      "Step: 7688 Weights: [0.35616337 2.13242021] , error: 0.4737442922375605\n",
      "Step: 7689 Weights: [0.35616338 2.13242021] , error: 0.47374429223756\n",
      "Step: 7690 Weights: [0.35616338 2.13242021] , error: 0.4737442922375602\n",
      "Step: 7691 Weights: [0.35616338 2.13242021] , error: 0.47374429223755954\n",
      "Step: 7692 Weights: [0.35616338 2.13242021] , error: 0.4737442922375582\n",
      "Step: 7693 Weights: [0.35616339 2.13242021] , error: 0.47374429223755765\n",
      "Step: 7694 Weights: [0.35616339 2.13242021] , error: 0.47374429223755743\n",
      "Step: 7695 Weights: [0.35616339 2.1324202 ] , error: 0.473744292237557\n",
      "Step: 7696 Weights: [0.35616339 2.1324202 ] , error: 0.4737442922375566\n",
      "Step: 7697 Weights: [0.35616339 2.1324202 ] , error: 0.4737442922375559\n",
      "Step: 7698 Weights: [0.3561634 2.1324202] , error: 0.4737442922375552\n",
      "Step: 7699 Weights: [0.3561634 2.1324202] , error: 0.47374429223755526\n",
      "Step: 7700 Weights: [0.3561634 2.1324202] , error: 0.47374429223755404\n",
      "Step: 7701 Weights: [0.3561634 2.1324202] , error: 0.4737442922375544\n",
      "Step: 7702 Weights: [0.35616341 2.1324202 ] , error: 0.47374429223755304\n",
      "Step: 7703 Weights: [0.35616341 2.1324202 ] , error: 0.47374429223755227\n",
      "Step: 7704 Weights: [0.35616341 2.1324202 ] , error: 0.4737442922375527\n",
      "Step: 7705 Weights: [0.35616341 2.1324202 ] , error: 0.4737442922375521\n",
      "Step: 7706 Weights: [0.35616341 2.1324202 ] , error: 0.4737442922375515\n",
      "Step: 7707 Weights: [0.35616342 2.1324202 ] , error: 0.47374429223755143\n",
      "Step: 7708 Weights: [0.35616342 2.1324202 ] , error: 0.4737442922375499\n",
      "Step: 7709 Weights: [0.35616342 2.1324202 ] , error: 0.47374429223754966\n",
      "Step: 7710 Weights: [0.35616342 2.1324202 ] , error: 0.4737442922375495\n",
      "Step: 7711 Weights: [0.35616343 2.1324202 ] , error: 0.4737442922375491\n",
      "Step: 7712 Weights: [0.35616343 2.1324202 ] , error: 0.4737442922375482\n",
      "Step: 7713 Weights: [0.35616343 2.1324202 ] , error: 0.473744292237548\n",
      "Step: 7714 Weights: [0.35616343 2.1324202 ] , error: 0.47374429223754755\n",
      "Step: 7715 Weights: [0.35616343 2.1324202 ] , error: 0.4737442922375469\n",
      "Step: 7716 Weights: [0.35616344 2.1324202 ] , error: 0.4737442922375466\n",
      "Step: 7717 Weights: [0.35616344 2.1324202 ] , error: 0.4737442922375454\n",
      "Step: 7718 Weights: [0.35616344 2.1324202 ] , error: 0.47374429223754566\n",
      "Step: 7719 Weights: [0.35616344 2.1324202 ] , error: 0.4737442922375452\n",
      "Step: 7720 Weights: [0.35616345 2.1324202 ] , error: 0.47374429223754433\n",
      "Step: 7721 Weights: [0.35616345 2.1324202 ] , error: 0.4737442922375453\n",
      "Step: 7722 Weights: [0.35616345 2.1324202 ] , error: 0.47374429223754383\n",
      "Step: 7723 Weights: [0.35616345 2.1324202 ] , error: 0.47374429223754266\n",
      "Step: 7724 Weights: [0.35616345 2.1324202 ] , error: 0.47374429223754333\n",
      "Step: 7725 Weights: [0.35616346 2.1324202 ] , error: 0.4737442922375419\n",
      "Step: 7726 Weights: [0.35616346 2.1324202 ] , error: 0.47374429223754183\n",
      "Step: 7727 Weights: [0.35616346 2.1324202 ] , error: 0.4737442922375411\n",
      "Step: 7728 Weights: [0.35616346 2.1324202 ] , error: 0.4737442922375405\n",
      "Step: 7729 Weights: [0.35616346 2.1324202 ] , error: 0.47374429223754067\n",
      "Step: 7730 Weights: [0.35616347 2.1324202 ] , error: 0.4737442922375401\n",
      "Step: 7731 Weights: [0.35616347 2.1324202 ] , error: 0.4737442922375394\n",
      "Step: 7732 Weights: [0.35616347 2.1324202 ] , error: 0.47374429223753944\n",
      "Step: 7733 Weights: [0.35616347 2.1324202 ] , error: 0.47374429223753817\n",
      "Step: 7734 Weights: [0.35616347 2.1324202 ] , error: 0.4737442922375381\n",
      "Step: 7735 Weights: [0.35616348 2.1324202 ] , error: 0.47374429223753817\n",
      "Step: 7736 Weights: [0.35616348 2.13242019] , error: 0.47374429223753733\n",
      "Step: 7737 Weights: [0.35616348 2.13242019] , error: 0.47374429223753667\n",
      "Step: 7738 Weights: [0.35616348 2.13242019] , error: 0.4737442922375366\n",
      "Step: 7739 Weights: [0.35616349 2.13242019] , error: 0.47374429223753645\n",
      "Step: 7740 Weights: [0.35616349 2.13242019] , error: 0.4737442922375354\n",
      "Step: 7741 Weights: [0.35616349 2.13242019] , error: 0.47374429223753517\n",
      "Step: 7742 Weights: [0.35616349 2.13242019] , error: 0.4737442922375351\n",
      "Step: 7743 Weights: [0.35616349 2.13242019] , error: 0.4737442922375342\n",
      "Step: 7744 Weights: [0.3561635  2.13242019] , error: 0.4737442922375341\n",
      "Step: 7745 Weights: [0.3561635  2.13242019] , error: 0.4737442922375338\n",
      "Step: 7746 Weights: [0.3561635  2.13242019] , error: 0.4737442922375338\n",
      "Step: 7747 Weights: [0.3561635  2.13242019] , error: 0.47374429223753295\n",
      "Step: 7748 Weights: [0.3561635  2.13242019] , error: 0.47374429223753195\n",
      "Step: 7749 Weights: [0.35616351 2.13242019] , error: 0.4737442922375317\n",
      "Step: 7750 Weights: [0.35616351 2.13242019] , error: 0.4737442922375311\n",
      "Step: 7751 Weights: [0.35616351 2.13242019] , error: 0.47374429223753156\n",
      "Step: 7752 Weights: [0.35616351 2.13242019] , error: 0.47374429223753023\n",
      "Step: 7753 Weights: [0.35616351 2.13242019] , error: 0.47374429223753095\n",
      "Step: 7754 Weights: [0.35616352 2.13242019] , error: 0.47374429223753\n",
      "Step: 7755 Weights: [0.35616352 2.13242019] , error: 0.47374429223752973\n",
      "Step: 7756 Weights: [0.35616352 2.13242019] , error: 0.47374429223752956\n",
      "Step: 7757 Weights: [0.35616352 2.13242019] , error: 0.4737442922375287\n",
      "Step: 7758 Weights: [0.35616352 2.13242019] , error: 0.4737442922375281\n",
      "Step: 7759 Weights: [0.35616353 2.13242019] , error: 0.47374429223752834\n",
      "Step: 7760 Weights: [0.35616353 2.13242019] , error: 0.4737442922375282\n",
      "Step: 7761 Weights: [0.35616353 2.13242019] , error: 0.4737442922375267\n",
      "Step: 7762 Weights: [0.35616353 2.13242019] , error: 0.47374429223752673\n",
      "Step: 7763 Weights: [0.35616353 2.13242019] , error: 0.473744292237527\n",
      "Step: 7764 Weights: [0.35616354 2.13242019] , error: 0.4737442922375258\n",
      "Step: 7765 Weights: [0.35616354 2.13242019] , error: 0.47374429223752623\n",
      "Step: 7766 Weights: [0.35616354 2.13242019] , error: 0.47374429223752546\n",
      "Step: 7767 Weights: [0.35616354 2.13242019] , error: 0.473744292237525\n",
      "Step: 7768 Weights: [0.35616354 2.13242019] , error: 0.4737442922375249\n",
      "Step: 7769 Weights: [0.35616354 2.13242019] , error: 0.4737442922375245\n",
      "Step: 7770 Weights: [0.35616355 2.13242019] , error: 0.4737442922375241\n",
      "Step: 7771 Weights: [0.35616355 2.13242019] , error: 0.4737442922375239\n",
      "Step: 7772 Weights: [0.35616355 2.13242019] , error: 0.4737442922375228\n",
      "Step: 7773 Weights: [0.35616355 2.13242019] , error: 0.4737442922375224\n",
      "Step: 7774 Weights: [0.35616355 2.13242019] , error: 0.47374429223752207\n",
      "Step: 7775 Weights: [0.35616356 2.13242019] , error: 0.47374429223752174\n",
      "Step: 7776 Weights: [0.35616356 2.13242019] , error: 0.4737442922375215\n",
      "Step: 7777 Weights: [0.35616356 2.13242019] , error: 0.47374429223752146\n",
      "Step: 7778 Weights: [0.35616356 2.13242019] , error: 0.4737442922375207\n",
      "Step: 7779 Weights: [0.35616356 2.13242019] , error: 0.4737442922375203\n",
      "Step: 7780 Weights: [0.35616357 2.13242018] , error: 0.47374429223752024\n",
      "Step: 7781 Weights: [0.35616357 2.13242018] , error: 0.47374429223751957\n",
      "Step: 7782 Weights: [0.35616357 2.13242018] , error: 0.4737442922375195\n",
      "Step: 7783 Weights: [0.35616357 2.13242018] , error: 0.47374429223751957\n",
      "Step: 7784 Weights: [0.35616357 2.13242018] , error: 0.4737442922375184\n",
      "Step: 7785 Weights: [0.35616357 2.13242018] , error: 0.47374429223751835\n",
      "Step: 7786 Weights: [0.35616358 2.13242018] , error: 0.4737442922375181\n",
      "Step: 7787 Weights: [0.35616358 2.13242018] , error: 0.4737442922375183\n",
      "Step: 7788 Weights: [0.35616358 2.13242018] , error: 0.4737442922375176\n",
      "Step: 7789 Weights: [0.35616358 2.13242018] , error: 0.47374429223751713\n",
      "Step: 7790 Weights: [0.35616358 2.13242018] , error: 0.4737442922375168\n",
      "Step: 7791 Weights: [0.35616359 2.13242018] , error: 0.47374429223751585\n",
      "Step: 7792 Weights: [0.35616359 2.13242018] , error: 0.4737442922375165\n",
      "Step: 7793 Weights: [0.35616359 2.13242018] , error: 0.47374429223751524\n",
      "Step: 7794 Weights: [0.35616359 2.13242018] , error: 0.47374429223751513\n",
      "Step: 7795 Weights: [0.35616359 2.13242018] , error: 0.47374429223751485\n",
      "Step: 7796 Weights: [0.35616359 2.13242018] , error: 0.473744292237515\n",
      "Step: 7797 Weights: [0.3561636  2.13242018] , error: 0.4737442922375138\n",
      "Step: 7798 Weights: [0.3561636  2.13242018] , error: 0.47374429223751424\n",
      "Step: 7799 Weights: [0.3561636  2.13242018] , error: 0.47374429223751374\n",
      "Step: 7800 Weights: [0.3561636  2.13242018] , error: 0.47374429223751363\n",
      "Step: 7801 Weights: [0.3561636  2.13242018] , error: 0.473744292237513\n",
      "Step: 7802 Weights: [0.35616361 2.13242018] , error: 0.47374429223751297\n",
      "Step: 7803 Weights: [0.35616361 2.13242018] , error: 0.4737442922375128\n",
      "Step: 7804 Weights: [0.35616361 2.13242018] , error: 0.4737442922375121\n",
      "Step: 7805 Weights: [0.35616361 2.13242018] , error: 0.4737442922375119\n",
      "Step: 7806 Weights: [0.35616361 2.13242018] , error: 0.47374429223751147\n",
      "Step: 7807 Weights: [0.35616361 2.13242018] , error: 0.47374429223751113\n",
      "Step: 7808 Weights: [0.35616362 2.13242018] , error: 0.4737442922375105\n",
      "Step: 7809 Weights: [0.35616362 2.13242018] , error: 0.47374429223751036\n",
      "Step: 7810 Weights: [0.35616362 2.13242018] , error: 0.47374429223751013\n",
      "Step: 7811 Weights: [0.35616362 2.13242018] , error: 0.4737442922375102\n",
      "Step: 7812 Weights: [0.35616362 2.13242018] , error: 0.473744292237509\n",
      "Step: 7813 Weights: [0.35616362 2.13242018] , error: 0.47374429223751\n",
      "Step: 7814 Weights: [0.35616363 2.13242018] , error: 0.47374429223750936\n",
      "Step: 7815 Weights: [0.35616363 2.13242018] , error: 0.47374429223750913\n",
      "Step: 7816 Weights: [0.35616363 2.13242018] , error: 0.47374429223750797\n",
      "Step: 7817 Weights: [0.35616363 2.13242018] , error: 0.4737442922375088\n",
      "Step: 7818 Weights: [0.35616363 2.13242018] , error: 0.47374429223750747\n",
      "Step: 7819 Weights: [0.35616364 2.13242018] , error: 0.473744292237508\n",
      "Step: 7820 Weights: [0.35616364 2.13242018] , error: 0.4737442922375069\n",
      "Step: 7821 Weights: [0.35616364 2.13242018] , error: 0.47374429223750647\n",
      "Step: 7822 Weights: [0.35616364 2.13242018] , error: 0.4737442922375066\n",
      "Step: 7823 Weights: [0.35616364 2.13242018] , error: 0.47374429223750675\n",
      "Step: 7824 Weights: [0.35616364 2.13242018] , error: 0.4737442922375062\n",
      "Step: 7825 Weights: [0.35616365 2.13242018] , error: 0.4737442922375057\n",
      "Step: 7826 Weights: [0.35616365 2.13242018] , error: 0.4737442922375059\n",
      "Step: 7827 Weights: [0.35616365 2.13242018] , error: 0.4737442922375053\n",
      "Step: 7828 Weights: [0.35616365 2.13242018] , error: 0.473744292237505\n",
      "Step: 7829 Weights: [0.35616365 2.13242017] , error: 0.4737442922375042\n",
      "Step: 7830 Weights: [0.35616365 2.13242017] , error: 0.4737442922375049\n",
      "Step: 7831 Weights: [0.35616366 2.13242017] , error: 0.4737442922375036\n",
      "Step: 7832 Weights: [0.35616366 2.13242017] , error: 0.4737442922375039\n",
      "Step: 7833 Weights: [0.35616366 2.13242017] , error: 0.47374429223750336\n",
      "Step: 7834 Weights: [0.35616366 2.13242017] , error: 0.47374429223750275\n",
      "Step: 7835 Weights: [0.35616366 2.13242017] , error: 0.4737442922375035\n",
      "Step: 7836 Weights: [0.35616366 2.13242017] , error: 0.47374429223750353\n",
      "Step: 7837 Weights: [0.35616367 2.13242017] , error: 0.47374429223750253\n",
      "Step: 7838 Weights: [0.35616367 2.13242017] , error: 0.473744292237502\n",
      "Step: 7839 Weights: [0.35616367 2.13242017] , error: 0.47374429223750153\n",
      "Step: 7840 Weights: [0.35616367 2.13242017] , error: 0.47374429223750225\n",
      "Step: 7841 Weights: [0.35616367 2.13242017] , error: 0.473744292237502\n",
      "Step: 7842 Weights: [0.35616367 2.13242017] , error: 0.47374429223750114\n",
      "Step: 7843 Weights: [0.35616368 2.13242017] , error: 0.47374429223750075\n",
      "Step: 7844 Weights: [0.35616368 2.13242017] , error: 0.47374429223750036\n",
      "Step: 7845 Weights: [0.35616368 2.13242017] , error: 0.4737442922375002\n",
      "Step: 7846 Weights: [0.35616368 2.13242017] , error: 0.4737442922374998\n",
      "Step: 7847 Weights: [0.35616368 2.13242017] , error: 0.47374429223750025\n",
      "Step: 7848 Weights: [0.35616368 2.13242017] , error: 0.47374429223749887\n",
      "Step: 7849 Weights: [0.35616368 2.13242017] , error: 0.47374429223749964\n",
      "Step: 7850 Weights: [0.35616369 2.13242017] , error: 0.4737442922374991\n",
      "Step: 7851 Weights: [0.35616369 2.13242017] , error: 0.4737442922374987\n",
      "Step: 7852 Weights: [0.35616369 2.13242017] , error: 0.473744292237499\n",
      "Step: 7853 Weights: [0.35616369 2.13242017] , error: 0.47374429223749814\n",
      "Step: 7854 Weights: [0.35616369 2.13242017] , error: 0.4737442922374978\n",
      "Step: 7855 Weights: [0.35616369 2.13242017] , error: 0.47374429223749764\n",
      "Step: 7856 Weights: [0.3561637  2.13242017] , error: 0.4737442922374978\n",
      "Step: 7857 Weights: [0.3561637  2.13242017] , error: 0.47374429223749676\n",
      "Step: 7858 Weights: [0.3561637  2.13242017] , error: 0.4737442922374967\n",
      "Step: 7859 Weights: [0.3561637  2.13242017] , error: 0.47374429223749703\n",
      "Step: 7860 Weights: [0.3561637  2.13242017] , error: 0.47374429223749687\n",
      "Step: 7861 Weights: [0.3561637  2.13242017] , error: 0.4737442922374965\n",
      "Step: 7862 Weights: [0.35616371 2.13242017] , error: 0.47374429223749537\n",
      "Step: 7863 Weights: [0.35616371 2.13242017] , error: 0.47374429223749615\n",
      "Step: 7864 Weights: [0.35616371 2.13242017] , error: 0.4737442922374958\n",
      "Step: 7865 Weights: [0.35616371 2.13242017] , error: 0.4737442922374952\n",
      "Step: 7866 Weights: [0.35616371 2.13242017] , error: 0.47374429223749537\n",
      "Step: 7867 Weights: [0.35616371 2.13242017] , error: 0.47374429223749426\n",
      "Step: 7868 Weights: [0.35616371 2.13242017] , error: 0.4737442922374949\n",
      "Step: 7869 Weights: [0.35616372 2.13242017] , error: 0.4737442922374944\n",
      "Step: 7870 Weights: [0.35616372 2.13242017] , error: 0.47374429223749476\n",
      "Step: 7871 Weights: [0.35616372 2.13242017] , error: 0.4737442922374945\n",
      "Step: 7872 Weights: [0.35616372 2.13242017] , error: 0.47374429223749426\n",
      "Step: 7873 Weights: [0.35616372 2.13242017] , error: 0.47374429223749376\n",
      "Step: 7874 Weights: [0.35616372 2.13242017] , error: 0.47374429223749326\n",
      "Step: 7875 Weights: [0.35616372 2.13242017] , error: 0.47374429223749304\n",
      "Step: 7876 Weights: [0.35616373 2.13242017] , error: 0.47374429223749276\n",
      "Step: 7877 Weights: [0.35616373 2.13242017] , error: 0.473744292237493\n",
      "Step: 7878 Weights: [0.35616373 2.13242017] , error: 0.47374429223749237\n",
      "Step: 7879 Weights: [0.35616373 2.13242017] , error: 0.47374429223749204\n",
      "Step: 7880 Weights: [0.35616373 2.13242017] , error: 0.47374429223749176\n",
      "Step: 7881 Weights: [0.35616373 2.13242017] , error: 0.47374429223749115\n",
      "Step: 7882 Weights: [0.35616374 2.13242017] , error: 0.4737442922374917\n",
      "Step: 7883 Weights: [0.35616374 2.13242017] , error: 0.47374429223749126\n",
      "Step: 7884 Weights: [0.35616374 2.13242017] , error: 0.4737442922374907\n",
      "Step: 7885 Weights: [0.35616374 2.13242016] , error: 0.47374429223749137\n",
      "Step: 7886 Weights: [0.35616374 2.13242016] , error: 0.47374429223749026\n",
      "Step: 7887 Weights: [0.35616374 2.13242016] , error: 0.4737442922374906\n",
      "Step: 7888 Weights: [0.35616374 2.13242016] , error: 0.4737442922374901\n",
      "Step: 7889 Weights: [0.35616375 2.13242016] , error: 0.4737442922374901\n",
      "Step: 7890 Weights: [0.35616375 2.13242016] , error: 0.47374429223748954\n",
      "Step: 7891 Weights: [0.35616375 2.13242016] , error: 0.4737442922374894\n",
      "Step: 7892 Weights: [0.35616375 2.13242016] , error: 0.47374429223748926\n",
      "Step: 7893 Weights: [0.35616375 2.13242016] , error: 0.47374429223748865\n",
      "Step: 7894 Weights: [0.35616375 2.13242016] , error: 0.4737442922374886\n",
      "Step: 7895 Weights: [0.35616375 2.13242016] , error: 0.4737442922374882\n",
      "Step: 7896 Weights: [0.35616376 2.13242016] , error: 0.473744292237489\n",
      "Step: 7897 Weights: [0.35616376 2.13242016] , error: 0.4737442922374881\n",
      "Step: 7898 Weights: [0.35616376 2.13242016] , error: 0.4737442922374879\n",
      "Step: 7899 Weights: [0.35616376 2.13242016] , error: 0.47374429223748754\n",
      "Step: 7900 Weights: [0.35616376 2.13242016] , error: 0.47374429223748793\n",
      "Step: 7901 Weights: [0.35616376 2.13242016] , error: 0.473744292237487\n",
      "Step: 7902 Weights: [0.35616376 2.13242016] , error: 0.4737442922374874\n",
      "Step: 7903 Weights: [0.35616377 2.13242016] , error: 0.47374429223748693\n",
      "Step: 7904 Weights: [0.35616377 2.13242016] , error: 0.4737442922374874\n",
      "Step: 7905 Weights: [0.35616377 2.13242016] , error: 0.47374429223748715\n",
      "Step: 7906 Weights: [0.35616377 2.13242016] , error: 0.47374429223748604\n",
      "Step: 7907 Weights: [0.35616377 2.13242016] , error: 0.4737442922374861\n",
      "Step: 7908 Weights: [0.35616377 2.13242016] , error: 0.47374429223748576\n",
      "Step: 7909 Weights: [0.35616377 2.13242016] , error: 0.47374429223748565\n",
      "Step: 7910 Weights: [0.35616378 2.13242016] , error: 0.4737442922374854\n",
      "Step: 7911 Weights: [0.35616378 2.13242016] , error: 0.47374429223748526\n",
      "Step: 7912 Weights: [0.35616378 2.13242016] , error: 0.473744292237485\n",
      "Step: 7913 Weights: [0.35616378 2.13242016] , error: 0.47374429223748465\n",
      "Step: 7914 Weights: [0.35616378 2.13242016] , error: 0.47374429223748515\n",
      "Step: 7915 Weights: [0.35616378 2.13242016] , error: 0.47374429223748493\n",
      "Step: 7916 Weights: [0.35616378 2.13242016] , error: 0.4737442922374834\n",
      "Step: 7917 Weights: [0.35616379 2.13242016] , error: 0.47374429223748415\n",
      "Step: 7918 Weights: [0.35616379 2.13242016] , error: 0.4737442922374841\n",
      "Step: 7919 Weights: [0.35616379 2.13242016] , error: 0.4737442922374846\n",
      "Step: 7920 Weights: [0.35616379 2.13242016] , error: 0.4737442922374833\n",
      "Step: 7921 Weights: [0.35616379 2.13242016] , error: 0.473744292237483\n",
      "Step: 7922 Weights: [0.35616379 2.13242016] , error: 0.4737442922374828\n",
      "Step: 7923 Weights: [0.35616379 2.13242016] , error: 0.4737442922374835\n",
      "Step: 7924 Weights: [0.35616379 2.13242016] , error: 0.47374429223748254\n",
      "Step: 7925 Weights: [0.3561638  2.13242016] , error: 0.47374429223748293\n",
      "Step: 7926 Weights: [0.3561638  2.13242016] , error: 0.4737442922374823\n",
      "Step: 7927 Weights: [0.3561638  2.13242016] , error: 0.47374429223748243\n",
      "Step: 7928 Weights: [0.3561638  2.13242016] , error: 0.47374429223748193\n",
      "Step: 7929 Weights: [0.3561638  2.13242016] , error: 0.4737442922374822\n",
      "Step: 7930 Weights: [0.3561638  2.13242016] , error: 0.4737442922374822\n",
      "Step: 7931 Weights: [0.3561638  2.13242016] , error: 0.47374429223748143\n",
      "Step: 7932 Weights: [0.35616381 2.13242016] , error: 0.4737442922374816\n",
      "Step: 7933 Weights: [0.35616381 2.13242016] , error: 0.4737442922374821\n",
      "Step: 7934 Weights: [0.35616381 2.13242016] , error: 0.4737442922374797\n",
      "Step: 7935 Weights: [0.35616381 2.13242016] , error: 0.47374429223748116\n",
      "Step: 7936 Weights: [0.35616381 2.13242016] , error: 0.4737442922374806\n",
      "Step: 7937 Weights: [0.35616381 2.13242016] , error: 0.47374429223748094\n",
      "Step: 7938 Weights: [0.35616381 2.13242016] , error: 0.4737442922374804\n",
      "Step: 7939 Weights: [0.35616381 2.13242016] , error: 0.4737442922374807\n",
      "Step: 7940 Weights: [0.35616382 2.13242016] , error: 0.47374429223748027\n",
      "Step: 7941 Weights: [0.35616382 2.13242016] , error: 0.4737442922374802\n",
      "Step: 7942 Weights: [0.35616382 2.13242016] , error: 0.4737442922374798\n",
      "Step: 7943 Weights: [0.35616382 2.13242016] , error: 0.47374429223747977\n",
      "Step: 7944 Weights: [0.35616382 2.13242016] , error: 0.4737442922374792\n",
      "Step: 7945 Weights: [0.35616382 2.13242016] , error: 0.47374429223747877\n",
      "Step: 7946 Weights: [0.35616382 2.13242016] , error: 0.47374429223747916\n",
      "Step: 7947 Weights: [0.35616382 2.13242016] , error: 0.4737442922374797\n",
      "Step: 7948 Weights: [0.35616383 2.13242016] , error: 0.473744292237479\n",
      "Step: 7949 Weights: [0.35616383 2.13242015] , error: 0.4737442922374787\n",
      "Step: 7950 Weights: [0.35616383 2.13242015] , error: 0.4737442922374785\n",
      "Step: 7951 Weights: [0.35616383 2.13242015] , error: 0.4737442922374783\n",
      "Step: 7952 Weights: [0.35616383 2.13242015] , error: 0.4737442922374785\n",
      "Step: 7953 Weights: [0.35616383 2.13242015] , error: 0.47374429223747816\n",
      "Step: 7954 Weights: [0.35616383 2.13242015] , error: 0.4737442922374778\n",
      "Step: 7955 Weights: [0.35616383 2.13242015] , error: 0.47374429223747794\n",
      "Step: 7956 Weights: [0.35616384 2.13242015] , error: 0.473744292237477\n",
      "Step: 7957 Weights: [0.35616384 2.13242015] , error: 0.4737442922374768\n",
      "Step: 7958 Weights: [0.35616384 2.13242015] , error: 0.4737442922374774\n",
      "Step: 7959 Weights: [0.35616384 2.13242015] , error: 0.47374429223747777\n",
      "Step: 7960 Weights: [0.35616384 2.13242015] , error: 0.47374429223747705\n",
      "Step: 7961 Weights: [0.35616384 2.13242015] , error: 0.4737442922374767\n",
      "Step: 7962 Weights: [0.35616384 2.13242015] , error: 0.47374429223747616\n",
      "Step: 7963 Weights: [0.35616384 2.13242015] , error: 0.4737442922374767\n",
      "Step: 7964 Weights: [0.35616385 2.13242015] , error: 0.4737442922374769\n",
      "Step: 7965 Weights: [0.35616385 2.13242015] , error: 0.47374429223747583\n",
      "Step: 7966 Weights: [0.35616385 2.13242015] , error: 0.4737442922374753\n",
      "Step: 7967 Weights: [0.35616385 2.13242015] , error: 0.4737442922374761\n",
      "Step: 7968 Weights: [0.35616385 2.13242015] , error: 0.4737442922374757\n",
      "Step: 7969 Weights: [0.35616385 2.13242015] , error: 0.47374429223747583\n",
      "Step: 7970 Weights: [0.35616385 2.13242015] , error: 0.4737442922374754\n",
      "Step: 7971 Weights: [0.35616385 2.13242015] , error: 0.4737442922374764\n",
      "Step: 7972 Weights: [0.35616386 2.13242015] , error: 0.47374429223747516\n",
      "Step: 7973 Weights: [0.35616386 2.13242015] , error: 0.4737442922374745\n",
      "Step: 7974 Weights: [0.35616386 2.13242015] , error: 0.47374429223747505\n",
      "Step: 7975 Weights: [0.35616386 2.13242015] , error: 0.47374429223747405\n",
      "Step: 7976 Weights: [0.35616386 2.13242015] , error: 0.47374429223747483\n",
      "Step: 7977 Weights: [0.35616386 2.13242015] , error: 0.4737442922374745\n",
      "Step: 7978 Weights: [0.35616386 2.13242015] , error: 0.47374429223747455\n",
      "Step: 7979 Weights: [0.35616386 2.13242015] , error: 0.4737442922374744\n",
      "Step: 7980 Weights: [0.35616387 2.13242015] , error: 0.47374429223747433\n",
      "Step: 7981 Weights: [0.35616387 2.13242015] , error: 0.4737442922374745\n",
      "Step: 7982 Weights: [0.35616387 2.13242015] , error: 0.4737442922374734\n",
      "Step: 7983 Weights: [0.35616387 2.13242015] , error: 0.4737442922374743\n",
      "Step: 7984 Weights: [0.35616387 2.13242015] , error: 0.47374429223747366\n",
      "Step: 7985 Weights: [0.35616387 2.13242015] , error: 0.4737442922374734\n",
      "Step: 7986 Weights: [0.35616387 2.13242015] , error: 0.4737442922374733\n",
      "Step: 7987 Weights: [0.35616387 2.13242015] , error: 0.4737442922374733\n",
      "Step: 7988 Weights: [0.35616387 2.13242015] , error: 0.47374429223747394\n",
      "Step: 7989 Weights: [0.35616388 2.13242015] , error: 0.47374429223747316\n",
      "Step: 7990 Weights: [0.35616388 2.13242015] , error: 0.4737442922374724\n",
      "Step: 7991 Weights: [0.35616388 2.13242015] , error: 0.4737442922374709\n",
      "Step: 7992 Weights: [0.35616388 2.13242015] , error: 0.4737442922374721\n",
      "Step: 7993 Weights: [0.35616388 2.13242015] , error: 0.4737442922374725\n",
      "Step: 7994 Weights: [0.35616388 2.13242015] , error: 0.47374429223747244\n",
      "Step: 7995 Weights: [0.35616388 2.13242015] , error: 0.4737442922374725\n",
      "Step: 7996 Weights: [0.35616388 2.13242015] , error: 0.4737442922374718\n",
      "Step: 7997 Weights: [0.35616389 2.13242015] , error: 0.4737442922374717\n",
      "Step: 7998 Weights: [0.35616389 2.13242015] , error: 0.47374429223747194\n",
      "Step: 7999 Weights: [0.35616389 2.13242015] , error: 0.4737442922374716\n",
      "Step: 8000 Weights: [0.35616389 2.13242015] , error: 0.47374429223747105\n",
      "Step: 8001 Weights: [0.35616389 2.13242015] , error: 0.4737442922374711\n",
      "Step: 8002 Weights: [0.35616389 2.13242015] , error: 0.47374429223747083\n",
      "Step: 8003 Weights: [0.35616389 2.13242015] , error: 0.4737442922374707\n",
      "Step: 8004 Weights: [0.35616389 2.13242015] , error: 0.4737442922374708\n",
      "Step: 8005 Weights: [0.35616389 2.13242015] , error: 0.47374429223747005\n",
      "Step: 8006 Weights: [0.3561639  2.13242015] , error: 0.4737442922374707\n",
      "Step: 8007 Weights: [0.3561639  2.13242015] , error: 0.47374429223747017\n",
      "Step: 8008 Weights: [0.3561639  2.13242015] , error: 0.4737442922374703\n",
      "Step: 8009 Weights: [0.3561639  2.13242015] , error: 0.4737442922374704\n",
      "Step: 8010 Weights: [0.3561639  2.13242015] , error: 0.4737442922374697\n",
      "Step: 8011 Weights: [0.3561639  2.13242015] , error: 0.47374429223746983\n",
      "Step: 8012 Weights: [0.3561639  2.13242015] , error: 0.47374429223746983\n",
      "Step: 8013 Weights: [0.3561639  2.13242015] , error: 0.4737442922374699\n",
      "Step: 8014 Weights: [0.3561639  2.13242015] , error: 0.47374429223747\n",
      "Step: 8015 Weights: [0.35616391 2.13242015] , error: 0.4737442922374696\n",
      "Step: 8016 Weights: [0.35616391 2.13242015] , error: 0.47374429223746894\n",
      "Step: 8017 Weights: [0.35616391 2.13242015] , error: 0.4737442922374694\n",
      "Step: 8018 Weights: [0.35616391 2.13242015] , error: 0.473744292237469\n",
      "Step: 8019 Weights: [0.35616391 2.13242015] , error: 0.47374429223746856\n",
      "Step: 8020 Weights: [0.35616391 2.13242015] , error: 0.4737442922374685\n",
      "Step: 8021 Weights: [0.35616391 2.13242015] , error: 0.47374429223746806\n",
      "Step: 8022 Weights: [0.35616391 2.13242015] , error: 0.47374429223746817\n",
      "Step: 8023 Weights: [0.35616391 2.13242015] , error: 0.4737442922374683\n",
      "Step: 8024 Weights: [0.35616391 2.13242014] , error: 0.4737442922374677\n",
      "Step: 8025 Weights: [0.35616392 2.13242014] , error: 0.4737442922374677\n",
      "Step: 8026 Weights: [0.35616392 2.13242014] , error: 0.47374429223746795\n",
      "Step: 8027 Weights: [0.35616392 2.13242014] , error: 0.4737442922374686\n",
      "Step: 8028 Weights: [0.35616392 2.13242014] , error: 0.47374429223746767\n",
      "Step: 8029 Weights: [0.35616392 2.13242014] , error: 0.4737442922374683\n",
      "Step: 8030 Weights: [0.35616392 2.13242014] , error: 0.47374429223746806\n",
      "Step: 8031 Weights: [0.35616392 2.13242014] , error: 0.47374429223746783\n",
      "Step: 8032 Weights: [0.35616392 2.13242014] , error: 0.47374429223746767\n",
      "Step: 8033 Weights: [0.35616392 2.13242014] , error: 0.47374429223746717\n",
      "Step: 8034 Weights: [0.35616393 2.13242014] , error: 0.4737442922374667\n",
      "Step: 8035 Weights: [0.35616393 2.13242014] , error: 0.47374429223746717\n",
      "Step: 8036 Weights: [0.35616393 2.13242014] , error: 0.4737442922374668\n",
      "Step: 8037 Weights: [0.35616393 2.13242014] , error: 0.4737442922374665\n",
      "Step: 8038 Weights: [0.35616393 2.13242014] , error: 0.47374429223746656\n",
      "Step: 8039 Weights: [0.35616393 2.13242014] , error: 0.4737442922374666\n",
      "Step: 8040 Weights: [0.35616393 2.13242014] , error: 0.4737442922374664\n",
      "Step: 8041 Weights: [0.35616393 2.13242014] , error: 0.4737442922374662\n",
      "Step: 8042 Weights: [0.35616393 2.13242014] , error: 0.47374429223746645\n",
      "Step: 8043 Weights: [0.35616393 2.13242014] , error: 0.4737442922374658\n",
      "Step: 8044 Weights: [0.35616394 2.13242014] , error: 0.47374429223746584\n",
      "Step: 8045 Weights: [0.35616394 2.13242014] , error: 0.4737442922374662\n",
      "Step: 8046 Weights: [0.35616394 2.13242014] , error: 0.47374429223746617\n",
      "Step: 8047 Weights: [0.35616394 2.13242014] , error: 0.473744292237466\n",
      "Step: 8048 Weights: [0.35616394 2.13242014] , error: 0.47374429223746567\n",
      "Step: 8049 Weights: [0.35616394 2.13242014] , error: 0.47374429223746584\n",
      "Step: 8050 Weights: [0.35616394 2.13242014] , error: 0.4737442922374654\n",
      "Step: 8051 Weights: [0.35616394 2.13242014] , error: 0.4737442922374655\n",
      "Step: 8052 Weights: [0.35616394 2.13242014] , error: 0.47374429223746567\n",
      "Step: 8053 Weights: [0.35616394 2.13242014] , error: 0.47374429223746517\n",
      "Step: 8054 Weights: [0.35616395 2.13242014] , error: 0.47374429223746517\n",
      "Step: 8055 Weights: [0.35616395 2.13242014] , error: 0.4737442922374653\n",
      "Step: 8056 Weights: [0.35616395 2.13242014] , error: 0.47374429223746484\n",
      "Step: 8057 Weights: [0.35616395 2.13242014] , error: 0.47374429223746484\n",
      "Step: 8058 Weights: [0.35616395 2.13242014] , error: 0.4737442922374644\n",
      "Step: 8059 Weights: [0.35616395 2.13242014] , error: 0.4737442922374641\n",
      "Step: 8060 Weights: [0.35616395 2.13242014] , error: 0.4737442922374643\n",
      "Step: 8061 Weights: [0.35616395 2.13242014] , error: 0.4737442922374645\n",
      "Step: 8062 Weights: [0.35616395 2.13242014] , error: 0.47374429223746417\n",
      "Step: 8063 Weights: [0.35616395 2.13242014] , error: 0.47374429223746456\n",
      "Step: 8064 Weights: [0.35616396 2.13242014] , error: 0.47374429223746406\n",
      "Step: 8065 Weights: [0.35616396 2.13242014] , error: 0.47374429223746406\n",
      "Step: 8066 Weights: [0.35616396 2.13242014] , error: 0.4737442922374635\n",
      "Step: 8067 Weights: [0.35616396 2.13242014] , error: 0.47374429223746356\n",
      "Step: 8068 Weights: [0.35616396 2.13242014] , error: 0.47374429223746367\n",
      "Step: 8069 Weights: [0.35616396 2.13242014] , error: 0.47374429223746345\n",
      "Step: 8070 Weights: [0.35616396 2.13242014] , error: 0.47374429223746334\n",
      "Step: 8071 Weights: [0.35616396 2.13242014] , error: 0.47374429223746284\n",
      "Step: 8072 Weights: [0.35616396 2.13242014] , error: 0.47374429223746306\n",
      "Step: 8073 Weights: [0.35616396 2.13242014] , error: 0.4737442922374635\n",
      "Step: 8074 Weights: [0.35616397 2.13242014] , error: 0.4737442922374631\n",
      "Step: 8075 Weights: [0.35616397 2.13242014] , error: 0.4737442922374625\n",
      "Step: 8076 Weights: [0.35616397 2.13242014] , error: 0.4737442922374629\n",
      "Step: 8077 Weights: [0.35616397 2.13242014] , error: 0.473744292237463\n",
      "Step: 8078 Weights: [0.35616397 2.13242014] , error: 0.4737442922374626\n",
      "Step: 8079 Weights: [0.35616397 2.13242014] , error: 0.4737442922374625\n",
      "Step: 8080 Weights: [0.35616397 2.13242014] , error: 0.4737442922374623\n",
      "Step: 8081 Weights: [0.35616397 2.13242014] , error: 0.4737442922374627\n",
      "Step: 8082 Weights: [0.35616397 2.13242014] , error: 0.4737442922374621\n",
      "Step: 8083 Weights: [0.35616397 2.13242014] , error: 0.4737442922374622\n",
      "Step: 8084 Weights: [0.35616397 2.13242014] , error: 0.47374429223746234\n",
      "Step: 8085 Weights: [0.35616398 2.13242014] , error: 0.4737442922374623\n",
      "Step: 8086 Weights: [0.35616398 2.13242014] , error: 0.47374429223746234\n",
      "Step: 8087 Weights: [0.35616398 2.13242014] , error: 0.47374429223746195\n",
      "Step: 8088 Weights: [0.35616398 2.13242014] , error: 0.47374429223746184\n",
      "Step: 8089 Weights: [0.35616398 2.13242014] , error: 0.4737442922374612\n",
      "Step: 8090 Weights: [0.35616398 2.13242014] , error: 0.4737442922374614\n",
      "Step: 8091 Weights: [0.35616398 2.13242014] , error: 0.47374429223746173\n",
      "Step: 8092 Weights: [0.35616398 2.13242014] , error: 0.4737442922374618\n",
      "Step: 8093 Weights: [0.35616398 2.13242014] , error: 0.4737442922374617\n",
      "Step: 8094 Weights: [0.35616398 2.13242014] , error: 0.47374429223746184\n",
      "Step: 8095 Weights: [0.35616399 2.13242014] , error: 0.473744292237461\n",
      "Step: 8096 Weights: [0.35616399 2.13242014] , error: 0.47374429223746156\n",
      "Step: 8097 Weights: [0.35616399 2.13242014] , error: 0.4737442922374613\n",
      "Step: 8098 Weights: [0.35616399 2.13242014] , error: 0.47374429223746045\n",
      "Step: 8099 Weights: [0.35616399 2.13242014] , error: 0.47374429223746106\n",
      "Step: 8100 Weights: [0.35616399 2.13242014] , error: 0.4737442922374602\n",
      "Step: 8101 Weights: [0.35616399 2.13242014] , error: 0.47374429223746106\n",
      "Step: 8102 Weights: [0.35616399 2.13242014] , error: 0.47374429223746084\n",
      "Step: 8103 Weights: [0.35616399 2.13242014] , error: 0.47374429223746073\n",
      "Step: 8104 Weights: [0.35616399 2.13242014] , error: 0.4737442922374605\n",
      "Step: 8105 Weights: [0.35616399 2.13242014] , error: 0.47374429223746106\n",
      "Step: 8106 Weights: [0.35616399 2.13242014] , error: 0.4737442922374607\n",
      "Step: 8107 Weights: [0.356164   2.13242014] , error: 0.47374429223746\n",
      "Step: 8108 Weights: [0.356164   2.13242014] , error: 0.47374429223746006\n",
      "Step: 8109 Weights: [0.356164   2.13242014] , error: 0.4737442922374595\n",
      "Step: 8110 Weights: [0.356164   2.13242014] , error: 0.47374429223745995\n",
      "Step: 8111 Weights: [0.356164   2.13242014] , error: 0.47374429223746\n",
      "Step: 8112 Weights: [0.356164   2.13242014] , error: 0.47374429223746034\n",
      "Step: 8113 Weights: [0.356164   2.13242014] , error: 0.4737442922374601\n",
      "Step: 8114 Weights: [0.356164   2.13242013] , error: 0.4737442922374596\n",
      "Step: 8115 Weights: [0.356164   2.13242013] , error: 0.4737442922374603\n",
      "Step: 8116 Weights: [0.356164   2.13242013] , error: 0.47374429223746\n",
      "Step: 8117 Weights: [0.356164   2.13242013] , error: 0.47374429223745923\n",
      "Step: 8118 Weights: [0.35616401 2.13242013] , error: 0.47374429223745984\n",
      "Step: 8119 Weights: [0.35616401 2.13242013] , error: 0.47374429223745884\n",
      "Step: 8120 Weights: [0.35616401 2.13242013] , error: 0.4737442922374589\n",
      "Step: 8121 Weights: [0.35616401 2.13242013] , error: 0.4737442922374596\n",
      "Step: 8122 Weights: [0.35616401 2.13242013] , error: 0.4737442922374586\n",
      "Step: 8123 Weights: [0.35616401 2.13242013] , error: 0.47374429223745906\n",
      "Step: 8124 Weights: [0.35616401 2.13242013] , error: 0.47374429223745884\n",
      "Step: 8125 Weights: [0.35616401 2.13242013] , error: 0.4737442922374595\n",
      "Step: 8126 Weights: [0.35616401 2.13242013] , error: 0.4737442922374587\n",
      "Step: 8127 Weights: [0.35616401 2.13242013] , error: 0.4737442922374595\n",
      "Step: 8128 Weights: [0.35616401 2.13242013] , error: 0.4737442922374585\n",
      "Step: 8129 Weights: [0.35616401 2.13242013] , error: 0.47374429223745845\n",
      "Step: 8130 Weights: [0.35616402 2.13242013] , error: 0.47374429223745823\n",
      "Step: 8131 Weights: [0.35616402 2.13242013] , error: 0.47374429223745795\n",
      "Step: 8132 Weights: [0.35616402 2.13242013] , error: 0.4737442922374581\n",
      "Step: 8133 Weights: [0.35616402 2.13242013] , error: 0.4737442922374578\n",
      "Step: 8134 Weights: [0.35616402 2.13242013] , error: 0.47374429223745856\n",
      "Step: 8135 Weights: [0.35616402 2.13242013] , error: 0.47374429223745873\n",
      "Step: 8136 Weights: [0.35616402 2.13242013] , error: 0.4737442922374584\n",
      "Step: 8137 Weights: [0.35616402 2.13242013] , error: 0.47374429223745806\n",
      "Step: 8138 Weights: [0.35616402 2.13242013] , error: 0.4737442922374583\n",
      "Step: 8139 Weights: [0.35616402 2.13242013] , error: 0.4737442922374574\n",
      "Step: 8140 Weights: [0.35616402 2.13242013] , error: 0.4737442922374583\n",
      "Step: 8141 Weights: [0.35616402 2.13242013] , error: 0.47374429223745845\n",
      "Step: 8142 Weights: [0.35616403 2.13242013] , error: 0.4737442922374584\n",
      "Step: 8143 Weights: [0.35616403 2.13242013] , error: 0.47374429223745795\n",
      "Step: 8144 Weights: [0.35616403 2.13242013] , error: 0.47374429223745773\n",
      "Step: 8145 Weights: [0.35616403 2.13242013] , error: 0.47374429223745823\n",
      "Step: 8146 Weights: [0.35616403 2.13242013] , error: 0.4737442922374575\n",
      "Step: 8147 Weights: [0.35616403 2.13242013] , error: 0.47374429223745734\n",
      "Step: 8148 Weights: [0.35616403 2.13242013] , error: 0.4737442922374576\n",
      "Step: 8149 Weights: [0.35616403 2.13242013] , error: 0.4737442922374571\n",
      "Step: 8150 Weights: [0.35616403 2.13242013] , error: 0.47374429223745695\n",
      "Step: 8151 Weights: [0.35616403 2.13242013] , error: 0.47374429223745695\n",
      "Step: 8152 Weights: [0.35616403 2.13242013] , error: 0.4737442922374576\n",
      "Step: 8153 Weights: [0.35616403 2.13242013] , error: 0.47374429223745773\n",
      "Step: 8154 Weights: [0.35616404 2.13242013] , error: 0.4737442922374567\n",
      "Step: 8155 Weights: [0.35616404 2.13242013] , error: 0.4737442922374568\n",
      "Step: 8156 Weights: [0.35616404 2.13242013] , error: 0.47374429223745684\n",
      "Step: 8157 Weights: [0.35616404 2.13242013] , error: 0.473744292237457\n",
      "Step: 8158 Weights: [0.35616404 2.13242013] , error: 0.4737442922374564\n",
      "Step: 8159 Weights: [0.35616404 2.13242013] , error: 0.47374429223745673\n",
      "Step: 8160 Weights: [0.35616404 2.13242013] , error: 0.4737442922374564\n",
      "Step: 8161 Weights: [0.35616404 2.13242013] , error: 0.47374429223745707\n",
      "Step: 8162 Weights: [0.35616404 2.13242013] , error: 0.4737442922374563\n",
      "Step: 8163 Weights: [0.35616404 2.13242013] , error: 0.4737442922374567\n",
      "Step: 8164 Weights: [0.35616404 2.13242013] , error: 0.473744292237456\n",
      "Step: 8165 Weights: [0.35616404 2.13242013] , error: 0.473744292237456\n",
      "Step: 8166 Weights: [0.35616404 2.13242013] , error: 0.47374429223745584\n",
      "Step: 8167 Weights: [0.35616405 2.13242013] , error: 0.473744292237456\n",
      "Step: 8168 Weights: [0.35616405 2.13242013] , error: 0.47374429223745596\n",
      "Step: 8169 Weights: [0.35616405 2.13242013] , error: 0.47374429223745596\n",
      "Step: 8170 Weights: [0.35616405 2.13242013] , error: 0.4737442922374556\n",
      "Step: 8171 Weights: [0.35616405 2.13242013] , error: 0.47374429223745584\n",
      "Step: 8172 Weights: [0.35616405 2.13242013] , error: 0.4737442922374554\n",
      "Step: 8173 Weights: [0.35616405 2.13242013] , error: 0.4737442922374552\n",
      "Step: 8174 Weights: [0.35616405 2.13242013] , error: 0.47374429223745573\n",
      "Step: 8175 Weights: [0.35616405 2.13242013] , error: 0.47374429223745584\n",
      "Step: 8176 Weights: [0.35616405 2.13242013] , error: 0.47374429223745573\n",
      "Step: 8177 Weights: [0.35616405 2.13242013] , error: 0.4737442922374556\n",
      "Step: 8178 Weights: [0.35616405 2.13242013] , error: 0.47374429223745573\n",
      "Step: 8179 Weights: [0.35616405 2.13242013] , error: 0.4737442922374554\n",
      "Step: 8180 Weights: [0.35616406 2.13242013] , error: 0.4737442922374553\n",
      "Step: 8181 Weights: [0.35616406 2.13242013] , error: 0.47374429223745534\n",
      "Step: 8182 Weights: [0.35616406 2.13242013] , error: 0.4737442922374547\n",
      "Step: 8183 Weights: [0.35616406 2.13242013] , error: 0.4737442922374552\n",
      "Step: 8184 Weights: [0.35616406 2.13242013] , error: 0.4737442922374553\n",
      "Step: 8185 Weights: [0.35616406 2.13242013] , error: 0.4737442922374548\n",
      "Step: 8186 Weights: [0.35616406 2.13242013] , error: 0.47374429223745507\n",
      "Step: 8187 Weights: [0.35616406 2.13242013] , error: 0.4737442922374544\n",
      "Step: 8188 Weights: [0.35616406 2.13242013] , error: 0.47374429223745435\n",
      "Step: 8189 Weights: [0.35616406 2.13242013] , error: 0.4737442922374552\n",
      "Step: 8190 Weights: [0.35616406 2.13242013] , error: 0.47374429223745484\n",
      "Step: 8191 Weights: [0.35616406 2.13242013] , error: 0.473744292237455\n",
      "Step: 8192 Weights: [0.35616406 2.13242013] , error: 0.47374429223745457\n",
      "Step: 8193 Weights: [0.35616406 2.13242013] , error: 0.4737442922374548\n",
      "Step: 8194 Weights: [0.35616407 2.13242013] , error: 0.47374429223745473\n",
      "Step: 8195 Weights: [0.35616407 2.13242013] , error: 0.4737442922374544\n",
      "Step: 8196 Weights: [0.35616407 2.13242013] , error: 0.4737442922374545\n",
      "Step: 8197 Weights: [0.35616407 2.13242013] , error: 0.47374429223745385\n",
      "Step: 8198 Weights: [0.35616407 2.13242013] , error: 0.4737442922374541\n",
      "Step: 8199 Weights: [0.35616407 2.13242013] , error: 0.4737442922374539\n",
      "Step: 8200 Weights: [0.35616407 2.13242013] , error: 0.4737442922374535\n",
      "Step: 8201 Weights: [0.35616407 2.13242013] , error: 0.47374429223745373\n",
      "Step: 8202 Weights: [0.35616407 2.13242013] , error: 0.47374429223745435\n",
      "Step: 8203 Weights: [0.35616407 2.13242013] , error: 0.4737442922374534\n",
      "Step: 8204 Weights: [0.35616407 2.13242013] , error: 0.47374429223745407\n",
      "Step: 8205 Weights: [0.35616407 2.13242013] , error: 0.47374429223745335\n",
      "Step: 8206 Weights: [0.35616407 2.13242013] , error: 0.47374429223745457\n",
      "Step: 8207 Weights: [0.35616407 2.13242013] , error: 0.4737442922374537\n",
      "Step: 8208 Weights: [0.35616408 2.13242013] , error: 0.4737442922374536\n",
      "Step: 8209 Weights: [0.35616408 2.13242013] , error: 0.4737442922374541\n",
      "Step: 8210 Weights: [0.35616408 2.13242013] , error: 0.47374429223745407\n",
      "Step: 8211 Weights: [0.35616408 2.13242013] , error: 0.47374429223745357\n",
      "Step: 8212 Weights: [0.35616408 2.13242013] , error: 0.47374429223745307\n",
      "Step: 8213 Weights: [0.35616408 2.13242013] , error: 0.4737442922374533\n",
      "Step: 8214 Weights: [0.35616408 2.13242013] , error: 0.47374429223745335\n",
      "Step: 8215 Weights: [0.35616408 2.13242013] , error: 0.47374429223745324\n",
      "Step: 8216 Weights: [0.35616408 2.13242013] , error: 0.47374429223745346\n",
      "Step: 8217 Weights: [0.35616408 2.13242013] , error: 0.47374429223745373\n",
      "Step: 8218 Weights: [0.35616408 2.13242013] , error: 0.47374429223745396\n",
      "Step: 8219 Weights: [0.35616408 2.13242013] , error: 0.4737442922374536\n",
      "Step: 8220 Weights: [0.35616408 2.13242013] , error: 0.4737442922374534\n",
      "Step: 8221 Weights: [0.35616408 2.13242013] , error: 0.4737442922374535\n",
      "Step: 8222 Weights: [0.35616409 2.13242013] , error: 0.4737442922374528\n",
      "Step: 8223 Weights: [0.35616409 2.13242013] , error: 0.47374429223745373\n",
      "Step: 8224 Weights: [0.35616409 2.13242013] , error: 0.47374429223745307\n",
      "Step: 8225 Weights: [0.35616409 2.13242013] , error: 0.47374429223745346\n",
      "Step: 8226 Weights: [0.35616409 2.13242013] , error: 0.4737442922374533\n",
      "Step: 8227 Weights: [0.35616409 2.13242013] , error: 0.4737442922374533\n",
      "Step: 8228 Weights: [0.35616409 2.13242012] , error: 0.47374429223745335\n",
      "Step: 8229 Weights: [0.35616409 2.13242012] , error: 0.4737442922374531\n",
      "Step: 8230 Weights: [0.35616409 2.13242012] , error: 0.4737442922374524\n",
      "Step: 8231 Weights: [0.35616409 2.13242012] , error: 0.47374429223745224\n",
      "Step: 8232 Weights: [0.35616409 2.13242012] , error: 0.4737442922374526\n",
      "Step: 8233 Weights: [0.35616409 2.13242012] , error: 0.4737442922374531\n",
      "Step: 8234 Weights: [0.35616409 2.13242012] , error: 0.47374429223745246\n",
      "Step: 8235 Weights: [0.35616409 2.13242012] , error: 0.4737442922374529\n",
      "Step: 8236 Weights: [0.35616409 2.13242012] , error: 0.4737442922374525\n",
      "Step: 8237 Weights: [0.3561641  2.13242012] , error: 0.4737442922374524\n",
      "Step: 8238 Weights: [0.3561641  2.13242012] , error: 0.47374429223745285\n",
      "Step: 8239 Weights: [0.3561641  2.13242012] , error: 0.4737442922374524\n",
      "Step: 8240 Weights: [0.3561641  2.13242012] , error: 0.47374429223745274\n",
      "Step: 8241 Weights: [0.3561641  2.13242012] , error: 0.47374429223745235\n",
      "Step: 8242 Weights: [0.3561641  2.13242012] , error: 0.47374429223745235\n",
      "Step: 8243 Weights: [0.3561641  2.13242012] , error: 0.47374429223745285\n",
      "Step: 8244 Weights: [0.3561641  2.13242012] , error: 0.4737442922374528\n",
      "Step: 8245 Weights: [0.3561641  2.13242012] , error: 0.4737442922374523\n",
      "Step: 8246 Weights: [0.3561641  2.13242012] , error: 0.47374429223745174\n",
      "Step: 8247 Weights: [0.3561641  2.13242012] , error: 0.4737442922374518\n",
      "Step: 8248 Weights: [0.3561641  2.13242012] , error: 0.473744292237452\n",
      "Step: 8249 Weights: [0.3561641  2.13242012] , error: 0.47374429223745157\n",
      "Step: 8250 Weights: [0.3561641  2.13242012] , error: 0.47374429223745185\n",
      "Step: 8251 Weights: [0.3561641  2.13242012] , error: 0.4737442922374523\n",
      "Step: 8252 Weights: [0.35616411 2.13242012] , error: 0.4737442922374513\n",
      "Step: 8253 Weights: [0.35616411 2.13242012] , error: 0.47374429223745174\n",
      "Step: 8254 Weights: [0.35616411 2.13242012] , error: 0.47374429223745196\n",
      "Step: 8255 Weights: [0.35616411 2.13242012] , error: 0.4737442922374515\n",
      "Step: 8256 Weights: [0.35616411 2.13242012] , error: 0.4737442922374515\n",
      "Step: 8257 Weights: [0.35616411 2.13242012] , error: 0.4737442922374524\n",
      "Step: 8258 Weights: [0.35616411 2.13242012] , error: 0.47374429223745146\n",
      "Step: 8259 Weights: [0.35616411 2.13242012] , error: 0.47374429223745157\n",
      "Step: 8260 Weights: [0.35616411 2.13242012] , error: 0.4737442922374521\n",
      "Step: 8261 Weights: [0.35616411 2.13242012] , error: 0.4737442922374516\n",
      "Step: 8262 Weights: [0.35616411 2.13242012] , error: 0.4737442922374515\n",
      "Step: 8263 Weights: [0.35616411 2.13242012] , error: 0.4737442922374516\n",
      "Step: 8264 Weights: [0.35616411 2.13242012] , error: 0.4737442922374515\n",
      "Step: 8265 Weights: [0.35616411 2.13242012] , error: 0.47374429223745085\n",
      "Step: 8266 Weights: [0.35616411 2.13242012] , error: 0.47374429223745146\n",
      "Step: 8267 Weights: [0.35616411 2.13242012] , error: 0.4737442922374512\n",
      "Step: 8268 Weights: [0.35616412 2.13242012] , error: 0.4737442922374516\n",
      "Step: 8269 Weights: [0.35616412 2.13242012] , error: 0.47374429223745107\n",
      "Step: 8270 Weights: [0.35616412 2.13242012] , error: 0.4737442922374515\n",
      "Step: 8271 Weights: [0.35616412 2.13242012] , error: 0.4737442922374511\n",
      "Step: 8272 Weights: [0.35616412 2.13242012] , error: 0.47374429223745107\n",
      "Step: 8273 Weights: [0.35616412 2.13242012] , error: 0.47374429223745135\n",
      "Step: 8274 Weights: [0.35616412 2.13242012] , error: 0.47374429223745107\n",
      "Step: 8275 Weights: [0.35616412 2.13242012] , error: 0.4737442922374504\n",
      "Step: 8276 Weights: [0.35616412 2.13242012] , error: 0.4737442922374514\n",
      "Step: 8277 Weights: [0.35616412 2.13242012] , error: 0.47374429223745107\n",
      "Step: 8278 Weights: [0.35616412 2.13242012] , error: 0.4737442922374506\n",
      "Step: 8279 Weights: [0.35616412 2.13242012] , error: 0.47374429223745124\n",
      "Step: 8280 Weights: [0.35616412 2.13242012] , error: 0.47374429223745135\n",
      "Step: 8281 Weights: [0.35616412 2.13242012] , error: 0.4737442922374508\n",
      "Step: 8282 Weights: [0.35616412 2.13242012] , error: 0.4737442922374506\n",
      "Step: 8283 Weights: [0.35616412 2.13242012] , error: 0.47374429223745057\n",
      "Step: 8284 Weights: [0.35616412 2.13242012] , error: 0.4737442922374507\n",
      "Step: 8285 Weights: [0.35616413 2.13242012] , error: 0.4737442922374509\n",
      "Step: 8286 Weights: [0.35616413 2.13242012] , error: 0.4737442922374513\n",
      "Step: 8287 Weights: [0.35616413 2.13242012] , error: 0.4737442922374501\n",
      "Step: 8288 Weights: [0.35616413 2.13242012] , error: 0.47374429223745024\n",
      "Step: 8289 Weights: [0.35616413 2.13242012] , error: 0.47374429223745074\n",
      "Step: 8290 Weights: [0.35616413 2.13242012] , error: 0.47374429223745057\n",
      "Step: 8291 Weights: [0.35616413 2.13242012] , error: 0.47374429223745074\n",
      "Step: 8292 Weights: [0.35616413 2.13242012] , error: 0.4737442922374502\n",
      "Step: 8293 Weights: [0.35616413 2.13242012] , error: 0.47374429223745035\n",
      "Step: 8294 Weights: [0.35616413 2.13242012] , error: 0.47374429223745007\n",
      "Step: 8295 Weights: [0.35616413 2.13242012] , error: 0.47374429223745057\n",
      "Step: 8296 Weights: [0.35616413 2.13242012] , error: 0.4737442922374504\n",
      "Step: 8297 Weights: [0.35616413 2.13242012] , error: 0.4737442922374505\n",
      "Step: 8298 Weights: [0.35616413 2.13242012] , error: 0.4737442922374506\n",
      "Step: 8299 Weights: [0.35616413 2.13242012] , error: 0.47374429223745\n",
      "Step: 8300 Weights: [0.35616413 2.13242012] , error: 0.47374429223744996\n",
      "Step: 8301 Weights: [0.35616413 2.13242012] , error: 0.47374429223745007\n",
      "Step: 8302 Weights: [0.35616414 2.13242012] , error: 0.4737442922374502\n",
      "Step: 8303 Weights: [0.35616414 2.13242012] , error: 0.47374429223744996\n",
      "Step: 8304 Weights: [0.35616414 2.13242012] , error: 0.4737442922374497\n",
      "Step: 8305 Weights: [0.35616414 2.13242012] , error: 0.47374429223745024\n",
      "Step: 8306 Weights: [0.35616414 2.13242012] , error: 0.4737442922374498\n",
      "Step: 8307 Weights: [0.35616414 2.13242012] , error: 0.47374429223744974\n",
      "Step: 8308 Weights: [0.35616414 2.13242012] , error: 0.4737442922374501\n",
      "Step: 8309 Weights: [0.35616414 2.13242012] , error: 0.4737442922374501\n",
      "Step: 8310 Weights: [0.35616414 2.13242012] , error: 0.4737442922374498\n",
      "Step: 8311 Weights: [0.35616414 2.13242012] , error: 0.4737442922374492\n",
      "Step: 8312 Weights: [0.35616414 2.13242012] , error: 0.4737442922374499\n",
      "Step: 8313 Weights: [0.35616414 2.13242012] , error: 0.4737442922374495\n",
      "Step: 8314 Weights: [0.35616414 2.13242012] , error: 0.4737442922374498\n",
      "Step: 8315 Weights: [0.35616414 2.13242012] , error: 0.47374429223745035\n",
      "Step: 8316 Weights: [0.35616414 2.13242012] , error: 0.4737442922374499\n",
      "Step: 8317 Weights: [0.35616414 2.13242012] , error: 0.47374429223745\n",
      "Step: 8318 Weights: [0.35616414 2.13242012] , error: 0.47374429223744924\n",
      "Step: 8319 Weights: [0.35616414 2.13242012] , error: 0.4737442922374494\n",
      "Step: 8320 Weights: [0.35616415 2.13242012] , error: 0.47374429223744935\n",
      "Step: 8321 Weights: [0.35616415 2.13242012] , error: 0.4737442922374494\n",
      "Step: 8322 Weights: [0.35616415 2.13242012] , error: 0.47374429223744957\n",
      "Step: 8323 Weights: [0.35616415 2.13242012] , error: 0.4737442922374495\n",
      "Step: 8324 Weights: [0.35616415 2.13242012] , error: 0.4737442922374493\n",
      "Step: 8325 Weights: [0.35616415 2.13242012] , error: 0.4737442922374496\n",
      "Step: 8326 Weights: [0.35616415 2.13242012] , error: 0.47374429223744874\n",
      "Step: 8327 Weights: [0.35616415 2.13242012] , error: 0.47374429223744924\n",
      "Step: 8328 Weights: [0.35616415 2.13242012] , error: 0.47374429223744907\n",
      "Step: 8329 Weights: [0.35616415 2.13242012] , error: 0.47374429223744885\n",
      "Step: 8330 Weights: [0.35616415 2.13242012] , error: 0.47374429223744763\n",
      "Step: 8331 Weights: [0.35616415 2.13242012] , error: 0.47374429223744935\n",
      "Step: 8332 Weights: [0.35616415 2.13242012] , error: 0.4737442922374494\n",
      "Step: 8333 Weights: [0.35616415 2.13242012] , error: 0.4737442922374494\n",
      "Step: 8334 Weights: [0.35616415 2.13242012] , error: 0.47374429223744935\n",
      "Step: 8335 Weights: [0.35616415 2.13242012] , error: 0.47374429223744907\n",
      "Step: 8336 Weights: [0.35616415 2.13242012] , error: 0.47374429223744885\n",
      "Step: 8337 Weights: [0.35616415 2.13242012] , error: 0.47374429223744874\n",
      "Step: 8338 Weights: [0.35616415 2.13242012] , error: 0.47374429223744907\n",
      "Step: 8339 Weights: [0.35616416 2.13242012] , error: 0.4737442922374492\n",
      "Step: 8340 Weights: [0.35616416 2.13242012] , error: 0.4737442922374488\n",
      "Step: 8341 Weights: [0.35616416 2.13242012] , error: 0.47374429223744874\n",
      "Step: 8342 Weights: [0.35616416 2.13242012] , error: 0.4737442922374494\n",
      "Step: 8343 Weights: [0.35616416 2.13242012] , error: 0.4737442922374494\n",
      "Step: 8344 Weights: [0.35616416 2.13242012] , error: 0.47374429223744896\n",
      "Step: 8345 Weights: [0.35616416 2.13242012] , error: 0.4737442922374484\n",
      "Step: 8346 Weights: [0.35616416 2.13242012] , error: 0.473744292237449\n",
      "Step: 8347 Weights: [0.35616416 2.13242012] , error: 0.47374429223744885\n",
      "Step: 8348 Weights: [0.35616416 2.13242012] , error: 0.4737442922374492\n",
      "Step: 8349 Weights: [0.35616416 2.13242012] , error: 0.4737442922374485\n",
      "Step: 8350 Weights: [0.35616416 2.13242012] , error: 0.4737442922374484\n",
      "Step: 8351 Weights: [0.35616416 2.13242012] , error: 0.47374429223744885\n",
      "Step: 8352 Weights: [0.35616416 2.13242012] , error: 0.4737442922374487\n",
      "Step: 8353 Weights: [0.35616416 2.13242012] , error: 0.4737442922374486\n",
      "Step: 8354 Weights: [0.35616416 2.13242012] , error: 0.4737442922374487\n",
      "Step: 8355 Weights: [0.35616416 2.13242012] , error: 0.47374429223744796\n",
      "Step: 8356 Weights: [0.35616416 2.13242012] , error: 0.473744292237449\n",
      "Step: 8357 Weights: [0.35616416 2.13242012] , error: 0.4737442922374488\n",
      "Step: 8358 Weights: [0.35616416 2.13242012] , error: 0.47374429223744896\n",
      "Step: 8359 Weights: [0.35616417 2.13242012] , error: 0.47374429223744896\n",
      "Step: 8360 Weights: [0.35616417 2.13242012] , error: 0.4737442922374485\n",
      "Step: 8361 Weights: [0.35616417 2.13242012] , error: 0.47374429223744796\n",
      "Step: 8362 Weights: [0.35616417 2.13242012] , error: 0.4737442922374485\n",
      "Step: 8363 Weights: [0.35616417 2.13242012] , error: 0.47374429223744774\n",
      "Step: 8364 Weights: [0.35616417 2.13242012] , error: 0.4737442922374483\n",
      "Step: 8365 Weights: [0.35616417 2.13242012] , error: 0.47374429223744774\n",
      "Step: 8366 Weights: [0.35616417 2.13242012] , error: 0.47374429223744785\n",
      "Step: 8367 Weights: [0.35616417 2.13242012] , error: 0.47374429223744796\n",
      "Step: 8368 Weights: [0.35616417 2.13242012] , error: 0.4737442922374479\n",
      "Step: 8369 Weights: [0.35616417 2.13242012] , error: 0.47374429223744857\n",
      "Step: 8370 Weights: [0.35616417 2.13242012] , error: 0.4737442922374484\n",
      "Step: 8371 Weights: [0.35616417 2.13242012] , error: 0.47374429223744785\n",
      "Step: 8372 Weights: [0.35616417 2.13242012] , error: 0.47374429223744785\n",
      "Step: 8373 Weights: [0.35616417 2.13242012] , error: 0.4737442922374487\n",
      "Step: 8374 Weights: [0.35616417 2.13242012] , error: 0.4737442922374481\n",
      "Step: 8375 Weights: [0.35616417 2.13242012] , error: 0.47374429223744835\n",
      "Step: 8376 Weights: [0.35616417 2.13242012] , error: 0.47374429223744813\n",
      "Step: 8377 Weights: [0.35616417 2.13242012] , error: 0.47374429223744785\n",
      "Step: 8378 Weights: [0.35616417 2.13242012] , error: 0.4737442922374482\n",
      "Step: 8379 Weights: [0.35616418 2.13242012] , error: 0.47374429223744835\n",
      "Step: 8380 Weights: [0.35616418 2.13242012] , error: 0.4737442922374474\n",
      "Step: 8381 Weights: [0.35616418 2.13242012] , error: 0.47374429223744857\n",
      "Step: 8382 Weights: [0.35616418 2.13242011] , error: 0.4737442922374482\n",
      "Step: 8383 Weights: [0.35616418 2.13242011] , error: 0.47374429223744713\n",
      "Step: 8384 Weights: [0.35616418 2.13242011] , error: 0.4737442922374481\n",
      "Step: 8385 Weights: [0.35616418 2.13242011] , error: 0.4737442922374478\n",
      "Step: 8386 Weights: [0.35616418 2.13242011] , error: 0.47374429223744824\n",
      "Step: 8387 Weights: [0.35616418 2.13242011] , error: 0.47374429223744774\n",
      "Step: 8388 Weights: [0.35616418 2.13242011] , error: 0.4737442922374482\n",
      "Step: 8389 Weights: [0.35616418 2.13242011] , error: 0.47374429223744785\n",
      "Step: 8390 Weights: [0.35616418 2.13242011] , error: 0.47374429223744813\n",
      "Step: 8391 Weights: [0.35616418 2.13242011] , error: 0.47374429223744735\n",
      "Step: 8392 Weights: [0.35616418 2.13242011] , error: 0.4737442922374482\n",
      "Step: 8393 Weights: [0.35616418 2.13242011] , error: 0.4737442922374479\n",
      "Step: 8394 Weights: [0.35616418 2.13242011] , error: 0.4737442922374474\n",
      "Step: 8395 Weights: [0.35616418 2.13242011] , error: 0.4737442922374476\n",
      "Step: 8396 Weights: [0.35616418 2.13242011] , error: 0.4737442922374475\n",
      "Step: 8397 Weights: [0.35616418 2.13242011] , error: 0.47374429223744685\n",
      "Step: 8398 Weights: [0.35616418 2.13242011] , error: 0.47374429223744796\n",
      "Step: 8399 Weights: [0.35616418 2.13242011] , error: 0.47374429223744735\n",
      "Step: 8400 Weights: [0.35616418 2.13242011] , error: 0.4737442922374475\n",
      "Step: 8401 Weights: [0.35616419 2.13242011] , error: 0.473744292237447\n",
      "Step: 8402 Weights: [0.35616419 2.13242011] , error: 0.47374429223744796\n",
      "Step: 8403 Weights: [0.35616419 2.13242011] , error: 0.47374429223744713\n",
      "Step: 8404 Weights: [0.35616419 2.13242011] , error: 0.4737442922374471\n",
      "Step: 8405 Weights: [0.35616419 2.13242011] , error: 0.47374429223744713\n",
      "Step: 8406 Weights: [0.35616419 2.13242011] , error: 0.473744292237447\n",
      "Step: 8407 Weights: [0.35616419 2.13242011] , error: 0.4737442922374471\n",
      "Step: 8408 Weights: [0.35616419 2.13242011] , error: 0.4737442922374471\n",
      "Step: 8409 Weights: [0.35616419 2.13242011] , error: 0.4737442922374471\n",
      "Step: 8410 Weights: [0.35616419 2.13242011] , error: 0.4737442922374475\n",
      "Step: 8411 Weights: [0.35616419 2.13242011] , error: 0.4737442922374472\n",
      "Step: 8412 Weights: [0.35616419 2.13242011] , error: 0.4737442922374471\n",
      "Step: 8413 Weights: [0.35616419 2.13242011] , error: 0.47374429223744735\n",
      "Step: 8414 Weights: [0.35616419 2.13242011] , error: 0.4737442922374475\n",
      "Step: 8415 Weights: [0.35616419 2.13242011] , error: 0.4737442922374472\n",
      "Step: 8416 Weights: [0.35616419 2.13242011] , error: 0.47374429223744746\n",
      "Step: 8417 Weights: [0.35616419 2.13242011] , error: 0.47374429223744774\n",
      "Step: 8418 Weights: [0.35616419 2.13242011] , error: 0.4737442922374474\n",
      "Step: 8419 Weights: [0.35616419 2.13242011] , error: 0.4737442922374478\n",
      "Step: 8420 Weights: [0.35616419 2.13242011] , error: 0.4737442922374475\n",
      "Step: 8421 Weights: [0.35616419 2.13242011] , error: 0.47374429223744685\n",
      "Step: 8422 Weights: [0.35616419 2.13242011] , error: 0.4737442922374465\n",
      "Step: 8423 Weights: [0.3561642  2.13242011] , error: 0.4737442922374474\n",
      "Step: 8424 Weights: [0.3561642  2.13242011] , error: 0.4737442922374469\n",
      "Step: 8425 Weights: [0.3561642  2.13242011] , error: 0.4737442922374464\n",
      "Step: 8426 Weights: [0.3561642  2.13242011] , error: 0.4737442922374472\n",
      "Step: 8427 Weights: [0.3561642  2.13242011] , error: 0.4737442922374475\n",
      "Step: 8428 Weights: [0.3561642  2.13242011] , error: 0.47374429223744713\n",
      "Step: 8429 Weights: [0.3561642  2.13242011] , error: 0.4737442922374473\n",
      "Step: 8430 Weights: [0.3561642  2.13242011] , error: 0.4737442922374472\n",
      "Step: 8431 Weights: [0.3561642  2.13242011] , error: 0.4737442922374463\n",
      "Step: 8432 Weights: [0.3561642  2.13242011] , error: 0.4737442922374473\n",
      "Step: 8433 Weights: [0.3561642  2.13242011] , error: 0.4737442922374466\n",
      "Step: 8434 Weights: [0.3561642  2.13242011] , error: 0.47374429223744713\n",
      "Step: 8435 Weights: [0.3561642  2.13242011] , error: 0.47374429223744663\n",
      "Step: 8436 Weights: [0.3561642  2.13242011] , error: 0.47374429223744696\n",
      "Step: 8437 Weights: [0.3561642  2.13242011] , error: 0.47374429223744685\n",
      "Step: 8438 Weights: [0.3561642  2.13242011] , error: 0.47374429223744663\n",
      "Step: 8439 Weights: [0.3561642  2.13242011] , error: 0.4737442922374469\n",
      "Step: 8440 Weights: [0.3561642  2.13242011] , error: 0.47374429223744696\n",
      "Step: 8441 Weights: [0.3561642  2.13242011] , error: 0.47374429223744713\n",
      "Step: 8442 Weights: [0.3561642  2.13242011] , error: 0.47374429223744663\n",
      "Step: 8443 Weights: [0.3561642  2.13242011] , error: 0.47374429223744685\n",
      "Step: 8444 Weights: [0.3561642  2.13242011] , error: 0.47374429223744735\n",
      "Step: 8445 Weights: [0.3561642  2.13242011] , error: 0.4737442922374469\n",
      "Step: 8446 Weights: [0.3561642  2.13242011] , error: 0.4737442922374469\n",
      "Step: 8447 Weights: [0.35616421 2.13242011] , error: 0.4737442922374459\n",
      "Step: 8448 Weights: [0.35616421 2.13242011] , error: 0.4737442922374462\n",
      "Step: 8449 Weights: [0.35616421 2.13242011] , error: 0.47374429223744624\n",
      "Step: 8450 Weights: [0.35616421 2.13242011] , error: 0.47374429223744685\n",
      "Step: 8451 Weights: [0.35616421 2.13242011] , error: 0.4737442922374468\n",
      "Step: 8452 Weights: [0.35616421 2.13242011] , error: 0.4737442922374468\n",
      "Step: 8453 Weights: [0.35616421 2.13242011] , error: 0.47374429223744663\n",
      "Step: 8454 Weights: [0.35616421 2.13242011] , error: 0.47374429223744674\n",
      "Step: 8455 Weights: [0.35616421 2.13242011] , error: 0.47374429223744646\n",
      "Step: 8456 Weights: [0.35616421 2.13242011] , error: 0.4737442922374459\n",
      "Step: 8457 Weights: [0.35616421 2.13242011] , error: 0.4737442922374463\n",
      "Step: 8458 Weights: [0.35616421 2.13242011] , error: 0.4737442922374465\n",
      "Step: 8459 Weights: [0.35616421 2.13242011] , error: 0.4737442922374461\n",
      "Step: 8460 Weights: [0.35616421 2.13242011] , error: 0.47374429223744485\n",
      "Step: 8461 Weights: [0.35616421 2.13242011] , error: 0.47374429223744624\n",
      "Step: 8462 Weights: [0.35616421 2.13242011] , error: 0.47374429223744663\n",
      "Step: 8463 Weights: [0.35616421 2.13242011] , error: 0.4737442922374463\n",
      "Step: 8464 Weights: [0.35616421 2.13242011] , error: 0.47374429223744624\n",
      "Step: 8465 Weights: [0.35616421 2.13242011] , error: 0.47374429223744674\n",
      "Step: 8466 Weights: [0.35616421 2.13242011] , error: 0.4737442922374464\n",
      "Step: 8467 Weights: [0.35616421 2.13242011] , error: 0.4737442922374463\n",
      "Step: 8468 Weights: [0.35616421 2.13242011] , error: 0.47374429223744635\n",
      "Step: 8469 Weights: [0.35616421 2.13242011] , error: 0.4737442922374455\n",
      "Step: 8470 Weights: [0.35616421 2.13242011] , error: 0.4737442922374461\n",
      "Step: 8471 Weights: [0.35616421 2.13242011] , error: 0.4737442922374469\n",
      "Step: 8472 Weights: [0.35616422 2.13242011] , error: 0.4737442922374464\n",
      "Step: 8473 Weights: [0.35616422 2.13242011] , error: 0.4737442922374462\n",
      "Step: 8474 Weights: [0.35616422 2.13242011] , error: 0.4737442922374465\n",
      "Step: 8475 Weights: [0.35616422 2.13242011] , error: 0.47374429223744646\n",
      "Step: 8476 Weights: [0.35616422 2.13242011] , error: 0.4737442922374463\n",
      "Step: 8477 Weights: [0.35616422 2.13242011] , error: 0.4737442922374464\n",
      "Step: 8478 Weights: [0.35616422 2.13242011] , error: 0.4737442922374467\n",
      "Step: 8479 Weights: [0.35616422 2.13242011] , error: 0.4737442922374467\n",
      "Step: 8480 Weights: [0.35616422 2.13242011] , error: 0.47374429223744563\n",
      "Step: 8481 Weights: [0.35616422 2.13242011] , error: 0.4737442922374461\n",
      "Step: 8482 Weights: [0.35616422 2.13242011] , error: 0.4737442922374458\n",
      "Step: 8483 Weights: [0.35616422 2.13242011] , error: 0.4737442922374462\n",
      "Step: 8484 Weights: [0.35616422 2.13242011] , error: 0.47374429223744674\n",
      "Step: 8485 Weights: [0.35616422 2.13242011] , error: 0.4737442922374459\n",
      "Step: 8486 Weights: [0.35616422 2.13242011] , error: 0.47374429223744646\n",
      "Step: 8487 Weights: [0.35616422 2.13242011] , error: 0.47374429223744596\n",
      "Step: 8488 Weights: [0.35616422 2.13242011] , error: 0.47374429223744624\n",
      "Step: 8489 Weights: [0.35616422 2.13242011] , error: 0.4737442922374465\n",
      "Step: 8490 Weights: [0.35616422 2.13242011] , error: 0.47374429223744596\n",
      "Step: 8491 Weights: [0.35616422 2.13242011] , error: 0.4737442922374462\n",
      "Step: 8492 Weights: [0.35616422 2.13242011] , error: 0.47374429223744546\n",
      "Step: 8493 Weights: [0.35616422 2.13242011] , error: 0.47374429223744563\n",
      "Step: 8494 Weights: [0.35616422 2.13242011] , error: 0.473744292237446\n",
      "Step: 8495 Weights: [0.35616422 2.13242011] , error: 0.47374429223744585\n",
      "Step: 8496 Weights: [0.35616422 2.13242011] , error: 0.47374429223744546\n",
      "Step: 8497 Weights: [0.35616422 2.13242011] , error: 0.4737442922374463\n",
      "Step: 8498 Weights: [0.35616422 2.13242011] , error: 0.4737442922374464\n",
      "Step: 8499 Weights: [0.35616423 2.13242011] , error: 0.47374429223744574\n",
      "Step: 8500 Weights: [0.35616423 2.13242011] , error: 0.47374429223744574\n",
      "Step: 8501 Weights: [0.35616423 2.13242011] , error: 0.4737442922374457\n",
      "Step: 8502 Weights: [0.35616423 2.13242011] , error: 0.4737442922374461\n",
      "Step: 8503 Weights: [0.35616423 2.13242011] , error: 0.4737442922374459\n",
      "Step: 8504 Weights: [0.35616423 2.13242011] , error: 0.4737442922374455\n",
      "Step: 8505 Weights: [0.35616423 2.13242011] , error: 0.47374429223744574\n",
      "Step: 8506 Weights: [0.35616423 2.13242011] , error: 0.473744292237446\n",
      "Step: 8507 Weights: [0.35616423 2.13242011] , error: 0.473744292237446\n",
      "Step: 8508 Weights: [0.35616423 2.13242011] , error: 0.4737442922374453\n",
      "Step: 8509 Weights: [0.35616423 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8510 Weights: [0.35616423 2.13242011] , error: 0.4737442922374456\n",
      "Step: 8511 Weights: [0.35616423 2.13242011] , error: 0.47374429223744596\n",
      "Step: 8512 Weights: [0.35616423 2.13242011] , error: 0.47374429223744513\n",
      "Step: 8513 Weights: [0.35616423 2.13242011] , error: 0.47374429223744585\n",
      "Step: 8514 Weights: [0.35616423 2.13242011] , error: 0.4737442922374452\n",
      "Step: 8515 Weights: [0.35616423 2.13242011] , error: 0.47374429223744563\n",
      "Step: 8516 Weights: [0.35616423 2.13242011] , error: 0.47374429223744585\n",
      "Step: 8517 Weights: [0.35616423 2.13242011] , error: 0.4737442922374461\n",
      "Step: 8518 Weights: [0.35616423 2.13242011] , error: 0.4737442922374456\n",
      "Step: 8519 Weights: [0.35616423 2.13242011] , error: 0.47374429223744585\n",
      "Step: 8520 Weights: [0.35616423 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8521 Weights: [0.35616423 2.13242011] , error: 0.4737442922374453\n",
      "Step: 8522 Weights: [0.35616423 2.13242011] , error: 0.4737442922374457\n",
      "Step: 8523 Weights: [0.35616423 2.13242011] , error: 0.47374429223744585\n",
      "Step: 8524 Weights: [0.35616423 2.13242011] , error: 0.47374429223744524\n",
      "Step: 8525 Weights: [0.35616423 2.13242011] , error: 0.4737442922374455\n",
      "Step: 8526 Weights: [0.35616423 2.13242011] , error: 0.4737442922374453\n",
      "Step: 8527 Weights: [0.35616423 2.13242011] , error: 0.47374429223744563\n",
      "Step: 8528 Weights: [0.35616424 2.13242011] , error: 0.47374429223744546\n",
      "Step: 8529 Weights: [0.35616424 2.13242011] , error: 0.4737442922374452\n",
      "Step: 8530 Weights: [0.35616424 2.13242011] , error: 0.47374429223744613\n",
      "Step: 8531 Weights: [0.35616424 2.13242011] , error: 0.47374429223744585\n",
      "Step: 8532 Weights: [0.35616424 2.13242011] , error: 0.4737442922374453\n",
      "Step: 8533 Weights: [0.35616424 2.13242011] , error: 0.4737442922374456\n",
      "Step: 8534 Weights: [0.35616424 2.13242011] , error: 0.47374429223744535\n",
      "Step: 8535 Weights: [0.35616424 2.13242011] , error: 0.4737442922374455\n",
      "Step: 8536 Weights: [0.35616424 2.13242011] , error: 0.4737442922374455\n",
      "Step: 8537 Weights: [0.35616424 2.13242011] , error: 0.4737442922374451\n",
      "Step: 8538 Weights: [0.35616424 2.13242011] , error: 0.4737442922374452\n",
      "Step: 8539 Weights: [0.35616424 2.13242011] , error: 0.4737442922374461\n",
      "Step: 8540 Weights: [0.35616424 2.13242011] , error: 0.47374429223744563\n",
      "Step: 8541 Weights: [0.35616424 2.13242011] , error: 0.47374429223744646\n",
      "Step: 8542 Weights: [0.35616424 2.13242011] , error: 0.4737442922374453\n",
      "Step: 8543 Weights: [0.35616424 2.13242011] , error: 0.47374429223744474\n",
      "Step: 8544 Weights: [0.35616424 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8545 Weights: [0.35616424 2.13242011] , error: 0.47374429223744524\n",
      "Step: 8546 Weights: [0.35616424 2.13242011] , error: 0.4737442922374456\n",
      "Step: 8547 Weights: [0.35616424 2.13242011] , error: 0.47374429223744524\n",
      "Step: 8548 Weights: [0.35616424 2.13242011] , error: 0.4737442922374451\n",
      "Step: 8549 Weights: [0.35616424 2.13242011] , error: 0.4737442922374451\n",
      "Step: 8550 Weights: [0.35616424 2.13242011] , error: 0.47374429223744524\n",
      "Step: 8551 Weights: [0.35616424 2.13242011] , error: 0.47374429223744474\n",
      "Step: 8552 Weights: [0.35616424 2.13242011] , error: 0.473744292237445\n",
      "Step: 8553 Weights: [0.35616424 2.13242011] , error: 0.4737442922374459\n",
      "Step: 8554 Weights: [0.35616424 2.13242011] , error: 0.4737442922374449\n",
      "Step: 8555 Weights: [0.35616424 2.13242011] , error: 0.473744292237445\n",
      "Step: 8556 Weights: [0.35616424 2.13242011] , error: 0.47374429223744546\n",
      "Step: 8557 Weights: [0.35616424 2.13242011] , error: 0.4737442922374455\n",
      "Step: 8558 Weights: [0.35616425 2.13242011] , error: 0.4737442922374446\n",
      "Step: 8559 Weights: [0.35616425 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8560 Weights: [0.35616425 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8561 Weights: [0.35616425 2.13242011] , error: 0.47374429223744563\n",
      "Step: 8562 Weights: [0.35616425 2.13242011] , error: 0.47374429223744563\n",
      "Step: 8563 Weights: [0.35616425 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8564 Weights: [0.35616425 2.13242011] , error: 0.47374429223744524\n",
      "Step: 8565 Weights: [0.35616425 2.13242011] , error: 0.4737442922374451\n",
      "Step: 8566 Weights: [0.35616425 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8567 Weights: [0.35616425 2.13242011] , error: 0.47374429223744485\n",
      "Step: 8568 Weights: [0.35616425 2.13242011] , error: 0.4737442922374452\n",
      "Step: 8569 Weights: [0.35616425 2.13242011] , error: 0.4737442922374453\n",
      "Step: 8570 Weights: [0.35616425 2.13242011] , error: 0.47374429223744485\n",
      "Step: 8571 Weights: [0.35616425 2.13242011] , error: 0.47374429223744496\n",
      "Step: 8572 Weights: [0.35616425 2.13242011] , error: 0.4737442922374456\n",
      "Step: 8573 Weights: [0.35616425 2.13242011] , error: 0.47374429223744485\n",
      "Step: 8574 Weights: [0.35616425 2.13242011] , error: 0.473744292237445\n",
      "Step: 8575 Weights: [0.35616425 2.13242011] , error: 0.47374429223744513\n",
      "Step: 8576 Weights: [0.35616425 2.13242011] , error: 0.4737442922374454\n",
      "Step: 8577 Weights: [0.35616425 2.13242011] , error: 0.4737442922374449\n",
      "Step: 8578 Weights: [0.35616425 2.13242011] , error: 0.4737442922374455\n",
      "Step: 8579 Weights: [0.35616425 2.13242011] , error: 0.4737442922374447\n",
      "Step: 8580 Weights: [0.35616425 2.13242011] , error: 0.4737442922374445\n",
      "Step: 8581 Weights: [0.35616425 2.13242011] , error: 0.4737442922374451\n",
      "Step: 8582 Weights: [0.35616425 2.13242011] , error: 0.4737442922374452\n",
      "Step: 8583 Weights: [0.35616425 2.13242011] , error: 0.4737442922374449\n",
      "Step: 8584 Weights: [0.35616425 2.13242011] , error: 0.473744292237445\n",
      "Step: 8585 Weights: [0.35616425 2.13242011] , error: 0.47374429223744485\n",
      "Step: 8586 Weights: [0.35616425 2.13242011] , error: 0.47374429223744474\n",
      "Step: 8587 Weights: [0.35616425 2.13242011] , error: 0.4737442922374453\n",
      "Step: 8588 Weights: [0.35616425 2.13242011] , error: 0.47374429223744485\n",
      "Step: 8589 Weights: [0.35616425 2.13242011] , error: 0.47374429223744513\n",
      "Step: 8590 Weights: [0.35616425 2.13242011] , error: 0.4737442922374445\n",
      "Step: 8591 Weights: [0.35616426 2.13242011] , error: 0.47374429223744474\n",
      "Step: 8592 Weights: [0.35616426 2.13242011] , error: 0.4737442922374447\n",
      "Step: 8593 Weights: [0.35616426 2.13242011] , error: 0.47374429223744496\n",
      "Step: 8594 Weights: [0.35616426 2.13242011] , error: 0.4737442922374451\n",
      "Step: 8595 Weights: [0.35616426 2.13242011] , error: 0.47374429223744363\n",
      "Step: 8596 Weights: [0.35616426 2.13242011] , error: 0.47374429223744463\n",
      "Step: 8597 Weights: [0.35616426 2.13242011] , error: 0.4737442922374452\n",
      "Step: 8598 Weights: [0.35616426 2.13242011] , error: 0.4737442922374452\n",
      "Step: 8599 Weights: [0.35616426 2.13242011] , error: 0.47374429223744463\n",
      "Step: 8600 Weights: [0.35616426 2.13242011] , error: 0.4737442922374444\n",
      "Step: 8601 Weights: [0.35616426 2.13242011] , error: 0.4737442922374445\n",
      "Step: 8602 Weights: [0.35616426 2.13242011] , error: 0.473744292237445\n",
      "Step: 8603 Weights: [0.35616426 2.13242011] , error: 0.4737442922374443\n",
      "Step: 8604 Weights: [0.35616426 2.13242011] , error: 0.4737442922374446\n",
      "Step: 8605 Weights: [0.35616426 2.13242011] , error: 0.4737442922374446\n",
      "Step: 8606 Weights: [0.35616426 2.13242011] , error: 0.4737442922374448\n",
      "Step: 8607 Weights: [0.35616426 2.13242011] , error: 0.4737442922374444\n",
      "Step: 8608 Weights: [0.35616426 2.13242011] , error: 0.47374429223744485\n",
      "Step: 8609 Weights: [0.35616426 2.13242011] , error: 0.4737442922374445\n",
      "Step: 8610 Weights: [0.35616426 2.13242011] , error: 0.4737442922374446\n",
      "Step: 8611 Weights: [0.35616426 2.13242011] , error: 0.4737442922374444\n",
      "Step: 8612 Weights: [0.35616426 2.13242011] , error: 0.4737442922374449\n",
      "Step: 8613 Weights: [0.35616426 2.13242011] , error: 0.47374429223744474\n",
      "Step: 8614 Weights: [0.35616426 2.13242011] , error: 0.4737442922374445\n",
      "Step: 8615 Weights: [0.35616426 2.13242011] , error: 0.47374429223744524\n",
      "Step: 8616 Weights: [0.35616426 2.13242011] , error: 0.47374429223744474\n",
      "Step: 8617 Weights: [0.35616426 2.13242011] , error: 0.4737442922374444\n",
      "Step: 8618 Weights: [0.35616426 2.13242011] , error: 0.4737442922374449\n",
      "Step: 8619 Weights: [0.35616426 2.13242011] , error: 0.4737442922374446\n",
      "Step: 8620 Weights: [0.35616426 2.13242011] , error: 0.4737442922374441\n",
      "Step: 8621 Weights: [0.35616426 2.13242011] , error: 0.4737442922374446\n",
      "Step: 8622 Weights: [0.35616426 2.13242011] , error: 0.4737442922374443\n",
      "Step: 8623 Weights: [0.35616426 2.1324201 ] , error: 0.47374429223744485\n",
      "Step: 8624 Weights: [0.35616426 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8625 Weights: [0.35616426 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8626 Weights: [0.35616426 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8627 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374448\n",
      "Step: 8628 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744424\n",
      "Step: 8629 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374448\n",
      "Step: 8630 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8631 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744435\n",
      "Step: 8632 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374451\n",
      "Step: 8633 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8634 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8635 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374448\n",
      "Step: 8636 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8637 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8638 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8639 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8640 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374448\n",
      "Step: 8641 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374444\n",
      "Step: 8642 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8643 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374444\n",
      "Step: 8644 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374447\n",
      "Step: 8645 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374447\n",
      "Step: 8646 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8647 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374447\n",
      "Step: 8648 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744496\n",
      "Step: 8649 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8650 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744435\n",
      "Step: 8651 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8652 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744435\n",
      "Step: 8653 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 8654 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374451\n",
      "Step: 8655 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744435\n",
      "Step: 8656 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8657 Weights: [0.35616427 2.1324201 ] , error: 0.473744292237445\n",
      "Step: 8658 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8659 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8660 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8661 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744446\n",
      "Step: 8662 Weights: [0.35616427 2.1324201 ] , error: 0.4737442922374447\n",
      "Step: 8663 Weights: [0.35616427 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8664 Weights: [0.35616427 2.1324201 ] , error: 0.47374429223744446\n",
      "Step: 8665 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374446\n",
      "Step: 8666 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8667 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8668 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8669 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374446\n",
      "Step: 8670 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8671 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374445\n",
      "Step: 8672 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374444\n",
      "Step: 8673 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744496\n",
      "Step: 8674 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374448\n",
      "Step: 8675 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374445\n",
      "Step: 8676 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744463\n",
      "Step: 8677 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8678 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8679 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8680 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744435\n",
      "Step: 8681 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8682 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744435\n",
      "Step: 8683 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8684 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8685 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8686 Weights: [0.35616428 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8687 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8688 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8689 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8690 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8691 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744474\n",
      "Step: 8692 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8693 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8694 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8695 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8696 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8697 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744435\n",
      "Step: 8698 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8699 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8700 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8701 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8702 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8703 Weights: [0.35616428 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8704 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8705 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8706 Weights: [0.35616428 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8707 Weights: [0.35616429 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8708 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744446\n",
      "Step: 8709 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8710 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8711 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8712 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8713 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8714 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8715 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8716 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8717 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8718 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8719 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374445\n",
      "Step: 8720 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 8721 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8722 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8723 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8724 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8725 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8726 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8727 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8728 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8729 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8730 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8731 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8732 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744424\n",
      "Step: 8733 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8734 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744446\n",
      "Step: 8735 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8736 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8737 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8738 Weights: [0.35616429 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8739 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8740 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744446\n",
      "Step: 8741 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8742 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8743 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8744 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8745 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8746 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8747 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8748 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8749 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374444\n",
      "Step: 8750 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8751 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8752 Weights: [0.35616429 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8753 Weights: [0.35616429 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8754 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8755 Weights: [0.3561643 2.1324201] , error: 0.4737442922374435\n",
      "Step: 8756 Weights: [0.3561643 2.1324201] , error: 0.4737442922374437\n",
      "Step: 8757 Weights: [0.3561643 2.1324201] , error: 0.47374429223744313\n",
      "Step: 8758 Weights: [0.3561643 2.1324201] , error: 0.47374429223744396\n",
      "Step: 8759 Weights: [0.3561643 2.1324201] , error: 0.4737442922374445\n",
      "Step: 8760 Weights: [0.3561643 2.1324201] , error: 0.4737442922374435\n",
      "Step: 8761 Weights: [0.3561643 2.1324201] , error: 0.47374429223744324\n",
      "Step: 8762 Weights: [0.3561643 2.1324201] , error: 0.4737442922374432\n",
      "Step: 8763 Weights: [0.3561643 2.1324201] , error: 0.47374429223744374\n",
      "Step: 8764 Weights: [0.3561643 2.1324201] , error: 0.47374429223744374\n",
      "Step: 8765 Weights: [0.3561643 2.1324201] , error: 0.4737442922374435\n",
      "Step: 8766 Weights: [0.3561643 2.1324201] , error: 0.473744292237444\n",
      "Step: 8767 Weights: [0.3561643 2.1324201] , error: 0.4737442922374437\n",
      "Step: 8768 Weights: [0.3561643 2.1324201] , error: 0.4737442922374436\n",
      "Step: 8769 Weights: [0.3561643 2.1324201] , error: 0.4737442922374438\n",
      "Step: 8770 Weights: [0.3561643 2.1324201] , error: 0.47374429223744363\n",
      "Step: 8771 Weights: [0.3561643 2.1324201] , error: 0.4737442922374443\n",
      "Step: 8772 Weights: [0.3561643 2.1324201] , error: 0.4737442922374436\n",
      "Step: 8773 Weights: [0.3561643 2.1324201] , error: 0.4737442922374441\n",
      "Step: 8774 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8775 Weights: [0.3561643 2.1324201] , error: 0.47374429223744396\n",
      "Step: 8776 Weights: [0.3561643 2.1324201] , error: 0.47374429223744363\n",
      "Step: 8777 Weights: [0.3561643 2.1324201] , error: 0.47374429223744347\n",
      "Step: 8778 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8779 Weights: [0.3561643 2.1324201] , error: 0.47374429223744524\n",
      "Step: 8780 Weights: [0.3561643 2.1324201] , error: 0.47374429223744396\n",
      "Step: 8781 Weights: [0.3561643 2.1324201] , error: 0.47374429223744396\n",
      "Step: 8782 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8783 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8784 Weights: [0.3561643 2.1324201] , error: 0.47374429223744374\n",
      "Step: 8785 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8786 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8787 Weights: [0.3561643 2.1324201] , error: 0.47374429223744396\n",
      "Step: 8788 Weights: [0.3561643 2.1324201] , error: 0.4737442922374435\n",
      "Step: 8789 Weights: [0.3561643 2.1324201] , error: 0.4737442922374438\n",
      "Step: 8790 Weights: [0.3561643 2.1324201] , error: 0.4737442922374444\n",
      "Step: 8791 Weights: [0.3561643 2.1324201] , error: 0.47374429223744313\n",
      "Step: 8792 Weights: [0.3561643 2.1324201] , error: 0.4737442922374434\n",
      "Step: 8793 Weights: [0.3561643 2.1324201] , error: 0.47374429223744396\n",
      "Step: 8794 Weights: [0.3561643 2.1324201] , error: 0.4737442922374439\n",
      "Step: 8795 Weights: [0.3561643 2.1324201] , error: 0.4737442922374441\n",
      "Step: 8796 Weights: [0.3561643 2.1324201] , error: 0.47374429223744385\n",
      "Step: 8797 Weights: [0.3561643 2.1324201] , error: 0.47374429223744396\n",
      "Step: 8798 Weights: [0.3561643 2.1324201] , error: 0.4737442922374437\n",
      "Step: 8799 Weights: [0.3561643 2.1324201] , error: 0.47374429223744363\n",
      "Step: 8800 Weights: [0.3561643 2.1324201] , error: 0.4737442922374435\n",
      "Step: 8801 Weights: [0.3561643 2.1324201] , error: 0.4737442922374438\n",
      "Step: 8802 Weights: [0.3561643 2.1324201] , error: 0.4737442922374435\n",
      "Step: 8803 Weights: [0.3561643 2.1324201] , error: 0.47374429223744313\n",
      "Step: 8804 Weights: [0.3561643 2.1324201] , error: 0.47374429223744435\n",
      "Step: 8805 Weights: [0.3561643 2.1324201] , error: 0.47374429223744374\n",
      "Step: 8806 Weights: [0.3561643 2.1324201] , error: 0.4737442922374439\n",
      "Step: 8807 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8808 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8809 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8810 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8811 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8812 Weights: [0.35616431 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8813 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374443\n",
      "Step: 8814 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8815 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8816 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8817 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8818 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8819 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8820 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8821 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8822 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8823 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 8824 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8825 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8826 Weights: [0.35616431 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8827 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8828 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8829 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8830 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8831 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8832 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744413\n",
      "Step: 8833 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8834 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8835 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8836 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8837 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8838 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8839 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8840 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8841 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8842 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8843 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8844 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8845 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8846 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8847 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 8848 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8849 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374442\n",
      "Step: 8850 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8851 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8852 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8853 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8854 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8855 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8856 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8857 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 8858 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8859 Weights: [0.35616431 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8860 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8861 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8862 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8863 Weights: [0.35616431 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8864 Weights: [0.35616431 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8865 Weights: [0.35616431 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8866 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8867 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 8868 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8869 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8870 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8871 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8872 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 8873 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374419\n",
      "Step: 8874 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 8875 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8876 Weights: [0.35616432 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8877 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8878 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 8879 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8880 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 8881 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 8882 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8883 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8884 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8885 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 8886 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8887 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374441\n",
      "Step: 8888 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8889 Weights: [0.35616432 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8890 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 8891 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8892 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8893 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8894 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8895 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8896 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8897 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 8898 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8899 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8900 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8901 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 8902 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8903 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8904 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8905 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8906 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8907 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8908 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8909 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8910 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 8911 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8912 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8913 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8914 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8915 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8916 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 8917 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8918 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8919 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8920 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8921 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8922 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8923 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8924 Weights: [0.35616432 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8925 Weights: [0.35616432 2.1324201 ] , error: 0.473744292237444\n",
      "Step: 8926 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8927 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8928 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8929 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 8930 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8931 Weights: [0.35616432 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8932 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 8933 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 8934 Weights: [0.35616432 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 8935 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 8936 Weights: [0.35616433 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8937 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8938 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8939 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 8940 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 8941 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8942 Weights: [0.35616433 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8943 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744446\n",
      "Step: 8944 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8945 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374426\n",
      "Step: 8946 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 8947 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 8948 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8949 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 8950 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8951 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8952 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8953 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 8954 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 8955 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8956 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8957 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8958 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8959 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8960 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8961 Weights: [0.35616433 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8962 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8963 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8964 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8965 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8966 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8967 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8968 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8969 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8970 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 8971 Weights: [0.35616433 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8972 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 8973 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8974 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 8975 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 8976 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 8977 Weights: [0.35616433 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 8978 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8979 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374444\n",
      "Step: 8980 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 8981 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 8982 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 8983 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 8984 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 8985 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8986 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374427\n",
      "Step: 8987 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 8988 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 8989 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 8990 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 8991 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8992 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374427\n",
      "Step: 8993 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 8994 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 8995 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 8996 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 8997 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 8998 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 8999 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 9000 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 9001 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744396\n",
      "Step: 9002 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9003 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9004 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9005 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9006 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 9007 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 9008 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9009 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9010 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9011 Weights: [0.35616433 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9012 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9013 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 9014 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9015 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 9016 Weights: [0.35616433 2.1324201 ] , error: 0.47374429223744247\n",
      "Step: 9017 Weights: [0.35616433 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9018 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9019 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9020 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374438\n",
      "Step: 9021 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9022 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9023 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 9024 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 9025 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9026 Weights: [0.35616434 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9027 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9028 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 9029 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 9030 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9031 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9032 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 9033 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9034 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9035 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 9036 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9037 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9038 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9039 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9040 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374439\n",
      "Step: 9041 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 9042 Weights: [0.35616434 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9043 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9044 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9045 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374426\n",
      "Step: 9046 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9047 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9048 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9049 Weights: [0.35616434 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9050 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 9051 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 9052 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9053 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9054 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9055 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9056 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9057 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 9058 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9059 Weights: [0.35616434 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9060 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 9061 Weights: [0.35616434 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9062 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9063 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 9064 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9065 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9066 Weights: [0.35616434 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9067 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9068 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 9069 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9070 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 9071 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9072 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 9073 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9074 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374426\n",
      "Step: 9075 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9076 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374436\n",
      "Step: 9077 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9078 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9079 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9080 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9081 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9082 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 9083 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9084 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9085 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9086 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9087 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744385\n",
      "Step: 9088 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 9089 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374427\n",
      "Step: 9090 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9091 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9092 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374425\n",
      "Step: 9093 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9094 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9095 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9096 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374425\n",
      "Step: 9097 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 9098 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9099 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9100 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 9101 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9102 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374424\n",
      "Step: 9103 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9104 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9105 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9106 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9107 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9108 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9109 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374425\n",
      "Step: 9110 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374426\n",
      "Step: 9111 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9112 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9113 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744313\n",
      "Step: 9114 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9115 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9116 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9117 Weights: [0.35616434 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9118 Weights: [0.35616434 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9119 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9120 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9121 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9122 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9123 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9124 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374425\n",
      "Step: 9125 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374437\n",
      "Step: 9126 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9127 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9128 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9129 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374434\n",
      "Step: 9130 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9131 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9132 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9133 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9134 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9135 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9136 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9137 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9138 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9139 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9140 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9141 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 9142 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374435\n",
      "Step: 9143 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9144 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9145 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9146 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9147 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9148 Weights: [0.35616435 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9149 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 9150 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9151 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9152 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744347\n",
      "Step: 9153 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744297\n",
      "Step: 9154 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9155 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9156 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9157 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9158 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9159 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9160 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9161 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9162 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9163 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9164 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 9165 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9166 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9167 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744247\n",
      "Step: 9168 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9169 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744285\n",
      "Step: 9170 Weights: [0.35616435 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9171 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744197\n",
      "Step: 9172 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 9173 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 9174 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744235\n",
      "Step: 9175 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9176 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9177 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374425\n",
      "Step: 9178 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9179 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744274\n",
      "Step: 9180 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9181 Weights: [0.35616435 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9182 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9183 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9184 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744363\n",
      "Step: 9185 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9186 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9187 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9188 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744374\n",
      "Step: 9189 Weights: [0.35616435 2.1324201 ] , error: 0.473744292237443\n",
      "Step: 9190 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374432\n",
      "Step: 9191 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374433\n",
      "Step: 9192 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744263\n",
      "Step: 9193 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744335\n",
      "Step: 9194 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374429\n",
      "Step: 9195 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374428\n",
      "Step: 9196 Weights: [0.35616435 2.1324201 ] , error: 0.47374429223744324\n",
      "Step: 9197 Weights: [0.35616435 2.1324201 ] , error: 0.4737442922374431\n",
      "Step: 9198 Weights: [0.35616435 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9199 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9200 Weights: [0.35616435 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9201 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9202 Weights: [0.35616435 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9203 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9204 Weights: [0.35616435 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9205 Weights: [0.35616435 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9206 Weights: [0.35616435 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9207 Weights: [0.35616435 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9208 Weights: [0.35616435 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9209 Weights: [0.35616435 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9210 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9211 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9212 Weights: [0.35616435 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9213 Weights: [0.35616435 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9214 Weights: [0.35616435 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9215 Weights: [0.35616435 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9216 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9217 Weights: [0.35616435 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9218 Weights: [0.35616435 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9219 Weights: [0.35616435 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9220 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9221 Weights: [0.35616435 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9222 Weights: [0.35616435 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9223 Weights: [0.35616435 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9224 Weights: [0.35616435 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9225 Weights: [0.35616435 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9226 Weights: [0.35616435 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9227 Weights: [0.35616435 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9228 Weights: [0.35616435 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9229 Weights: [0.35616435 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9230 Weights: [0.35616435 2.13242009] , error: 0.473744292237443\n",
      "Step: 9231 Weights: [0.35616435 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9232 Weights: [0.35616435 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9233 Weights: [0.35616435 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9234 Weights: [0.35616435 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9235 Weights: [0.35616435 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9236 Weights: [0.35616435 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9237 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9238 Weights: [0.35616435 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9239 Weights: [0.35616435 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9240 Weights: [0.35616435 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9241 Weights: [0.35616435 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9242 Weights: [0.35616435 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9243 Weights: [0.35616435 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9244 Weights: [0.35616435 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9245 Weights: [0.35616435 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9246 Weights: [0.35616435 2.13242009] , error: 0.473744292237443\n",
      "Step: 9247 Weights: [0.35616435 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9248 Weights: [0.35616435 2.13242009] , error: 0.473744292237443\n",
      "Step: 9249 Weights: [0.35616435 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9250 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9251 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9252 Weights: [0.35616436 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9253 Weights: [0.35616436 2.13242009] , error: 0.4737442922374442\n",
      "Step: 9254 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9255 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9256 Weights: [0.35616436 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9257 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9258 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9259 Weights: [0.35616436 2.13242009] , error: 0.4737442922374415\n",
      "Step: 9260 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9261 Weights: [0.35616436 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9262 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9263 Weights: [0.35616436 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9264 Weights: [0.35616436 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9265 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9266 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9267 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9268 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9269 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9270 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9271 Weights: [0.35616436 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9272 Weights: [0.35616436 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9273 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9274 Weights: [0.35616436 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9275 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9276 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9277 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9278 Weights: [0.35616436 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9279 Weights: [0.35616436 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9280 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9281 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9282 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9283 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9284 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9285 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9286 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9287 Weights: [0.35616436 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9288 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9289 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9290 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9291 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9292 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9293 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9294 Weights: [0.35616436 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9295 Weights: [0.35616436 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9296 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9297 Weights: [0.35616436 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9298 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9299 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9300 Weights: [0.35616436 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9301 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9302 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9303 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9304 Weights: [0.35616436 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9305 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9306 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9307 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9308 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9309 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9310 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9311 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9312 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9313 Weights: [0.35616436 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9314 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9315 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9316 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9317 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9318 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9319 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9320 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9321 Weights: [0.35616436 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9322 Weights: [0.35616436 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9323 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9324 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9325 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9326 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9327 Weights: [0.35616436 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9328 Weights: [0.35616436 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9329 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9330 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9331 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9332 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9333 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9334 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9335 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9336 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9337 Weights: [0.35616436 2.13242009] , error: 0.4737442922374437\n",
      "Step: 9338 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9339 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9340 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9341 Weights: [0.35616436 2.13242009] , error: 0.47374429223744374\n",
      "Step: 9342 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9343 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9344 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9345 Weights: [0.35616436 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9346 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9347 Weights: [0.35616436 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9348 Weights: [0.35616436 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9349 Weights: [0.35616436 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9350 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9351 Weights: [0.35616436 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9352 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9353 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9354 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9355 Weights: [0.35616436 2.13242009] , error: 0.47374429223744186\n",
      "Step: 9356 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9357 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9358 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9359 Weights: [0.35616436 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9360 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9361 Weights: [0.35616436 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9362 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9363 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9364 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9365 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9366 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9367 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9368 Weights: [0.35616436 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9369 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9370 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9371 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9372 Weights: [0.35616436 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9373 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9374 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9375 Weights: [0.35616436 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9376 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9377 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9378 Weights: [0.35616436 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9379 Weights: [0.35616436 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9380 Weights: [0.35616436 2.13242009] , error: 0.473744292237443\n",
      "Step: 9381 Weights: [0.35616436 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9382 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9383 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9384 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9385 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9386 Weights: [0.35616436 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9387 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9388 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9389 Weights: [0.35616436 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9390 Weights: [0.35616436 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9391 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9392 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9393 Weights: [0.35616436 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9394 Weights: [0.35616436 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9395 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9396 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9397 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9398 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9399 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9400 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9401 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9402 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9403 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9404 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9405 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9406 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9407 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9408 Weights: [0.35616436 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9409 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9410 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9411 Weights: [0.35616436 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9412 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9413 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9414 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9415 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9416 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9417 Weights: [0.35616436 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9418 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9419 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9420 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9421 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9422 Weights: [0.35616436 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9423 Weights: [0.35616436 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9424 Weights: [0.35616436 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9425 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9426 Weights: [0.35616436 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9427 Weights: [0.35616436 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9428 Weights: [0.35616436 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9429 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9430 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9431 Weights: [0.35616436 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9432 Weights: [0.35616436 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9433 Weights: [0.35616436 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9434 Weights: [0.35616436 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9435 Weights: [0.35616436 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9436 Weights: [0.35616436 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9437 Weights: [0.35616436 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9438 Weights: [0.35616436 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9439 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9440 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9441 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9442 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9443 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9444 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9445 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9446 Weights: [0.35616437 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9447 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9448 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9449 Weights: [0.35616437 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9450 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9451 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9452 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9453 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9454 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9455 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9456 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9457 Weights: [0.35616437 2.13242009] , error: 0.4737442922374437\n",
      "Step: 9458 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9459 Weights: [0.35616437 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9460 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9461 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9462 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9463 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9464 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9465 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9466 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9467 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9468 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9469 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9470 Weights: [0.35616437 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9471 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9472 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9473 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9474 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9475 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9476 Weights: [0.35616437 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9477 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9478 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9479 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9480 Weights: [0.35616437 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9481 Weights: [0.35616437 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9482 Weights: [0.35616437 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9483 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9484 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9485 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9486 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9487 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9488 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9489 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9490 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9491 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9492 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9493 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9494 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9495 Weights: [0.35616437 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9496 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9497 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9498 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9499 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9500 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9501 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9502 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9503 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9504 Weights: [0.35616437 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9505 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9506 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9507 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9508 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9509 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9510 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9511 Weights: [0.35616437 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9512 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9513 Weights: [0.35616437 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9514 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9515 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9516 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9517 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9518 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9519 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9520 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9521 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9522 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9523 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9524 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9525 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9526 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9527 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9528 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9529 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9530 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9531 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9532 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9533 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9534 Weights: [0.35616437 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9535 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9536 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9537 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9538 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9539 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9540 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9541 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9542 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9543 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9544 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9545 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9546 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9547 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9548 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9549 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9550 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9551 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9552 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9553 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9554 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9555 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9556 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9557 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9558 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9559 Weights: [0.35616437 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9560 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9561 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9562 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9563 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9564 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9565 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9566 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9567 Weights: [0.35616437 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9568 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9569 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9570 Weights: [0.35616437 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9571 Weights: [0.35616437 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9572 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9573 Weights: [0.35616437 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9574 Weights: [0.35616437 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9575 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9576 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9577 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9578 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9579 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9580 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9581 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9582 Weights: [0.35616437 2.13242009] , error: 0.4737442922374437\n",
      "Step: 9583 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9584 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9585 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9586 Weights: [0.35616437 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9587 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9588 Weights: [0.35616437 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9589 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9590 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9591 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9592 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9593 Weights: [0.35616437 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9594 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9595 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9596 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9597 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9598 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9599 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9600 Weights: [0.35616437 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9601 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9602 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9603 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9604 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9605 Weights: [0.35616437 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9606 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9607 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9608 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9609 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9610 Weights: [0.35616437 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9611 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9612 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9613 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9614 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9615 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9616 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9617 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9618 Weights: [0.35616437 2.13242009] , error: 0.4737442922374441\n",
      "Step: 9619 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9620 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9621 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9622 Weights: [0.35616437 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9623 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9624 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9625 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9626 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9627 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9628 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9629 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9630 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9631 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9632 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9633 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9634 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9635 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9636 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9637 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9638 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9639 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9640 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9641 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9642 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9643 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9644 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9645 Weights: [0.35616437 2.13242009] , error: 0.4737442922374436\n",
      "Step: 9646 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9647 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9648 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9649 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9650 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9651 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9652 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9653 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9654 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9655 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9656 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9657 Weights: [0.35616437 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9658 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9659 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9660 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9661 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9662 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9663 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9664 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9665 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9666 Weights: [0.35616437 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9667 Weights: [0.35616437 2.13242009] , error: 0.473744292237443\n",
      "Step: 9668 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9669 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9670 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9671 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9672 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9673 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9674 Weights: [0.35616437 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9675 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9676 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9677 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9678 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9679 Weights: [0.35616437 2.13242009] , error: 0.4737442922374422\n",
      "Step: 9680 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9681 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9682 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9683 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9684 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9685 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9686 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9687 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9688 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9689 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9690 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9691 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9692 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9693 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9694 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9695 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9696 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9697 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9698 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9699 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9700 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9701 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9702 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9703 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9704 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9705 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9706 Weights: [0.35616437 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9707 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9708 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9709 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9710 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9711 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9712 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9713 Weights: [0.35616437 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9714 Weights: [0.35616437 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9715 Weights: [0.35616437 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9716 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9717 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9718 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9719 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9720 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9721 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9722 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9723 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9724 Weights: [0.35616437 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9725 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9726 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9727 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9728 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9729 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9730 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9731 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9732 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9733 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9734 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9735 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9736 Weights: [0.35616437 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9737 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9738 Weights: [0.35616437 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9739 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9740 Weights: [0.35616437 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9741 Weights: [0.35616437 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9742 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9743 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9744 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9745 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9746 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9747 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9748 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9749 Weights: [0.35616437 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9750 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9751 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9752 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9753 Weights: [0.35616437 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9754 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9755 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9756 Weights: [0.35616437 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9757 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9758 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9759 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9760 Weights: [0.35616437 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9761 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9762 Weights: [0.35616437 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9763 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9764 Weights: [0.35616437 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9765 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9766 Weights: [0.35616437 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9767 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9768 Weights: [0.35616437 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9769 Weights: [0.35616437 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9770 Weights: [0.35616437 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9771 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9772 Weights: [0.35616437 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9773 Weights: [0.35616437 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9774 Weights: [0.35616437 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9775 Weights: [0.35616437 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9776 Weights: [0.35616437 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9777 Weights: [0.35616437 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9778 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9779 Weights: [0.35616438 2.13242009] , error: 0.4737442922374422\n",
      "Step: 9780 Weights: [0.35616438 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9781 Weights: [0.35616438 2.13242009] , error: 0.473744292237443\n",
      "Step: 9782 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9783 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9784 Weights: [0.35616438 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9785 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9786 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9787 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9788 Weights: [0.35616438 2.13242009] , error: 0.473744292237443\n",
      "Step: 9789 Weights: [0.35616438 2.13242009] , error: 0.4737442922374434\n",
      "Step: 9790 Weights: [0.35616438 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9791 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9792 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9793 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9794 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9795 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9796 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9797 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9798 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9799 Weights: [0.35616438 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9800 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9801 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9802 Weights: [0.35616438 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9803 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9804 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9805 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9806 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9807 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9808 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9809 Weights: [0.35616438 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9810 Weights: [0.35616438 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9811 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9812 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9813 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9814 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9815 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9816 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9817 Weights: [0.35616438 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9818 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9819 Weights: [0.35616438 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9820 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9821 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9822 Weights: [0.35616438 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9823 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9824 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9825 Weights: [0.35616438 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9826 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9827 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9828 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9829 Weights: [0.35616438 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9830 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9831 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9832 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9833 Weights: [0.35616438 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9834 Weights: [0.35616438 2.13242009] , error: 0.4737442922374423\n",
      "Step: 9835 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9836 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9837 Weights: [0.35616438 2.13242009] , error: 0.473744292237443\n",
      "Step: 9838 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9839 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9840 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9841 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9842 Weights: [0.35616438 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9843 Weights: [0.35616438 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9844 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9845 Weights: [0.35616438 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9846 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9847 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9848 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9849 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9850 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9851 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9852 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9853 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9854 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9855 Weights: [0.35616438 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9856 Weights: [0.35616438 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9857 Weights: [0.35616438 2.13242009] , error: 0.47374429223744247\n",
      "Step: 9858 Weights: [0.35616438 2.13242009] , error: 0.47374429223744313\n",
      "Step: 9859 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9860 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9861 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9862 Weights: [0.35616438 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9863 Weights: [0.35616438 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9864 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9865 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9866 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9867 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9868 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9869 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9870 Weights: [0.35616438 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9871 Weights: [0.35616438 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9872 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9873 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9874 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9875 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9876 Weights: [0.35616438 2.13242009] , error: 0.4737442922374422\n",
      "Step: 9877 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9878 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9879 Weights: [0.35616438 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9880 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9881 Weights: [0.35616438 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9882 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9883 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9884 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9885 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9886 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9887 Weights: [0.35616438 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9888 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9889 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9890 Weights: [0.35616438 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9891 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9892 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9893 Weights: [0.35616438 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9894 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9895 Weights: [0.35616438 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9896 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9897 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9898 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9899 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9900 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9901 Weights: [0.35616438 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9902 Weights: [0.35616438 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9903 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9904 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9905 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9906 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9907 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9908 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9909 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9910 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9911 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9912 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9913 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9914 Weights: [0.35616438 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9915 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9916 Weights: [0.35616438 2.13242009] , error: 0.47374429223744235\n",
      "Step: 9917 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9918 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9919 Weights: [0.35616438 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9920 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9921 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9922 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9923 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9924 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9925 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9926 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9927 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9928 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9929 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9930 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9931 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9932 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9933 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9934 Weights: [0.35616438 2.13242009] , error: 0.4737442922374422\n",
      "Step: 9935 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9936 Weights: [0.35616438 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9937 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9938 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9939 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9940 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9941 Weights: [0.35616438 2.13242009] , error: 0.4737442922374424\n",
      "Step: 9942 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9943 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9944 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9945 Weights: [0.35616438 2.13242009] , error: 0.47374429223744335\n",
      "Step: 9946 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9947 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9948 Weights: [0.35616438 2.13242009] , error: 0.47374429223744347\n",
      "Step: 9949 Weights: [0.35616438 2.13242009] , error: 0.47374429223744363\n",
      "Step: 9950 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9951 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9952 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9953 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9954 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9955 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9956 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9957 Weights: [0.35616438 2.13242009] , error: 0.4737442922374426\n",
      "Step: 9958 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9959 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9960 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9961 Weights: [0.35616438 2.13242009] , error: 0.47374429223744285\n",
      "Step: 9962 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9963 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9964 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9965 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9966 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9967 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9968 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9969 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9970 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9971 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9972 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9973 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9974 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9975 Weights: [0.35616438 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9976 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9977 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n",
      "Step: 9978 Weights: [0.35616438 2.13242009] , error: 0.4737442922374418\n",
      "Step: 9979 Weights: [0.35616438 2.13242009] , error: 0.4737442922374427\n",
      "Step: 9980 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9981 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9982 Weights: [0.35616438 2.13242009] , error: 0.4737442922374433\n",
      "Step: 9983 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9984 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9985 Weights: [0.35616438 2.13242009] , error: 0.4737442922374429\n",
      "Step: 9986 Weights: [0.35616438 2.13242009] , error: 0.47374429223744224\n",
      "Step: 9987 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9988 Weights: [0.35616438 2.13242009] , error: 0.4737442922374432\n",
      "Step: 9989 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9990 Weights: [0.35616438 2.13242009] , error: 0.47374429223744324\n",
      "Step: 9991 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9992 Weights: [0.35616438 2.13242009] , error: 0.4737442922374435\n",
      "Step: 9993 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9994 Weights: [0.35616438 2.13242009] , error: 0.4737442922374431\n",
      "Step: 9995 Weights: [0.35616438 2.13242009] , error: 0.47374429223744274\n",
      "Step: 9996 Weights: [0.35616438 2.13242009] , error: 0.47374429223744297\n",
      "Step: 9997 Weights: [0.35616438 2.13242009] , error: 0.4737442922374425\n",
      "Step: 9998 Weights: [0.35616438 2.13242009] , error: 0.47374429223744263\n",
      "Step: 9999 Weights: [0.35616438 2.13242009] , error: 0.4737442922374428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.35616438, 2.13242009])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getcoefficients(X,y,w,0.01,10000,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had put in the ability to plot too so why not plot the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35616438, 2.13242009])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getcoefficients(X,y,w,0.01,10000,False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should hopefully still get there\n",
    "\n",
    "With more complicated functions it might get \"stuck\" in one of those valleys like I said in class but thankfully this example does not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did the graph look like with the [20,50] initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35631862, 2.13240245])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/IAAAKnCAYAAAAlVnbIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABR8ElEQVR4nO3de5iVZb0//s8CBFSYQeXcjIKBkqZYigRaWrAlSpNqq5HlqcO2sJ9+0dpSe6sdduN273TnITL3V7GDmu6vWlqbNqJiKioHMVEjsEGcYvDIDKAgzjy/P2Y7Oc5awwzMPOv0el3Xui7XfT/rWZ+Fz+Xlm/t5PncmSZIkAAAAgKLQK98FAAAAAJ0nyAMAAEAREeQBAACgiAjyAAAAUEQEeQAAACgigjwAAAAUEUEeAAAAioggDwAAAEWkT74LKETNzc3x17/+NQYOHBiZTCbf5QAAAFDikiSJTZs2xciRI6NXr47X3AX5LP76179GdXV1vssAAACgzDz//PNRVVXV4TGCfBYDBw6MiJY/wIqKijxX0zl/+UvEQQe1H3/66Yh3vSv9egAAAOi8xsbGqK6ubs2jHRHks3jrdvqKioqiCfKNjRGZTESS/G2sV6+IgQMjiuQnAAAAlL3OPN6t2V2JWL26bYiPiGhujlizJj/1AAAA0DME+RIxdmzLivzbZTIRY8bkpx4AAAB6hiBfwjTcBwAAKD2CfIlwaz0AAEB5EORLhFvrAQAAyoMgDwAAAEVEkC8R2W6tT5KIH/4wP/UAAADQM/Ia5GtqamLChAkxcODAGDp0aMyYMSNWrVrV5pitW7fGrFmzYp999okBAwbEpz/96diwYUOH502SJC666KIYMWJE7L777jF16tRYvXp1T/6UvMt2a31ExBVXRNTVpV8PAAAAPSOvQX7RokUxa9aseOSRR2LBggWxffv2OO6442LLli2tx/yf//N/4q677orbbrstFi1aFH/961/jU5/6VIfnveyyy+LKK6+MH//4x/Hoo4/GnnvuGdOmTYutW7f29E/Km6qqiPPPbz/e1KThHQAAQCnJJMk7b8jOnxdffDGGDh0aixYtig996EPR0NAQQ4YMiZtuuin+/u//PiIi/vjHP8Z73vOeWLx4cXzgAx9od44kSWLkyJFx/vnnxwUXXBAREQ0NDTFs2LCYN29efOYzn9lhHY2NjVFZWRkNDQ1RUVHRvT+yB9XVRey7b9tb7DOZiHXrWoI+AAAAhakrObSgnpFvaGiIiIi99947IiKWLVsW27dvj6lTp7YeM27cuNh3331j8eLFWc9RW1sb9fX1bT5TWVkZEydOzPmZbdu2RWNjY5tXqbCXPAAAQGkpmCDf3Nwc5513Xhx11FHx3ve+NyIi6uvro2/fvjFo0KA2xw4bNizq6+uznuet8WHDhnX6MzU1NVFZWdn6qq6u3sVfkx/2kgcAACh9BRPkZ82aFStXroxbbrkl9e+eM2dONDQ0tL6ef/751GvoDvaSBwAAKH0FEeTPOeecuPvuu+O+++6Lqrc9zD18+PB44403YuPGjW2O37BhQwwfPjzrud4af2dn+44+069fv6ioqGjzKhVurQcAACgteQ3ySZLEOeecE3fccUfce++9MXr06Dbzhx9+eOy2226xcOHC1rFVq1bFunXrYtKkSVnPOXr06Bg+fHibzzQ2Nsajjz6a8zOlwq31AAAApS+vQX7WrFnx85//PG666aYYOHBg1NfXR319fbz++usR0dKk7gtf+ELMnj077rvvvli2bFmceeaZMWnSpDYd68eNGxd33HFHRERkMpk477zz4nvf+178+te/jieffDJOO+20GDlyZMyYMSMfPzM1AwZkH99zz3TrAAAAoOf0yeeXz507NyIijj322DbjN9xwQ5xxxhkREXHFFVdEr1694tOf/nRs27Ytpk2bFj/60Y/aHL9q1arWjvcREd/4xjdiy5Yt8eUvfzk2btwYRx99dMyfPz/69+/fo78n3zZvzj6+ZUu6dQAAANBzCmof+UJhH3kAAADSVLT7yNP9NLsDAAAoLYJ8CdHsDgAAoPQJ8iXEPvIAAAClT5AHAACAIiLIl5Bst9YnScQPf5ifegAAAOh+gnwJyXZrfUTEFVe0dLQHAACg+AnyJaSqKuL889uPNzVpeAcAAFAqBPkSc+65Gt4BAACUMkG+DNhLHgAAoHQI8iXGXvIAAAClTZAvMQMGZB/fc8906wAAAKBnCPIlZvPm7ONbtqRbBwAAAD1DkC8x2bag0+wOAACgdAjyZUCzOwAAgNIhyJcYze4AAABKmyBfYtxaDwAAUNoE+TLg1noAAIDSIciXGLfWAwAAlDZBvsTYRx4AAKC0CfIlxj7yAAAApU2QLzFjx0b0yvJvdenS9GsBAACg+wnyJaaqKuLSS9uPX3hhRF1d+vUAAADQvQT5EnTEEe3Hmpo0vAMAACgFgnwJ0vAOAACgdAnyJUjDOwAAgNIlyJegsWMjMpm2Y5lMxJgx+akHAACA7iPIl4l3BnsAAACKkyBfglavjkiStmPNzZrdAQAAlAJBvgRpdgcAAFC6BPkSpNkdAABA6RLkS5BmdwAAAKVLkC8Tmt0BAACUBkG+BGl2BwAAULoE+RKk2R0AAEDpEuRLkGZ3AAAApUuQL0Fjx0b0yvJvdunS9GsBAACgewnyJaiqKuLSS9uPX3hhRF1d+vUAAADQfQT5EnXEEe3Hmpo0vAMAACh2gnyJ0vAOAACgNAnyJUrDOwAAgNIkyJeosWMjMpm2Y5lMxJgx+akHAACA7iHIl5F3BnsAAACKjyBfolavjkiStmPNzZrdAQAAFDtBvkRpdgcAAFCaBPkSpdkdAABAaRLkS5RmdwAAAKVJkC8jmt0BAAAUP0G+RGl2BwAAUJoE+RKl2R0AAEBpEuRLlGZ3AAAApUmQL1Fjx0b0yvJvd+nS9GsBAACg+wjyJaqqKuLSS9uPX3hhRF1d+vUAAADQPQT5EnbEEe3Hmpo0vAMAAChmgnwJ0/AOAACg9AjyJUzDOwAAgNIjyJcwK/IAAAClR5AvYVbkAQAASo8gX8LGjo3IZNqOZTIRY8bkpx4AAAB2nSBfZt4Z7AEAACgugnwJW706IknajjU3234OAACgmAnyJUyzOwAAgNIjyJcwze4AAABKjyBfwjS7AwAAKD2CPAAAABSRvAb5Bx54IE444YQYOXJkZDKZuPPOO9vMZzKZrK9/+7d/y3nOSy65pN3x48aN6+FfUpiyNbtLkogf/jA/9QAAALDr8hrkt2zZEuPHj49rrrkm6/z69evbvK6//vrIZDLx6U9/usPzHnzwwW0+9+CDD/ZE+QUv2631ERFXXBFRV5d+PQAAAOy6Pvn88unTp8f06dNzzg8fPrzN+1/96lfx4Q9/OPbff/8Oz9unT592ny1HVVUR558f8e//3na8qallC7qqqvzUBQAAwM4rmmfkN2zYEL/5zW/iC1/4wg6PXb16dYwcOTL233//OPXUU2PdunUdHr9t27ZobGxs8yoVJ5+cfdwWdAAAAMWpaIL8jTfeGAMHDoxPfepTHR43ceLEmDdvXsyfPz/mzp0btbW18cEPfjA2bdqU8zM1NTVRWVnZ+qquru7u8vPGFnQAAAClJZMk72yHlh+ZTCbuuOOOmDFjRtb5cePGxd/93d/FVVdd1aXzbty4Mfbbb7+4/PLLc67mb9u2LbZt29b6vrGxMaqrq6OhoSEqKiq69H2Fpq4uYt992za9y2Qi1q1zaz0AAEChaGxsjMrKyk7l0Lw+I99Zv//972PVqlXxy1/+ssufHTRoUBxwwAGxZs2anMf069cv+vXrtyslFpVsDfAAAAAoDkVxa/3//b//Nw4//PAYP358lz+7efPmePbZZ2PEiBE9UFnhy7YFXXNzS7M7AAAAik9eg/zmzZtjxYoVsWLFioiIqK2tjRUrVrRpTtfY2Bi33XZbfPGLX8x6jilTpsTVV1/d+v6CCy6IRYsWxdq1a+Phhx+OT37yk9G7d++YOXNmj/6WQjVgQPZxze4AAACKU15vrV+6dGl8+MMfbn0/e/bsiIg4/fTTY968eRERccstt0SSJDmD+LPPPhsvvfRS6/u6urqYOXNmvPzyyzFkyJA4+uij45FHHokhQ4b03A8pYJrdAQAAlJaCaXZXSLrSZKDQLVkSceSR7ccfeyxiwoT06wEAAKC9ruTQonhGnp1nRR4AAKC0CPIlzjPyAAAApUWQL3FW5AEAAEqLIF/ixo6N6JXl3/LSpenXAgAAwK4T5EtcVVXEpZe2H7/wwoi6uvTrAQAAYNcI8mXgiCPajzU1RaxZk34tAAAA7BpBvgxoeAcAAFA6BPkyoOEdAABA6RDky4AVeQAAgNIhyJcBK/IAAAClQ5AvA2PHRmQybccymYgxY/JTDwAAADtPkC9T7wz2AAAAFAdBvgysXh2RJG3HmpttPwcAAFCMBPkyoNkdAABA6RDky4BmdwAAAKVDkC8DVuQBAABKhyBfBnKtyN96a7p1AAAAsOsE+TKQbfu5iIgrroioq0u/HgAAAHaeIF8Gqqoizj+//XhTk871AAAAxUaQLxPnntt+VT6TiRgzJj/1AAAAsHME+TKW7XZ7AAAACpsgXyZWr45IkrZjzc1urQcAACg2gnyZsAUdAABAaRDky0SuLei2bEm3DgAAAHaNIF8mrMgDAACUBkG+TFiRBwAAKA2CfJmwIg8AAFAaBPkyYUUeAACgNAjyZcKKPAAAQGkQ5MtErhX5W29Ntw4AAAB2jSBfJsaOjchk2o9fcUVEXV369QAAALBzBPkyUVUVcf757cebmiLWrEm/HgAAAHaOIF9Gzj23/ap8JhMxZkx+6gEAAKDrBPkyl+12ewAAAAqXIF9GVq+OSJK2Y83Nbq0HAAAoJoJ8GbEFHQAAQPET5MtIri3otmxJtw4AAAB2niBfRqzIAwAAFD9BvoxYkQcAACh+gnwZsSIPAABQ/AT5MpJrRf7WW9OtAwAAgJ0nyJeRsWOz7xt/xRURdXXp1wMAAEDXCfJlpKoq4vzz2483NdlLHgAAoFgI8mXm5JOzj3tOHgAAoDgI8mVG53oAAIDiJsiXGZ3rAQAAipsgX2asyAMAABQ3Qb7MWJEHAAAoboJ8mbEiDwAAUNwE+TKTbS/5TCZizJj81AMAAEDXCPK0C/YAAAAULkG+zKxeHZEkbceamyPWrMlPPQAAAHSNIF9mNLsDAAAoboJ8mcnV7O7WW9OtAwAAgJ0jyJeZbM3uIiKuuCKiri79egAAAOgaQb7MVFVFnH9++/GmJs/JAwAAFANBvgydfHL2cc/JAwAAFD5Bvgzlek5+y5Z06wAAAKDrBPkypHM9AABA8RLky5AVeQAAgOIlyJchK/IAAADFS5AvQ1bkAQAAipcgX4asyAMAABQvQb4MWZEHAAAoXnkN8g888ECccMIJMXLkyMhkMnHnnXe2mT/jjDMik8m0eX30ox/d4XmvueaaGDVqVPTv3z8mTpwYjz32WA/9guJkRR4AAKB45TXIb9myJcaPHx/XXHNNzmM++tGPxvr161tfN998c4fn/OUvfxmzZ8+Oiy++OJYvXx7jx4+PadOmxQsvvNDd5RetXCvyt96abh0AAAB0XSZJkiTfRUREZDKZuOOOO2LGjBmtY2eccUZs3Lix3Up9RyZOnBgTJkyIq6++OiIimpubo7q6Or72ta/FhRde2KlzNDY2RmVlZTQ0NERFRUVXfkZRqKuL2HffiHf+m+/dO2Lt2oiqqryUBQAAULa6kkML/hn5+++/P4YOHRoHHnhgfOUrX4mXX34557FvvPFGLFu2LKZOndo61qtXr5g6dWosXrw45+e2bdsWjY2NbV6lrKoq4vzz2483NUWsWZN+PQAAAHReQQf5j370o/HTn/40Fi5cGP/6r/8aixYtiunTp0dTU1PW41966aVoamqKYcOGtRkfNmxY1NfX5/yempqaqKysbH1VV1d36+8oRCefnH3cc/IAAACFrU++C+jIZz7zmdZ/PuSQQ+LQQw+Nd7/73XH//ffHlClTuu175syZE7Nnz25939jYWPJhXud6AACA4lTQK/LvtP/++8fgwYNjTY77vwcPHhy9e/eODRs2tBnfsGFDDB8+POd5+/XrFxUVFW1epU7negAAgOJUVEG+rq4uXn755RgxYkTW+b59+8bhhx8eCxcubB1rbm6OhQsXxqRJk9IqsyhYkQcAAChOeQ3ymzdvjhUrVsSKFSsiIqK2tjZWrFgR69ati82bN8fXv/71eOSRR2Lt2rWxcOHCOPHEE2PMmDExbdq01nNMmTKltUN9RMTs2bPjuuuuixtvvDGeeeaZ+MpXvhJbtmyJM888M+2fV9CsyAMAABSnvD4jv3Tp0vjwhz/c+v6t59RPP/30mDt3bvzhD3+IG2+8MTZu3BgjR46M4447Lr773e9Gv379Wj/z7LPPxksvvdT6/pRTTokXX3wxLrrooqivr4/DDjss5s+f364BXrmzIg8AAFCcCmYf+UJS6vvIR0QsWRJx5JHtxx97LGLChPTrAQAAKGcltY88PcOKPAAAQHES5MuUZ+QBAACKkyBfpnKtyN96a7p1AAAA0DWCfJkaOzYik2k/fsUVEXV16dcDAABA5wjyZaqqKuL889uPNzVFrFmTfj0AAAB0jiBfxk4+Ofu45+QBAAAKlyBfxnSuBwAAKD6CfBnTuR4AAKD4CPJlzIo8AABA8RHky5gVeQAAgOIjyJex2trs42vXploGAAAAXSDIAwAAQBER5MvY6NHZx0eNSrUMAAAAukCQL2O5mt3demu6dQAAANB5gnwZGzs2IpNpP37FFRF1denXAwAAwI4J8mWsqiri/PPbjzc1RaxZk349AAAA7JggX+ZOPjn7uC3oAAAACpMgX+ZyPSe/ZUu6dQAAANA5gnyZGzAg+7gVeQAAgMIkyJc5K/IAAADFRZAvc1bkAQAAiosgX+asyAMAABQXQb7MWZEHAAAoLoJ8mbMiDwAAUFwE+TKXa0X+nnvSrQMAAIDOEeTLXK4V+ZqaiLq6dGsBAABgxwT5Mjd2bEQm0368uTlizZr06wEAAKBjgnyZq6qKmDMn+5yGdwAAAIVHkCemTs0+ruEdAABA4RHksQUdAABAERHksQUdAABAERHksSIPAABQRAR5rMgDAAAUEUEeK/IAAABFRJDHijwAAEAREeTJuSJ/zz3p1gEAAMCOCfLkXJGvqYmoq0u3FgAAADomyBNjx0ZkMu3Hm5sj1qxJvx4AAAByE+SJqqqIOXOyz2l4BwAAUFgEeSIiYurU7OMa3gEAABQWQZ6IsAUdAABAsRDkiQhb0AEAABQLQZ6IsCIPAABQLAR5IsKKPAAAQLEQ5IkIK/IAAADFQpAnIiJqa7OPr12bahkAAADsgCBPh+69N98VAAAA8HaCPBERMXly9vHrrouoq0u3FgAAAHIT5ImIiKqqiAsuaD/e1BSxZk369QAAAJCdIE+rk0/OPq7hHQAAQOEQ5Gml4R0AAEDhE+QBAACgiAjytBo9Ovv4qFGplgEAAEAHBHlabd6cfXzLlnTrAAAAIDdBnlYDBmQf1+wOAACgcAjytLIiDwAAUPgEeVrlWpG/55506wAAACA3QZ5WuVbka2oi6urSrQUAAIDsBHlajR0bkcm0H29ujlizJv16AAAAaE+Qp1VVVcScOdnnNLwDAAAoDII8bUydmn1cwzsAAIDCIMjThi3oAAAACpsgTxu1tdnH165NtQwAAAByEOQBAACgiOQ1yD/wwANxwgknxMiRIyOTycSdd97ZOrd9+/b4x3/8xzjkkENizz33jJEjR8Zpp50Wf/3rXzs85yWXXBKZTKbNa9y4cT38S0rH6NHZx0eNSrUMAAAAcshrkN+yZUuMHz8+rrnmmnZzr732Wixfvjz++Z//OZYvXx633357rFq1Kj7xiU/s8LwHH3xwrF+/vvX14IMP9kT5JSnXXvKa3QEAABSGPvn88unTp8f06dOzzlVWVsaCBQvajF199dVx5JFHxrp162LffffNed4+ffrE8OHDu7XWcpGr2d0990Qce2yqpQAAAJBFUT0j39DQEJlMJgYNGtThcatXr46RI0fG/vvvH6eeemqsW7cunQJLQK4V+ZqaiLq6dGsBAACgvaIJ8lu3bo1//Md/jJkzZ0ZFRUXO4yZOnBjz5s2L+fPnx9y5c6O2tjY++MEPxqZNm3J+Ztu2bdHY2NjmVa7Gjo3IZNqPNzdHrFmTfj0AAAC0VRRBfvv27XHyySdHkiQxd+7cDo+dPn16nHTSSXHooYfGtGnT4re//W1s3Lgxbr311pyfqampicrKytZXdXV1d/+EolFVFTFnTvY5e8kDAADkX8EH+bdC/HPPPRcLFizocDU+m0GDBsUBBxwQazpYTp4zZ040NDS0vp5//vldLbuoTZ2afVzDOwAAgPwr6CD/VohfvXp13HPPPbHPPvt0+RybN2+OZ599NkaMGJHzmH79+kVFRUWbVznL1fDOijwAAED+5TXIb968OVasWBErVqyIiIja2tpYsWJFrFu3LrZv3x5///d/H0uXLo1f/OIX0dTUFPX19VFfXx9vvPFG6zmmTJkSV199dev7Cy64IBYtWhRr166Nhx9+OD75yU9G7969Y+bMmWn/vKJVW5t9fO3aVMsAAAAgi7xuP7d06dL48Ic/3Pp+9uzZERFx+umnxyWXXBK//vWvIyLisMMOa/O5++67L479373Qnn322XjppZda5+rq6mLmzJnx8ssvx5AhQ+Loo4+ORx55JIYMGdKzPwYAAABSkNcgf+yxx0aSJDnnO5p7y9p3LBPfcsstu1pW2Rs9Ovv4qFGplgEAAEAWBf2MPPmRay95ze4AAADyT5CnnVzN7u65J906AAAAaE+Qp51cK/I1NRF1denWAgAAQFuCPO2MHRuRybQfb26OWLMm/XoAAAD4G0GedqqqIubMyT5nL3kAAID8EuTJavz47OP2kgcAAMgvQR4AAACKiCBPVvaSBwAAKEyCPFnZSx4AAKAwCfJklWsvec3uAAAA8kuQJ6va2uzjmt0BAADklyBPl9x7b74rAAAAKG+CPFlNnpx9/NprI+rq0q0FAACAvxHkyaqqKuIf/qH9eJJELF6cfj0AAAC0EOTJ6SMfyXcFAAAAvJMgT072kgcAACg8gjw56VwPAABQeAR5AAAAKCKCPDnlurX+iSfSrQMAAIC/EeTJafPm7OM1NbagAwAAyBdBnpzGjo3IZNqPNzdHrFmTfj0AAAAI8nSgqipizpzsc3vumW4tAAAAtBDk6dD48dnHda4HAADID0EeAAAAioggT4dyda4fNSrVMgAAAPhfgjwdytW5fsuWdOsAAACghSBPhwYMyD6u2R0AAEB+CPJ0qLY2+7hmdwAAAPkhyLNT7r033xUAAACUJ0GeDk2enH382msj6urSrQUAAABBnh2oqor4h39oP54kEYsXp18PAABAuRPk2aHx47OPv/xyunUAAAAgyNMJ++zTtXEAAAB6jiDPDo0enX181KhUywAAACAEeTrBFnQAAACFQ5AHAACAIiLIs0O5bq1/4ol06wAAAECQpxM2b84+XlNjL3kAAIC0CfLs0NixEZlM+/Hm5og1a9KvBwAAoJwJ8uxQVVXEnDnZ5/bcM91aAAAAyp0gT6eMH599XOd6AACAdAnyAAAAUEQEeTolV+f6UaNSLQMAAKDsCfJ0Sm1t9nG31gMAAKRLkKdTXn65a+MAAAD0DEGeTtlnn+zjTzyRbh0AAADlTpCnUyZPzj5+7bURdXXp1gIAAFDOBHk6paoq4h/+of14kkQsXpx+PQAAAOVKkKfTPvKRfFcAAACAIE+n2YIOAAAg/wR5Os0WdAAAAPnXpSB/2WWXxeuvv976/qGHHopt27a1vt+0aVN89atf7b7qKCi2oAMAAMi/LgX5OXPmxKZNm1rfT58+Pf7yl7+0vn/ttdfi2muv7b7qKCi5tqDLNQ4AAED361KQT5Kkw/eUtlzPyNtLHgAAID2ekafTNm/OPl5TYy95AACAtAjydNrYsRGZTPvx5uaINWvSrwcAAKAc9enqB/7zP/8zBgwYEBERb775ZsybNy8GDx4cEdHm+XlKT1VVxJw5Ed//fvu5PfdMvx4AAIBy1KUgv++++8Z1113X+n748OHxs5/9rN0xlK7x47OPr10bMWFCqqUAAACUpS4F+bU2DC97tqADAADIL8/I0yW2oAMAAMivLgX5xYsXx913391m7Kc//WmMHj06hg4dGl/+8pdj27Zt3VoghSXXFnSjRqVaBgAAQNnqUpD/zne+E0899VTr+yeffDK+8IUvxNSpU+PCCy+Mu+66K2pqarq9SApHbW328euvT7cOAACActWlIL9ixYqYMmVK6/tbbrklJk6cGNddd13Mnj07rrzyyrj11lu7vUgK309+Yi95AACANHQpyL/66qsxbNiw1veLFi2K6dOnt76fMGFCPP/8891XHQVn8uTs4/aSBwAASEeXgvywYcOi9n/vrX7jjTdi+fLl8YEPfKB1ftOmTbHbbrt1b4UUlKqqiG9+M/ucveQBAAB6XpeC/Mc+9rG48MIL4/e//33MmTMn9thjj/jgBz/YOv+HP/wh3v3ud3f6fA888ECccMIJMXLkyMhkMnHnnXe2mU+SJC666KIYMWJE7L777jF16tRYvXr1Ds97zTXXxKhRo6J///4xceLEeOyxxzpdEzvW0V7yAAAA9KwuBfnvfve70adPnzjmmGPiuuuui5/85CfRt2/f1vnrr78+jjvuuE6fb8uWLTF+/Pi45pprss5fdtllceWVV8aPf/zjePTRR2PPPfeMadOmxdatW3Oe85e//GXMnj07Lr744li+fHmMHz8+pk2bFi+88ELnfygdspc8AABA/mSSJEm6+qGGhoYYMGBA9O7du834K6+8EgMHDtyp2+szmUzccccdMWPGjIhoWY0fOXJknH/++XHBBRe0fu+wYcNi3rx58ZnPfCbreSZOnBgTJkyIq6++OiIimpubo7q6Or72ta/FhRde2KlaGhsbo7KyMhoaGqKioqLLv6XU3XprxCmnZB8/6aT06wEAACh2Xcmhfbpy4rPOOqtTx13fDXuR1dbWRn19fUydOrV1rLKyMiZOnBiLFy/OGuTfeOONWLZsWcyZM6d1rFevXjF16tRYvHhxzu/atm1bbNu2rfV9Y2PjLtdfyuwlDwAAkD9dCvLz5s2L/fbbL973vvfFTizkd0l9fX1ERJsu+W+9f2vunV566aVoamrK+pk//vGPOb+rpqYmvv3tb+9ixeWjo73kJ0xItxYAAIBy06Ug/5WvfCVuvvnmqK2tjTPPPDM+97nPxd57791TtaVmzpw5MXv27Nb3jY2NUV1dnceKitNPfhLxrW+1dLYHAACgZ3Sp2d0111wT69evj2984xtx1113RXV1dZx88snxu9/9rttX6IcPHx4RERs2bGgzvmHDhta5dxo8eHD07t27S5+JiOjXr19UVFS0eZGbveQBAADyp0tBPqIl9M6cOTMWLFgQTz/9dBx88MHx1a9+NUaNGhWbN2/utsJGjx4dw4cPj4ULF7aONTY2xqOPPhqTJk3K+pm+ffvG4Ycf3uYzzc3NsXDhwpyfoevsJQ8AAJA/XQ7ybT7cq1dkMplIkiSampq6/PnNmzfHihUrYsWKFRHR0uBuxYoVsW7dushkMnHeeefF9773vfj1r38dTz75ZJx22mkxcuTI1s72ERFTpkxp7VAfETF79uy47rrr4sYbb4xnnnkmvvKVr8SWLVvizDPP3JWfyjvYSx4AACA/uvSMfERLh/fbb789rr/++njwwQfj+OOPj6uvvjo++tGPRq9eXft7gaVLl8aHP/zh1vdvPad++umnx7x58+Ib3/hGbNmyJb785S/Hxo0b4+ijj4758+dH//79Wz/z7LPPxksvvdT6/pRTTokXX3wxLrrooqivr4/DDjss5s+f364BHrvGXvIAAAD50aV95L/61a/GLbfcEtXV1XHWWWfFqaeeGoMHD+7J+vLCPvI7NnduxFe/mn387LPTrwcAAKCY9dg+8j/+8Y9j3333jf333z8WLVoUixYtynrc7bff3pXTUoT22adr4wAAAHSPLgX50047LTKZTE/VQhEZPTr7+BNPRJx0Urq1AAAAlJMu3VpfLtxav2P33RfxkY+0H89kItats5c8AABAV3Qlh+5S13rK19ix2ceTJGLx4nRrAQAAKCeCPDulqiris5/NPqdzPQAAQM8R5NlpJ56YfVzDOwAAgJ4jyLPTcjW8GzUq1TIAAADKiiDPTqutzT6+dm2qZQAAAJQVQZ6dlutZ+F//Ot06AAAAyokgz07L9Sz8TTdF1NWlWwsAAEC5EOTZaZMnZx9vbo5YsybdWgAAAMqFIM9Oq6qK+OY3s8/tuWe6tQAAAJQLQZ5dMn589nEN7wAAAHqGIM8uydXwLtc4AAAAu0aQBwAAgCIiyAMAAEAREeTZJbm2oHviiXTrAAAAKBeCPLsk1xZ0115rL3kAAICeIMizS6qqIv7hH9qPJ0nE4sXp1wMAAFDqBHl2Wa4t6HSuBwAA6H6CPAAAABQRQR4AAACKiCDPLsvVuT7XOAAAADtPkGeXjR6dfdwWdAAAAN1PkGeXbd6cffz737cFHQAAQHcT5NllY8dmH7cFHQAAQPcT5NllVVURn/1s9jlb0AEAAHQvQZ5ucfTR+a4AAACgPAjy9KiHHsp3BQAAAKVFkKdb5Npq7qabNLwDAADoToI83WLy5Ozjzc0Ra9akWwsAAEApE+TpFlVVEd/8Zva5PfdMtxYAAIBSJsjTbcaPzz6+dm2qZQAAAJQ0QZ5uk2urOVvQAQAAdB9BHgAAAIqIIE+PswUdAABA9xHk6Ta5tqD7xS9sQQcAANBdBHm6Ta4t6JIkYvHidGsBAAAoVYI83aaqKuKzn80+p+EdAABA9xDk6VYnnph9PNdt9wAAAHSNIE+3Gj06+/ioUamWAQAAULIEebpVbW328bVrUy0DAACgZAnydKtcz8L/+tfp1gEAAFCqBHm6lS3oAAAAepYgT7eyBR0AAEDPEuTpVragAwAA6FmCPN3u6KPzXQEAAEDpEuQBAACgiAjypOahh/JdAQAAQPET5Ol2OtcDAAD0HEGebqdzPQAAQM8R5Ol2OtcDAAD0HEGeHqFzPQAAQM8Q5AEAAKCICPKkSud6AACAXSPI0yN0rgcAAOgZgjw9Qud6AACAniHI0yN0rgcAAOgZgjw9Rud6AACA7ifIAwAAQBER5EmdzvUAAAA7T5Cnx+hcDwAA0P0EeXqMzvUAAADdT5Cnx+hcDwAA0P0KPsiPGjUqMplMu9esWbOyHj9v3rx2x/bv3z/lqnmLzvUAAADdq0++C9iRJUuWRFNTU+v7lStXxt/93d/FSSedlPMzFRUVsWrVqtb3mUymR2sEAACAtBR8kB8yZEib95deemm8+93vjmOOOSbnZzKZTAwfPrynS2MXPPRQxNln57sKAACA4lPwt9a/3RtvvBE///nP46yzzupwlX3z5s2x3377RXV1dZx44onx1FNPdXjebdu2RWNjY5sX3UPnegAAgO5VVEH+zjvvjI0bN8YZZ5yR85gDDzwwrr/++vjVr34VP//5z6O5uTkmT54cdR2kxpqamqisrGx9VVdX90D15UnnegAAgO6VSZIkyXcRnTVt2rTo27dv3HXXXZ3+zPbt2+M973lPzJw5M7773e9mPWbbtm2xbdu21veNjY1RXV0dDQ0NUVFRsct1l7tTT4246ab243Pnur0eAAAgoiWHVlZWdiqHFvwz8m957rnn4p577onbb7+9S5/bbbfd4n3ve1+sWbMm5zH9+vWLfv367WqJ5HD00dmDPAAAAF1XNLfW33DDDTF06ND4+Mc/3qXPNTU1xZNPPhkjRozoocoAAAAgPUUR5Jubm+OGG26I008/Pfr0aXsTwWmnnRZz5sxpff+d73wn/ud//if+/Oc/x/Lly+Nzn/tcPPfcc/HFL34x7bLZgYceyncFAAAAxacogvw999wT69ati7POOqvd3Lp162L9+vWt71999dX40pe+FO95z3viYx/7WDQ2NsbDDz8cBx10UJol8zY61wMAAHSfomp2l5auNBlgx+rqInJtBHDrrREnnZRuPQAAAIWmKzm0KFbkKW5VVRGf/Wz2uZdfTrcWAACAYifIk4qjj853BQAAAKVBkCevNLwDAADoGkGevNLwDgAAoGsEeVKRq3N9kkQsXpxuLQAAAMVMkCcVkyfnntPwDgAAoPMEeVLRUed6AAAAOk+QJzU61wMAAOw6QZ6807keAACg8wR5UpOr4Z3O9QAAAJ0nyJOaXA3vdK4HAADoPEGe1HTU8E7negAAgM4R5EnVwQdnH3/11XTrAAAAKFaCPKl64YXs4/fdl24dAAAAxUqQJ1UHHph9/J57NLwDAADoDEGeVJ1wQvZxDe8AAAA6R5AnVRreAQAA7BpBntQdfXS+KwAAAChegjypy9WhfsGCdOsAAAAoRoI8qdu6Nfv47bdreAcAALAjgjypy9XwLkLDOwAAgB0R5EndhAkREydmn9PwDgAAoGOCPHlx+unZxx96KN06AAAAio0gT0H5xS88Jw8AANARQZ682Gef7ONJ4jl5AACAjgjy5MXkybnnPCcPAACQmyBPXlRVRXz2s/muAgAAoPgI8uTNwQdnH1+wIN06AAAAiokgT95s3Zp9/PbbNbwDAADIRZAnb044IfechncAAADZCfLkzYQJERMnZp/T8A4AACA7QZ68+sQnso+/+mq6dQAAABQLQZ68euGF7OP33ZduHQAAAMVCkCevDjww+/g992h4BwAAkI0gT17laniXJBreAQAAZCPIk1dVVREzZmSfW7Mm1VIAAACKgiBP3u23X/bxF19Mtw4AAIBiIMiTd0OHZh9ftCjdOgAAAIqBIE/ejRmTfXz58oglS9KtBQAAoNAJ8uTd5Mm5537zm/TqAAAAKAaCPHnXUcO7fv1SLQUAAKDgCfIUhAkTso8vXZpuHQAAAIVOkKcgbN2affz22yPq6tKtBQAAoJAJ8hSEE07IPbd4cXp1AAAAFDpBnoIwYULEYYdln1uzJtVSAAAACpogT8E45pjs4/fdl24dAAAAhUyQp2AMHZp9fMECz8kDAAC8RZCnYIwZk3vOc/IAAAAtBHkKxuTJuedefjm9OgAAAAqZIE/BqKqKmDEj+9yrr6ZaCgAAQMES5Cko++2XffznP0+3DgAAgEIlyFNQDjww+/jTT0csWZJuLQAAAIVIkKegnHBC7rnf/Ca9OgAAAAqVIE9BqaqKmDYt+9zWrenWAgAAUIgEeQrOuHHZx5cvT7cOAACAQiTIU3ByPSe/YEFEXV26tQAAABQaQZ6C09Fz8nffnV4dAAAAhUiQp+BUVUVMmZJ97k9/SrcWAACAQiPIU5AOPzz7+DPPpFsHAABAoRHkKUj9+mUfnz/fc/IAAEB5E+QpSJ6TBwAAyE6QpyBNmBDx7ndnn1u2LN1aAAAACokgT8E65pjs44sWpVsHAABAIRHkKVhHHJF9fPXqiCVL0q0FAACgUBR0kL/kkksik8m0eY0bN67Dz9x2220xbty46N+/fxxyyCHx29/+NqVq6W4dPSf/m9+kVwcAAEAhKeggHxFx8MEHx/r161tfDz74YM5jH3744Zg5c2Z84QtfiMcffzxmzJgRM2bMiJUrV6ZYMd2lqipi2rTsc1u3plsLAABAoSj4IN+nT58YPnx462vw4ME5j/3hD38YH/3oR+PrX/96vOc974nvfve78f73vz+uvvrqFCumO+W6AeOuu9KtAwAAoFAUfJBfvXp1jBw5Mvbff/849dRTY926dTmPXbx4cUydOrXN2LRp02Lx4sUdfse2bduisbGxzYvCcOCB2cefftpz8gAAQHkq6CA/ceLEmDdvXsyfPz/mzp0btbW18cEPfjA2bdqU9fj6+voYNmxYm7Fhw4ZFfX19h99TU1MTlZWVra/q6upu+w3smo6ek7/55vTqAAAAKBQFHeSnT58eJ510Uhx66KExbdq0+O1vfxsbN26MW2+9tVu/Z86cOdHQ0ND6ev7557v1/Oy8qqqIo47KPrd0abq1AAAAFIKCDvLvNGjQoDjggANizZo1WeeHDx8eGzZsaDO2YcOGGD58eIfn7devX1RUVLR5UTg+9rHs47//fURdXbq1AAAA5FtRBfnNmzfHs88+GyNGjMg6P2nSpFi4cGGbsQULFsSkSZPSKI8eMmZM7rm7706vDgAAgEJQ0EH+ggsuiEWLFsXatWvj4Ycfjk9+8pPRu3fvmDlzZkREnHbaaTFnzpzW488999yYP39+/OAHP4g//vGPcckll8TSpUvjnHPOyddPoBtMnpx77vbb06sDAACgEBR0kK+rq4uZM2fGgQceGCeffHLss88+8cgjj8SQIUMiImLdunWxfv361uMnT54cN910U/zkJz+J8ePHx3/913/FnXfeGe9973vz9RPoBlVVETNmZJ9bsMDt9QAAQHnJJEmS5LuIQtPY2BiVlZXR0NDgefkCceutEaeckn1u7tyIs89Otx4AAIDu1JUcWtAr8vCWjm6v/9Of0qsDAAAg3wR5ikJVVcS0adnnFixItxYAAIB8EuQpGkcemX185cqIJUvSrQUAACBfBHmKxgkn5J77zW/SqwMAACCfBHmKxoQJEQcdlH3u0UfTrQUAACBfBHmKyt/9Xfbx+fNtQwcAAJQHQZ6icuCBuefuvju9OgAAAPJFkKeodPSc/LJl6dUBAACQL4I8RaWqKuKoo7LPLVqUbi0AAAD5IMhTdE49Nfv46tW2oQMAAEqfIE/R6ej2+ptvTq8OAACAfBDkKTpVVRFHHJF97s47Uy0FAAAgdYI8RSnXc/K1tW6vBwAASpsgT1HK9Zx8hNvrAQCA0ibIU5QmTIjYb7/sc26vBwAASpkgT9GaMSP7uNvrAQCAUibIU7TcXg8AAJQjQZ6iNWFCxLvfnX1u6dJ0awEAAEiLIE9RO+us7OO//31EXV26tQAAAKRBkKeojRmTe+7uu9OrAwAAIC2CPEVt8uTcc5dfnl4dAAAAaRHkKWpVVRFHHZV9bvVq3esBAIDSI8hT9HSvBwAAyokgT9E74YTcc3femVoZAAAAqRDkKXpVVRFTpmSfq611ez0AAFBaBHlKQk1N7jm31wMAAKVEkKckTJgQsd9+2efcXg8AAJQSQZ6SMWNG9nG31wMAAKVEkKdkdNS9/lvfSq8OAACAniTIUzI6ur1+wYKIurp06wEAAOgJgjwlJdft9RERd9+dWhkAAAA9RpCnpHR0e/3ll6dXBwAAQE8R5CkpEyZEjBuXfW71ak3vAACA4ifIU3J++tPcc+efn14dAAAAPUGQp+RMmBAxYkT2ud//XtM7AACguAnylKRzzsk9p+kdAABQzAR5StJpp+Weu+yy9OoAAADoboI8JamqKuJ978s+V1ur6R0AAFC8BHlK1ne+k3vuW99Krw4AAIDuJMhTso4/PmLvvbPPLVig6R0AAFCcBHlK2uc/n3tO0zsAAKAYCfKUtFNPzT2n6R0AAFCMBHlK2oQJEdXV2ec0vQMAAIqRIE/J+9GPcs91tGIPAABQiAR5St7xx0dUVmafW73aqjwAAFBcBHnKwje+kXvOVnQAAEAxEeQpC6edlnvOVnQAAEAxEeQpC1VVEVOm5J7/2c/SqwUAAGBXCPKUjZqa3HO2ogMAAIqFIE/ZmDAh4t3vzj63cWPE3XenWg4AAMBOEeQpKzffnHvu859Prw4AAICdJchTViZMiBg5MvucVXkAAKAYCPKUnWuvzT13zjnp1QEAALAzBHnKzvHHR+y9d/a5556LWLIk3XoAAAC6QpCnLH3ve7nnTj01vToAAAC6SpCnLJ1wQu651autygMAAIVLkKcsVVVFzJiRe96qPAAAUKgEecrWVVflnrMqDwAAFCpBnrK1o1X5D384tVIAAAA6TZCnrHW0Kr9lS8RZZ6VXCwAAQGcI8pS1qqqO946/4YaIurr06gEAANgRQZ6yd9VVEXvtlXv+3HPTqwUAAGBHBHmIiN/9Lvfc7bdblQcAAAqHIA8RMWFCxLvfnXt++vT0agEAAOhIQQf5mpqamDBhQgwcODCGDh0aM2bMiFWrVnX4mXnz5kUmk2nz6t+/f0oVU8xuvjn33MqVtqMDAAAKQ0EH+UWLFsWsWbPikUceiQULFsT27dvjuOOOiy1btnT4uYqKili/fn3r67nnnkupYorZhAkRBx2Ue37atPRqAQAAyKVPvgvoyPz589u8nzdvXgwdOjSWLVsWH/rQh3J+LpPJxPDhw3u6PErQ734XUV2dfe7VVyP+v/8v4sor060JAADg7Qp6Rf6dGhoaIiJi77337vC4zZs3x3777RfV1dVx4oknxlNPPZVGeZSAqqqIM87IPX/VVRrfAQAA+ZVJkiTJdxGd0dzcHJ/4xCdi48aN8eCDD+Y8bvHixbF69eo49NBDo6GhIf793/89HnjggXjqqaeiqqoq62e2bdsW27Zta33f2NgY1dXV0dDQEBUVFd3+Wyh8u+8esXVr9rn3vz9i2bJ06wEAAEpbY2NjVFZWdiqHFs2K/KxZs2LlypVxyy23dHjcpEmT4rTTTovDDjssjjnmmLj99ttjyJAhce211+b8TE1NTVRWVra+qnPdW03ZuO223HPLl2t8BwAA5E9RrMifc8458atf/SoeeOCBGD16dJc/f9JJJ0WfPn3i5hxtya3Ik83QoREvvph9bo89InbQcxEAAKDTSmZFPkmSOOecc+KOO+6Ie++9d6dCfFNTUzz55JMxYsSInMf069cvKioq2rzgN7/JPffaaxFnnZVeLQAAAG8p6CA/a9as+PnPfx433XRTDBw4MOrr66O+vj5ef/311mNOO+20mDNnTuv773znO/E///M/8ec//zmWL18en/vc5+K5556LL37xi/n4CRSxCRMiJk3KPX/DDRrfAQAA6Svo7efmzp0bERHHHntsm/Ebbrghzvjf1uLr1q2LXr3+9vcRr776anzpS1+K+vr62GuvveLwww+Phx9+OA7qaINwyOHhhztufHfEERH19enWBAAAlLeieEY+bV15NoHSt2RJxJFH5p7/2tfsLQ8AAOyaknlGHgrBhAkRHd3QYW95AAAgTYI8dMLvftfx/Nix6dQBAAAgyEMnVFVFnHNO7vmtWyOqq9OrBwAAKF+CPHTSVVdFvOtduefr6iKmTEmvHgAAoDwJ8tAFdXURu+2We/7ee1ua4wEAAPQUQR666M9/7nh+8uR06gAAAMqTIA9dtKPn5d98M2LEiPTqAQAAyosgDzvhqqsi9tsv93x9fcRRR6VXDwAAUD4EedhJa9dG9O+fe/7hhyP+6Z9SKwcAACgTgjzsgtWrO57/l39paZAHAADQXQR52AU7el4+ImLUqFRKAQAAyoQgD7toR8/LNzVF9OuXXj0AAEBpE+ShG6xdGzFgQO75N96I2HPP1MoBAABKmCAP3WTTpog+fXLPv/ZaRGVlevUAAAClSZCHblRb2/F8Y2PE0KHp1AIAAJQmQR66UVVVxGWXdXzMiy9amQcAAHaeIA/d7Otfj/ja1zo+prExYuDAdOoBAABKiyAPPeDKKyM+8pGOj9m8WQM8AACg6wR56CELF0ZMntzxMa+9Zms6AACgawR56EEPPbTjMP/GGxG77ZZOPQAAQPET5KGHdSbMv/lmRCYTUVeXTk0AAEDxEuQhBZ0J8xER1dUR3/pWz9cDAAAUL0EeUvLQQztugBcR8f3vRxxxRM/XAwAAFCdBHlK0cOGOt6aLiFi2zF7zAABAdoI8pOzKKyP+7d92fFxjY0Tv3hFLlvR8TQAAQPEQ5CEPLrgg4vnnd3xcc3PEkUdGHH54z9cEAAAUB0Ee8qSqKiJJOrf13PLlLcfpag8AAAjykGdvvBFRUbHj4958s6Wr/Zln9nxNAABA4RLkoQA0NHS+U/28eRF77ml1HgAAypUgDwViyZLO7yH/2mstq/Mnn9yzNQEAAIVHkIcC8r3vtTTBGzCgc8ffdltLZ/u77+7ZugAAgMIhyEOBqaqK2LSp88/CNzdHnHBCxMCBAj0AAJQDQR4K1PXXt6zOd6arfUTE5s0tgb6y0t7zAABQygR5KGBVVS1d7TvbCC8iorGxZe/54cMFegAAKEWCPBSBJUsiHnssok+fzn9mw4aWQL/33m65BwCAUiLIQ5GYMCFi+/aud6p/9dWWW+7792/Zug4AAChugjwUmV/+suXZ+cGDu/a5bdtaGuj16hVx0UU9UxsAANDzBHkoQlVVES++GHHXXZ3fqu4tSRLx3e9GZDIRBx5olR4AAIqNIA9F7PjjW7aqu+uuiL59u/75P/2pZZU+k2lpqOdZegAAKHyCPJSA449vuXX+hhu61hDv7ZYta3mWvleviOOO0/EeAAAKlSAPJeSMM1oa4t1wQ0tzu52RJBELFrR0vO/d20o9AAAUGkEeStAZZ0S8/nrLLfd7773z52lu/ttKfSbTcq7TTouoq+u2UgEAgC4S5KGEHX98xMsvt+xBf9xxu36+V1+N+NnPIqqrI3bbLWLIEB3wAQAgbYI8lIEJEyJ+97uW2+Z/8IOI3Xff9XO++WbESy/9rQP+7rtHDBrk+XoAAOhpgjyUmdmzI1577W+r9L17d895t26NaGj42/P1b4X7igrP2QMAQHcS5KFMvbVK/+abLc/Sv//9LeG7O23d2rI93tufs99995aX5+0BAGDnCPJAHH98S9hubm7peH/AAd0f6t+ydWvL6+3P2/ft+7eAv/vunr0HAICOCPJAG2ecEbFqVUuov+uuiEmTdq3zfWds3/63gL91a/tn79967bFHxMCBLfV4Fh8AgHKVSZIkyXcRhaaxsTEqKyujoaEhKioq8l0OFIzLL295vfJKy/Z2haJ///ZjmUzL8//9+0dMnx7x/e9HVFWlXxsAAHRGV3KoIJ+FIA+dc9FFEXPnRmzeHLFtW0tX/ELWp0/LK5u3gn9T099+R79+LY37/uVfWnoKAABATxHkd5EgDzvn7rsjLr44YvXqltvliyHcd8VbK//ZQn9HdnT8bru19CW45JKWfgUAAJQfQX4XCfLQfd4Z7iNanoMnt9137/xfFHT3XyrsyvHFem61pH9utaR/brWkf261pH9utaR/7mKppVjushTkd5EgDz3v8ssjrryypXv99u1/+4+tkA8AQE85/fSIefPyXUV2XcmhutYDeTF7dsTatRENDRGvvdbSPO/111sC/T//c8TgwS23sr/9tfvuPbctHgAApe/GG0tj5yNBHig43/lOxIsv/i3cv/V67bW2e93vuWf7sP/20A8AAO/00EP5rmDX5ejfDFC4zjij5dUZb98yr6MHid75TJVb/AEAStNRR+W7gl3nGfksPCMPRLQ8P1VTE/GXv7QE/Ld0Z6OWUuvsDwBQyErlGXlBPgtBHkjTOzv7F0P311I6t1rSP7da0j+3WtI/t1rSP7da0j93sdRSil3r3VoPkGfHH2//eAAAOk+zOwAAACgigjwAAAAUEUEeAAAAioggDwAAAEVEkAcAAIAiUhRB/pprrolRo0ZF//79Y+LEifHYY491ePxtt90W48aNi/79+8chhxwSv/3tb1OqFAAAAHpWwQf5X/7ylzF79uy4+OKLY/ny5TF+/PiYNm1avPDCC1mPf/jhh2PmzJnxhS98IR5//PGYMWNGzJgxI1auXJly5QAAAND9MkmSJPkuoiMTJ06MCRMmxNVXXx0REc3NzVFdXR1f+9rX4sILL2x3/CmnnBJbtmyJu+++u3XsAx/4QBx22GHx4x//uFPf2djYGJWVldHQ0BAVFRXd80MAAAAgh67k0IJekX/jjTdi2bJlMXXq1NaxXr16xdSpU2Px4sVZP7N48eI2x0dETJs2LefxAAAAUEz65LuAjrz00kvR1NQUw4YNazM+bNiw+OMf/5j1M/X19VmPr6+vz/k927Zti23btrW+b2hoiIiWvxEBAACAnvZW/uzMTfMFHeTTUlNTE9/+9rfbjVdXV+ehGgAAAMrVpk2borKyssNjCjrIDx48OHr37h0bNmxoM75hw4YYPnx41s8MHz68S8dHRMyZMydmz57d+r65uTleeeWV2GeffSKTyezCL+hZjY2NUV1dHc8//7xn+SlIrlEKnWuUYuA6pdC5Ril0xXKNJkkSmzZtipEjR+7w2IIO8n379o3DDz88Fi5cGDNmzIiIlpC9cOHCOOecc7J+ZtKkSbFw4cI477zzWscWLFgQkyZNyvk9/fr1i379+rUZGzRo0K6Wn5qKioqCviDBNUqhc41SDFynFDrXKIWuGK7RHa3Ev6Wgg3xExOzZs+P000+PI444Io488sj4j//4j9iyZUuceeaZERFx2mmnxbve9a6oqamJiIhzzz03jjnmmPjBD34QH//4x+OWW26JpUuXxk9+8pN8/gwAAADoFgUf5E855ZR48cUX46KLLor6+vo47LDDYv78+a0N7datWxe9ev2t+f7kyZPjpptuin/6p3+Kb37zmzF27Ni48847473vfW++fgIAAAB0m4IP8hER55xzTs5b6e+///52YyeddFKcdNJJPVxV/vXr1y8uvvjido8FQKFwjVLoXKMUA9cphc41SqErxWs0k3Smtz0AAABQEHrt+BAAAACgUAjyAAAAUEQEeQAAACgigjwAAAAUEUG+iF1zzTUxatSo6N+/f0ycODEee+yxfJdECXrggQfihBNOiJEjR0Ymk4k777yzzXySJHHRRRfFiBEjYvfdd4+pU6fG6tWr2xzzyiuvxKmnnhoVFRUxaNCg+MIXvhCbN29uc8wf/vCH+OAHPxj9+/eP6urquOyyy3r6p1EiampqYsKECTFw4MAYOnRozJgxI1atWtXmmK1bt8asWbNin332iQEDBsSnP/3p2LBhQ5tj1q1bFx//+Mdjjz32iKFDh8bXv/71ePPNN9scc//998f73//+6NevX4wZMybmzZvX0z+PEjB37tw49NBDo6KiIioqKmLSpEnx3//9363zrk8KzaWXXhqZTCbOO++81jHXKfl0ySWXRCaTafMaN25c63xZXp8JRemWW25J+vbtm1x//fXJU089lXzpS19KBg0alGzYsCHfpVFifvvb3ybf+ta3kttvvz2JiOSOO+5oM3/ppZcmlZWVyZ133pk88cQTySc+8Ylk9OjRyeuvv956zEc/+tFk/PjxySOPPJL8/ve/T8aMGZPMnDmzdb6hoSEZNmxYcuqppyYrV65Mbr755mT33XdPrr322rR+JkVs2rRpyQ033JCsXLkyWbFiRfKxj30s2XfffZPNmze3HnP22Wcn1dXVycKFC5OlS5cmH/jAB5LJkye3zr/55pvJe9/73mTq1KnJ448/nvz2t79NBg8enMyZM6f1mD//+c/JHnvskcyePTt5+umnk6uuuirp3bt3Mn/+/FR/L8Xn17/+dfKb3/wm+dOf/pSsWrUq+eY3v5nstttuycqVK5MkcX1SWB577LFk1KhRyaGHHpqce+65reOuU/Lp4osvTg4++OBk/fr1ra8XX3yxdb4cr09BvkgdeeSRyaxZs1rfNzU1JSNHjkxqamryWBWl7p1Bvrm5ORk+fHjyb//2b61jGzduTPr165fcfPPNSZIkydNPP51ERLJkyZLWY/77v/87yWQyyV/+8pckSZLkRz/6UbLXXnsl27Ztaz3mH//xH5MDDzywh38RpeiFF15IIiJZtGhRkiQt1+Ruu+2W3Hbbba3HPPPMM0lEJIsXL06SpOUvrHr16pXU19e3HjN37tykoqKi9br8xje+kRx88MFtvuuUU05Jpk2b1tM/iRK01157Jf/5n//p+qSgbNq0KRk7dmyyYMGC5JhjjmkN8q5T8u3iiy9Oxo8fn3WuXK9Pt9YXoTfeeCOWLVsWU6dObR3r1atXTJ06NRYvXpzHyig3tbW1UV9f3+ZarKysjIkTJ7Zei4sXL45BgwbFEUcc0XrM1KlTo1evXvHoo4+2HvOhD30o+vbt23rMtGnTYtWqVfHqq6+m9GsoFQ0NDRERsffee0dExLJly2L79u1trtNx48bFvvvu2+Y6PeSQQ2LYsGGtx0ybNi0aGxvjqaeeaj3m7ed46xj/3aUrmpqa4pZbboktW7bEpEmTXJ8UlFmzZsXHP/7xdteS65RCsHr16hg5cmTsv//+ceqpp8a6desionyvT0G+CL300kvR1NTU5kKMiBg2bFjU19fnqSrK0VvXW0fXYn19fQwdOrTNfJ8+fWLvvfduc0y2c7z9O6Azmpub47zzzoujjjoq3vve90ZEyzXUt2/fGDRoUJtj33md7ugazHVMY2NjvP766z3xcyghTz75ZAwYMCD69esXZ599dtxxxx1x0EEHuT4pGLfcckssX748ampq2s25Tsm3iRMnxrx582L+/Pkxd+7cqK2tjQ9+8IOxadOmsr0+++S7AADoLrNmzYqVK1fGgw8+mO9SoI0DDzwwVqxYEQ0NDfFf//Vfcfrpp8eiRYvyXRZERMTzzz8f5557bixYsCD69++f73KgnenTp7f+86GHHhoTJ06M/fbbL2699dbYfffd81hZ/liRL0KDBw+O3r17t+vEuGHDhhg+fHieqqIcvXW9dXQtDh8+PF544YU282+++Wa88sorbY7Jdo63fwfsyDnnnBN333133HfffVFVVdU6Pnz48HjjjTdi48aNbY5/53W6o2sw1zEVFRVl+z8RdF7fvn1jzJgxcfjhh0dNTU2MHz8+fvjDH7o+KQjLli2LF154Id7//vdHnz59ok+fPrFo0aK48soro0+fPjFs2DDXKQVl0KBBccABB8SaNWvK9r+jgnwR6tu3bxx++OGxcOHC1rHm5uZYuHBhTJo0KY+VUW5Gjx4dw4cPb3MtNjY2xqOPPtp6LU6aNCk2btwYy5Ytaz3m3nvvjebm5pg4cWLrMQ888EBs37699ZgFCxbEgQceGHvttVdKv4ZilSRJnHPOOXHHHXfEvffeG6NHj24zf/jhh8duu+3W5jpdtWpVrFu3rs11+uSTT7b5S6cFCxZERUVFHHTQQa3HvP0cbx3jv7vsjObm5ti2bZvrk4IwZcqUePLJJ2PFihWtryOOOCJOPfXU1n92nVJINm/eHM8++2yMGDGifP87mu9ue+ycW265JenXr18yb9685Omnn06+/OUvJ4MGDWrTiRG6w6ZNm5LHH388efzxx5OISC6//PLk8ccfT5577rkkSVq2nxs0aFDyq1/9KvnDH/6QnHjiiVm3n3vf+96XPProo8mDDz6YjB07ts32cxs3bkyGDRuWfP7zn09WrlyZ3HLLLckee+xh+zk65Stf+UpSWVmZ3H///W22pXnttddajzn77LOTfffdN7n33nuTpUuXJpMmTUomTZrUOv/WtjTHHXdcsmLFimT+/PnJkCFDsm5L8/Wvfz155plnkmuuuaagt6WhcFx44YXJokWLktra2uQPf/hDcuGFFyaZTCb5n//5nyRJXJ8Uprd3rU8S1yn5df755yf3339/Ultbmzz00EPJ1KlTk8GDBycvvPBCkiTleX0K8kXsqquuSvbdd9+kb9++yZFHHpk88sgj+S6JEnTfffclEdHudfrppydJ0rIF3T//8z8nw4YNS/r165dMmTIlWbVqVZtzvPzyy8nMmTOTAQMGJBUVFcmZZ56ZbNq0qc0xTzzxRHL00Ucn/fr1S971rncll156aVo/kSKX7fqMiOSGG25oPeb1119PvvrVryZ77bVXssceeySf/OQnk/Xr17c5z9q1a5Pp06cnu+++ezJ48ODk/PPPT7Zv397mmPvuuy857LDDkr59+yb7779/m++AXM4666xkv/32S/r27ZsMGTIkmTJlSmuITxLXJ4XpnUHedUo+nXLKKcmIESOSvn37Ju9617uSU045JVmzZk3rfDlen5kkSZL83AsAAAAAdJVn5AEAAKCICPIAAABQRAR5AAAAKCKCPAAAABQRQR4AAACKiCAPAAAARUSQBwAAgCIiyAMAPW7UqFHxH//xH/kuAwBKgiAPACXmjDPOiBkzZkRExLHHHhvnnXdeat89b968GDRoULvxJUuWxJe//OXU6gCAUtYn3wUAAIXvjTfeiL59++7054cMGdKN1QBAebMiDwAl6owzzohFixbFD3/4w8hkMpHJZGLt2rUREbFy5cqYPn16DBgwIIYNGxaf//zn46WXXmr97LHHHhvnnHNOnHfeeTF48OCYNm1aRERcfvnlccghh8See+4Z1dXV8dWvfjU2b94cERH3339/nHnmmdHQ0ND6fZdccklEtL+1ft26dXHiiSfGgAEDoqKiIk4++eTYsGFD6/wll1wShx12WPzsZz+LUaNGRWVlZXzmM5+JTZs2tR7zX//1X3HIIYfE7rvvHvvss09MnTo1tmzZ0kN/mgBQOAR5AChRP/zhD2PSpEnxpS99KdavXx/r16+P6urq2LhxY3zkIx+J973vfbF06dKYP39+bNiwIU4++eQ2n7/xxhujb9++8dBDD8WPf/zjiIjo1atXXHnllfHUU0/FjTfeGPfee2984xvfiIiIyZMnx3/8x39ERUVF6/ddcMEF7epqbm6OE088MV555ZVYtGhRLFiwIP785z/HKaec0ua4Z599Nu688864++674+67745FixbFpZdeGhER69evj5kzZ8ZZZ50VzzzzTNx///3xqU99KpIk6Yk/SgAoKG6tB4ASVVlZGX379o099tgjhg8f3jp+9dVXx/ve9774/ve/3zp2/fXXR3V1dfzpT3+KAw44ICIixo4dG5dddlmbc779eftRo0bF9773vTj77LPjRz/6UfTt2zcqKysjk8m0+b53WrhwYTz55JNRW1sb1dXVERHx05/+NA4++OBYsmRJTJgwISJaAv+8efNi4MCBERHx+c9/PhYuXBj/8i//EuvXr48333wzPvWpT8V+++0XERGHHHLILvxpAUDxsCIPAGXmiSeeiPvuuy8GDBjQ+ho3blxEtKyCv+Xwww9v99l77rknpkyZEu9617ti4MCB8fnPfz5efvnleO211zr9/c8880xUV1e3hviIiIMOOigGDRoUzzzzTOvYqFGjWkN8RMSIESPihRdeiIiI8ePHx5QpU+KQQw6Jk046Ka677rp49dVXO/+HAABFTJAHgDKzefPmOOGEE2LFihVtXqtXr44PfehDrcftueeebT63du3aOP744+PQQw+N//f//l8sW7YsrrnmmohoaYbX3Xbbbbc27zOZTDQ3N0dERO/evWPBggXx3//933HQQQfFVVddFQceeGDU1tZ2ex0AUGgEeQAoYX379o2mpqY2Y+9///vjqaeeilGjRsWYMWPavN4Z3t9u2bJl0dzcHD/4wQ/iAx/4QBxwwAHx17/+dYff907vec974vnnn4/nn3++dezpp5+OjRs3xkEHHdTp35bJZOKoo46Kb3/72/H4449H375944477uj05wGgWAnyAFDCRo0aFY8++misXbs2XnrppWhubo5Zs2bFK6+8EjNnzowlS5bEs88+G7/73e/izDPP7DCEjxkzJrZv3x5XXXVV/PnPf46f/exnrU3w3v59mzdvjoULF8ZLL72U9Zb7qVOnxiGHHBKnnnpqLF++PB577LE47bTT4phjjokjjjiiU7/r0Ucfje9///uxdOnSWLduXdx+++3x4osvxnve856u/QEBQBES5AGghF1wwQXRu3fvOOigg2LIkCGxbt26GDlyZDz00EPR1NQUxx13XBxyyCFx3nnnxaBBg6JXr9z/azB+/Pi4/PLL41//9V/jve99b/ziF7+ImpqaNsdMnjw5zj777DjllFNiyJAh7ZrlRbSspP/qV7+KvfbaKz70oQ/F1KlTY//9949f/vKXnf5dFRUV8cADD8THPvaxOOCAA+Kf/umf4gc/+EFMnz698384AFCkMol9WgAAAKBoWJEHAACAIiLIAwAAQBER5AEAAKCICPIAAABQRAR5AAAAKCKCPAAAABQRQR4AAACKiCAPAAAARUSQBwAAgCIiyAMAAEAREeQBAACgiAjyAAAAUET+f1NcTG0PsaJXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getcoefficients(X,y,np.array([20,50]),0.01,5000, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error got smaller at an earlier epoch\n",
    "\n",
    "Other ML systems will use the idea of changing the learning rate every so often (Neural Networks with solver=adam does this), so it gets an initial kick with a higher learning rate to start, then when it pleateaus - it shrinks the learning rate to try and learn some more, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if it works with more features - It should as I wrote the functions to use numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,5,8,2,6], [1,2,8,-10,23], [1,2,8,10,-23],\n",
    "             [1,12,-2,5,23],[1,24,8,21,23],[1,53,4,6,12],[1,3,2,-5,-10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([8,-3,4,10,1,6,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time I'm setting the initial weights to be random numbers, hopefully it doesn't mess up below when you run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.uniform(size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(fit_intercept=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression(fit_intercept=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.15677080e+01,  3.25267906e-03, -1.02505283e+00,  3.35661860e-02,\n",
       "       -1.36555447e-01])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any bigger alpha will fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.15676215e+01,  3.25390334e-03, -1.02504360e+00,  3.35656116e-02,\n",
       "       -1.36555003e-01])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getcoefficients(X,y,w,0.001,50000,False,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should see that the .fit function is not just magic. This is the basis of what it is doing and whenever you want an ML system to learn, it has to do lots of these \"steps\" to get the best model it can find.\n",
    "\n",
    "Different models will use different error/lost/cost functions (Logistic Regressions uses the one I mentioned in class for example). You can control the number of epochs and the learning rates as these are hyperparameters. There are \"fancier\" gradient descent methods (such as Mini-batch Stochastic Gradient Descent) which makes things faster but still having good performance.\n",
    "\n",
    "Neural Networks are much more complicated than linear regression, finding the gradient for them is even more so - but we'll come to that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cars Example\n",
    "Let's try the age vs value cars example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([5,4,6,5,5,5,6,6,2,7,7]).reshape(-1,1)\n",
    "y=np.array([85,103,70,82,89,98,66,95,169,70,48])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add the 1s for the intercept to our x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [4],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [2],\n",
       "       [7],\n",
       "       [7]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onecolumn = np.ones([x.shape[0],1])\n",
    "onecolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((onecolumn, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 5.],\n",
       "       [1., 4.],\n",
       "       [1., 6.],\n",
       "       [1., 5.],\n",
       "       [1., 5.],\n",
       "       [1., 5.],\n",
       "       [1., 6.],\n",
       "       [1., 6.],\n",
       "       [1., 2.],\n",
       "       [1., 7.],\n",
       "       [1., 7.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([195.46846847, -20.26126126])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getcoefficients(X,y,np.random.uniform(size=2),0.01,50000,False,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195.46846846846847 -20.261261261261264\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x,y)\n",
    "print(model.intercept_, model.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try mtcars.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mazda RX4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mazda RX4 Wag</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datsun 710</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hornet 4 Drive</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hornet Sportabout</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
       "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
       "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
       "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
       "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
       "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
       "\n",
       "   carb  \n",
       "0     4  \n",
       "1     4  \n",
       "2     1  \n",
       "3     1  \n",
       "4     2  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load mtcars\n",
    "dfcars=pd.read_csv(\"mtcars.csv\")\n",
    "dfcars=dfcars.rename(columns={\"Unnamed: 0\":\"name\"})\n",
    "dfcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfcars['mpg']\n",
    "allX = dfcars.iloc[:, 2:]\n",
    "from sklearn.model_selection import train_test_split\n",
    "allX_train, allX_test, y_train, y_test = train_test_split(allX, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = allX_train[[\"wt\",\"hp\",\"drat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = allX_train[[\"wt\",\"hp\",\"drat\"]].values\n",
    "X_test = allX_test[[\"wt\",\"hp\",\"drat\"]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.935,  66.   ,   4.08 ],\n",
       "       [  3.73 , 180.   ,   3.07 ],\n",
       "       [  2.62 , 110.   ,   3.9  ],\n",
       "       [  3.44 , 175.   ,   3.15 ],\n",
       "       [  5.345, 230.   ,   3.23 ],\n",
       "       [  3.46 , 105.   ,   2.76 ],\n",
       "       [  3.78 , 180.   ,   3.07 ],\n",
       "       [  4.07 , 180.   ,   3.07 ],\n",
       "       [  3.84 , 245.   ,   3.73 ],\n",
       "       [  2.875, 110.   ,   3.9  ],\n",
       "       [  2.32 ,  93.   ,   3.85 ],\n",
       "       [  2.14 ,  91.   ,   4.43 ],\n",
       "       [  3.215, 110.   ,   3.08 ],\n",
       "       [  3.52 , 150.   ,   2.76 ],\n",
       "       [  1.513, 113.   ,   3.77 ],\n",
       "       [  3.435, 150.   ,   3.15 ],\n",
       "       [  1.615,  52.   ,   4.93 ],\n",
       "       [  2.78 , 109.   ,   4.11 ],\n",
       "       [  2.465,  97.   ,   3.7  ],\n",
       "       [  3.19 ,  62.   ,   3.69 ],\n",
       "       [  3.44 , 123.   ,   3.92 ],\n",
       "       [  5.25 , 205.   ,   2.93 ],\n",
       "       [  3.17 , 264.   ,   4.22 ],\n",
       "       [  1.835,  65.   ,   4.22 ],\n",
       "       [  3.57 , 245.   ,   3.21 ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scale this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = StandardScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.26234592, -1.21810835,  0.86474409],\n",
       "       [ 0.6147756 ,  0.64834799, -0.94426902],\n",
       "       [-0.54600707, -0.49772169,  0.54234571],\n",
       "       [ 0.31150805,  0.56648587, -0.80098086],\n",
       "       [ 2.30366208,  1.4669692 , -0.65769269],\n",
       "       [ 0.33242306, -0.57958381, -1.49951067],\n",
       "       [ 0.6670631 ,  0.64834799, -0.94426902],\n",
       "       [ 0.97033065,  0.64834799, -0.94426902],\n",
       "       [ 0.72980811,  1.71255556,  0.23785836],\n",
       "       [-0.27934078, -0.49772169,  0.54234571],\n",
       "       [-0.85973211, -0.7760529 ,  0.45279061],\n",
       "       [-1.04796714, -0.80879775,  1.49162982],\n",
       "       [ 0.07621427, -0.49772169, -0.926358  ],\n",
       "       [ 0.39516806,  0.15717527, -1.49951067],\n",
       "       [-1.70365248, -0.44860442,  0.30950244],\n",
       "       [ 0.3062793 ,  0.15717527, -0.80098086],\n",
       "       [-1.59698596, -1.44732229,  2.38718087],\n",
       "       [-0.37868704, -0.51409412,  0.91847715],\n",
       "       [-0.70809834, -0.71056321,  0.1841253 ],\n",
       "       [ 0.05007052, -1.28359805,  0.16621427],\n",
       "       [ 0.31150805, -0.28488018,  0.57816776],\n",
       "       [ 2.20431582,  1.0576586 , -1.19502332],\n",
       "       [ 0.02915551,  2.02363162,  1.11549838],\n",
       "       [-1.36692093, -1.23448078,  1.11549838],\n",
       "       [ 0.44745557,  1.71255556, -0.69351473]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "#model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.168 [-2.82706981 -2.22336158  0.94591045]\n"
     ]
    }
   ],
   "source": [
    "print(model.intercept_,model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with our method. Initialise our weights randomely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32733862, 0.58244679, 0.20385028, 0.4965084 ])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.uniform(size=4)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = np.hstack((np.ones([allX_train[[\"wt\",\"hp\",\"drat\"]].values.shape[0],1]), allX_train[[\"wt\",\"hp\",\"drat\"]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs = np.hstack((np.ones([X_train.shape[0],1]), X_train))\n",
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215.85768685847364"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(Xs,ys,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-19.84066138,   5.48209505,   5.09298255,  -3.94606543])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullgrad(Xs, ys, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w - alpha*fullgrad(Xs,ys,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.168     , -4.89964827, -4.88913227,  4.44257382])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.720155238907992"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(Xs,ys,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.168     , -2.82706981, -2.22336158,  0.94591045])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getcoefficients(Xs,ys,w,0.1,10000,False, True, showall=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above should hopefully give you the idea of what's happening with the .fit method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
